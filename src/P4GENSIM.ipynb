{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 4 Recuperación ranqueada y vectorización de documentos (RRDV) GENSIM\n",
    "## Integrantes\n",
    "* Juan Esteban Arboleda\n",
    "* Luccas Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocesamiento\n",
    "Lo primero que se llevara a cabo para poder hacer la recuperación ranqueada es la tokenizacion de los documentos y generacion del vocabulario. Ademas es importante tener en cuenta que el vocabulario debe estar ordenado, no debe contener stop-words, debe estar stemizado y normalizado\n",
    "\n",
    "* A continucion se cargan los documentos y los queries en una estructura de datos, se debe cambiar DOCUMENTS_PATH y QUERIES_PATH por la ruta donde se encuentran los documentos y los queries respectivamente\n",
    "* El archivo de salida es guardado en RRDV_RESULTS_FILE_PATH con el formato exigido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wes2015.d001.naf</td>\n",
       "      <td>William Beaumont and the Human Digestion.  Wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wes2015.d002.naf</td>\n",
       "      <td>Selma Lagerlöf and the wonderful Adventures of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wes2015.d003.naf</td>\n",
       "      <td>Ferdinand de Lesseps and the Suez Canal.  Ferd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wes2015.d004.naf</td>\n",
       "      <td>Walt Disney’s ‘Steamboat Willie’ and the Rise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wes2015.d005.naf</td>\n",
       "      <td>Eugene Wigner and the Structure of the Atomic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>wes2015.d327.naf</td>\n",
       "      <td>James Parkinson and Parkinson’s Disease.  Wood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>wes2015.d328.naf</td>\n",
       "      <td>Juan de la Cierva and the Autogiro.  Demonstra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>wes2015.d329.naf</td>\n",
       "      <td>Squire Whipple – The Father of the Iron Bridge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>wes2015.d330.naf</td>\n",
       "      <td>William Playfair and the Beginnings of Infogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>wes2015.d331.naf</td>\n",
       "      <td>Juan Bautista de Anza and the Route to San Fra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename                                               body\n",
       "1    wes2015.d001.naf  William Beaumont and the Human Digestion.  Wil...\n",
       "2    wes2015.d002.naf  Selma Lagerlöf and the wonderful Adventures of...\n",
       "3    wes2015.d003.naf  Ferdinand de Lesseps and the Suez Canal.  Ferd...\n",
       "4    wes2015.d004.naf  Walt Disney’s ‘Steamboat Willie’ and the Rise ...\n",
       "5    wes2015.d005.naf  Eugene Wigner and the Structure of the Atomic ...\n",
       "..                ...                                                ...\n",
       "327  wes2015.d327.naf  James Parkinson and Parkinson’s Disease.  Wood...\n",
       "328  wes2015.d328.naf  Juan de la Cierva and the Autogiro.  Demonstra...\n",
       "329  wes2015.d329.naf  Squire Whipple – The Father of the Iron Bridge...\n",
       "330  wes2015.d330.naf  William Playfair and the Beginnings of Infogra...\n",
       "331  wes2015.d331.naf  Juan Bautista de Anza and the Route to San Fra...\n",
       "\n",
       "[331 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import math\n",
    "import time\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Rutas a definir segun la ubicacion de los archivos\n",
    "DOCUMENTS_PATH = '../data/docs-raw-texts'\n",
    "QUERIES_PATH = '../data/queries-raw-texts'\n",
    "GENSIM_RESULTS_FILE_PATH = \"../data/GENSIM-consultas_resultados\"\n",
    "RELEVANCE_JUDGMENTS_FILE_PATH = \"../data/relevance-judgments.tsv\"\n",
    "\n",
    "def load_documents(folder_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a Pandas DataFrame where each row represents a document in folder_path.\n",
    "    The DataFrame will have as many rows as there are documents in folder_path\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            folder_path: str\n",
    "                The path to the folder that contains the documents to load\n",
    "    \n",
    "        Returns\n",
    "        --------\n",
    "            documents: pd.DataFrame\n",
    "                Pandas DataFrame with two columns: \"filename\" and \"body\"\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    index = []\n",
    "    id = 1\n",
    "    columns = ['filename', 'body']\n",
    "    for filename in os.listdir(folder_path):\n",
    "        text = pd.read_xml(os.path.join(folder_path, filename))['raw'].tolist()[1]\n",
    "        filtered_text = text.replace('\\n', ' ').replace('\\xa0', ' ')\n",
    "        document = [filename, filtered_text]\n",
    "        documents.append(document)\n",
    "        index.append(id)\n",
    "        id += 1\n",
    "\n",
    "    return pd.DataFrame(documents, index, columns)\n",
    "\n",
    "documents = load_documents(DOCUMENTS_PATH)\n",
    "queries = load_documents(QUERIES_PATH)\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero que todo tokenizamos el texto, para esto utilizamos el word tokenize de la libreria NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\juanc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\juanc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "documents['tokens'] = documents['body'].apply(word_tokenize)\n",
    "queries['tokens'] = queries['body'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos todos los signos de puntuacion, contracciones del ingles y dejamos el texto todo en minusculas (normalizar) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(token_list):\n",
    "    return [token.lower() for token in token_list if (token not in string.punctuation and (len(token)>1 or token.isnumeric()))]\n",
    "\n",
    "documents['tokens']=documents['tokens'].apply(lambda x: remove_punctuation(x))\n",
    "queries['tokens']=queries['tokens'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de tokenizar, dejar todo en minusculas, quitaremos las stop words para que reduzcan el vocabulario y no afecten el resultado final. Para esto usaremos la libreria nltk y su metodo stopwords.words('english')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#TODO no se si normalizar cuente como poner todo en minusculas\n",
    "def remove_stop_words(token_list):\n",
    "    return [token for token in token_list if token not in stop_words]\n",
    "\n",
    "documents['tokens']=documents['tokens'].apply(lambda x: remove_stop_words(x))\n",
    "queries['tokens']=queries['tokens'].apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de eliminar las stop words se hace stemming a las palabras restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stemming(token_list):\n",
    "    return [stemmer.stem(token) for token in token_list]\n",
    "\n",
    "documents['tokens']=documents['tokens'].apply(lambda x: stemming(x))\n",
    "queries['tokens']=queries['tokens'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto el texto de cada documento y query esta en un formato mas facil de procesar, por lo que se procede a realizar la representacion vectorial de los documentos y queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Representación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se crea un diccionario y el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(documents[\"tokens\"])\n",
    "corpus = [dictionary.doc2bow(text) for text in documents[\"tokens\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el modelo TF-IDF a partor del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula el tf-idf para el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la matriz de similitudes, con respecto a la cual se puede consultar la similitud de un documento con respecto a todos los documentos del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la similitud coseno entre las consultas y el corpus y se escribe el archivo de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear output file contents\n",
    "open(GENSIM_RESULTS_FILE_PATH, \"w\").close()\n",
    "file = open(GENSIM_RESULTS_FILE_PATH, \"a\")\n",
    "\n",
    "# This dictionary will be used to evaluate metrics\n",
    "ret_docs = {}\n",
    "\n",
    "# Loop through queries\n",
    "for i, query in queries.iterrows():\n",
    "    # Open output file\n",
    "    query_str = query['filename'].replace('.naf', '').replace('wes2015.', '')\n",
    "    file.write(query_str + \" \")\n",
    "\n",
    "    # Perform cosine similarity between corpus ans query\n",
    "    query_bow = dictionary.doc2bow(query[\"tokens\"])\n",
    "    query_tfidf = tfidf[query_bow]\n",
    "    sims = index[query_tfidf]\n",
    "    sims = sorted(enumerate(sims, start=1), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    ret_docs[query_str] = []\n",
    "\n",
    "    # Write output file\n",
    "    doc_counter = 0\n",
    "    for docId, sim in sims:\n",
    "        if(sim > 0):\n",
    "            if docId < 10:\n",
    "                doc_str = \"d00\" + str(docId)\n",
    "            elif docId < 100:\n",
    "                doc_str = \"d0\" + str(docId)\n",
    "            else:\n",
    "                doc_str = \"d\" + str(docId)\n",
    "            file.write(doc_str + \":\" + str(sim))\n",
    "            if i != len(sims):\n",
    "                file.write(\",\")\n",
    "        # Add document to ret_docs\n",
    "        ret_docs[query_str].append(doc_str + \":\" + str(sim))\n",
    "        doc_counter += 1\n",
    "    \n",
    "    if i != queries.shape[0]:\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de las funciones para evaluar las métricas\n",
    "Éstas son las mismas funciones definidas en el punto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(relevance: list) -> float:\n",
    "    \"\"\"\n",
    "    Returns the precision of a query result.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "            relevance: list\n",
    "                A binary vector. The kth element of the vector\n",
    "                represent if the kth returned document is relevant\n",
    "                to the query. 1 represent that it is relevant. 0\n",
    "                represent that it is not.\n",
    "    \"\"\"\n",
    "    relevance = np.array(relevance)\n",
    "    num = np.sum(relevance)\n",
    "    den = len(relevance)\n",
    "\n",
    "    return num / den\n",
    "\n",
    "def precision_at_k(relevance: list, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Returns the precision @ k of a query result.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "            relevance: list\n",
    "                A binary vector. The kth element of the vector\n",
    "                represent if the kth returned document is relevant\n",
    "                to the query. 1 represent that it is relevant. 0\n",
    "                represent that it is not.\n",
    "\n",
    "            k: int\n",
    "                Position untill which the metric should be evaluated.\n",
    "    \"\"\"\n",
    "    relevance = relevance[:k]\n",
    "    \n",
    "    return precision(relevance)\n",
    "\n",
    "def recall_at_k(relevance: list, n_relevant_docs, k):\n",
    "    \"\"\"\n",
    "    Returns the Recall @ k of a query result result.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "            relevance: list\n",
    "                A binary vector. The kth element of the vector\n",
    "                represent if the kth returned document is relevant\n",
    "                to the query. 1 represent that it is relevant. 0\n",
    "                represent that it is not.\n",
    "            \n",
    "            n_relevant_docts: int\n",
    "                The number of relevant documents to the query.\n",
    "\n",
    "            k: int\n",
    "                Position untill which the metric should be evaluated.\n",
    "    \"\"\"\n",
    "    relevance = np.array(relevance)\n",
    "    relevance = relevance[:k]\n",
    "\n",
    "    num = np.sum(relevance)\n",
    "    den = n_relevant_docs\n",
    "\n",
    "    return num / den\n",
    "\n",
    "def average_precision(relevance: list) -> float:\n",
    "    \"\"\"\n",
    "    Returns the average precision of a query result\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "            relevance: list\n",
    "                A binary vector. The kth element of the vector\n",
    "                represent if the kth returned document is relevant\n",
    "                to the query. 1 represent that it is relevant. 0\n",
    "                represent that it is not.\n",
    "                The relevance list MUST contain all the relevant documents.\n",
    "    \"\"\"\n",
    "\n",
    "    k = 1\n",
    "    n_relevant_documents = np.sum(relevance)\n",
    "    current_rel_documents = 0\n",
    "    current_p_at_k_sum = 0\n",
    "    rec_at_k = 0\n",
    "    while rec_at_k < 1:\n",
    "        if relevance[k-1] == 1:\n",
    "            current_rel_documents += 1\n",
    "            current_p_at_k_sum += precision_at_k(relevance, k)\n",
    "        \n",
    "        rec_at_k = recall_at_k(relevance, n_relevant_documents, k)\n",
    "        k += 1\n",
    "\n",
    "    return current_p_at_k_sum / current_rel_documents\n",
    "\n",
    "def dcg_i(relevance: list, i: int) -> float:\n",
    "    \"\"\"\n",
    "    Returns the DCG_i. i.e. relevance_i / log2(max(i,2))\n",
    "\n",
    "    Params\n",
    "        ------\n",
    "            relevance: list\n",
    "                A numeric vector where the kth component of the vector\n",
    "                represents the relevance of the kth returned document.\n",
    "    \"\"\"\n",
    "    return relevance[i - 1] / math.log2(max(i,2))\n",
    "\n",
    "\n",
    "def dcg_at_k(relevance: list, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Returns the DCG @ k of a query result.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "            relevance: list\n",
    "                A numeric vector where the kth component of the vector\n",
    "                represents the relevance of the kth returned document.\n",
    "\n",
    "            k: int\n",
    "                Position untill which the metric should be evaluated.     \n",
    "    \"\"\"\n",
    "    relevance = np.array(relevance)\n",
    "    cr_sum = 0\n",
    "    for i in range(1, k+1):\n",
    "        cr_sum += dcg_i(relevance, i)\n",
    "\n",
    "    return cr_sum\n",
    "\n",
    "def ndcg_at_k(relevance: list, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Returns normalized DCG @ k of a query result.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "            relevance: list\n",
    "                A numeric vector where the kth component of the vector\n",
    "                represents the relevance of the kth returned document.\n",
    "\n",
    "            k: int\n",
    "                Position untill which the metric should be evaluated.  \n",
    "    \"\"\"\n",
    "    ordered_relevance = relevance.copy()\n",
    "    ordered_relevance.sort(reverse=True)\n",
    "\n",
    "    cr_sum1 = 0\n",
    "    cr_sum2 = 0\n",
    "\n",
    "    for i in range(1, k+1):\n",
    "        cr_sum1 += dcg_i(relevance, i)\n",
    "        cr_sum2 += dcg_i(ordered_relevance, i)\n",
    "\n",
    "    return cr_sum1 / cr_sum2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q01 - P@M: 0.33,\tR@M: 0.33,\tAP: 0.70,\tNDCG@M: 0.40\n",
      "q02 - P@M: 0.64,\tR@M: 0.64,\tAP: 0.69,\tNDCG@M: 0.63\n",
      "q03 - P@M: 1.00,\tR@M: 1.00,\tAP: 1.00,\tNDCG@M: 0.98\n",
      "q04 - P@M: 0.71,\tR@M: 0.71,\tAP: 0.88,\tNDCG@M: 0.78\n",
      "q06 - P@M: 0.67,\tR@M: 0.67,\tAP: 0.86,\tNDCG@M: 0.81\n",
      "q07 - P@M: 0.25,\tR@M: 0.25,\tAP: 0.17,\tNDCG@M: 0.26\n",
      "q08 - P@M: 0.67,\tR@M: 0.67,\tAP: 0.77,\tNDCG@M: 0.75\n",
      "q09 - P@M: 0.83,\tR@M: 0.83,\tAP: 0.93,\tNDCG@M: 0.89\n",
      "q10 - P@M: 0.38,\tR@M: 0.38,\tAP: 0.30,\tNDCG@M: 0.41\n",
      "q12 - P@M: 1.00,\tR@M: 1.00,\tAP: 1.00,\tNDCG@M: 0.96\n",
      "q13 - P@M: 0.80,\tR@M: 0.80,\tAP: 0.74,\tNDCG@M: 0.72\n",
      "q14 - P@M: 0.58,\tR@M: 0.58,\tAP: 0.48,\tNDCG@M: 0.48\n",
      "q16 - P@M: 0.50,\tR@M: 0.50,\tAP: 0.36,\tNDCG@M: 0.60\n",
      "q17 - P@M: 0.50,\tR@M: 0.50,\tAP: 0.44,\tNDCG@M: 0.70\n",
      "q18 - P@M: 0.71,\tR@M: 0.71,\tAP: 0.81,\tNDCG@M: 0.86\n",
      "q19 - P@M: 0.50,\tR@M: 0.50,\tAP: 0.50,\tNDCG@M: 1.00\n",
      "q22 - P@M: 0.57,\tR@M: 0.57,\tAP: 0.51,\tNDCG@M: 0.53\n",
      "q23 - P@M: 0.25,\tR@M: 0.25,\tAP: 0.29,\tNDCG@M: 0.60\n",
      "q24 - P@M: 0.00,\tR@M: 0.00,\tAP: 0.09,\tNDCG@M: 0.00\n",
      "q25 - P@M: 0.50,\tR@M: 0.50,\tAP: 0.75,\tNDCG@M: 0.67\n",
      "q26 - P@M: 1.00,\tR@M: 1.00,\tAP: 1.00,\tNDCG@M: 1.00\n",
      "q27 - P@M: 0.38,\tR@M: 0.38,\tAP: 0.47,\tNDCG@M: 0.65\n",
      "q28 - P@M: 0.67,\tR@M: 0.67,\tAP: 0.75,\tNDCG@M: 0.81\n",
      "q29 - P@M: 0.83,\tR@M: 0.83,\tAP: 0.82,\tNDCG@M: 0.98\n",
      "q32 - P@M: 1.00,\tR@M: 1.00,\tAP: 1.00,\tNDCG@M: 1.00\n",
      "q34 - P@M: 1.00,\tR@M: 1.00,\tAP: 1.00,\tNDCG@M: 1.00\n",
      "q36 - P@M: 0.90,\tR@M: 0.90,\tAP: 0.95,\tNDCG@M: 0.91\n",
      "q37 - P@M: 0.67,\tR@M: 0.67,\tAP: 0.67,\tNDCG@M: 1.00\n",
      "q38 - P@M: 0.38,\tR@M: 0.38,\tAP: 0.31,\tNDCG@M: 0.32\n",
      "q40 - P@M: 0.67,\tR@M: 0.67,\tAP: 0.67,\tNDCG@M: 0.54\n",
      "q41 - P@M: 0.86,\tR@M: 0.86,\tAP: 0.86,\tNDCG@M: 0.92\n",
      "q42 - P@M: 0.33,\tR@M: 0.33,\tAP: 0.47,\tNDCG@M: 0.61\n",
      "q44 - P@M: 0.50,\tR@M: 0.50,\tAP: 0.56,\tNDCG@M: 0.56\n",
      "q45 - P@M: 0.88,\tR@M: 0.88,\tAP: 0.85,\tNDCG@M: 0.87\n",
      "q46 - P@M: 0.33,\tR@M: 0.33,\tAP: 0.26,\tNDCG@M: 0.28\n",
      "MAP -  0.6548\n"
     ]
    }
   ],
   "source": [
    "rj_file = open(RELEVANCE_JUDGMENTS_FILE_PATH, \"r\")\n",
    "rj_lines = rj_file.readlines()\n",
    "\n",
    "results = {}\n",
    "\n",
    "for rj in rj_lines:\n",
    "    # continue if reading an empty line\n",
    "    if rj == \"\":\n",
    "        continue\n",
    "    \n",
    "    temp = rj.strip().split()\n",
    "\n",
    "    query_str = temp[0]\n",
    "    relevant_docs_lst = temp[1].split(\",\")\n",
    "    relevant_docs = {}\n",
    "    returned_docs = [doc.split(\":\")[0] for doc in  ret_docs[query_str]]\n",
    "\n",
    "    for doc in relevant_docs_lst:\n",
    "        temp2 = doc.split(\":\")\n",
    "        relevant_docs[temp2[0]] = float(temp2[1])\n",
    "\n",
    "\n",
    "    n_relevant_docs = 0\n",
    "    bin_relevance = []\n",
    "    num_relevance = []\n",
    "    \n",
    "    i = 0\n",
    "    while n_relevant_docs < len(relevant_docs):\n",
    "        if i < len(returned_docs):\n",
    "            ret_doc = returned_docs[i]\n",
    "            if ret_doc in relevant_docs:\n",
    "                bin_relevance.append(1)\n",
    "                num_relevance.append(relevant_docs[ret_doc])\n",
    "                n_relevant_docs += 1\n",
    "            else:\n",
    "                bin_relevance.append(0)\n",
    "                num_relevance.append(0)\n",
    "        else:\n",
    "            bin_relevance.append(1)\n",
    "            n_relevant_docs += 1\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    results[query_str] = {\n",
    "        \"P@M\": precision_at_k(bin_relevance, len(relevant_docs)),\n",
    "        \"R@M\": recall_at_k(bin_relevance, len(relevant_docs), len(relevant_docs)),\n",
    "        \"AP\": average_precision(bin_relevance),\n",
    "        \"NDCG@M\": ndcg_at_k(num_relevance, len(relevant_docs))\n",
    "    }\n",
    "\n",
    "\n",
    "# Print results and calculate map\n",
    "ap_sum = 0\n",
    "for q_id in results:\n",
    "    result = results[q_id]\n",
    "    print(str(q_id), \" - \",\n",
    "          \"P@M: \", \"{:.2f}\".format(result[\"P@M\"]), \",\\t\",\n",
    "          \"R@M: \", \"{:.2f}\".format(result[\"R@M\"]), \",\\t\",\n",
    "          \"AP: \", \"{:.2f}\".format(result[\"AP\"]),\",\\t\",\n",
    "          \"NDCG@M: \", \"{:.2f}\".format(result[\"NDCG@M\"]), sep=\"\")\n",
    "    \n",
    "    ap_sum += result[\"AP\"]\n",
    "        \n",
    "mean_average_presition = ap_sum / len(results)\n",
    "print(\"MAP - \", \"{:.4f}\".format(mean_average_presition))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
