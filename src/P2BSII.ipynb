{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 2 Búsqueda binaria usando índice invertido (BSII)\n",
    "## Integrantes\n",
    "* Juan Esteban Arboleda\n",
    "* Luccas Rojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  'William Beaumont and the Human Digestion.  William Beaumont: Physiology of digestion Image Source.  On November 21, 1785, US-American surgeon William Beaumont was born. He became best known as “Father of Gastric Physiology” following his research on human digestion. William Beaumont was born in Lebanon, Connecticut and became a physician. He served as a surgeon’s mate in the Army during the War of 1812. He opened a private practice in Plattsburgh, New York, but rejoined the Army as a surgeon in 1819. Beaumont was stationed at Fort Mackinac on Mackinac Island in Michigan in the early 1820s when it existed to protect the interests of the American Fur Company. The fort became the refuge for a wounded 19-year-old French-Canadian fur trader named Alexis St. Martin when a shotgun went off by accident in the American Fur Company store at close range June 6th, 1822. St. Martin’s wound was quite serious because his stomach was perforated and several ribs were broken. Nobody really expected that the young man would survive but he really did. The skin around St. Martin’s wound fused to the hole in his stomach, leaving a permanent opening – a gastric fistula. [1] Beaumont quickly noticed that there was much research potential. Back then, not too much was known about the digestive system. In order to gain more information, Beaumont performed numerous experiments on St. Martin over a period of eight years. The experiments must have been really uncomfortable for the man, who was inserted bits of different foods tied to strings through the hole in his stomach, pulling them out periodically to observe digestion. Beaumont also removed gastric juice, examining it to better understand its nature. Beaumont became the “Father of Gastric Physiology” and his findings were published in the book “Experiments and Observations on the Gastric Juice and the Physiology of Digestion” in 1833. The work is now considered as the basis of much of the early knowledge on digestion. William Beaumont discovered that hydrochloric acid is the main chemical responsible for breaking down food and he suggested that another important digestive chemical, which is now known as pepsin. He suggested that digestion is a chemical process, not merely a mechanical one caused by stomach muscle movement. Also, Beaumont gave insights on how emotions, temperature, and physical activity can affect digestion. Beaumont’s famous patient, St. Martin, outlived the scientist even though his wound never completely healed. He had several children and died at the age of 83. [2] At yovisto, you may be interested in a video lecture on The Digestive System.'],\n",
       " [2,\n",
       "  'Selma Lagerlöf and the wonderful Adventures of Niels Holgersson.  Cover of The Wonderful Adventures of Nils.  On November 20, 1858, Swedish author and Nobel Laureate Selma Lagerlöf was born. She is best known for her children’s book ‘The Wonderful Adventures of Nils‘. Moreover, she was the first female writer to win the Nobel Prize in literature. Selma Lagerlöf attended a teachers college in Stockholm and became a teacher at the girls’ secondary school in Landskrona. Lagerlöf had been writing poetry for a long time, but never published anything until 1890. She received the first prize in a literary competition and began publishing excerpts from the book which was to be her first, best, and most popular work. Gösta Berlings Saga was published in 1891, but went unnoticed until its Danish translation received wide critical acclaim and paved the way for the book‘s lasting success in Sweden and elsewhere. She received financial support from the royal family and the Swedish Academy, which enabled her to give up teaching completely and focus on writing. Lagerlöf traveled to Italy and published ‘The Miracles of Antichrist‘ in 1897, followed by ‘Jerusalem‘ in 1900. However, to her most famous books belongs the book ‘Nils Holgerssons underbara resa genom Sverige‘, published in 1906. [1] The book starts out with the young Nils Holgersson, who takes delight in hurting the animals at his family’s farm. The boy catches a tomte while his family is out at church and Nils, who refuses to let the tomte free is turned into a tomte as well. The shrunken boy is now able to talk to the farm animals, who are delighted to see Nils being so tiny and they seek revenge. Meanwhile, wild geese are flying over the farm and a white farm goose attempts to join them. Nils holds on to the bird’s neck as it successfully takes off and joins the wild birds. Those are not too pleased to be joined by a boy and a domestic goose, but they take both on several adventures across Sweden. The goose and Nils have to accomplish several tasks in order to be accepted by the group. Also, Nils learns that the tomte might change him back to regular size, if he did good. [2] The story around Nils’ adventures became so well known in Sweden, that a picture of Nils Holgersson, on the back of a goose flying over the plains of Scania, was printed on the reverse side of the Swedish 20 krona banknote. Several film adaptations have been produced all over the world and even a very successful anime series was produced. At yovisto, you may be interested in the video ‘Pixar – a Human Story of Computer Animation‘'],\n",
       " [3,\n",
       "  'Ferdinand de Lesseps and the Suez Canal.  Ferdinand Marie, Vicomte de Lesseps (1805-1894).  On November 19, 1805, French diplomat and later developer of the Suez Canal Ferdinand Marie, Vicomte de Lesseps was born. The Suez Canal that was constructed under de Lessep‘s supervision in 1869 joined the Mediterranean and Red Seas, substantially reducing sailing distances and times between the West and the East. Ferdinand de Lesseps was born at Versailles, Yvelines, in 1805 into a family of French career-diplomats. His first years were spent in Italy, where his father was occupied with his consular duties. He was educated at the College of Henry IV in Paris. From the age of 18 years to 20 he was employed in the commissary department of the army. From 1825 to 1827 he acted as assistant vice-consul at Lisbon, where his uncle, Barthélemy de Lesseps, was the French chargé d’affaires. This uncle was an old companion of French explorer Jean-François de La Pérouse and the only survivor of the expedition in which La Pérouse perished. Following the profession of his father, Ferdinand de Lesseps during his early career was posted to Tunisia and Egypt. In 1832 de Lesseps was appointed vice-consul at Alexandria. Fortunately for de Lesseps, Mehemet Ali, the viceroy of Egypt, owed his position in part to the recommendations made on his behalf to the French government by Mathieu de Lesseps, who was consul-general in Egypt when Ali was a colonel. Because of this, de Lesseps received a warm welcome from the viceroy and became good friends with his son, Said Pasha. De Lesseps became fascinated with the cultures of the Mediterranean and Middle East and the growth of western European trade. After postings to Spain and Italy, in 1849 he retired after a disagreement with the French government, and never again occupied any public office.[1] In 1854, De Lessep’s friend Said Pasha became the new viceroy of Egypt. De Lesseps immediately returned to Egypt, where he was given a warm welcome and, soon afterwards, permission to begin work on the Suez Canal for which he had been inspired by reading about Napoleon‘s abandoned plans for a canal that would allow large ships wishing to sail to the east to go directly from the Mediterranean to the Red Sea, thereby cutting out the long sea journey around Africa. On 7 November 1854 De Lesseps landed at Alexandria A first scheme, directed by Lesseps, was immediately drawn up by the surveyors Linant Bey and Mougel Bey providing for direct communication between the Mediterranean and Red Sea, and, after being slightly modified, it was adopted by an international commission of engineers in 1856.[2] The Compagnie universelle du canal maritime de Suez was organized at the end of 1858. On 25 April 1859 the first blow of the pickaxe was given by de Lesseps at Port Said. During the following ten years, de Lesseps had to overcome the continuing opposition of the British government preventing the Sultan from approving the construction of the canal, and at one stage he even had to seek the support of his cousin, Empress Eugenie, to persuade the Emperor Napoleon III to act as arbitrator in the disputes. Finally, on 17 November 1869, the canal was officially opened by the Khedive, Ismail Pasha. Despite several futile trials, de Lesseps had failed to get also support for his project by the British government. British attitudes finally changed when the canal was seen to be a success and de Lesseps was treated as a great celebrity on his subsequent visit to Britain. In 1875, the Egyptian government sold its shares in the canal and the British prime minister, Benjamin Disraeli, bought effective control of the Canal Company. In his 74th year, de Lesseps began to plan a new canal in Panama. In 1879, an international congress was held in Paris, which chose the route for the Panama Canal and appointed de Lesseps as leader of the undertaking. However, the decision to dig a Panama Canal at sea level to avoid the use of locks, and the inability of contemporary medical science to deal with epidemics of malaria and yellow fever, doomed the project. The Panama Canal Company declared itself bankrupt in December 1888 and entered liquidation in February 1889. The failure of the project is sometimes referred to as the Panama Canal Scandal, after rumors circulated that French politicians and journalists had received bribes. A French court found de Lesseps and his son Charles guilty of mismanagement. Both were heavily fined and sentenced to imprisonment. In the event, de Lesseps did not go to jail, but his son paid for his elderly father’s misjudgements with a year in prison. De Lesseps died on 7 December 1894. At yovisto you can learn more about the work on the Suez Canal and European politics in the 19th century in the lecture “European Imperialism and its Zenith” of Prof. Dr. Thomas W. Laqueur from University of Berkeley. References and further Reading: [1] Ferdinand de Lesseps at BBC History [2] Ferdinand de Lesseps at Britannica online [3] Ferdinand de Lesseps at Association Lesseps Related Articles: The Opening of the Panama Canal Jean-François de La Pérouse and his Voyage around the World Gustav Eiffel and his famous Tower Baron Haussmann’s Renovation of Paris Oscar Niemeyer – The Visionary Architect'],\n",
       " [4,\n",
       "  'Walt Disney’s ‘Steamboat Willie’ and the Rise of Mickey Mouse.  Mickey Mouse star in Walk of Fame Image by Flickr user freshwater2006.  On November 18, 1928, Walt Disney’s animated movie ‘Steamboat Willie‘ was released that presented his most famous character ‘Mickey Mouse‘ for the very first time in New York City. The film is also notable for being the first cartoon with synchronized sound. The movie was produced in black-and-white and debuts Mickey Mouse as well as his girlfriend Minnie. Even though it was the third of Mickey’s films to be produced, it was the first to be distributed. The movie starts out with Mickey steering a river steamboat until the boat’s real captain Pete appears, who orders Mickey off the bridge. Mickey and Pete then proceed to fight back and forth on the ship while they accidentally trip and fall. Eventually, Minnie appears on board and the two mice proceed to make music together using the animals aboard. Meanwhile, Pete gets angry again, ordering Mickey to peel the potatoes. A parrot appears, who makes fun of the mouse and Mickey throws a potato at him, which knocks the parrot into the river. Oswald the Lucky Rabbit used to be the star of Disney’s and he was one of the first cartoon characters that had personality. However, Disney lost the rights to the character and Mickey Mouse was intended to become the new star. The first films starring Mickey Mouse were silent films and did not really impress the audiences. No distributor was found and Disney came to realize that adding sound to a cartoon would probably increase its appeal. However, Steamboat Willie was not the first cartoon synchronized sound. Dave and Max Fleischer’s Inkwell Studios produced 19 sound cartoons in the mid 1920s using the Phonofilm sound-on-film process. Unfortunately, the sound could not be synchronized completely. Steamboat Willie was produced using a click track to keep his musicians on the beat. Back then, click track meant that optical marks were made on the film to indicate precise timings for musical accompaniment. Initially, the producers had doubts about the sound in a cartoon and Disney arranged a test screening with a small audience consisting of Disney employees and their wives. The live sound accompanied the partly finished film Steamboat Willie. Behind the movie screen, a bed sheet was installed along with a microphone and speakers. The sound, consisting of a mouth organ, percussion and several ‘special effects‘ like bells and whistles, was produced from behind the sheet. The audience loved it and a company was hired to professionally produce the sound system as well as the Green Brothers Novelty Band for the final soundtrack. Steamboat Willie premiered at Universal’s Colony Theater in New York City on November 18, 1928 and was an instant success which caused Walt Disney and Mickey Mouse international fame. At yovisto, you may be interested in the lecture ‘The Power of Cartoons‘ by Patrick Chappatte.'],\n",
       " [5,\n",
       "  'Eugene Wigner and the Structure of the Atomic Nucleus.  Eugene Paul Wigner (1902-1995). On November 17, 1902, Hungarian American theoretical physicist and mathematician Eugene Paul Wigner was born. He is best known for for his contributions to the theory of the atomic nucleus and the elementary particles, particularly through the discovery and application of fundamental symmetry principles for which he shared the 1963 Nobel Prize in Physics with Maria Goeppert. Wigner’s thesis Bildung und Zerfall von Molekülen (“Formation and Decay of Molecules”) was supervised by Michael Polanyi and contains the first theory of the rates of association and dissociation of molecules. Having completed his doctorate, Wigner returned to Budapest to join his father’s tannery firm as planned. However, things did not go too well. Wigner’s father supported him taking the post in Berlin, where he accepted an offer from Karl Weissenberg at the Kaiser Wilhelm Institute in Berlin. Weissenberg wanted someone to assist him with his work on x-ray crystallography, and Polanyi had recommended Wigner. [2] Wigner received a request from Arnold Sommerfeld to work in Göttingen as an assistant to the great mathematician David Hilbert. This proved a disappointment, as Hilbert‘s interests had shifted to logic. Wigner nonetheless studied independently. He laid the foundation for the theory of symmetries in quantum mechanics and in 1927 introduced what is now known as the Wigner D-matrix. An offer to spend a term in Princeton saw him travel to the United States at the end of 1930. From 1930 to 1933 Wigner spent part of the year at Princeton, part at Berlin. His Berlin post vanished under the Nazi rules passed in 1933 and from then, except for the years 1936 - 1938 in Wisconsin, Wigner spent the rest of his career at Princeton.[2] In 1937, Wigner became a naturalized citizen of the United States. In 1939, it was Wigner, who introduced Leó Szilárd to Albert Einstein for a meeting that resulted in the Einstein-Szilárd letter which urged President Franklin D. Roosevelt to initiate the Manhattan Project to develop atomic bombs. During the Manhattan Project, Wigner led a team that was to design the production nuclear reactors that would convert uranium into weapons gradeplutonium. At the time, reactors existed only on paper, and no reactor had yet gone critical. In July1942, Wigner chose a conservative 100 MW design, with a graphite neutron moderator and water cooling, which led to the successful development of the world’s first atomic reactor, Chicago Pile One (CP-1) that achieved a nuclear chain reaction in 1942. In 1946, Wigner accepted a position as director of research and development at Clinton Laboratory (now Oak Ridge National Laboratory) in Oak Ridge, Tenn. Not an administrator by background or temperament, Wigner left after a year and returned to teaching and research at Princeton University.[3] In 1963, Wigner was awarded the Nobel Prize in Physics, along with American physicist Maria Goeppert-Mayer and German physicist J. Hans D. Jensen, for work on the structure of the atomic nucleus. He professed to never have considered the possibility that this might occur, and he added: “I never expected to get my name in the newspapers without doing something wicked.” Wigner also won the Enrico Fermi award in 1958, and the National Medal of Science in 1969. Near the end of his life, Wigner’s thoughts turned more philosophical. He became interested in the Vedanta philosophy of Hinduism, particularly its ideas of the universe as an all pervading consciousness. Eugene Paul Wigner died in Princeton on January 1, 1995. At yovisto, you may enjoy a short video lecture by Tyler DeWitt on the ‘Atomic Structure: Discovery of the Neutron‘'],\n",
       " [6,\n",
       "  'Eugenio Beltrami and Non-Euclidian Geometry.  Eugenio Beltrami (1835-1900). On November 16, 1835, Italian mathematician Eugenio Beltrami was born. He is most notable for his work concerning differential geometry and mathematical physics. His work was noted especially for clarity of exposition. He was the first to prove consistency of non-Euclidean geometry by modeling it on a surface of constant curvature, the pseudosphere. Eugenio Beltrami was born in Cremona in Lombardy, then a part of the Austrian Empire, and now part of Italy. The son of an artist who painted miniatures, young Eugenio certainly inherited artistic talents from his family, but in his case in addition to the mathematical talents he would acquire, it was musicrather than painting that became important in his life. He began studying mathematics at University of Pavia in 1853, but was expelled from Ghislieri College in 1856 due to his political opinions. During this time he was taught and influenced by Francesco Brioschi, who had been appointed as professor of applied mathematics at the University of Pavia the year before Beltrami began his studies. Beltrami had to discontinue his studies because of financial hardship and spent the next several years as a secretary working for the Lombardy–Venice railroad company first in Verona and later in Milan. While Beltrami was in Milan the Kingdom of Italy was established in 1861, an important political event which did much to invigorate the academic scene in Italy. Beltrami began to work hard at his mathematical studies again and in 1862 he published his first paper. As a result, he was appointed to the University of Bologna as a professor in 1862. In 1870, a new University of Rome was set up in the new Italian capital and Beltrami was appointed to the chair of rational mechanics there in 1873. After three years in Rome, Beltrami moved to Pavia to take up the chair of mathematical physics there. However, Beltrami returned to Rome in 1891 and spent his last years teaching there.[1] He became the president of the Accademia dei Lincei in 1898 and, the following year, a senator of the kingdom. A lover of music, Beltrami was interested in the relationship between mathematics and music.[2] M.C.Escher, Circle Limit IV, illustrating hyperbolic geometry In 1868 Beltrami published two memoirs dealing with consistency and interpretations of non-Euclidean geometry of Bolyai and Lobachevsky. Beltrami proposed that this geometry could be realized on a surface of constant negative curvature, a pseudosphere. For Beltrami’s concept, lines of the geometry are represented by geodesics on the pseudosphere and theorems of non-Euclidean geometry can be proved within ordinary three-dimensional Euclidean space, and not derived in an axiomatic fashion, as Lobachevsky and Bolyai had done previously. Already in 1840, Minding already considered geodesic triangles on the pseudosphere and remarked that the corresponding “trigonometric formulas” are obtained from the corresponding formulas of spherical trigonometry by replacing the usual trigonometric functions with hyperbolic functions In the second memoir “Fundamental theory of spaces of constant curvature“, Beltrami continued this logic and gave an abstract proof of equiconsistency of hyperbolic and Euclidean geometry for any dimension. He accomplished this by introducing several models of non-Euclidean geometry that are now known as the Beltrami–Klein model, the Poincaré disk model, and the Poincaré half-plane model, together with transformations that relate them. Although today Beltrami’s “Essay” is recognized as very important for the development of non-Euclidean geometry, the reception at the time was less enthusiastic. Beltrami also worked on optics, thermodynamics, elasticity, electricity and magnetism. His contributions to these topics appeared in the four-volume work, Opere Matematiche (1902-20), published posthumously. At yovisto, you can learn more about Non-Euclidian geometry in the History of Mathematics lecture of Professor N. J. Wildberger “MathHist12 – Non-Euclidian Geometry“.'],\n",
       " [7,\n",
       "  'Bernard Mandeville and the Fable of the Bees.  Bernard Mandeville’s – The Fable of Bees.  On November 15, 1670, Dutch philosopher, political economist and satirist Bernard Mandeville was born. He became famous for The Fable of the Bees, a satire that suggests many key principles of economic thought, including division of labor and the “invisible hand“, seventy years before these concepts were more thoroughly elucidated by Adam Smith. Not very much is known about the life of Bernard Mandeville. He probably grew up in Rotterdam, Netherlands and was the son of a physician. He enrolled at Leiden University and produced his thesis De brutorum operationibus in 1689. In it, Mandeville advocated the Cartesian theory of automatism among animals. He received his degree in medicine in 1691 and his disputation was titled De chylosi vitiata. He became a well known and respected physician and produced several literary works as well, which were considered just as successful. The Grumbling Hive was probably published in 1705 and in 1714, it was again published under the famous name of The Fable of The Bees: or, Private Vices, Public Benefits. Next to the mentioned poem, a detailed discussion is included in the book. It consists numerous key principles of economic thought, such as the division of labour and the famous invisible hand. Mandeville describes a well working community of bees until the bees suddenly turn into honest and virtuous beings. Their community collapses due to the lack of the desire for personal benefits. Mandeville explained that vice was necessary for economic prosperity, which was a quite scandalous point of view. Mandeville and also Adam Smith expressed that individual’s collective actions may lead to a public benefit. However, Smith believed in a virtuous self-interest which results in invisible co-operation and that there was no need for someone to garner the benefit. Mandeville however thought that politicians had to ensure that the people’s passions really resulted in public benefits. Back in the day, Mandeville’s ideas were seen as degrading in concerns of the human nature. At yovisto, you may be interested in a video lecture on Adam Smith and the Wealth of Nations by Professor James Paradis.'],\n",
       " [8,\n",
       "  'Leo Baekeland and the Beginning of the Plastic Age.  Bakelite Billiard Balls Image: Chemical Heritage Foundation at Flickr.  On November 14, 1863, Belgian-born American chemist Leo Henricus Arthur Baekeland was born. His invention of Bakelite, an inexpensive, nonflammable, versatile, and popular plastic, marked the beginning of the modern plastics industry. Leo Baekeland completed his doctorate at the University of Ghent and taught for a few years. He continued his studies of chemistry in New York City, England, Scotland, and Germany. He was then persuaded to stay in the United States and he began working at a New York photographic supply house, which inspired him for later developments, especially Velox, an improved photographic paper that could be developed in gaslight rather than sunlight. [1] The Velox photographic paper was sold to Kodak and Baekeland was able to maintain a home laboratory and hire the assistant Nathaniel Thurlow. Both knew of the great potential phenol-formaldehyde resins and they read about the experiments by Adolf von Baeyer and Werner Kleeberg. They reported that when he mixed phenol, a common disinfectant, with formaldehyde, it formed a hard, insoluble material that ruined his laboratory equipment, because once it has formed, it could not be removed. The produced substance was described as a hard amorphous mass, infusible and insoluble and thus of little use. Further scientists, including Adolf Luft performed several experiments in order to create a commercially viable plastic molding compound. However, none of them was known to have created a useful product. At that time, many chemists began recognizing that many of the natural resins and fibers useful for coatings, adhesives, and woven fabrics were polymers even though its molecular structure was not completely known. When Baekeland and his assistant started to investigate the reactions of phenol and formaldehyde, they produced ‘Novolak’, but unfortunately, this was never really successful. The scientists moved on to developing a phenol-formaldehyde binder for asbestos. They managed to carefully control the pressure and temperature applied to an intermediate made from the two reagents, he produced a polymer that produced a hard moldable plastic when it was mixed with certain fillers and Bakelite was born. [1,2, 3] Bakelite had the advantage, that it could be molded quickly. Also, it was known for its extraordinarily high resistance and thus, became a popular material for the emerging electrical and automobile industries. Soon, Bakelite was integrated in numerous areas of living. Jewellery was made out of it as well as telephones, or even billiard balls (see picture above). [1] At yovisto, you may be interested in a talk by Diana Cohen on ‘Tough truths about plastic pollution‘.'],\n",
       " [9,\n",
       "  'Dorothea Erxleben – Germany’s First Female Medical Doctor.  Dorothea Christiane Erxleben (1715 – 1762).  On November 13, 1715, Dorothea Christiane Erxleben, first female medical doctor in Germany was born. It was very hard for her to overcome the prejudices of the University professors and to finish her studies with a proper examination. What is even worse is that it should take until 1901 that the second woman in Germany was able to make her exams as a doctor. Already Erxleben’s father was a doctor in Aschersleben, Germany. It is known that from early age, she showed much interest in nature science and that she proved to be quite smart. The director of her school was giving her Latin classes as a free time activity and her father and uncle taught her in theoretical and practical medicine as well as nature scientific topics. Dorothea Erxleben was educated almost in the same way her brother did and aimed at an academic degree. However, she was not accepted at the university and her father wrote a letter to Frederick the Great who then advised the University of Halle to admit the young student. Then however, Dorothea did not accept the offer. [1,2] She began to practice medicine in her hometown, but was not welcomed due to the lack of a formal education and degree. As she was accused by many to be only an amateur scientist, she wrote a long letter explaining her situation and that it was a shame that women were not able to freely attend the university like men. She continued practicing in her father’s doctor’s office next to raising her four children. Unfortunately, a patient died during Erxleben’s treatment and she was again accused as a dilettante. She decided to catch up on her degree and went back to university. Her dissertation from 1755 was titled “Quod nimis cito ac iucunde curare saepius fiat causa minus tutae curationis” and was successful. [1,2] Unfortunately, women were officially allowed to be examined in medicine and pharmaceutics only in 1899. At Halle, one department of the hospital was named after Erxleben and even a theater play was written for her. Dorothea Erxleben passed away on June 13, 1762. [1,2] At yovisto, you may be interested in the lecture ‘On the History of Women in Science‘ by Professor Susanne Williams.'],\n",
       " [10,\n",
       "  'Sir James Young Simpson and the Chloroform.  Sir James Young Simpson, 1st Baronet (1811-1870).  On November 12, 1847, Scottish obstetrician and important figure in the history of medicine Sir James Young Simpson published his self trial experiments with the new anesthetic chloroform. “All pain is per se and especially in excess, destructive and ultimately fatal in its nature and effects.” (James Young Simpson) Simpson was born in Bathgate near Edinburg, West Lothian, Scotland, as the seventh son and eighth child of an impecunious baker. Simpson attended the University of Edinburgh from the age of only 14, graduating at the age of 18 but, as he was so young, had to wait two years before he got his license to practice medicine. In 1838 he designed the Air Tractor, the earliest known vacuum extractor to assist childbirth but the method did not become popular until the invention of the ventouse over a century later. At the age of 28 he was appointed to the Chair of Medicine and Midwifery at the University of Edinburgh, here he became a pioneer in obstetrics and gynecology. He improved the design of obstetric forceps that to this day are known in obstetric circles as “Simpson’s Forceps” and, like German physician Ignaz Semmelweis, fought against the contagion of puerperal sepsis. His most noted contribution should be the introduction of anaesthesia to childbirth. Simpson, unlike most medical men of his day, was quite concerned about the pain his patients suffered during childbirth, and searched for ways to alleviate it. While visiting London, he met with the surgeon Robert Lister, who praised the use of ether as an anesthetic in a recent operation. Already in 1799, Sir Humphry Davy used nitrous oxide (laughing gas) as the first anaesthetic. Ether, however, was not conducive for obstetrics, so Simpson continued to experiment with different chemical compounds.[3] In 1847, the same year he was appointed physician to Queen Victoria while she was visiting in Scotland, Simpson discovered the anesthetic properties of chloroform. Together with two of his friends, Drs Keith and Duncan, Simpson used to sit every evening in his dining room to try new chemicals to see if they had any anaesthetic effect. On 4 November 1847 they decided to try a ponderous material named chloroform that they had previously ignored. On inhaling the chemical they found that a general mood of cheer and humour had set in. But suddenly all of them collapsed only to regain consciousness the next morning. Simpson knew, as soon as he woke up, that he had found something that could be used as an anaesthetic. It was very much by chance that Simpson survived the chloroform dosage he administered to himself. If he had inhaled too much and died, chloroform would have been seen as a dangerous substance, which in fact it is. Simpson was the first to utilize chloroform as an anesthetic to ease the pain of childbirth. This practice was initially opposed by the Church because it tampered with the Divine Order. According to Genesis the pain of childbirth was the Lord’s punishment on womankind for Eve eating the apple from the tree of knowledge. The controversy surrounding this practice quickly disappeared after Queen Victoria used chloroform to help her deliver Prince Leopold in 1853.[3] But, Simpson’s medical contributions extended beyond obstetric anaesthesia. Simpson pioneered the uterine sound, long forceps,  wire sutures, and improved statistical analysis of operative outcomes. He wrote important memoirs on fetal pathology and hermaphroditism, and made contributions to the fields of archeology and medical history. Simpson was honoured with a first baronet in 1866. He died four years later in 1870 at the age of 59 in his home. The day of his funeral was declared a day of public mourning in Edinburgh and two thousand people followed his hearse through streets lined by over 30,000 mourners.[2] At yovisto, you can watch a TED talk given by Dr. Stuart Hameroff, a clinical anesthesiologist, who has studied how anesthetic gas molecules selectively erase consciousness via delicate quantum effects on protein dynamics. In his talk “Do we have a quantum Soul?“, Hameroff explored the theoretical implications for consciousness to exist independent of the body.'],\n",
       " [11,\n",
       "  'Louis Antoine de Bougainville and his Voyage Around the World.  Bougainville reaching Tahiti Probably on November 11, 1729, French admiral and explorer Louis Antoine de Bougainville was born. A contemporary of James Cook, gained fame for his expeditions, the first recorded settlement on the Falkland Islands and his voyages into the Pacific Ocean. The largest of the Solomon Islands is named after him, as is the colorful tropical climbing plant bougainvillaea. Louis Antoine de Bougainville was born in Paris and began to study law, which he abandoned shortly after. Bougainville joined the army in 1753 and was sent to London as secretary to the French embassy three years later. During the Seven Years’ War, Bougainville gained experience at sea. Also, he participated in the defense of Quebec City and later became a diplomat taking part in negotiating the Treaty of Paris that eventually conceded most of New France to the British Empire. After the war, the French decided to colonize the Falkland Islands, which were not well known at this time. Bougainville decided to travel there on his own expense. He set out in 1763 with the Eagle and the Sphinx and they reached the French Bay in 1764. The explorer then received the permission to circumnavigate the globe in the 1760s and he would become the first known French to sail around the world. It is assumed that this was also the first expedition to carry professional naturalists and geographers aboard. The crew traveled with two ships, La Boudeuse with 214 men and Étoile with 116 men. The botanist Philibert Commerçon named the flower Bougainvillea. Also on board was Jeanne Baret, who joined the expedition disguised as a man, calling herself Jean Baret. She enlisted as valet and assistant to Commerçon, but that is a whole different story. Bougainville visited the island of Otaheite. From Tahiti, the crew sailed westward to southern Samoa and the New Hebrides.  Bougainville almost discovered the Great Barrier Reef and sailed towards Solomon Islands. However, the expedition was attacked probably by people from New Ireland and they headed towards the Moluccas. The expedition managed to complete the mission with the loss of seven men. In the 1770s, Bougainville published his travel log titled as Le voyage autour du monde, par la frégate La Boudeuse, et la flûte L’Étoile. In it, the geographical, biological, and anthropologic findings of Argentina, Patagonia, Tahiti, and Indonesia were explained. At yovisto, you may be interested in a video lecture on the Age of Discovery by Jim Bennett.'],\n",
       " [12,\n",
       "  'Robert Morison and the Classification of Plants.  Robert Morison (1620-1683). On November 10, 1683, Scottish botanist and taxonomist Robert Morison passed away. A forerunner of naturalist John Ray, he elucidated and developed the first systematic classification of plants. Born in 1620 in Aberdeen, Scotland, as son of John Morison and his wife Anna Gray, Robert Morison was an outstanding scholar who gained his Master of Arts degree and Ph.D. from the University of Aberdeen at the age of eighteen. He devoted himself at first to mathematics, and studied Hebrew, being intended by his parents for the ministry [1] During the English Civil War he joined the Royalist Cavaliers and was seriously wounded at the Battle of the Bridge of Dee during the Civil War. On recovering he fled to France when it became apparent that the cause was lost. In France he applied himself to the study of anatomy, zoology, botany, mineralogy, and chemistry, studying Theophrastus, Dioscorides, and in 1648 he took a doctorate in medicine at the University of Angers in Western France and from then on devoted himself entirely to the study of botany. On the recommendation of his tutor Vespasian Robin, the French king’s botanist, he was received into the household of Gaston, Duke of Orleans in 1649 or 1650, as one of his physicians, and as a colleague of Abel Bruyner and Nicholas Marchant, the keepers of the duke’s garden at Blois, a post which he subsequently held for ten years.[1] He was sent by the Duke to Montpellier, Fontainebleau, Burgundy, Poitou, Brittany, Languedoc, and Provence in search of new plants, and seems to have explained to his patron his views on classification. In 1660, despite inducements to make him stay in France, Morison returned to England at the invitation of the newly restored Charles II, where he became royal physician and Professor of Botany in Oxford in 1669. One of his first publications for the newly revived University Press was the Hortus Regius Blesensis (1669), the catalogue to which Morison added the description of 260 previously un-described plants, although later many were considered only varieties and others were already well known. Illustration from Morison’s Plantarum Umbelliferarum Distributio Nova (1672) In the same year, Morison published Praeludia Botanica, a work which stressed using the structure of a plant’s fruits for classification. At the time, classification focused on the habitat and obvious properties of the plant and Morison’s criticism of existing botanical systems caused some anger among his contemporaries. In the preface to his Plantarum Umbelliferarum Distributio Nova (1672), Morison gave a definitive statement of the principles of his method and was the first person ever to write a “monograph of a specific group of plants“, the Umbelliferae. Carrot and parsley also belong to the family of Umbelliferae and are now called Apiaceae. They were identified already by Rembert Dodoens as a distinct group for the first time in 1583. Using a classification based on seed characteristics supplemented by differences in vegetative features, Morison divided plants with umbel type inflorescences into different genera of true umbellifers and those which were ‘Umbellae improprie dicto’ from different genera such as Valeriana, Filipendula, and Thalictrum.[2] Morison drew much criticism from his contemporaries as he stated that he had derived his schema from the book of Nature alone and did not mention his debt to Italian botanist Andrea Cesalpino whose system he closely followed. Carl Linneaus wrote about Morison in a 1737 letter: “Morison was vain, yet he cannot be sufficiently praised for having revived a system which was half expiring. If you look through Tournefort’s genera you will readily admit how much he owes to Morison, full as much as the latter was indebted to Cesalpino, though Tournefort himself was a conscientious investigator. All that is good in Morison is taken from Cesalpino, from whose guidance he wanders in pursuit of natural affinities rather than of characters.” Morison was fatally injured by the pole of a carriage as he was crossing the street on 9 Nov. 1683 and died the following day. At yovisto, you can learn more about botany in the video lecture on ‘Human Livelihoods Depend on Wild Flowers: Kew’s Millennium Seed Bank explained‘.'],\n",
       " [13,\n",
       "  'Florence Sabin – Preparing the Ground for Women in Medical Science.  Florence Sabin (1871 – 1953).  On November 9, 1871, American medical scientist Florence Rena Sabin was born. She was a pioneer for women in science. She was the first woman to hold a full professorship at Johns Hopkins School of Medicine, the first woman elected to the National Academy of Sciences, and the first woman to head a department at the Rockefeller Institute for Medical Research. Florence Sabin was born in Colorado, but grew up with her Uncle Albert Sabin in Chicago and then with their paternal grandparents in Vermont. She earned her bachelor’s degree from Smith College in 1893 and taught mathematics and zoology afterwards. Sabin then attended the John Hopkins University School of Medicine and graduated there as the first woman. Franklin Mall noticed Sabin’s skills in the laboratory and the anatomist then helped the young woman to get involved in further projects and building up a good reputation. As part of Mall’s projects, Sabin produced a 3D model of a newborn baby’s brainstem. This project was considered successful and the textbook ‘An Atlas of the Medulla and Midbrain‘ was published as a result in 1901. Another project focused on the embryological development of the lymphatic system which proved that the lymphatic system is formed from the embryo’s blood vessels. [1,2] Sabin became an intern at Johns Hopkins Hospital followed by a research fellowship in the Department of Anatomy at Johns Hopkins School of Medicine. She began to teach at the department in 1902 and was appointed full professor of embryology and histology in 1917. Florence Sabin was back then the first known woman in the position of the full professor at a medical college and the first female president of the American Association of Anatomists as well as the first lifetime woman member of the National Academy of Sciences. Sabin later focused her research on the origins of blood, blood vessels, blood cells, the histology of the brain, and the pathology and immunology of tuberculosis. She also became the head of the Department of Cellular Studies at the Rockefeller Institute for Medical Research in New York City. After her retirement, Florence Sabin became involved in health projects in Colorado and published studies revealing the bad health situations all over the state. She fought against uninterested politicians and her effort was rewarded with new health bills which became known as the ‘Sabin Health Laws’. She took part in modernizing the public health system and became manager of health and charities for Denver, donating her salary to medical research. Florence Sabin passed away on October 3, 1953. [3] At yovisto, you may be interested in a TED Talk about Visualizing the medical data explosion by Anders Ynnerman.'],\n",
       " [14,\n",
       "  'Hermann ‘Klecks’ Rorschach and his Eponymous Test.  The tenth blot of the Rorschach Inkblot Test.  On November 8, 1884, Swiss Freudian psychiatrist and psychoanalyst Hermann Rorschach was born. He is best known for developing a projective test known as the Rorschach inkblot test. This test was reportedly designed to reflect unconscious parts of the personality that “project” onto the stimuli. Hermann Rorschach was born in Zurich, Switzerland and it is known was he was encouraged by his father, an art teacher, to express himself creatively. The young Rorschach became fascinated with making pictures out of inkblots in his early years. These kind of pictures were in Switzerland very well known as ‘Klecksography‘ and the student was soon called ‘Klecks’ by his classmates. It is assumed that Rorschach was not quite sure which topic to study at the university. As he had difficulties to chose between art and science, Rorschach asked Ernst Haeckel, who advised the young student to focus on science. However, Rorschach never abandoned art completely. [1,2] Rorschach attended Academie de Neuchatel in 1904, studying geology and botany and studied French at the Universite de Dijon. He enrolled at the University of Bern in order to study medicine and specialized in psychology. He completed his studies in Zurich, Berlin, and Nuremberg. During his studies, Rorschach began to study psychology in combination with imagery association. Justinus Kerner published a book of a poetry collection in 1857 with each poem inspired by an accompanying inkblot. Also Alfred Binet saw inkblot tests as a potential measure of creativity. Hermann Rorschach noticed that especially schizophrenic patients associated different things with inkblots than others. This observation was followed by a series of experiments and the development of the first version of the inkblot test as a measure of schizophrenia in 1921. His test came into use in the late 1930s after Samuel Beck and Bruno Klopfer expanded its original scope. Since then, psychologists used the inkblot tests to make judgements about broad personality traits even though Rorschach originally expressed his skepticism towards using the inkblot’s value in assessing personality. [1,2] Hermann Rorschach could not live to see these developments of the inkblot test. He died suddenly on April 2, 1922 at the young age of 37. However, by the 1960s, the famous Rorschach inkblot test became widely used, especially in the Unites States for personality tests. It was even ranked eighth in a long list of tests used all over the US for outpatient mental health care. Up to this day, the inkblot test is widely criticized, especially because it has been modified several times by various researchers. Still, it is considered as one of the primary tests used in hospitals, schools, jails and courtrooms and is used to decide on parental custody rights, assess the emotional issues of children, and determine if a prisoner is eligible for parole. [3] At yovisto, you may be interested in a video lecture by the psychology Professor Glenn Wilson on How to profile a killer.'],\n",
       " [15,\n",
       "  'William Stukeley and the Mystery of Stonehenge.  Stonehenge, photo: wikipedia.  On November 7, 1687, English antiquarian and Anglican clergyman William Stukeley was born. He pioneered the archaeological investigation of the prehistoric monuments of Stonehenge and Avebury, work for which he has been remembered as probably the most important of the early forerunners of the discipline of archaeology. Stukeley was also one of the first biographers of Isaac Newton, of whom he was a friend. William Stukeley was born in Holbeach in Lincolnshire, as the son of a lawyer. After taking his M.B. degree at Corpus Christi College, Cambridge, Stukeley went to London and studied medicine at St Thomas’ Hospital. While still a student he began making topographical and architectural drawings as well as sketches of historical artefacts. In 1710, he started in practice in Boston, Lincolnshire, becoming a member of Spalding Gentlemen’s Society, before returning in 1717 to London. In the same year, he became a Fellow of the Royal Society and, in 1718, joined in the establishment of the Society of Antiquaries, acting for nine years as its secretary. In 1719 Stukeley took his M.D. degree, and in 1720 became a Fellow of the Royal College of Physicians, publishing in the same year his first contribution to antiquarian literature. “Our predecessors, the Druids of Britain, tho’ left in the extremest west to the improvement of their own thoughts, yet advanc’d their inquiries, under all disadvantages, to such heights, as should make our moderns asham’d, to wink in the sunshine of learning and religion.” from William Stukeley: Stonehenge: A Temple Restor’d to the British Druids, Preface. (1740)[2]. An inward view of Stonehenge from August 1722 [3] After reading an account by antiquary and natural philosopher John Aubrey, who lived about 70 years before Stukeley, he began to develope a particular interest in the Stonehenge and Avebury monuments. He spent years surveying Stonehenge and Avebury and mapping the burials and earthworks around them. Stukeley’s principal works, elaborate accounts of Stonehenge and Avebury, appeared in 1740 and 1743. These were supposed to be the first of a multi-volume universal history. Stukeley believed that these pre-Roman sites had been built by ‘Celts‘, led by their priests, the Druids. Mixing speculation with evidence from ancient texts, he concluded that the Celts were originally Phoenician colonists, who had ‘civilized’ Britain long before the Romans arrived. Stukeley painted a romantic but fictitious vision of the Druids worshipping at Stonehenge that has lasted to the present day. He proposed that the cults of the druids are based on an ancient patriarchial religion that also was the original religion of mankind. This had subsequently degenerated as idol-worship had emerged. Stukeley himself being a priest of the Church of England, believed that the Druids and the early Christians were examples of this religion. Interestingly, these views were widely and enthusiastically accepted in the late 18th century. Stukeley perceived the entire prehistoric landscape as laid out in a sacred pattern with centres at Stonehenge and Avebury. The stone circles and earthworks at Avebury he recognized as part of a larger figure inscribed in the landscape in the form of a serpent. Stukeley saw serpents, and dragons (a variant form of the same creature, as are also “worms”), all over countryside and linked the image with the many local legends of dragons and dragon-killers found throughout the Britain. The places associated with the dragon legend appear always to coincide with sites of ancient sanctity.[3] Stukeley’s work on Stonehenge was one of the first to attempt to date the monument. Working with the renowned astronomer Edmund Halley, he proposed that the builders of Stonehenge knew about magnetism, and had aligned the monument with magnetic north. Stukeley used some incomplete data about the variation of the North Magnetic Pole Despite his romantic theorizing, he was an excellent field archaeologist, and his surveys of the monuments in the 1720s remain of interest. His extensive antiquarian travels are recorded in Itinerarium Curiosum (1724Observant Itinerary”). Besides his work on archeology, Stukeley was one of the first learned gentlemen to be attracted to speculative freemasonry as well as a friend of Isaac Newton, about whom he wrote a memoir of his life in 1752. Actually, this is one of the earliest sources for the story of the falling apple that inspired Newton’s formulation of the theory of gravitation. Artist, prolific writer and poet, architect, archaeologist, antiquarian, scientist, physician, clergyman, druid, musician, numismatist, traveller, genealogist, gardener and animal lover, William Stukeley was all of these. After Stukeleys death in 1765 it was not until the 19th century that archaeologists took up from where he had finished his work. At yovisto you can learn more about Stonehenge in the lecture of Prof. Jeanne Willette from Otis College of Art and Design on “Stonehenge”'],\n",
       " [16,\n",
       "  'Adolphe Sax and the Saxophone.  Adolphe Sax (1814-1894)  .  On November 6, 1814, Belgian musical instrument designer and musician Antoine-Joseph “Adolphe” Sax was born. Besides playing flute and clarinet, he is well known for having invented the saxophone. Sax became something of a footnote in history after his creation was almost forgotten after his death, until it was revived by jazz musicians who barely remembered his name.[2] Back in the time when I was a student, I remember one fellow student who ‘polluted’ the air of the student’s dorm for two long semesters with his (futile) practicing on that very instrument invented by Gustave Sax. I can tell you that it is really a pain to listen to a beginner’s trials on the Saxophone. Antoine-Joseph Sax was born in Dinant, Belgium, as the oldest of 11 children to Charles-Joseph Sax, an instrument designer, who made several changes to the design of the horn. Sax became his father’s apprentice and began to make his own instruments at an early age, entering two of his flutes and a clarinet into a competition at the age of 15. He subsequently studied those two instruments at the Royal Conservatory of Brussels. The Saxtuba, one of Adolphe Sax‘s instruments (1867) In 1835 he perfected a bass clarinet superior to any that had preceded it. Before long, Sax concluded that Belgium was too small for his ambitions. At the Belgian Exhibition (an industrial fair) in 1840 he presented nine inventions, among them an organ, a piano tuning process and a sound-reflecting screen. The judges felt that Sax was too young to receive the gold medal, and instead awarded him the vermeil (gilded silver). Sax came to Paris in 1842 and succeeded in interesting many eminent men, including composer Hector Berlioz. He set up a workshop in the Rue St Georges and studied acoustics, discovering a new principle in the manufacture of wind instruments, viz. That it is the proportions given to a column of air vibrating in a sonorous tube, and these alone, that determine the character of the timbre produced: the material of the walls of the tube is not of the slightest importance so long as it offers enough resistance.[1]Together with his genius for mechanical invention Sax seems to have combined a knowledge of self-advertisement, and his name was often prefixed to successful types of instrument for the invention of which he was not primarily responsible. Sax also developed the saxotromba family, valved brass instruments with narrower bore than the saxhorns, in 1845, though they survived only briefly. Saxhorn instruments spread rapidly throughout the world. The saxhorn valves were accepted as state of the art and are largely unchanged today. On June 22, 1846 he registered the saxophone and won his gold medal at the Paris Industrial Exposition in 1849. By the ned of the year Sax had designed, on paper, a full range of saxophones (from sopranino to subcontrabass). Although they never became standard orchestral instruments, the saxophones made his reputation and secured him a job, teaching at the Paris Conservatoire in 1857. “Its principal merit in my view is the varied beauty of its accent, sometimes serious, sometimes calm, sometimes impassioned, dreamy or melancholic, or vague, like the weakened echo of an echo, like the indistinct plaintiff moans of the breeze in the woods and, even better, like the mysterious vibrations of a bell, long after it has been struck” (Hector Berlioz about the Saxophone) Sax’s workshop sold some 20,000 instruments between 1843 and 1860, but he was not a talented money manager, and sales were not enough to keep him solvent. He filed for bankruptcy three times, in 1852, 1873, and 1877, and he was saved from a fourth debacle only by the intervention of another of his admirers, Emperor Napoleon III. He also effected various improvements in piston instruments, of which the most important was the substitution of a single ascending piston for a number of descending ones. Sax suffered from lip cancer between 1853 and 1858 but made a full recovery. In 1870 Sax’s position at the Paris Conservatory was terminated in the aftermath of the Franco-Prussian War, and he lived his final years in straitened circumstances, kept out of poverty only by a small pension arranged for him by an admirer. He died in 1894 in Paris and was interred in the Cimetière de Montmartre. At yovisto, you can learn more about the saxophone in the lecture of Dr. Amy Muchnick on woodwind instruments, entitled “The Instrument Families 2“.'],\n",
       " [17,\n",
       "  'Edvard Munch and the Munch Affair.  Madonna by Edvard Munch Version from Munch Museum, Oslo Image: wikipedia.  On November 5, 1892, Norwegian painter and printmaker Edvard Munch evoked bitter controversy with his exhibition on behalf of the Union of Berlin Artists. Even though the exhibition was closed after only one week, the scandal made Munch highly famous. The event became later known as the ‘Munch Affair’. Edvard Munch was born on December 12, 1863 and grew up in Oslo. His family often faced hard times due to the fatal illnesses of his mother and sister. Also his brother Andreas died shortly after his marriage. These sad events are known to have highly affected Munch’s art in later years. He attended a technical school before dedicating his life to art. Due to his efforts, Munch was soon introduced to Norway‘s leading artist, Christian Krohg, whose works were influenced by Realism. The first success Munch’s came with the painting ‘The Sick Child‘ which presumably deals with his sister’s early death. A few years later, he painted a portrait of the leader of the Christiania bohemians Hans Jæger, who is known to have influenced Munch in this period. Munch began an extensive biographical literary production which he resumed at different periods in his life. These writings serve as a reference for several of the central motifs of the nineties. Munch was awarded a state travel grant for three years and went to Paris. Unfortunately, he was informed that his father passed away shortly after getting settled in France. The artist then painted several dark pictures including ‘Night’. In this period, Munch did first sketches of the famous ‘The Scream‘, which is often described at the first expressionistic picture. [1,3] Edvard Munch in 1902 Edvard Munch got the chance to present his art in France and was also invited to show his masterpieces to the Artist’s Association of Berlin. The event became widely known as a “succès de scandale” or better the Munch Affair. The press understood Munch‘s work as “pictures of an Ibsenesque mood arousing curiosity both on a social and psychological level“. It is assumed that these different opinions on Munch’s art origin from the polarized artistic life that Berlin and Paris had after the war between Germany and France of 1870/71. While Paris was known to be quite open to new impulses, Berlin was probably more striving for educational national art. The exhibition of Edvard Munch was opened with 55 works on November 5th, 1892at the “Architektenhaus”. Unfortunately, the conservative painter Anton von Werner, Director of the Imperial Academy of Fine Arts claimed that the exhibition should be closed to the general public because Munch’s masterpieces were degenerate art. The exhibition lasted for only seven days in total. However, throughout Germany, the people wanted to see an international scandal. The event made Munch famous over night. Also, the Berlin Secession was founded in Berlin, an association of progressive artists, with Max Liebermann as its first President. Munch’s scandal exhibition then toured Düsseldorf, Cologne, and reopened in Berlinin December the same year. Even though the artist did not sell anything, Munch earned an income from the ticket sales. The artist was well integrated in the Berlin circle of artists and intellectuals and stayed in the city for a few years. [2] Almost 20 years after Munch’s death in 1944, the Munch Museum at Tøyen was opened, which hosts about 1100 paintings as well as a few thousand drawings and prints. Munch‘s art was known to be quite personalized. His symbolism was personal, but his influence spread especially throughout the German expressionism. Munch was also the first known Western artist to have his pictures exhibited at the National Gallery in Beijing. In 1994, one version of The Scream was stolen, and another in 2004. The works were recovered but were severely damaged. The Scream was sold for $119.9 million in 2012. [1,3] At yovisto, you may be interested in a video lecture on German Expressionism by Cornelia Fey at San Diego.'],\n",
       " [18,\n",
       "  'Spyridon Marinatos and the Discovery of Akrotiri.    Archaeological site in Akrotiri, Santorini Image author: F. Eveleens.  On November 4, 1901, Greek archeologist Spyridon Nikolaou Marinatos was born. His most notable discovery was Akrotiri, the site of an ancient port city on the island of Thera, in the southern Aegean Sea. Spyridon Marinatos became along with Georgia Andrea the director of the Herakelion Museum in 1929. He was acquainted with Sir Arthur Evans, who became among other things famous for unearthing the palace of Knossos on the Greek island of Crete. Marinatos began gaining first excavation experiences as well, conducting several excavations on Crete at Dreros, Arkalochori, Vathypetro, and Gazi. He became professor at the University of Athens and began increasing his interest in the Mycenaeans, regarding them as the first Greeks. The archaeologist excavated sites in the Peloponnese including a royal tomb. Also, Marinatos performed excavations at the famous battle sites at Thermopylae and Marathon. [1] The first findings on the island of Santorini were made around 1867. A construction company found several old shards and remains of old walls. Henri Mamet and Henri Gorceix were the first known archaeologists to excavate remains of buildings and wall art. At Akrotiri, the first excavations were performed in 1899 by the German Robert Zahn, who found a building, jewelry and some fisher nets. However, it was back then not possible to accurately determine the finding’s age. Around 1939, Marinatos analyzed parts from the excavation site at Knossos and developed the theory, that the pumice the researchers found there originated from Santorini and that the floods resulting from the eruption could have been the reason for the sudden disappearance of the Minoan culture. About thirty years after World War II, Marinatos began performing excavations to further research on his theory. The archaeologist found a location, where the pumice layer was only 15m thick and already after four meters of digging, workers found jars from the Broze Age and at the second day of excavations, a two story building was spotted and excavated. After further days at the site, it became clear that Marinatos and his team found an entire city from the Bronze Age. Sadly, Spyridon Marinatos was killed during an accident at the excavation site. He was buried at Akrotiri and the excavations were interrupted for quite a while due to the sad incident. Even on this day, the excavations continue and are led by Marinatos‘ former assistant Christos Doumas. [2] fresco from the bronze age in the minoan town Akrotiri, Santorini, Greece Akrotiri of Thera is one of the most important prehistoric settlements of the Aegean. The first habitation probably dates from the late Neolithic times. During the early Bronze Age, a settlement was founded and in the middle and early late Bronze Age it was extended and developed into one of the main urban centers and ports of the Aegean. Researchers were mostly impressed by the large extent of the settlement, the elaborate drainage system, the multi storey buildings with magnificent wall-paintings, furniture, and vessels. It is also assumed that due to the numerous imported objects, the inhabitants had a wide network of external relations. The town’s life came to an abrupt end in the last quarter of the 17th century B.C. when the inhabitants were obliged to abandon it as a result of severe earthquakes, followed by the eruption. The volcanic materials covered the entire island and the town itself. These materials, however, have protected up to date the buildings and their contents, just like in Pompei. [3] At yovisto, you may be interested in a video on the Ancient Minoans Aegean Empire.'],\n",
       " [19,\n",
       "  'Daniel Rutherford and the isolation of Nitrogen.  Daniel Rutherford (1749-1819). On November 3, 1749, Scottish physician, chemist and botanist Daniel Rutherford was born. Rutherford was the uncle of famous novelist Sir Walter Scott. But originally, he is most famous for the isolation of nitrogen in 1772. The second son of Professor John Rutherford and his second wife Anne Mackay, Daniel Rutherford was born in Edinburgh on 3 November 1749. Educated at first at home, he was sent, when seven years old, to the school of a Mr. Mundell, afterwards to an academy in England, and thence to the University of Edinburgh, where, after graduating M.A., he entered on his medical studies. There, he obtained his diploma as M.D. 12 Sept. 1772, his inaugural dissertation being ‘De aere fixo dicto aut Mephitico.’ [1] The dissertation opens with an account of the work of Joseph Black and of Henry Cavendish on ‘fixed’ or ‘mephitic air’ (i.e. carbonic acid). Rutherford proceeds to point out that ‘by means of animal respiration’ pure air not only in part becomes mephitic, but also undergoes another singular change in its nature. The mephitic air he supposes to have been probably generated from the food, and to have been expelled as a harmful substance from the blood, by means of the lungs. He found experimentally that air passed over ignited charcoal and treated with caustic lye behaves in the same way as air made noxious by respiration. He continued that when a metal, phosphorus, or sulphuris calcined in air (probably in the case of the sulphurin the presence of water), the residual gas contains no ‘mephitic air,’ but only undergoes the ‘singular change’ above referred to. The remaining air did not support combustion, and a mouse could not live in it. Rutherford gave no name to the residual gas, but referred to it only as “noxious air” or “phlogisticated air”. Being convinced of the contemporary phlogiston theory that postulated a fire-like element called phlogiston, contained within combustible bodies and released during combustion – Rutherford explained his results in terms of it. The residue of air left after burning, in fact a mixture of nitrogen and carbon dioxide, was therefore referred to as phlogisticated air, having taken up all of the phlogiston. Phlogiston remained the dominant theory until the 1780s when Antoine-Laurent Lavoisier showed that combustion requires a gas that has mass (oxygen) and could be measured by means of weighing closed vessels. Nowadays, the gas is called nitrogen, introduced from the French nitrogène, coined in 1790by French chemist Jean-Antoine Chaptal. The name comes from its Greek roots, nitron (meaning “saltpeter”, modern potassium nitrate) and genes (meaning “forming”) and Rutherford was given credit for discovering it, though his conclusions were somewhat incorrect. Nitrogenis one of the most abundant elements in the atmosphere(~78%) and is found in all proteins and nucleic acids. Nitrogenis an inert (relatively non-reactive) gas that has the atomic number of seven and forms many inorganic compounds that are used as fertilizers and noxious gases. After publication and having completed his university course, Rutherford travelled in England, went to Francein 1773, and thence to Italy. He returned in 1775 to Edinburgh, where he began to practise. He became a licentiate of the Royal College of Physicians of Edinburgh in 1776 and a fellow the year after. He was president of the college from December 1796 to Dec. 1798. In 1786, he succeeded Dr. John Hope as professor of botany in the university and keeper of the Royal Botanic Garden at Edinburgh. When ten years old Rutherford suffered from gout, which increased in severity in later life, and was probably the cause of his sudden death, on 15 November 1819. Learn more about gases in the yovisto lecture of Prof. Sylvia Ceyer from MIT’s Open Course Ware on ‘Kinetic Theory – Behavior of Gases‘.'],\n",
       " [20,\n",
       "  'Alexander Lippisch and the Delta Wing.  Convair XF-92A Image: Nasa.  On November 2, 1894, German pioneer of aerodynamics and aviation Alexander M. Lippisch was born. He made important contributions to the understanding of flying wings, delta wings and the ground effect. His designs of tailless and delta-winged aircraft in the 1920s and 1930s were important in the development of high-speed jet and rocket airplanes. His most famous design is the Messerschmitt Me 163 rocket-powered interceptor. In 1909, Lippisch is assumed to have witnessed a flight by Orville Wright in Berlin Tempelhof, which highly fascinated him. However, the young man still planned to follow his father’s footsteps and enter art school. However, during World War I, Lippisch was able to fly as an aerial photographer and mapper and kept this interest in flying after the war. He became increasingly fascinated by tail-less aircraft and finished his first design in 1921, which was called the Lippisch-Espenlaub E-2 glider. This was the first of his designs that would reach production and it was built by Gottlob Espenlaub. In 1924, Lippisch was appointed Director of the Aeronautical Department of the RhonRossitten-Gesellschaft (RRG, which later became the German Research Institute for Soaring Flight). Alexander Lippisch developed his designs step by step, first testing his concepts as a flying model, then as a man-carrying glider followed by the design of the powered aircraft. He preferred this method over expensive wind tunnel experiments. From his further designs in the period evolved his Storch model and his delta-wing designs. In 1929, the Storch IV glider demonstrated impressive stability and control characteristics with Gunther Gronhoff at the controls. The craft was demonstrated at the Tempelhof Airfield in Berlin, where Lippisch once saw Orville Wright and the young engineer hoped to receive financial backing from the government. Even though the government was not highly interested, the pilot Captain Herman Kohl was and he expressed his interest in the idea of a tailless aircraft for flights across the Atlantic. The engineer interrupted his work on the Storch series and developed the renowned Delta series. [1] In June 1931, the powered Delta I was flown and since Gunther Gronhoff’s test flights were so successful, another demonstration at Tempelhof as conducted with great success. The Delta I was the world’s first tailless delta wing aircraft to actually fly. Lippisch’s interest resulted in a total of five aircraft, numbered Delta I – Delta V, which were built between 1931 and 1939. [1,2] During a research program with wind tunnels, it was found that the delta wing was an advantage for supersonic flight and the engineer set to work designing a supersonic, ramjet-powered fighter, the Lippisch P.13a. However, the project had only advanced as far as a development glider, the DM-1. After World War II, Lippisch came to the United States in order to design a hybrid jet/rocket engine. After the F-92, the Convair XF-92 was developed and led Convair to proposing delta wing for most of their projects through the 1950s and into the 1960s, including the F-102 Delta Dagger, F-106 Delta Dart and B-58 Hustler. At yovisto, you may be interested in a detailed interview with a former pilot of a delta winged Blackbird, who discusses his experiences in the air and talks about myths concerning the aircraft and their missions.'],\n",
       " [21,\n",
       "  'Oskar Barnack – the Father of 35mm Photography.  Oskar Barnack (1879-1936). On November 1, 1879, German optical engineer, precision mechanic, and industrial designer Oskar Barnack was born. He is often referred to as the father of 35 mm photography for his invention of the first miniature commercially successful camera, the Leica. In the age of digital photography, something like 35 mm film might seem like some forgotten relict. But, it really was a revolution that brought photography too the masses – in the same way as the invention of the film roll and its application in the famous Kodak box camera almost 50 years earlier. Actually, very little is only known about the private life of Oskar Barnack. Most known information about his life concerns his creation. Born in Lynow, Brandenburg, a hamlet south of Berlin, Barnack was a master mechanic and inventor working for the Carl Zeiss company, when he received the offer to join the Ernst Leitz Optische Werke in Wetzlar in 1911. There, he was in charge of microscope research for Ernst Leitz at Wetzlar, Hessen, Germany, as head of the construction department. He was an enthusiastic photographer, but the heavy equipment of the day was difficult for him to handle due to his poor health. Thus, he sought to reduce the size and weight of cameras and supporting equipment used for outdoor photography. As early as 1905, he had the idea of reducing the format of negatives and then enlarging the photographs after they had been exposed, involving a small camera and an enlarger.In 1912, he constructed already a 35 mm movie camera. Between 1913 and 1914 he developed the Ur-Leica, a prototype camera using 35mm motion picture film. From the start, the film was transported horizontally and not vertically, as was the case with movie cameras. The format 24×36mm, a format we’ve all been accustomed to, was obtained by doubling the normal movie-image. At the time, most cameras were equipped with glass plates or roll film. While cumbersome, their large negatives eliminated the need for enlargement. But lenses and films had reached a level that reduced the quality of getting prints through enlarging.[2] Instead of the exposure plates used in past Leitz cameras, the Leica used a standardized film strip, adapted from 35 mm Eastman Kodak roll-film. Barnack decided that the 18 x 24 mm (3:4 aspect ratio) standard movie frame was not large enough for good still photo quality with the films of the day and doubled the frame size to 24 x 36 mm (2:3 aspect ratio), with the image horizontal instead of vertical. Another Leitz employee, Max Berek, was instrumental in developing a lens for this camera, as he developed the first 50mm f/3.5 lens as the optimum focal length for the 24 x 36mm format. the ‘original’ Leica from 1914 His 35 mm design helped introduce the concept of exposing a small area of film to create a negative, then enlarging the image in a darkroom. The onset of World War I  kept the first Leica from being manufactured until 1924, and it was not introduced to the public until 1925, when Leica’s chief, the optician Ernst Leitz, took a gamble and authorized the production of 1,000 cameras. Despite of other contemporary successful early 35mm camera models should the early Leicas became the most influential 35mm cameras. Many other camera makers started their 35mm camera business by simply copying original Leica models, often disregarding any legislation against product piracy. Some renowned companies learned to make sophisticated camera mechanics that way, and switched later to the production of own 35mm camera constructions.[2] Barnack’s invention has changed photography significantly. The Leica was extremely compact and could be fitted with a very high quality lens that enabled photographers to work in ordinary outdoor settings with available light. It was always instantly ready to capture life and action effortlessly from any angle with the photographer often able to remain unnoticed. Without the usual heavy equipment, photographs of people no longer had to be confined to stiff conventionally artistic poses.[3] Eleven years after its introduction in 1935, the camera and enlarger section was the most profitable for the Leitz company that still produced microscopes and huntingscopes. At yovisto you can learn more about the history of photography in the presentation of Nancy Crandall about the origins and beginnings of photography.'],\n",
       " [22,\n",
       "  'Adolf von Baeyer and the Color Blue.  Adolf von Baeyer (1835 – 1917).  On October 31, 1835, German chemist and Nobel Laureate Johann Friedrich Wilhelm Adolf von Baeyer was born. He was the first who succeeded with the synthesis of indigo (1880) and formulated its structure (1883), for which he was awarded the Nobel Prize for Chemistry in 1905. Johann Friedrich Wilhelm Adolf von Baeyer was interested in chemical experiments from early age. His father was a lieutenant-general and originated the European system of geodetic measurement. Von Baeyer enrolled at the University of Berlin in 1853 studying mostly mathematics and physics. He visited Bunsen‘s laboratory in Heidelberg and began working on methyl chloride. Von Baeyer published his first work in 1857 and was able to start working at Kekulé’s private laboratory in Heidelberg. He became interested in the ingenious structure theory and received his doctorate in 1858 in Berlinfor his work on cacodyl compounds which had been done in Kekulé’s laboratory. [1,3] About two years later, the scientist became university teacher and lecturer in organic chemistry at the “Gewerbe-Akademie” in Berlin. In 1866, the University of Berlin, at the suggestion of A.W. Hofmann, conferred on him a senior lectureship, which, however, was unpaid. In this period however, Baeyer started his work on indigo, which soon led to the discovery of indole and to the partial synthesis of indigotin. Also in this period, Baeyer developed his theory of carbon-dioxide assimilation in formaldehyde. He was appointed chair at the University of Munich after Justus von Liebig had passed away and Baeyer was able to perform the synthesis of indigo. One year later, in 1881, the Royal Society of London awarded him the Davy Medal for his work with indigo. To celebrate his 70th birthday, a collection of his scientific papers was published in 1905. [1,2] Adolf von Baeyer‘s work was known to be completed with admirable penetration and extraordinary experimental skill. He was careful never to overestimate the value of a theory. While Kekulé sometimes approached Nature with preconceived opinions, von Baeyer would say: “I have never set up an experiment to see whether I was right, but to see how the materials behave“. Even in old age his views did not become fixed, and his mind remained open to new developments in chemical science. [1] At yovisto, you may be interested in a short video on how to create indigo.'],\n",
       " [23,\n",
       "  'Hans Grade – German Aviation Pioneer.  Hans Grade before takeoff, 1912.  On October 30, 1909, German aviation pioneer Hans Grade won the 40.000 Reichsmark “Lanz-Preis der Lüfte”, flying a new monoplane design, the ‘Libelle’ (Dragon Fly), the first really airworthy motor plane of Germany. Most probably, you have never heard of Hans Grade, who is also scarcely known in his home country. Nevertheless, he is one of the early pioneers of aviation and today, we will tell his story. Hans Grade was born on May 17, 1879, in Köslin, the largest city of Middle Pomerania in today’s north-western Poland. Working as a trainee in mechanical engineering in Grevenbroich, Cologne, he studied engineering at the Technische Hochschule in Charlottenburg, Berlin from 1900 to 1904. In 1903, Grade designed and constructed his first motorbike in Köslin and took over an engine workshop. In 1905, he founded the Grade-Motoren-Werke GmbH in Magdeburg and in 1907, he began experiments with a triplane at Magdeburg Athletic Field. On 28 October 1908he successfully conducted the first motor-flight over German soil in a motorized triplane aircraft of his own construction at Magdeburg, where he succeeded in making a short hop, attaining an altitude of 8 meters. In September 1909, he made the first recognized flight of a German designed and built airplane from the Johannisthal Aerodome at Berlin. The first flights were scarcely more than hops, but by November, 1909, he had logged one journey of 55 minutes duration. On 30 October 1909, flying a new monoplane design he won the 40.000 Reichsmark “Lanz-Preis der Lufte”, for the first German to fly a flat “8” in a German aircraft with German engine around two pylons 1000 meters apart, no match for pilots from other nations at that time. In 1910, Grade established the first aviation school in Germany. Grade continued with air displays in Hamburg, Bremen, Breslau and Magdeburg. On April 10, 1910, Grade sets an altitude record in Magdeburg of 1450 meters and in 1912 he was awarded The Crown Medal 4th class by the German Emperor. It was also a Grade monoplane that carried Germany’s first air mail, when pilot Pentz made a flight from Bork to Bruck in February 1912 with a small sack of mail in his lap. Although successful, Grade monoplanes did not become as famous as many contemporary European designs, and for this reason comparatively few were built. The small aircraft company, founded with his prize money, did not survived the Versaille-agreement of 1918. His extraordinary construction of driving a car with no use of a gear-box did not stand against the established constructions. In 1921 he established an automobile company called “Grade Automobilwerke AG“, which produced small, 2 seater personal cars. The Grade Automobilwerke AG was closed in 1927 owing to financial difficulties. After the Nazi takeover in the 1930s Grade tried, without success, to develop a new Volksflugzeug and in 1934 he undertook research projects for the German aircraft manufacturers. In 1939 May 14 he re-flew his original monoplane from 1909, then 30 years old, at Berlin Tempelhof Airport for about 550 metres to celebrate his sixtieth birthday. Hans Grade died in 1946 at the age of 67. At yovisto you can learn more about the future of aviation and space flight in the presentation from Marc Millis on ‘Space Flight Predictions: After AI & Transhumanism‘'],\n",
       " [24,\n",
       "  'Othniel Charles Marsh and the Great Bone Wars.  O.C. Marsh (back row and center), surrounded by armed assistants for his 1872 expedition. On October 29, 1831, American paleontologist Othniel Charles Marsh was born. Being one of the preeminent scientists in the field, he discovered over 1000 fossils and contributed greatly to knowledge of extinct North American vertebrates. From the 1870s to 1890s he competed with rival paleontologist Edward Drinker Cope in a period of frenzied Western American expeditions known as the Bone Wars. The term “paleontology” was coined just nine years before Othniel Charles Marsh‘s birth October 29, 1831 on a farm in Lockport, New York. A family of modest means, his father’s only ambition for his son was that he become a field hand on the family farm. But his mother Mary was the younger sister of famous banker and philanthropist George Peabody. Unfortunately she died when the boy was not quite 3 years old. With the support of his millionaire uncle, Marsh graduated from Phillips Academy, Andover in 1856 and Yale College in 1860. He then studied geology and mineralogy at Yale’s Sheffield Scientific School (1860-1862), and afterwards paleontology and anatomy in Berlin, Heidelberg and Breslau (1862-1865). He returned to the United States in 1866 and was appointed the first Professor of vertebrate paleontology at Yale University in the U.S. It was at this time, in the early 1860s, while Peabody was making plans for the eventual distribution of his fortune to worthy causes, that Marsh persuaded him to include Yale in his list of beneficiaries and to establish the Peabody Museum of Natural History at Yale with a gift of $150,000. In 1867 he was appointed one of the Museum’s first curators, and also assumed the (unofficial) directorship of the Museum which he had been instrumental in establishing.[2] Marsh himself received a substantial inheritance after Peabody’s death in 1869, which spared him the necessity of receiving a salary from Yale — and doing the teaching to earn it. Marsh should meet his strongest competitor and opponent Edward Drinker Cope, while being in Berlin as a graduate student. Edward Drinker Cope was born nine years after Marsh on July 28, 1840 to a wealthy family in Pennsylvania. He took an immediate liking to natural history as a child and attended classes at the Academy of Natural Sciences in Philadelphia. At 18, Cope published his first scholarly article while working as a researcher at the Academy of Natural Sciences. In 1863, to avoid Cope being drafted into the Civil War, Cope’s father sent his son to Germany to study natural history. There he met fellow graduate student O.C. Marsh at age thirty-two, also attending the University of Berlin. Marsh held two university degrees in comparison to Edward’s lack of formal schooling past sixteen, but Edward had written 37 scientific papers in comparison to Marsh’s two published works. Upon returning to the U.S. in 1864, Cope and Marsh maintained their friendly relationship and maintained correspondence, exchanging manuscripts, fossils, and photographs.[4] Legend has it that the battle between the men began when Marsh paid some of Cope’s hired diggers to send fossils to him and not to Cope. Matters became worse in 1870, when Cope published a description of Elasmosaurus, a giant plesiosaur – and Marsh gleefully pointed out that Cope had accidentally placed the skull on the wrong end of the beast. The battle was on: for the next twenty years, the two men attacked and slandered each other in print, while they and their crews raced to find and describe the most and the finest new fossils. Each scientist hired field crews to unearth and ship back fossils as fast as possible. The rival crews were known to spy on each other, dynamite their own and each other’s secret localities to keep their opponents from digging there, and occasionally steal each other’s fossils – all the time exposed to harsh conditions and danger from hostile Native Americans. Marsh eventually “won” the so-called “Bone Wars” by finding 80 new species of dinosaur, while Cope found 56. Cope did not take this lightly, and the two fought within scientific journals for many years to come, rumored to be at the expense of recognized scientific method.[4] Credited with the discovery of more than a thousand fossil vertebrates and the description of at least 500 more, Marsh published major works on toothed birds, gigantic horned mammals, and North American dinosaurs. He also wrote Fossil Horses in America (1874) and Introduction and Succession of Vertebrate Life in America (1877). Marsh garnered national attention in the late 1860s when he revealed that the alleged remains of a prehistoric man known as the Cardiff Giant were fake.[3] O.C. Marsh died on March 18, 1899, a few years after his great rival Cope At yovisto you can learn more about paleontology in the TED talk of Dr. Paul Sereno on ‘What can Fossils Teach Us?‘.'],\n",
       " [25,\n",
       "  'Constantine and the Battle at the Milvian Bridge.  Battle of the Milvian Bridge by Giulio Romano, 1520-24.  On October 28, 312 AD, the Battle of the Milvian Bridge between the Roman Emperors Constantine I and Maxentius took place. Constantine won the battle and started on the path that led him to end the Tetrarchy and become the sole ruler of the Roman Empire. According to historians, the battle marked the beginning of Constantine’s conversion to Christianity and thus fostered the rise of Christianity. So, just another of those Roman Battles After Diocletian stepped down on 1 May 305, his successors began to struggle for control of the Roman Empire almost immediately. Although Constantine was the son of the Western Emperor Constantius, the Tetrarchic ideology did not necessarily provide for hereditary succession. When Constantius died on 25 July 306, his father’s troops proclaimed Constantine as Augustus in Eboracum (York). In Rome, the favorite was Maxentius, the son of Constantius‘ imperial colleague Maximian, who seized the title of emperor shortly after on 28 October 306. But whereas Constantine’s claim was recognized by Galerius, ruler of the Eastern provinces and the senior emperor in the Empire, Maxentius was treated as a usurper. Galerius ordered his co-Augustus, Severus, to put him down in early 307. Once Severus arrived in Italy, however, his army defected to Maxentius. Severus was captured, imprisoned, and executed. Galerius himself marched on Rome in the autumn, but failed to take the city. Constantine avoided conflict with both Maxentius and the Eastern emperors for most of this period. By 312, however, Constantine and Maxentius were engaged in open hostility with one another, although they were brothers in law. In the spring of 312, Constantine gathered his forces and decided to oust Maxentius himself. He easily overran northern Italy, winning two major battles: the first near Turin, the second at Verona. It is commonly stated that on the evening of 27 October with the armies preparing for battle, Constantine had a vision which led him to fight under the protection of the Christian God. The details of that vision, however, differ between the sources reporting it. From Eusebius, two accounts of the battle survive. The first, shorter one in the Ecclesiastical History promotes the belief that God helped Constantine but does not mention any vision. In his later Life of Constantine, Eusebius gives a detailed account of a vision and stresses that he had heard the story from the Emperor himself. According to this version, Constantine with his army was marching, when he looked up to the sun and saw a cross of light above it, and with it the Greek words “[you shall] conquer When the two armies clashed at the Milvian Bridge in Rome, Constantine won a decisive victory. The dispositions of Maxentius may have been faulty as his troops seem to have been arrayed with the River Tiber too close to their rear, giving them little space to allow re-grouping in the event of their formations being forced to give ground. The temporary bridge set up alongside the Milvian Bridge, over which many of the Maxentian troops were escaping, collapsed, and those stranded on the north bank of the Tiber were either taken prisoner or killed. Maxentius was among the dead, having drowned in the river while trying to swim across it in a desperate bid to escape or, alternatively, he is described as having been thrown by his horse into the river. Constantine’s victory gave him total control of the Western Roman Empire paving the way for Christianity to become the dominant religion for the Roman Empire and ultimately for Europe. The following year, 313, Constantine and Licinius issued the Edict of Milan, which made Christianity an officially recognised and tolerated religion in the Roman Empire. At yovisto you can learn more the Roman Empire under emperor Constantine in the lecture series of Prof Diana Kleiner on Roman Architecture about ‘Rome of Constantine and a New Rome‘.'],\n",
       " [26,\n",
       "  'Jean-Rondolphe Perronet and the Bridges of Paris.  Jean-Rodolphe Perronet (1708-1794). On October 27, 1708, French architect and structural engineer Jean-Rodolphe Perronet was born. He is best known for his many stone arch bridges, among them his most popular work, the Paris Pont de la Concorde. Jean-Rodolphe Perronet was born in Suresnes, a suburb of Paris, the son of a Swiss Guardsman. At 17 he entered the architectural practice of Jean Beausire, “first architect” to the city of Paris, as an apprentice. He was put in charge of the design and construction of Paris’s grand sewer, embankment works and the maintenance of the banlieue’s roads. In 1735, he was named sous-ingénieur (under-engineer) to Alençon. Perronet’s perceived energy for the district of Alençon came to the notice of Trudaine – the overseer of finances in charge of roads – who put him in charge of training surveyors and those drawing maps to provide competent staff for the Ponts et Chaussées - Bridges and Embankments (Civil Engineering Department) in 1736. [3] In 1737, he became sous-ingénieur, then engineer to the généralité of Alençon. In 1747, Perronet was named director of the Bureau des dessinateurs du Roi (Royal office of designers), which had also just put Daniel-Charles Trudaine in charge of producing maps and plans for the kingdom. This first École des ponts et chaussées was based in the hôtel Libéral Bruant in Paris. Perronet was given the task of training bridge and road engineers and of overseeing their work in the généralités in which they worked. The Bureau became the Bureau des élèves des ponts et chaussées, then in 1775 was renamed the École des ponts et chaussées. Its organiser, inspiration and teacher, Perronet was a true spiritual father to his students and used a new teaching method which seems very contemporary to modern eyes. During this time he became friends with the Swiss bridge-builder Charles Labelye. Perronet was an outstanding leader and teacher, and the “spiritual father” of the 350 engineers he trained during the 47 years in which he directed the School. Once they had qualified from the School, Perronet was often responsible for their appointments and then followed their progress and gave them advice throughout their careers. Perronet’s work as an engineer is just as remarkable and innovative as his work as an administrator. During construction of a bridge at Mantes in 1763, Perronet made the discovery that the horizontal thrust of a series of elliptical arches was passed along to the abutments at the ends of the bridge. Armed with this knowledge, he carried the stone arch bridge to its ultimate design form, with extremely flat arches that were supported during construction by timbering (falsework) and mounted on very slender piers, which widened the waterway for navigation and reduced scour from the current.[2] Pont de Neuilly, completed in 1794 Besides his 13 bridges, he constructed more than 2500 km of tree-lined roads when working for the District of Paris, but also worked as a hydraulic engineer on the Canal de l’Yvette [3] The best-known bridges — among the thirteen that Perronet designed — are the Pont de Neuilly (completed 1774 and often called the most graceful stone bridge ever built), the Pont Sainte-Maxence (1785), and the Pont de la Concorde (1791), still standing. Perroner was named premier ingénieur du roi in 1763 and became a member of the associate of the Académie des sciences in 1765. Besides his bridges, he also contributed the article Pompe à feu (fire-engine) to the Encyclopédie ou Dictionnaire raisonné des sciences, des arts et des métiers. In 1772, Perronet was elected a foreign member of the Royal Swedish Academy of Sciences. He was 80 years old when he began the Pont de la Concorde, originally called the Pont Louis XV, in 1787. Despite the outbreak of the French Revolution, he kept the work going, completing it in 1791. In 1794, Perronet died in Paris, aged 85. At yovisto, unfortunately we don’t have a video featuring the work of Jean-Rodolphe Perronet. Nevertheless, you might be interested in a lecture of Design Thinking by Timothy Brown about ‘Designers should think big‘.'],\n",
       " [27,\n",
       "  'Giovanni Maria Lancisi and his Medical Discoveries.  Giovanni Maria Lancisi (1654-1720). On October 26, 1654, Italian physician, epidemiologist and anatomist Giovanni Maria Lancisi was born. A personal physician to three popes, he is considered the first modern hygienist. He made a correlation between the presence of mosquitoes and the prevalence of malaria. He was also known for his studies about cardiovascular diseases, and is remembered in the eponymous Lancisi’s sign. Giovanni Maria Lancisi, also often referred to under his Latinized name Johannes Maria Lancisius, was educated at the Collegio Romano and the University of Rome, where he studied philosophy and liberal arts. He also briefly studied theology, but became progressively interested in natural history. Finally, he turned his attention to medicine and enrolled in the senior college of the Sapienza at Rome from where he graduated as Doctor of Philosophy and Medicine in 1672. [3] In 1684, Lancisi was appointed Public Professor of Anatomy in the Senior College of the University of Sapienza in Rome. Ag ate 34, Lancisi was appointed physician to Pope Innocent XI and in 1689 after the Pope’s death subsequently he was physician to Popes Innocent XII and Clement XI. Lancisi wrote the classic monograph De subitaneis mortibus (1707, “On Sudden Death”) at the request of Clement XI to explain an increase in the number of sudden deaths in Rome. Lancisi attributed sudden death to such causes as cerebral hemorrhage, cardiac hypertrophy and dilation, and vegetations on the heart valves. This treatise and De motu cordis et aneurysmatibus (1728, “On the Motion of the Heart and on Aneurysms”), in which he discussed the various causes of heart enlargement and was the first to describe aneurysms of syphilitic origin, markedly contributed to knowledge of cardiac pathology. Although a clear description of angina pectoris would not appear for more than half a century, Lancisi described complaints which surely represented this entity. He wrote, “internal pains of the chest, accompanied at one moment by difficulty of breathing, especially when ascending hills, and at another by a strangling sensation of the heart and frequently by an uneven pulse … are apt to kill out of time, particularly if the patients subject themselves to violent exertions and glut themselves with unwholesome food. ”Lancisi also published De Noxiis Paludum Effluviis (On the Noxious Effluvia of Marshes) in 1717, in which he recognized that mosquito-infested swamps are the breeding ground for malaria and recommended drainage of these areas to prevent it. He was given the lost anatomical plates of Bartolomeo Eustachius by Pope Clement XI. These plates were made in 1562 and had been forgotten in the Vatican Library. Lancisi edited and published them in 1714 as the Tabulae anatomicae. Early in the 18th century, Lancisi had protested the medieval approaches to containing rinderpest in cattle by famously stating that “it is better to kill all sick and suspect animals, instead of allowing the disease to spread in order to have enough time and the honour to discover a specific treatment that is often searched for without any success”. It was no wonder then, that it was the same Giovanni Maria Lancisi who made the first breakthrough in the control of rinderpest, a procedure that was later adopted by Thomas Bates. Arguably, Lancisi’s most notable medical contribution was the anatomical description of the medial longitudinal striae of the corpus callosum, in addition to other documents he wrote in the field of neurology. Lancisi was a multifaceted man with vast interests outside of medicine including language and literature.[2] Lancisi died in 1720 after brief illness. At yovisto, you can learn more about Malaria, one of the diseases Giovanni Maria Lancisi was struggling with in the lecture of Gresham College Prof. Francis Cox on “Twenty-first Century Threats: Malaria“.'],\n",
       " [28,\n",
       "  'William Higinbotham and Tennis for Two.  Tennis for Two played on an Oscilloscope.  On October 25, 1910, US-american physicist William “Willy” A. Higinbotham was born. A member of the Manhattan Project, he later became a leader in the nonproliferation movement of nuclear weapons. Moreover, he is also known for his development of ‘Tennis for Two‘, the first interactive analog computer game and one of the first electronic games to use a graphical display. William Alfred Higinbotham was born in Bridgeport, Connecticut, and grew up in Caledonia, New York. His father was a minister in the Presbyterian Church. He earned his undergraduate degree from Williams College in 1932 and continued his studies at Cornell University. He worked on the radar system at MIT from 1941 to 1943. During World War II, he worked at Los Alamos National Laboratory and headed the lab’s electronics group in the later years of the war, where his team developed electronics for the first nuclear bomb. His team created the bomb’s ignition mechanism as well as measuring instruments for the device. Higinbotham also created the radar display for the experimental B-28 bomber. Following his experience with nuclear weapons, Higinbotham helped found the nuclear nonproliferation group Federation of American Scientists, serving as its first chairman and executive secretary. From 1974 until his death in 1994, Higinbotham served as the technical editor of the Journal of Nuclear Materials Management. The History of video games dates back to the time directly after World War 2. In 1947 Higinbotham took a position at Brookhaven National Laboratory, where he worked until his retirement in 1984. In 1958, Higinbotham created Tennis for Two to cure the boredom of visitors to Brookhaven National Laboratory. He learned that one of Brookhaven‘s computers could calculate ballistic missile trajectories and he used this ability to form the game’s foundation. The game was created on a Donner Model 30 analog computer. The game uses an oscilloscope as the graphical display to display the path of a simulated ball on a tennis court. The designed circuit displayed the path of the ball and reversed its path when it hit the ground. The circuit also sensed if the ball hit the net and simulated velocity with drag. Users could interact with the ball using an analog aluminum controller to click a button to hit the ball and use a knob to control the angle. Hitting the ball also emitted a sound. The device was designed in about two hours and was assembled within three weeks with the help of Robert V. Dvorak. In fact, when the game was first shown on October 18, 1958, hundreds of visitors lined up to play the new game during its debut. It was such a hit that Higinbotham created an expanded version for the 1959 exposition[3] Higinbotham remained little interested in video games, preferring to be remembered for his work in nuclear nonproliferation. At yovisto, you can see the original version of Tennis for Two.'],\n",
       " [29,\n",
       "  'Charles Joseph Minard and the Art of Infographics.  Charles Joseph Minard (1781-1870). On October 24, 1870, French civil engineer Charles Joseph Minard passed away. He is best noted for his ground breaking inventions in the field of information graphics. Charles Joseph Minard was born on March 27, 1781, in Dijon, France, as the son of Pierre Etienne Minard, a clerk of the court and an officer of the secondary school, and Benign Lame lady. He was baptized at Saint Michel on the day of his birth. At age four Minard learned to read and to write, and when he was six his father enrolled him an elementary course in anatomy. He completed his fourth year of study at the secondary school at Dijon early, and then applied himself to studying Latin, literature, and physical and math sciences. At age 15, he was admitted to the prestigious École Polytechnique, where among his professors among others Lagrange and Fourier made a profound impression on him [1]. He left there in order to study civil engineering at École nationale des ponts et chaussées (the School of Bridges and Roads). In September 1810 he was sent by the government to Anvers and then almost immediately to the port of Flessingue. There, he solved a critical problem with a cofferdam that was leaking water faster than it could be removed. He solved the problem by using pumps driven by a steam engine, only the third time this solution had been applied to a project. He worked for many years as a civil engineer on the construction of dams, canals and bridge projects throughout Europe. On November 1, 1830, he was named superintendent of the School of Bridges and Roads, where he continued to serve through 1836. While there he was awarded the cross of the Legion of Honor. He then became inspector of the Corps of Bridges until he retired in 1851, after which he dedicated himself to private research. Charles Minard’s map of Napoleon’s disastrous Russian campaign of 1812. Minard was a pioneer of the use of graphics in engineering and statistics. He first began to publish cartes figuratives (figurative maps) during the mid-1840s, when he was nearly sixty-five years old. Most of his early maps dealt with flows of goods and passengers along railroad, river and oceangoing routes of commerce. Minard’s maps became renowned around France not so much for their statistical or cartographic merits, but for the style he used in visualizing the numerical and relational aspects of flows.[2] He is most well known for his famous cartographic depiction of numerical data on a map of of Napoleon’s disastrous losses suffered during the Russian campaign of 1812 (Carte figurative des pertes successives en hommes de l’Armée Française dans la campagne de Russie 1812-1813). The illustration is perhaps the single best-known statistical graphic of the nineteenth century and depicts Napoleon’s army departing the Polish-Russian border. A thick band illustrates the size of his army at specific geographic points during their advance and retreat. It displays six types of data in two dimensions: the number of Napoleon’s troops[2,3] This type of band graph for illustration of flows was later named Sankey diagram. At yovisto you can learn more about the visualization of statistical data in the famous TED-talk of Prof. Hans Rosling on ‘Let my dataset change your mindset‘.'],\n",
       " [30,\n",
       "  'Felix Bloch and the Nuclear Magnetic Resonance Method.  Felix Bloch (1905 – 1983) Image: Stanford University / Courtesy Stanford News Service.  On October 23, 1905, Swiss-born American physicist Felix Bloch was born. He is best known for his investigations into nuclear induction and nuclear magnetic resonance, which are the underlying principles of MRI. He was awarded the 1952 Nobel Prize in Physics for developing the nuclear magnetic resonance (NMR) method of measuring the magnetic field of atomic nuclei. Felix Bloch was educated at the Eidgenössische Technische Hochschule in Zurich, starting out in engineering. Later on, he increased his interest in physics and attended the lectures of Peter Debye and Hermann Weyl at ETH Zürich and Erwin Schrödinger at the University of Zurich. One of his fellow students was also John von Neumann. Bloch graduated in 1927 and continued his studies at the University of Leipzig. There, he met and studied with Werner Heisenberg, he received his Ph.D. in 1928. His doctoral thesis established the quantum theory of solids, using Bloch waves to describe the electrons. Bloch remained in Europe in the following period. He studied with Wolfgang Pauli in Zürich, Niels Bohr in Copenhagen and Enrico Fermi in Rome. He was then appointed privatdozent in Leipzig and had to leave Germany due to the rise of the Nazi party. Bloch continued his career at Stanford University and later Berkeley. He became a citizen of the United States and worked on nuclear power at Los Alamos National Laboratory during World War II before resigning to join the radar project at Harvard University. Felix Bloch focused on his research on nuclear magnetic resonance and nuclear induction. Nuclear magnetic resonance was first described and measured in molecular beams by Isidor Rabi around 1938. In 1944, Rabi was awarded the Nobel Prize in physics for this work on the topic. About two years later, Felix Bloch and Edward Mills Purcell expanded the technique for use on liquids and solids, for which they shared the Nobel Prize in Physics in 1952. The three scientists, Rabi, Bloch, and Purcell observed that magnetic nuclei could absorb RF energy when placed in a magnetic field and when the RF was of a frequency specific to the identity of the nuclei. When this absorption occurs, the nucleus is described in resonance. Different atomic nuclei within a molecule resonate at different frequencies for the same magnetic field strength. The observation of such magnetic resonance frequencies of the nuclei present in a molecule allows any trained user to discover essential chemical and structural information about the molecule. The development of Nuclear Magnetic Resonance as a technique in analytical chemistry and biochemistry parallels the development of electromagnetic technology and advanced electronics and their introduction into civilian use. At yovisto, you may be interested in a video lecture on MRI-Driven Turbulence – MRI-driven Turbulence with Resistivity by Professor Takayoshi Sano at Princeton.'],\n",
       " [31,\n",
       "  'The Planetary Tables of Erasmus Reinhold.  On October 22, 1511, German astronomer and mathematician Erasmus Reinhold was born. He is considered to be the most influential astronomical pedagogue of his generation. Furthermore, he is best known for his carefully calculated first set of planetary tables applying Copernican theory, published in 1551. Erasmus Reinhold was born and died in Saalfeld, Thuringia, Germany. His father Johannes Reinhold was a tax collector. In 1530 went to Wittenberg to study at the Academia Leucorea under Jacob Milich, from where he graduated in 1535 as Magister. In 1536 he was appointed professor of higher mathematics by Philipp Melanchthon. In contrast to the limited modern definition, “mathematics” at the time also included applied mathematics, especially astronomy. His colleague, Georg Joachim Rheticus, also studied at Wittenberg and was appointed professor of lower mathematics in 1536. Reinhold catalogued a large number of stars. In summer 1549 he became dean of the artistic faculty and one year later principal of the university Wittenberg. His publications on astronomy include a commentary on Georg Purbach‘s Theoricae novae planetarum. Reinhold knew about Nicolaus Copernicus and his heliocentric ideas prior to the publication of De revolutionibis and made a favourable reference to him in his commentary on Purbach. However, Reinhold like other astronomers translated Copernicus‘ mathematical methods back into a geocentric system, rejecting heliocentric cosmology on physical and theological grounds. In 1551, Duke Albert of Brandenburg Prussia supported Reinhold and financed the printing of Reinhold’s Prutenicae Tabulae or Prussian Tables, upon which Reinhold spent seven years labour. These astronomical tables helped to disseminate calculation methods of Copernicus throughout the Empire. Both Reinholds’s Prutenic Tables and Copernicus‘ studies were the foundation for the Calendar Reform by Pope Gregory XIII in 1582. With his tables, Reinhold intended to replace the Alfonsine Tables; he added redundant tables to his new tables so that compilers of almanacs familiar with the older Alfonsine Tables could perform all the steps in an analogous manner. Copernicus’s heliocentric claims did not, then, win over the hearts of all European astronomers overnight. Rather, the Prussian Tables became popular in German speaking countries for nationalistic and confessional reasons, it seems, and it is through these tables that Copernicus’s reputation was established as a skilled mathematician or an astronomer on a par with Ptolemy, and helped to disseminate the Copernicus‘ methods of calculating the positions of astronomical objects throughout the Holy Roman Empire. Erasmus Reinhold died in 1553 in Saalfeld because of a lung disease at age 42. At yovisto, you can learn more about the scientific, social and religious impact of the Copernican Revolution with the lecture ‘Mathematics, Motion, and Truth: The Earth goes round the Sun‘ by Jeremy Gray of Gresham University.'],\n",
       " [32,\n",
       "  'Samuel W. Alderson and the Crash Test Dummies.  The Hybrid III crash test dummy family.  On October 21, 1914, US-american engineer Samuel W. Alderson was born. He is best known for his development of the crash test dummy, a device that, during the last half of the twentieth century, was widely used by automobile manufacturers to test the reliability of automobile seat belts and other safety protocols. Samuel W. Alderson attended several colleges including Reed College, California Institute of Technology, and the University of California Berkeley. However, his higher education was interrupted by his periods of working at his family’s sheet-metal business. Alderson started his PhD in physics at the University of Berkeley under J. Robert Oppenheimer and E.O. Lawrence, but never finished his dissertation. He began developing electric motors for missile guidance systems during World War II and continued his career at IBM in order to design motor-powered prosthetic arms. Alderson founded his own company in 1952 in order to create anthropometric dummies to test the safety of the ejection seats used in aircraft. Back then, the automobile industry became also increasingly interested in testing the impact of strong forces to the human bodies like in car accidents. It is known that the first experiments were performed with cadavers, mostly older white male bodies were used. Then, volunteers served as living crash test dummies before living animals (mostly pigs) were used to collect the data. However, tests like these were highly controversial. Also, it was hard to collect reliable data that was comparable, since cadavers differed from each other and often could only be used once. Thus, Alderson began creating an anthropometric test dummy that could be mass-produced, tested, and re-tested. [2] Other companies enteres the market as well. The very first test dummy was called ‘Sierra Sam’ followed by Alderson’s V.I.P produced in 1968. The V.I.P had a steel rib cage, articulated joints and a flexible neck, with cavities to hold instrumentation, and was designed to mimic the acceleration and weight distribution properties of an average male. The Hybrid I was introduced in the 1970s by General Motors, which combined Alderson’s design with that of Sierra Engineering. The following most notable versions were titled Hybrid II and III and had improved neck flexibility and head rotation. Also, the bodies not only simulated a male body anymore, whole dummy families have been created to improve safety in automobiles. In the further development of crash test dummies, models were designed for specific impacts, like front or side crashes. Side impact dummies would measure, what happened to the ribs, the spine and internal organs. To the most advanced dummies belong WorldSID model, able to record 258 separate measurements in one test, and the prototype from Denton ATD, with LEDs on each of the dummy’s 12 ribs that can then be tracked by light-angle sensors, thereby measuring movement in all three dimensions. Samuel Alderson also became known for his humanoid figures that were able to dub medical phantoms. They were designed to measure radiation exposure, as well as synthetic wounds worn by soldiers during training exercises. The dummies were even capable of oozing fake blood. However, his contribution to automotive safety, in the form of the crash test dummy, that saved the most lives and become an icon of popular culture. At yovisto, you may be interested in crash test dummy footage.'],\n",
       " [33,\n",
       "  'Vannoccio Biringuccio and the Art of Metalworking.  De la Pirotechnia (1540) by Vannoccio Biringuccio Probably on October 20, 1480, Italian matallurgist Vannoccio Biringuccio was born. He is best known for his manual on metalworking, De la pirotechnia, published posthumously in 1540. Biringuccio is considered by some as the father of the foundry industry. Biringuccio was born in Siena to Paolo Biringuccio, thought to have been an architect and public servant, and his mother was Lucrezia di Bartolommeo Biringuccio. He was baptised on October 20, 1480. Thus, he might have been born the day before. He was a follower of Pandolfo Petrucci, the head of the powerful Petrucci family, the rulers of the Italian city of Siena. As a young man Biringuccio was travelling in Italy as well as in Germany inspecting metallurgical operations. After running an iron mine and forge at Boccheggiano for Pandolfo Petrucci, he was appointed to a post with the arsenal at Siena and in 1513 directed the mint. When Pandolfo died, Biringuccio remained tied to the Petrucci family, being employed by Pandolfo’s son Borghese Petrucci. However, the uprising of 1515 forced Borghese to flee from Siena, taking Biringuccio with him. Biringuccio traveled about Italy, and visited Sicily in 1517. In 1523 Pope Clement VII caused the reinstatement of the Petrucci family, and along with them Biringuccio was able to return from exile. In 1524 he was granted a monopoly on the production of saltpeter across all of Siena. However, this was short lived — already in 1526, the people of Siena revolted and threw the Petrucci family out again. Although, the family made an attempt aided by Biringuccio to regain Siena by force, but it failed. Thereafter Biringuccio served the Venetian and Florentine republics, and cast cannon and built fortifications for the Este and Farnese families. In 1530, Siena entered a more peaceful phase, and Biringuccio returned, time in honor, as senator and, succeeding Baldassare Peruzzi, as architect and director of building construction at the Duomo. In 1538 he became head of the papal foundry in Rome, and director of munitions. His exact place and date of death is unknown The reason for Biringuccio’s fame is certainly the publication of his manual on metalworking, De la pirotechnia, published posthumously in 1540. Thus, Biringuccio is considered by some as the father of the foundry industry as De la pirotechnia is the first printed account of proper foundry practice. It also gives details of mining practice, the extraction and refining of numerous metals, alloys such as brass, and compounds used in foundries and explosives. It preceded the printing of De re metallica by Georg Agricola by more than a decade. Moreover, Agricola’s famed sections on glass, steel, and the purification of salts by crystallization are in fact taken nearly verbatim from the Pirotechnia. The work is one of earliest technical manuscripts to survive from the Renaissance, and is thus a valuable source of information on technical practice at the time of writing. The work was printed in 1540 in Venice, and has been reprinted numerous times [2]. Biringuccio is also important in art history for his description of the peculiarly Renaissance arts of casting medallions, statues, statuettes, and bells. His account of typecasting, given in considerable detail, is the earliest known. The Pirotechnia contains eighty-three woodcuts, the most useful being those depicting furnaces for distillation, bellows mechanisms, and devices for boring cannon and drawing wire.[2] A member of Fraternita di Santa Barbara guild, before his book information on metallurgy and military arts were closely held secrets. In fact, his book is credited with starting the tradition of scientific and technical literature.[2] Also, Pirotechnia offers one of the first written attempts to explain what causes a rocket to move. Biringuccio attributed the propulsive force to a “strong wind”: One part of fire takes up as much space as ten parts of air, and one part of air takes up the space of ten parts of water, and one part of water as much as ten parts of earth. Now sulfur is earth, consisting of the four elementary principles, and when the sulfur conducts the fire into the driest part of the powder, fire, and air increase … the other elements also gird themselves for battle with each other and the rage of battle is changed by their heat and moisture into a strong wind. (Vannoccio Biringuccio, De la Pirotechnia, 1540) At yovisto, you can learn more about the epoch of the European Renaissance in the lecture of Prof. Thomas W. Laqceur from Berkeley on ‘European Civilization from the Renaissance to the Present‘.'],\n",
       " [34,\n",
       "  'Eudoxus and the Method of Exhaustion.  Eudoxus, Lunar Crater As for many people from antiquity, we also have no birthdate for Eudoxus of Cnidus, who was a Greek astronomer, mathematician, scholar and student of Plato. All of his works are lost or have survived as fragments in the texts of other classical writers. He is best known for having developed the method of exhaustion, a precursor to the integral calculus. Eudoxus of Cnidus was born around 408 BC as the son of Aischines of Cnidus. His name Eudoxus means “honored” or “of good repute”. It is analogous to the Latin name Benedictus. As to his teachers, we know according to the 3rd-century-ce historian Diogenes Laërtius that Eudoxus travelled to Tarentum, Italy, where he studied with Archytas who was a follower of Pythagoras, from whom he learned mathematics. Eudoxus also visited Sicily, where he studied medicine with Philiston, before making his first visit to Athens in the company of the physician Theomedon in about 387 BC. Eudoxus spent two months in Athens on this visit and he certainly attended lectures on philosophy by Plato and other philosophers at the Academy which had only been established a short time before.[1] Eudoxus was quite poor and could only afford an apartment at the Piraeus. To attend Plato’s lectures, he walked the seven miles each direction, each day. Due to his poverty, his friends raised funds sufficient to send him to Heliopolis, Egypt to pursue his study of astronomy and mathematics. He lived there for 16 months. From Egypt, he then traveled north to Cyzicus, located on the south shore of the Sea of Marmara, the Propontis. He traveled south to the court of Mausolus. During his travels he gathered many students of his own. After a brief interlude in Athens, he eventually returned to his native Cnidus, where he served in the city assembly. However he continued his scholarly work, writing books and lecturing on theology, astronomy and meteorology. He had built an observatory on Cnidus and we know that from there he observed the star Canopus. The observations made at his observatory in Cnidus, as well as those made at the observatory near Heliopolis, formed the basis of two books referred to by Hipparchus. These works were the Mirror and the Phaenomena which are thought by some scholars to be revisions of the same work. Hipparchus tells us that the works concerned the rising and setting of the constellations but unfortunately these books, as all the works of Eudoxus, have been lost. In mathematical astronomy, his fame is due to the introduction of the astronomical globe, and his early contributions to understanding the movement of the planets. According to Eudoxus‘ model, the spherical earth is at rest at the center. Around this center, 27 concentric spheres rotate. The exterior sphere caries the fixed stars, the others account for the sun, moon, and five planets. Each planet requires four spheres, the sun and moon, three each. Eudoxus is considered by some to be the greatest of classical Greek mathematicians, and in all antiquity, second only to Archimedes. His work on proportions shows tremendous insight into numbers Richard Dedekind, who himself emphasised that his work was inspired by the ideas of Eudoxus. Another remarkable contribution to mathematics made by Eudoxus was his early work on integration using his method of exhaustion. This work developed directly out of his work on the theory of proportion since he was now able to compare irrational numbers. It was also based on earlier ideas of approximating the area of a circle by Antiphon where Antiphon took inscribed regular polygons with increasing numbers of sides. According to Eratosthenes of Cyrene, Eudoxus also contributed a solution to the problem of doubling the cube—that is, the construction of a cube with twice the volume of a given cube. Aristotle preserved Eudoxus’s views on metaphysics and ethics. Unlike Plato, Eudoxus held that forms are in perceptible things. He also defined the good as what all things aim for, which he identified with pleasure. At yovisto, you you can learn more about Eudoxus in the lecture of Prof. N. J. Wildenberger on ‘The Infinity in Greek Mathematics‘.'],\n",
       " [35,\n",
       "  'Nicholas Culpeper and the Complete Herbs of England.  Nicholas Culpeper.  On October 18, 1616, English botanist, herbalist, physician, and astrologer Nicholas Culpeper was born. Culpeper spent the greater part of his life in the English outdoors cataloging hundreds of medicinal herbs. Thus, he is best known for his publication of Complete Herbal (1653), a comprehensive listing of English medicinal herbs and their uses, which still is in print today. It is widely believed that Nicholas Culpeper came from aristocratic origins and grew up in a family, owning land, which was a privilege denied to many in these years. Culpeper was highly influenced by his grandfather Reverend William Attersole, who was known to be an intellectual. He taught his grandson and it is assumed that he had high ambitions for the young Nicholas, including sending him to Cambridge, where the Attersole himself had once been educated. He was educated in Latin as well as Greek and it is believed that he read numerous books he found in his grandfather’s library on astrology at early age. Further, it is assumed that there he also discovered William Turner’s Herbal, which apparently initiated his interest in medicine, plants and herbs. [1] However, Culpeper’s grandfather was not really amused when finding out about the boy’s interests and soon restricted his readings to the Bible. He was sent to Cambridge at the age of 16 in order to study theology and to become a Church Minister in later years. Well, this was the initial plan, but the teenager soon decided differently and read the medical works of Hippocrates and Galen instead. On this day, Culpeper is quite well known as the ‘rebel’ scientist, who next to his studies apparently began drinking and smoking to compensate his frustration on his grandfather. Due to a secret relationship Culpeper’s with heiress Judith Rivers which turned into quite a scandal, the student left Cambridge. However, Reverend Attersole organized an apprenticeship for his grandson with the Master Apothecary, Daniel White and soon after abandoned his grandson. He was apprenticed for over seven years and catalogued various medicinal herbs in this period. When he was finally able to abandon his ties with White, Culpeper continued his ‘career’ in London’s poorer areas and soon gained a reputation as the healer of the poor. It is assumed that he charged only very little or nothing at all for his services as he highly sympathized with their struggles. [1,2] It is further assumed that Culpeper had ambitions to reform the medical system, questioning traditional methods and exploring new ways of healing. A key factor in order to do so was the systematization of the use of herbals. His focus moved from tradition to reason and began combining plants and diseases. His ‘Complete Herbal’ is known to have had a great influence on medicine in the western world. The success is also due to the fact that he managed to translate numerous documents discussing medicinal plants from Latin into English. [2] At yovisto, you may be interested in a Gresham Video Lecture on ‘The Hidden Face of British Gardening‘ by Prof. Dr. Sir Roderick Floud.'],\n",
       " [36,\n",
       "  'Socrates and the Socratic Method.  Socrates by Leonidas Drosis, Athens – Academy of Athens Image: DIMSFIKAS at Greek Wikipedia Socrates was a classical Greek (Athenian) philosopher credited as one of the founders of Western philosophy. He remains an enigmatic figure in philosophy, because he did not leave as a single line of text. He is known chiefly through the accounts of later classical writers, especially the writings of his students Plato and Xenophon. Nevertheless, you might consider his importance in the fact that all Greek philosophers are categorized in philosophers before (Pre-Socratic) and after Socrates. Socrates is known for his unique style of conversations, including his own denial of knowledge. In his conversations, Socrates became the student and made those he questioned the teacher rejecting all attempts to pass off another person’s ideas or the beliefs of the majority as truth. Socrates wanted to entirely focus on the respondents own thinking and in the Socratic method, the philosopher focused on a person’s original and critical thinking in the context of life’s important questions and the importance of the human moral development. [1]   Explaining the Socratic Method is not easy, because there is no single and consistent definition due to the diversity with which ‘the method’ has been used in history. Even in delivered writings by Plato, there is not just one Socratic Method. According to Plato, the elenchus is the technique Socrates used to investigate ethical concepts such as justice or virtue. Elenchus is widely defined as an ‘argument of disproof or refutation, cross-examining, testing, scrutiny especially for purposes of refutation. It is believed that four steps have been used to do so. First, Socrates‘ interlocutor asserts a thesis which Socrates considers false and targets for refutation. He then secures his interlocutor’s agreement to further premises and argues that these further premises imply the contrary of the original thesis. In the last step, Socrates then claims that he has shown that his interlocutor’s thesis is false and that its negation is true. However, these steps are widely debated. It has especially been concerned whether this method leads to knowledge or whether it is used to refute false claims to knowledge. Other historians like W. K. C. Guthrie believe that the Socratic method actually aims to demonstrate one’s ignorance and that the recognition of a person’s ignorance may lead to knowledge. [2]It is believed, that Socrates applied his methods mainly to concepts that lacked a specific definition, including the virtues of piety, wisdom, courage, justice, and so on. In his investigations, Socrates challenged the implicit moral beliefs of the interlocutors, bringing out inadequacies and inconsistencies in their beliefs. Through investigating the inadequacies, Socrates also revealed his ignorance and it is believed that he thought his own awareness of his personal ignorance made him wiser than those who, though ignorant, still claimed knowledge. Apparently, the philosopher used his method to investigate a person’s moral believes. He claimed that ”   At yovisto, you may be interested in a video lecture on ‘Life of Reason? Socrates vs. Alcibiades‘ by Lanier Anderson at Stanford University.'],\n",
       " [37,\n",
       "  'Albrecht von Haller – Father of Modern Physiology.  Albrecht von Haller (1708 – 1777).  On October 16, 1708, Swiss anatomist, physiologist, naturalist and poet Albrecht von Haller was born. He made prolific contributions to physiology, anatomy, botany, embryology, poetry, and scientific bibliography. Moreover, he is often referred to as the “Father of modern Physiology”. It is said that Albrecht von Haller learned Greek and Hebrew at the age of 10 and authored translations from Ovid, Horace and Virgil before turning 15. However, his interest turned to the field of medicine soon and the young man enrolled at the University of Tübingen, Germany when he was approximately 16 years old. Haller continued his studied at Leiden where Bernhard Siegfried Albinus taught anatomy. In his final thesis, Haller proved that the salivary duct, which Georg Coschwitz claimed to have discovered was simply a blood-vessel. Haller went to London, Paris, and Basel in order to meet contemporary scientists and increased his interest in higher mathematics and botany. The scientist began collecting plants mostly in Switzerland which became the basis his great work on the flora of Switzerland. Next to his works on botany, Haller also used the experiences he made in the Alps to create several poems. ‘Die Alpen’ was published in his 1732 edition of ‘Gedichte’. It is assumed that Haller’s poem was one of the first signs of the increasing appreciation of the mountains and is considered historically relevant. [1] In Bern, Haller started to officially practice as a physician before being appointed chair of medicine, anatomy, botany, and surgery at the University of Göttingen, Germany. It is known that in this period, Haller devoted much of his time to organize a botanical garden as well as a anatomical theatre and museum next to publishing many poems and conducting a monthly journal to which he contributed around 900 articles. In 1751, he was elected president for life of the newly founded Royal Society of Sciences at Göttingen. [3] However, it is also known that Haller never really felt home in Göttingen and moved back to Switzerland in 1753. Albrecht von Haller was known for his experimental studies. He managed to analyze the irritability of muscle and the sensibility of nerves, studying circulation time and the automatic action of the heart. It is assumed that Haller was the first to give detailed explanation of respiration. He published his famous ‘Elementa Physialogiae Carports Hamani’ (Elements of Physiology) in the late 1750s, which is considered as one of the most influential works on the subject back then. It was also Haller, who discovered that only nerves produce sensation and only those parts of the body connected to the nervous system can undergo a sensation. [2] As Albrecht von Haller was active in so many scientific fields, you may be interested in the video lecture ‘Science, Medicine, and Religion’ as part of the lecture series ‘European Civilization from the Renaissance to the Present’ by Professor Laqueur at Berkeley.'],\n",
       " [38,\n",
       "  'Evangelista Torricelli and the Barometer.  Evangelista Torricelli (1608-1647). On October 15, 1608, Italian physicist and mathematician Evangelista Torricelli was born, best known for his invention of the barometer, but is also known for his advances in Optics. Evangelista Torricelli was born in Rome, the firstborn child of Gaspare Ruberti, a poor textile worker, and Giacoma Torricelli. His family was from Faenza in the Province of Ravenna, then part of the Papal States. His parents sent Evangelista to be educated in Faenza, under the care of his uncle, Jacobo, a Camaldolese monk, who after a basic education took Torricelli into a Jesuit College in 1624, to study mathematics and philosophy. Then Torricelli went to Rome to study science under the Benedictine monk Benedetto Castelli, a student of Galileo Galilei. While in Rome, Torricelli became also the student of the mathematician, Bonaventura Cavalieri, with whom he became great friends. In 1641, Castelli sent Torricelli’s monograph of the path of projectiles to Galileo, by that time a prisoner in his villa at Arcetri. Although Galileo promptly invited Torricelli to visit, he did not accept until just three months before Galileo’s death. The reason for this was that Torricelli’s mother died. For the last three months of Galileo’s life, Torricelli acted as his amanuensis. After Galileo’s death in 1642, Grand Duke Ferdinando II de’ Medici asked Torricelli to succeed Galileo as the grand-ducal mathematician and chair of mathematics at the University of Pisa. In this role he solved some of the great mathematical problems of the day, such as finding a cycloid’s area and center of gravity. Torricelli’s chief invention was the mercury barometer. “This instrument is named from two Greek words, signifying two measures of weight, since by it a column of air is weighed against a column of mercury.” The barometer arose from the need to solve a practical problem. Pump makers of the Grand Duke of Tuscany attempted to raise water to a height of 12 meters or more, but found that 10 meters was the limit with a suction pump. Torricelli employed mercury, fourteen times more dense than water. In 1643 he created a tube approximately one meter long, sealed at the top, filled it with mercury, and set it vertically into a basin of mercury. The column of mercury fell to about 76 cm, leaving a Torricellian vacuum above. As we now know, the column’s height fluctuated with changing atmospheric pressure; this was the first barometer. The torr, a unit of pressure used in vacuum measurements, is named after Torricelli. “Noi viviamo sommersi nel fondo d’un pelago d’aria. (We live submerged at the bottom of an ocean of air.)”, Evangelista Torricelli in a letter to Michelangelo Ricci, 11 June 1644 In 1644 the French scientist Marin Mersenne visited Torricelli and took back to his friend Blaise Pascal the idea of the mercury barometer. If, Pascal thought, air was indeed pressing downward upon us as Torricelli contended, the total weight of the air, and hence its pressure, should decrease as altitude increases. With the help of his brother-in-law, Pascal showed that barometric pressure did indeed decrease as one ascended a mountain. Pascal’s observational evidence showed beyond any doubt that Torricelli’s theory was correct.[2] Torricelli died in Florence on 25 October 1647, a few days after having contracted typhoid fever, and was buried at the Basilica of San Lorenzo. The asteroid 7437 Torricelli and a crater on the Moon were named in his honor.   At yovisto, you can learn more about Toricelli’s mercury barometer and the physics behind in the lecture of MIT Prof. Donald Sadoway on ‘Solid State Chemistry‘.'],\n",
       " [39,\n",
       "  'Pythagoras and his Eponymous Theorem.  Bust of Pythagoras, Musei Capitolini, Roma. One of the founders of Western mathematics was the Greek philosopher Pythagoras of Samos. He is often revered as a great mathematician, mystic, and scientist and is best known for the Pythagorean theorem which bears his name. It was said that he was the first man to call himself a philosopher, or lover of wisdom. Anyway, his eponymous theorem possibly is the best known theorem in mathematics. Accurate facts about the life of Pythagoras are so few that most information concerning him is untrustworthy, making it nearly impossible to provide more than a vague outline of his life. Herodotus, Isocrates, and other early writers all agree that Pythagoras was born on Samos, the Greek island in the eastern Aegean, as the son of Mnesarchus, a gem-engraver or a merchant from Tyre, and his wife Pythais. As to the date of his birth, Aristoxenus stated that Pythagoras left Samos in the reign of Polycrates, at the age of 40, which would give a date of birth around 570 BC. Little is known of Pythagoras‘s childhood. Certainly he was well educated, learning to play the lyre, learning poetry and to recite Homer. There were, among his teachers, three philosophers who were to influence Pythagoras while he was a young man. One of the most important was Pherekydes who many describe as the teacher of Pythagoras. The other two who shoud introduce him to mathematical ideas were Thales and his pupil Anaximander who both lived on Miletus. It is said that Pythagoras visited Thales in Miletus when he was between 18 and 20 years old, while Thales already was an old man and. Nevertheless he he created a strong impression on Pythagoras and contributed to Pythagoras’s interest in mathematics and astronomy. He advised him to travel to Egypt to learn more of these subjects. Thales’s pupil, Anaximander, lectured on Miletus and Pythagoras attended these lectures. Anaximander certainly was interested in geometry and cosmology and many of his ideas would influence Pythagoras’s own views.[1]. Pythagoras left Samos for Egypt in about 535 B.C. to study with the priests in the temples. Many of the practices of the society he created later in Italy can be traced to the beliefs of Egyptian priests, such as the codes of secrecy, striving for purity, and refusal to eat beans or to wear animal skins as clothing. [2] According to current research, it is not easy to say how much Pythagoras learned from the Egyptian priests, or indeed, whether he learned anything at all from them. According to Porphyry, Pythagoras was refused admission to all the temples except the one at Diospolis where he was accepted into the priesthood after completing the rites necessary for admission.[1] He took part in several discussions with the Egyptian priests and possibly embraced the various customs of Egyptian priests such as secrecy, not eating beans and wearing clothes that are not made from animal skins. During his time in Egypt, he pursued his education and specialized in Geometry and Mathematics.[3] In 525 BC Cambyses II, the king of Persia, invaded Egypt and Pythagoras was taken prisoner and taken to Babylon. It was about 520 BC when Pythagoras returned to Samos and after a short interlude went to southern Italy in about 518 BC. There, Pythagoras founded a philosophical and religious school in Croton that had many followers. Pythagoras was the head of the society with an inner circle of followers known as mathematikoi. The mathematikoi lived permanently with the society, had no personal possessions and were vegetarians. They were taught by Pythagoras himself and obeyed strict rules. The outer circle of the Society were known as the akousmatics and they lived in their own houses, only coming to the Society during the day. They were allowed their own possessions and were not required to be vegetarians.[1] Since the fourth century AD (according to Proclus, the last major Greek philosopher), Pythagoras has commonly been given credit for discovering the Pythagorean theorem, a theorem in geometry that states that in a right-angled triangle the area of the square on the hypotenuse (the side opposite the right angle) is equal to the sum of the areas of the squares of the other two sides. While the theorem that now bears his name was known and previously utilized by the Babylonians and Indians, he, or his students, are often said to have constructed the first proof. Because of the secretive nature of his school and the custom of its students to attribute everything to their teacher, there is no evidence that Pythagoras himself worked on or proved this theorem. For that matter, there is no evidence that he worked on any mathematical or meta-mathematical problems. According to legend, the way Pythagoras discovered that musical notes could be translated into mathematical equations was when he passed blacksmiths at work one day and thought that the sounds emanating from their anvils were beautiful and harmonious and decided that whatever scientific law caused this to happen must be mathematical and could be applied to music. He went to the blacksmiths to learn how the sounds were produced by looking at their tools. He discovered that it was because the hammers were “simple ratios of each other, one was half the size of the first, another was 2/3 the size, and so on.” Pythagoras went to Delos in 513 BC to nurse his old teacher Pherekydes who was dying. He remained there for a few months until the death of his friend and teacher and then returned to Croton. In 510 BC Croton attacked and defeated its neighbour Sybaris and there is certainly some suggestions that Pythagoras became involved in the dispute. Then in around 508 BC the Pythagorean Society at Croton was attacked by Cylon, a noble from Croton itself. Pythagoras escaped to Metapontium and the most authors say he died there, some claiming that he committed suicide because of the attack on his Society.[1] At yovisto, you you can learn more about the Pythagorean theorem in the lecture of Yale Prof. N. J. Wildenberger on ‘History of Mathematics‘.'],\n",
       " [40,\n",
       "  'Peter Barlow and the Barlow Lenses.  Peter Barlow (1776 – 1862).  On October 13, 1776, British mathematician and physicist Peter Barlow was born. He is still reknown today for his development of two varieties of achromatic (non-colour-distorting) telescope lenses, the so-called Barlow lenses. Despite lacking formal education, Peter Barlow became assistant mathematical master at the Royal Military Academy in Woolwich in 1801. His first research achievements mostly focused on the field of mathematics. His ‘Theory of mathematics’ was published in 1811 and he started working in the field of magnetism around 1819. Just a few years later, Barlow was elected fellow of the Royal Society. He worked on problems associated with magnetic measurements and the issue of deviation in ship compasses caused by iron pieces in the hull. In 1825, he was awarded the Royal Society Copley Medal for his method of correcting the deviation by juxtaposing the compass with a suitably shaped piece of iron used as neutralizing plate. The scientist also began conducting experiments on the influence of rotation upon magnetic and non-magnetic bodies, which was suggested by John Herschel. [1] In the meantime, Barlow had already published his second book titled ‘New mathematical tables’, which soon became well known as ‘Barlow’s Tables’. In the book, Barlow gives factors, squares, cubes, square roots, reciprocals and hyperbolic logarithms of all numbers from 1 to 10000. Another major scientific contribution by Peter Barlow is the famous Barlow Lens, which is understood as a diverging lens which, used in series with other optics in an optical system, increases the effective focal length of an optical system as perceived by all components that are after it in the system. It is mostly used in the field of astronomy and has an effect of increasing the magnification of the image. [2,3] During his career, Barlow also made several contributions to the theory of strength of materials and published an essay on the strength and stress of timber in 1817. This work was continued after his death by his sons, who also included a biography of their father. [4] At yovisto, you may enjoy a video lecture by Carolin Crawford on ‘Large Telescopes and why we need them‘'],\n",
       " [41,\n",
       "  'Ascanio Sobrero and the Power of Nitroglycerine.  Ascanio Sobrero (1812-1888). On October 12, 1812, Italian chemist Ascanio Sobrero was born. During his experimental research he discovered the explosive compound nitroglycerine. Sobrero was horrified by the destructive potential of his discovery, and made no effort to develop that power himself. Possibly, the only name that pops up in your mind when you think of the explosive nitroglycerine is Alfred Nobel, the guy who also funded the eponymous prices for advancement in science as well as for world peace. But, it was not Alfred Nobel, who really invented the explosive. In fact he was like Ascanio Sobrero a student of Théophile-Jules Pelouze in Paris. Later he patented, commercialized, and profited from Sobrero’s discoveries and developed the easier and safer to use dynamite. Ascanio Sobrero was born in Casale Monferrato, Italy. There is not much to find in the sources about his youth. He was studying medicine in Turin and then in Paris under Théophile-Jules Pelouze, an industrial chemist and the author of several technical handbooks, one of the pioneers in the chemistry of nitrocellulose (i.e. the explosive material guncotton). Subsequently, Sobrero studied chemistry at the University of Gießen with Justus Liebig, and earned his doctorate in 1832. In 1845 he became professor at the University of Turin. Around 1846, during his researches Sobrero discovered nitroglycerine by adding glycerol to a mixture of concentrated nitric and sulfuric acids. Pure nitroglycerin is a colorless, oily, somewhat toxic liquid having a sweet, burning taste. He tried heating a drop in a test tube, whereupon it exploded, sending glass fragments everywhere, scarring his face and hands. Initially Sobrero called it “pyroglycerine”, and warned vigorously against its use in his private letters and in a journal article, stating that it was extremely dangerous and impossible to handle. Sobrero is quoted to have said “When I think of all the victims killed during nitroglycerine explosions, and the terrible havoc that has been wreaked, which in all probability will continue to occur in the future, I am almost ashamed to admit to be its discoverer.”  In fact, Sobrero was so frightened by what he created that he kept it a secret for over a year. Pyroglycerine soon came to be known generally as nitroglycerin, or blasting oil. Because of the risks inherent in its manufacture and the lack of dependable means for its detonation, nitroglycerin was largely a laboratory curiosity. Until another of Pelouze’s students, the young Alfred Nobel, who returned to the Nobel family’s defunct armaments factory, began experimenting with the material around 1860. It did, indeed prove to be very difficult to discover how to handle it safely. In the 1860s Nobel received several patents around the world for mixtures, devices and manufacturing methods based on the explosive power of nitroglycerine, eventually leading to the invention of dynamite, ballistite and gelignite from which he made a fortune. Although Nobel always acknowledged and honored Sobrero as the man who had discovered nitroglycerine, Sobrero was not only dismayed by the uses to which the explosive had been put, but also on occasion claimed that he was not given sufficient recognition. Since the 1860s, nitroglycerin has been used as an active ingredient in the manufacture of explosives, mostly dynamite, and as such it is employed in the construction, demolition, and mining industries. Similarly, since the 1880s, it has been used by the military as an active ingredient, and a gelatinizer for nitrocellulose, in some solid propellants, such as Cordite and Ballistite. But, since 1878 nitroglycerin is also used medically as a potent vasodilator to treat heart conditions, such as angina pectoris and chronic heart failure. At yovisto, you can learn about the inglorious application of Ascanio Sobrero’s as well as Alfred Nobel’s invention in the hands of political radicals. Yale Prof. John Merrimen will talk about the ‘Dynamite Club: The Annarchists‘ in one of his history lectures'],\n",
       " [42,\n",
       "  'Heinrich Olbers and the Olbers’ Paradox.  Heinrich Olbers (1758-1840). On October 11, 1758, German physician and astronomer Heinrich Wilhelm Matthias Olbers was born. Besides his discovery of coments and minor planets, Olbers is best known for his new method to calculate the velocity of falling stars. Maybe you have also heard of the famous Olbers’ paradox, which asks “why is the night sky dark if there are so many bright stars all around to light it?” Heinrich Olbers was born in Arbergen, today part of Bremen, Germany, as eighth of the sixteen children of Johann Georg Olbers, a Protestant minister. In 1777, after finishing the Gymnasium Illustre in Bremen, he went to the University of Göttingen to study medicine to become a physician. But, already as a schoolboy, Olbers developed an appreciation for astronomy. He was fascinated by the great comet of 1769 and also took additional lectures in physics, mathematics, and astronomy while studying medicine in Göttingen. It was during those years that he developed an interest in comets, an interest he retained for the rest of his life. In 1779 Olbers devised a new method of calculating the orbits of comets. In medical school Olbers specialized in the emerging field of ophthalmology (the study of the function and treatment of eyes) and wrote his dissertation on how the eye shifts its focus. After his graduation in 1780, he began practicing medicine in Bremen and quickly drew a large clientele. At night he dedicated his time to astronomical observation, making the upper story of his home into an observatory, where he pointed telescopes out of two large bay windows, and started with the collection of a private library of astronomical books. Actually, his astronomy library had more than 4,000 items, and it is now considered one of the most extensive private collections in all of Europe. He took a leading role in the search for a planet between Mars and Jupiter. On March 28, 1802, Olbers discovered and named the asteroid Pallas, the second asteroid to be identified after Giuseppe Piazzi‘s discovery of Ceres in 1801. Actually, it was Carl Friedrich Gauss, who sent Olbers on the hunt for asteroids. Gauss, who had attempted to calculate the orbit of the newly discovered Ceres, asked Olbers to look for Ceres one year after its discovery, in the location Gauss had predicted. Olbers spotted Ceres in the location predicted by Gauss, thus proving the mathematician correct. The event that initiated a lifelong friendship between the two men. Five years later, on March 29, 1807, he discovered the asteroid Vesta, which he allowed Gauss to name. As the word “asteroid” was not yet coined, the literature of the time referred to these minor planets as planets in their own right. Because Johann Elert Bode’s law, which gave the sequence of planetary distances in terms of a numerological formula, implied that there should be a planet between Mars and Jupiter, Olbers proposed that asteroids are the broken-up remnants of a medium-sized planet that once orbited in the asteroid belt region.[1] The current view of most scientists is that tidal effects from the planet Jupiter disrupted the planet-formation process in the asteroid belt. After that Olbers returned to comet hunting. By the end of his life he had found four new comets and calculated the orbits of eighteen others. Olbers also hypothesized, correctly, that matter ejected by a comet‘s nucleus is swept back into a tail by the force of the sun.[2] On March 6, 1815, Olbers also discovered a periodic comet, now named after him. After the death of his wife in 1820, Olbers retired from his medical practice to become a full-time astronomer. In 1823 he addressed a complex phenomenon that still bears his name, the “Olbers’ paradox“, which asks “Why is the sky dark at night?” If one assumes that the universe is infinite and contains an infinite number of unchanging stars, then it stands to reason that the sky should be lit up continuously by stars too numerous to count. The paradox, however, is that this description does not match with what we observe. Olbers attempted an explanation for this, one which we now know is only partially correct. He theorized that interstellar space is not transparent, but contains dust which absorbs energy from the stars, preventing some of their light from reaching us on Earth. But, there are more arguments to answer the question: The number of stars in the universe is not infinite. There simply are not enough stars in the sky to keep it lit up day and night. Moreover, we now know that the universe is not unchanging, but that it is expanding and galaxies are moving apart. Olbers was held in great esteem by his contemporaries. He was deputed by his fellow citizens to assist at the baptism of Napoleon II of France on June 9, 1811, because his hometown Bremen was part of the French empire by that time (1811-1813). He was also a member of the corps legislatif in Paris 1812–1813. In 1804 he was elected a Fellow of the Royal Society of London, a Foreign Honorary Member of the American Academy of Arts and Sciences in 1822, and in 1827 a foreign member of the Royal Swedish Academy of Sciences. In 1840, Olbers died in Bremen aged 81. He was twice married, and one son survived him. At yovisto you can learn more about astronomy in a popular lecture by Neil deGrasse Tyson at the University of Washington in Seattle.'],\n",
       " [43,\n",
       "  'Henry Cavendish and the Weight of the Earth.  Drawing of torsion balance device used by Henry Cavendish in the ‘Cavendish Experiment‘.  On October 10, 1731, British natural philosopher Henry Cavendish was born. A scientist as well as an important experimental and theoretical chemist and physicist, Cavendish is noted for his discovery of hydrogen or what he called “inflammable air“. Most notably, he determined the mass and density of the Earth. Henry Cavendish was born in Nice and attended a private school near London. He enrolled the University of Cambridge, but left without a degree three years later in order to experiment in his own laboratory at his family’s home. He was elected to the Royal Society and the Royal Society Club and was active in the Council of the Royal Society of London. [1] Cavendish actively researched in several scientific fields including mechanics, optics, and magnetism. He combined metals with acids and made hydrogen which he called ‘inflammable air‘ and dissolved alkalis in acids calling it ‘fixed air‘. He further experimented with his creations and collected them in bottles before measuring their solubility in water and their specific gravity, noting their combustibility. For his papers on these experiments, Cavendish was awarded the Royal Society’s Copley Medal. Later in the century, gas chemistry became more important, especially with Antoine-Laurent Lavoisier’s reform of chemistry, generally known as the chemical revolution. Further studies on gases included Cavendish’s 1785 investigation of the composition of air and it is known that his results were pretty accurate back then. The scientist became also interested in the problem of the nature of heat in the 1760s and explained heat as the result of the motion of matter. He developed a general theory of heat, probably in the 1780s, which was mathematical as well as mechanical. The theory included the principle of the conservation of heat and the concept of the mechanical equivalent of heat. [2] However, the famous Cavendish experiment became the scientist’s best known. It was conducted in 1798 in order to determine the density of the Earth and the device used was a modification of the torsion balance built by the geologist John Michell. The device consisted of a torsion balance with a pair of lead spheres suspended from the arm of a torsion balance and two much larger stationary lead balls as depicted in the picture above. The scientist intended to measure the gravitational attraction between the balls, which he achieved by calculating the period of oscillation of the torsion balance and then using his results to further calculate the density of the Earth. Cavendish found out that on average, the Earth’s density was 5.48 times greater than that of water. His calculations paved the way for others to calculate accurate values for the gravitational constant and Earth’s mass. [3] At yovisto, you may be interested in a short video lecture explaining the Cavendish Experiment.'],\n",
       " [44,\n",
       "  'Karl Schwarzschild and the Event Horizon.  Karl Schwarzschild (1873 – 1916).  On October 9, 1873, German physicist and astronomer Karl Schwarzschild was born. He provided the first exact solution to the Einstein field equations of general relativity, for the limited case of a single spherical non-rotating mass, which he accomplished in 1915, the same year that Albert Einstein first introduced general relativity. The Schwarzschild solution leads to a derivation of the Schwarzschild radius, which is the size of the event horizon of a non-rotating black hole. Karl Schwarzschild was born in Frankfurt (Main), Germany and it is assumed that his family was well situated. It has been delivered that Schwarzschild was a child prodigy, who published his first paper on celestial mechanics and constructed his own telescope before his 17th birthday. He began his career at the University of Strasbourg in 1891 where he received a decent education in practical astronomy. In Munich, Schwarzschild earned his doctorate in 1896 with a thesis on Henri Poincaré’s theories. [1,2] Schwarzschild was then appointed as an assistant at the Von Kuffner Observatory in Ottakring, a suburb of Vienna, where he stayed until 1899. During his time in Vienna, Schwarzschild worked on ways to determine the apparent brightness of stars using photographic plates. While lecturing in Munich as Privatdozent, the scientist noticed a significant difference between the measured photographic magnitudes and the tabulated visual magnitudes. He concluded that the effect was due to the different colors of the stars and the range of magnitude change as measured by his photographic methods was greater than the range of change in visual magnitude. He further concluded that this effect is caused by the changes in surface temperature of the variable star through its cycle. [3] In the 1910s, Schwarzschild was appointed professor at the prestigious University of Göttingen, where he met and worked with important contemporary scientists including David Hilbert and Hermann Minkowski. Also, Schwarzschild became director of the Göttingen observatory. The scientist was appointed director of the Astrophysical Observatory in Potsdam, the most prestigious post available for an astronomer in Germany at that time and joined the German army with the outbreak of World War II. Still, he somehow managed to write several papers in 1915, two on relativity theory and one on quantum theory. Schwarzschild is now credited with producing the first exact solutions to Albert Einstein’s field equations as well as the Schwarzschild metric. [2] In Schwarzschild’s solution, a radius for a given mass is identified, also known as the Schwarzschild radius. If the mass could be compressed to fit within that radius, no known force or degeneracy pressure could stop it from continuing to collapse into a gravitational singularity or black hole. This means that where the radius of the body is less than its Schwarzschild radius, everything falls inevitably into the central body. When the mass density of this central body exceeds a certain limit, it triggers a gravitational collapse to a Schwarzschild black hole, known as a non-charged, non-rotating black hole. However, the possibility of black holes were in general not accepted until the second half of the 20th Century, and Schwarzschild himself did not believe in the physical reality of black holes, believing his theoretical solution to be physically meaningless. [2] At yovisto, you may be interested in a short video lecture on Black Holes.'],\n",
       " [45,\n",
       "  'Thales of Miletus – (possibly) the Father of Greek Mathematics.  Illustration of (possibly) Thales of Miletus For today’s blog post, there is no birthday of a popular scientist. Moreover, we want to tackle famous people in the history of science, who don’t have a known birthday. This of course holds for many philosophers, mathematicians, or natural scientists of Antiquity or early Middle Ages. Today, we want to start with the father of ancient Greek mathematics, Thales of Miletus. According to Bertrand Russel, Western philosophy (as well as mathematics) begins with Thales of Miletus. It is assumed that Thales of Miletus was born in the city of Miletus, an ancient Greek Ionian city on the western coast of Asia Minor in today’s Turkey. Even though his exact time of life is unknown, historians later attempted to calculate it on the basis of events related to him in the later sources, most notably in the work “Lives and Opinions of Eminent Philosophers” by Diogenes Laertius. Laertius wrote that Thales of Miletus may have died in the 58th Olympiad at the age of 78. Further, it is assumed that Miletus’ family was financially good situated. [1] It is believed that Miletus wrote ‘On the Solstice‘ and ‘On the Equinox‘, but none of these works survived and many doubt that Miletus left any written book. Still, in general there is only little doubt that Miletus at the time had revolutionary approaches to philosophy and mathematics. This is mostly delivered by Aristotle, who wrote in his ‘Metaphysics‘ that Miletus believed that everything comes out of water and that the earth floats on water. Seneca also wrote that this ‘floating theory’ was used by Miletus to explain earthquakes. Revolutionary about this theory was the fact that Miletus apparently rejected supernatural and mystical theories and that he was most likely the first to explain the world by unifying hypothesis. [2] Thales of Miletus is on this day also credited with several geometric theorems. One states that a circle is bisected by its diameter, he said that angles in a triangle opposite two sides of equal length are equal. Also, Miletus is credited with the theorems that opposite angles formed by intersecting straight lines are equal, that the angle inscribed inside a semicircle is a right angle, and that a triangle is determined if its base and the two angles at the base are given. Still, it is not clear if Miletus really is to be credited with these theorems, as many historians now argue. It is possible that Miletus did not even have a way of measuring angles and most likely in that case, equal angles would have not been a concept he would have understood precisely. [3] At yovisto, you may be interested in a short video explanation on Thales of Miletus.'],\n",
       " [46,\n",
       "  'Richard Leuckart and the Tapeworm.  Karl Georg Friedrich Rudolf Leuckart (1822-1898). On October 7, 1822, German zoologist Karl Georg Friedrich Rudolf Leuckart was born. He is known to be one of the initiators of modern parasitology. Leuckart described the complicated life histories of various parasites, including tapeworms and the liver fluke, and demonstrated that some human diseases, such as trichinosis, are caused by multicellular animals of the various wormlike phyla. Rudolf Leuckart was born in Helmstedt, Lower Saxony as son of Gottfried Leuckart, print shop owner and councilman, and nephew of famous surgeon and natural scientist Friedrich Andreas Sigismund Leuckart (1794–1843). It was his uncle, who made a strong impression on Leuckart and awakened his love for zoology. As a youth, he showed an early interest in zoology and in insects in particular. In 1842, he enrolled at the university of Göttingen to study medical and natural sciences, where he studied under the renowned zoologist, Rudolph Wagner, with whom he formed a lifelong friendship and who encouraged him to research in this branch of science. In 1845 he finished his doctoral thesis (De monstris eorumque causis et ortu) with distinction and subsequently habilitated in 1847 as “Privatdozent” (outside lecturer) in physiology and zoology with a study on the system on marine invertebrates. A result of this workd was the division of Georges Cuvier’s Radiata into into two phyla: Coelenterata and Echinodermata (terms of his own devising). The result marked the beginning of a new period of scientific zoology, that of animal systematics based on subtle morphological investigations. The publication of this study as a result of his expedition to the North Sea, soon raised his popularity among fellow scientists. In 1850 at age 28, he became a professor of zoology at the University of Giessen, where Justus von Liebig and the anatomist and embryologist Theodor Bischoff were attracting many young researchers. Leuckart is remembered for his work in parasitology, particularly research regarding tapeworm and trichinosis. He was especially interested in the sexual organs of the lower animals and in parthenogenesis, as well as in polymorphism, a term he originated. He was the first to prove that Taenia saginata occurs only in cattle (and humans), and Taenia solium occurs only in swine (and humans). His study of Trichina helped support Rudolf Virchow‘s campaign to create meat inspection laws in Germany. With Virchow and Friedrich Albert von Zenker, he was the first to document the life cycle of the parasite Trichinella spiralis in swine and humans. He also did important studies of the sheep liver fluke. Coelenterata (Hydromedusae, Acalephae) from Leuckart’s Wall Charts [2] In 1869 Leuckart accepted an offer from the University of Leipzig. The facilities at his disposal were at first inadequate, but in 1880 he was given a new zoological institute constructed according to his plans and furnished with laboratories, a museum, and a library. Zoologists from all over the world came to the institute as guest researchers. Leuckart’s outstanding skill as a teacher and his clear delivery brought him many students who later held chairs of zoology all over the world.[1] In the field of entomology, he conducted investigations into the micropyle and fertilization of insect eggs, the reproduction and development involving members of Pupipara, parthenogenesis among insects, and studies on the anatomy and life history of the honeybee. Between 1877 and 1892, he developed a series of zoological wall charts that have been used worldwide as teaching aids. The fruit of Leuckart’s research in parasitology, the two-volume Die menschlichen parasiten und die von ihnen herrührenden Krankheiten, was never completed; the aging Leuckart did not find the strength to finish it. Nevertheless, it has become a classic of parasitology. Today the “Rudolf-Leuckart-Medaille” is an annual award for research in parasitology by the Deutschen Gesellschaft für Parasitologie (German Society of Parasitology). “It is not possible for man, as a thinking being, to close his mind to the knowledge that he is ruled by the same power as is the animal world. Like the despised worm he lives in dependence upon external commands, and like the worn he perishes, even when he has shaken the world through the power of his ideas.” (Richard Leuckart) At yovisto, you can learn more about biology in the lecture of MIT Prof. Eric Lander in his first lecture on ‘Introduction into Biology‘ from 2004.'],\n",
       " [47,\n",
       "  'Richard Dedekind and the Real Numbers.  Richard Dedekind (1831 – 1916)  .  On October 6, 1831, German mathematician Julius Wilhelm Richard Dedekind was born. He is known for making important contributions to abstract algebra (particularly ring theory), algebraic number theory and the foundations of the real numbers. Richard Dedekind was the son of an administrator at Collegium Carolinum in Braunschweig. His family was known as pretty influential and the young Richard enrolled in 1848 at the Collegium in order to study mathematics as well. Two years later, he continued his studies in Göttingen and was taught by the famous Carl Friedrich Gauß who motivated him to write his dissertation in 1852 ‘On the Theory of Eulerian Integralsi‘. However, Dedekind preferred to continue his studies at the University of Berlin, which was known to have the best reputation in the field of mathematics. There, he was awarded the habilitation and returned to Göttingen shortly after, where he was appointed Privatdozent of geometry and probability. It is assumed that Dedekind was the first to teach Galois’ theory and to understand the notion of groups in algebra and arithmetic. After a short period of teaching in Zurich, Switzerland, Dedekind returned to his native Braunschweig where he spent the rest of his working career, because the Collegium Carolinum was upgraded to an Institute of Technology. [1] One of Dedekind’s best known contributions to mathematics is the ‘Dedekind cut‘. The idea behind a cut is that an irrational number divides the rational numbers into two classes, with all the members of one class being strictly greater than all the members of the other class. His thought on irrational numbers and Dedekind cuts was published in his pamphlet “Continuity and irrational numbers”, in modern terminology better known as completeness. In the later 1870s, Dedekind began his first works fundamental to ring theory, even though the term ‘ring‘ never appeared in his writings. Dedekind defined an ideal as a subset of a set of numbers, composed of algebraic integers that satisfy polynomial equations with integer coefficients. The concept underwent further development in the hands of Hilbert and, especially, of Emmy Noether. [2] Dedekind was elected to the Academies of Berlin and Rome, and to the French Academy of Sciences. He received honorary doctorates from the universities of Oslo, Zurich, and Braunschweig.   At yovisto, you may be interested in a lecture on Gauss’ Law.'],\n",
       " [48,\n",
       "  'Robert Goddard – the Man who ushered in the Space Age.  Robert H. Goddard (1882-1945). On October 5, 1882, American professor, physicist, and inventor Robert Hutchins Goddard was born. He is credited with creating and building the world’s first liquid-fueled rocket, which he successfully launched on March 16, 1926. Goddard’s work as both theorist and engineer anticipated many of the developments that were to make spaceflight possible. He has been called the man who ushered in the Space Age. Moreover, I’m pretty sure that you have heart of the Goddard Space Flight Center, a major NASA space science laboratory located in Greenbelt, Maryland. There is also a crater on the moon named after Goddard as well as the Blue Origin Goddard, a private spacecraft which first flew in November 2006. Robert H. Goddard was born in Worcester, Massachusetts to Nahum Danford Goddard, a businessman, and Fannie Hoyt Goddard. Early in life, young Robert suffered from pulmonary tuberculosis which kept him out of school for long periods of time. However, he kept up with his studies and was an avid readers. It was after reading H.G. Wells’s “The War of the Worlds” that he first became interested in space exploration. He experimented with chemicals and created a cloud of smoke and an explosion in the house. Goddard’s father further encouraged Robert’s scientific interest by providing him with a telescope, a microscope, and a subscription to Scientific American. After graduating from school, Robert Goddard applied and was accepted at Worcester Polytechnic Institute. In 1907, while a student at Worcester Polytechnic Institute in Massachusetts, Goddard experimented on a rocket powered by gunpowder in the basement of the physics building. Clouds of smoke caused a lot of commotion and the faculty, rather than expel him, took an interest in his work. Goddard received his B.S. degree in physics from Worcester Polytechnic in 1908, and after serving there for a year as an instructor in physics, he began his graduate studies at Clark University in Worcester in the fall of 1909. Goddard received his M.A. degree in physics from Clark University in 1910, and then stayed at Clark to complete his Ph.D. in physics in 1911. He spent another year at Clark as an honorary fellow in physics, and in 1912, he accepted a research fellowship at Princeton University’s Palmer Physical Laboratory. Unfortunately, in early 1913, Goddard became seriously ill with tuberculosis, and had to leave his position at Princeton. He then returned to Worcester, where he began a prolonged process of recovery. In 1914, his first two landmark patents were accepted and registered. The first described a multi-stage rocket fueled with a solid “explosive material.” The second described a rocket fueled with a solid fuel (explosive material) or with liquid propellants (gasoline and liquid nitrous oxide). The two patents would eventually become important milestones in the history of rocketry. Overall, he published 214 patents, some posthumously by his wife. Goddard’s thoughts on space flight started to emerge in 1915, when he theorized that a rocket would work in a vacuum, and didn’t need to push against air in order to fly. This meant that in the vacuum of space, rocket engines would be able to produce thrust. At his own expense, he began to make systematic studies about propulsion provided by various types of gunpowder. He began experiments on the efficiency of rockets. He bought some commercial rockets and measured their thrust using a ballistic pendulum, a heavy mass suspended by ropes, to which the rocket was attached. The rocket was fired, and the height to which the pendulum rose provided a measure of the total momentum (mass times velocity) imparted to it. Goddard also used an equivalent set-up, where the mass pushed against a spring, instead of being suspended.[3] Goddard turned his attention to the components of his rockets. A Swedish engineer, Gustav De Laval, had designed a turbine for a steam engine that implemented a new kind of nozzle to blow jets of steam onto the wheel. The nozzle first narrowed, then expanded, allowing the steam to reach the speed of sound and creating an efficient conversion of heat to motion. By replacing his existing nozzle with the De Laval nozzle, Goddard’s rockets were able to increase their efficiency to up to 63 percent. In 1917, Goddard received a $5,000 grant from the Smithsonian Institution in Washington, D.C., to support his development of a rocket to probe the upper atmosphere. Clark University also contributed financially, and Goddard had permission to use their lab and the lab at Worcester Polytechnic Institute for experimentation.[4] Powder rockets were still problematic. Goddard returned to an idea he first developed in 1914 for a liquid-fueled rocket. Hermann Oberth in Germany and Konstantin Tsiolkovsky in Russia had both reached the same conclusion. Working independently — with no apparent knowledge of one another’s research — they made similar developments in the field of rocket science. All three are considered to be the fathers of modern rocketry. Goddard’s rocket relied on a combination of gasoline and liquid oxygen. Two lines ran into the combustion chamber. To overcome the high temperatures required for the combustion of pure oxygen, Goddard designed the extremely cold liquid oxygen to cool the combustion chamber as it traveled from the fuel tank, a method still used today. Indeed, the flight of Goddard’s rocket on March 16, 1926, at Auburn, Mass., was as significant to history as that of the Wright brothers at Kitty Hawk. Primitive in their day as the achievement of the Wrights, Goddard’s rockets made little impression on government officials. Only through modest subsidies from the Smithsonian Institution and the Daniel Guggenheim Foundation, as well as the leaves of absence granted him by the Worcester Polytechnic Institute of Clark University, was Goddard able to sustain his lifetime of devoted research and testing.[1] Goddard moved to Roswell, New Mexico, in the 1930s, where he continued to work on his rockets over the course of his lifetime. The open desolation provided the perfect place to work on his rockets in safety, and he launched 31 rockets over 15 years. Goddard was able to flight-test many of his rockets, but many resulted in what the uninitiated would call failures, usually resulting from engine malfunction or loss of control. But Goddard never lived to see his dream of a rocket traveling into space. He died of throat cancer at his home in Baltimore on Aug. 10, 1945, twelve years before the launch of the Russian satellite, Sputnik. At yovisto, you can learn more about the future of the US space program in the TED talk of Bert Rutan on “The Future of Space“.'],\n",
       " [49,\n",
       "  'James Lind and a Cure for Scurvy.  James Lind (1714-1794). On October 4, 1714, Scottish physician James Lind was born. He was a pioneer of naval hygiene in the Royal Navy. By conducting the first ever clinical trial, he developed the theory that citrus fruits cured scurvy. His work advanced the practice of preventive medicine and improved nutrition. James Lind was born in Edinburgh, Scotland, to Margaret (Smelum) and James Lind, a prosperous merchant whose wife had medical connections. He attended grammar school in his youth, and then was apprenticed to the Edinburgh physician George Langlands,a fellow of the Incorporation of Surgeons which preceded the Royal College of Surgeons of Edinburgh, in 1731. He became a surgeon’s mate in the British navy in 1739, serving in the Mediterranean, off the coast of West Africa and in the West Indies. By 1747 he had become surgeon of HMS Salisbury in the Channel Fleet, and conducted his experiment on scurvy while that ship was patrolling the Bay of Biscay. It was a well known fact that far more sailors on British warships died from scurvy than from battle. In 1740 the catastrophic result of Anson’s circumnavigation attracted much attention in Europe; out of 1900 men, 1400 had died, most of them allegedly from having contracted scurvy. Vitamin C is necessary for the maintenance of healthy connective tissue. If sailors did not get vitamin C in their food, especially from fruits like oranges, lemons, or limes, then they developed the symptoms of scurvy: bleeding gums, loosened teeth, stiff or swollen joints, and bleeding under the skin. Infections often resulted, and if infections did not kill the sailors, then they soon died from convulsions or coma if they were left untreated. On long voyages, entire crews could be decimated by scurvy. [1] Before Lind’s work, eversince antiquity in various parts of the world others had noticed that citrus fruits were good for health. The Spanish physician, Michael Servetus, said in 1537 that citrus fruits were good for digestion. Admiral Sir Richard Hawkins of the British Navy noticed in 1593 that feeding his men citrus fruit each day seem to eliminate scurvy. Also John Woodall (1570–1643), an English military surgeon of the British East India Company recommended them but their use did not become widespread. Although Lind was not the first to suggest citrus fruit as a cure for scurvy, he was the first to study their effect by a systematic experiment in 1747. Lind set out in 1747 to prove experimentally that citrus fruits cured scurvy. Lind thought that scurvy was due to putrefaction of the body which could be helped by acids, and thus included a dietary supplement of an acidic quality in the experiment. While he was aboard the H.M.S. Salisbury from August to October 1747, he created an experiment in which he tested the effectiveness of dietary supplements on scurvy patients. He started after two months at sea when the ship was afflicted with scurvy. He divided twelve scorbutic sailors into six groups of two. They all received the same diet but, in addition, group one was given a quart of cider daily, group two twenty-five drops of elixir of vitriol (sulfuric acid), group three six spoonfuls of vinegar, group four half a pint of seawater, group five received two oranges and one lemon, and the last group a spicy paste plus a drink of barley water. The treatment of group five stopped after six days when they ran out of fruit, but by that time one sailor was fit for duty while the other had almost recovered. Apart from that, only group one also showed some effect of its treatment. Just after that patrol he left the Navy, wrote his MD thesis on venereal diseases and earned his MD from the University of Edinburgh Medical School, and was granted a license to practice in Edinburgh, Scotland. In May 1750 he was elected a fellow of the Royal College of Physicians of Edinburgh. In 1753 he published A treatise of the scurvy, which was virtually ignored. In 1758 he was appointed chief physician of the Royal Naval Hospital Haslar at Gosport. When James Cook went on his first voyage he carried wort (the liquid extracted from the mashing process during the brewing of beer or whisky), sauerkraut and a syrup, or “rob”, of oranges and lemons as antiscorbutics, but only the results of the trials on wort were published. In 1762 Lind’s Essay on the most effectual means of preserving the health of seamen appeared. In it he recommended growing salad on wet blankets. This was actually put in practice, and in the winter of 1775 the British Army in North America was supplied with mustard and cress seeds. However Lind, like most of the medical profession, believed that scurvy had multiple causes, but essentially was a result of ill-digested and putrefying food within the body, bad water, excessive work and living in a damp atmosphere which prevented healthful perspiration. Although he recognized the benefits of citrus fruit, he never advocated citrus juice as a single solution, but recommended multiple remedies. James Lind retired as chief physician at Haslar in 1783, and his son John, who had been his assistant, succeeded him in the post. Lind died in Gosport in 1794. At yovisto, you can learn more about scurvy in the great presentation of Meg Rosenbaum entitled ‘Arrr, Scurvy Knaves!‘ published and animated via PhD Comics.'],\n",
       " [50,\n",
       "  'Sir Patrick Manson – The Father of Tropical Medicine.  Manson teaching at the Albert Dock Seamen‘s Hospital 1901.  On October 3, 1844, Scottish physician Sir Patrick Manson was born. He made important discoveries in parasitology, and was the founder of the field of tropical medicine. He was the first to identify an insect for the spread of infection. Patrick Manson began studying medicine at the University of Aberdeen in 1860 and continued his career at a psychiatric institute after graduating. However, Manson desired to travel and practiced medicine mostly in Taiwan and China. There, he was probably the first to notice filarial worms and microfilariae in the blood of infected people with elephantiasis, and discovered that they could be picked up by blood-sucking mosquitoes and transmitted to others. Especially in Amoy, China, Manson was able to collect information on tropical diseases which helped him to later develop ground breaking theories and improve the malaria situation. [1,3] Based on his findings in Taiwan and China, Manson continued his studies in London, where he was appointed physician to the Seamen’s Hospital Society. He published his famous malaria hypothesis ‘On the Nature and Significance of the Crescentic and Flagellated Bodies in Malarial Blood’ in 1894 in the British Medical Journal. He explained that mosquitoes supported the parasite development and described the process on how the malaria parasite acquired infectivity towards humans, passing it from person to person. Ronald Ross was then inspired by Manson‘s work and he was later able to discover the life cycle of the malaria parasite. [1] Patrick Manson was appointed medical advisor to the Colonial Office in 1897 and was soon appointed Lecturer in Tropical Diseases to the Royal Free Hospital for Women. The scientist continued publishing works on tropical diseases and received several honors and awards for his achievements including his research on filaria, his discovery of the lung fluke, a parasitic worm in dogs and many more. On this day, Manson is widely considered the Father of Tropical Medicine. He passed away on April 9, 1922. [2] At yovisto, you may be interested in a video lecture on malaria by Professor Francis Cox at Gresham College.'],\n",
       " [51,\n",
       "  'Willy Ley – Founder of the German Rocket Society.  Willy Ley (right), with Wernher von Braun (center), and Dr. Heinz Haber (left).  On October 2, 1906, German-American engineer, science writer, spaceflight advocate, and historian of science Willy Ley was born. Ley is known for being the founder of the German Rocket Society, one of the first group of men to experiment with rockets. Fiercely anti-Nazi, unlike Wernher von Braun, in 1934, he emigrated to the U.S. rather than pursuing military applications of rocketry. In the U.S., he became a popularizer of space exploration and travel, writing many popular books. Willy Ley was born in Berlin, Germany and studied journalism at the University of Königsberg. Initially, Ley was interested in paleontology but later on, he became increasingly fascinated by space travel. First, he was influenced by Hermann Oberth’s pioneering works and published his first on work on the topic titled ‘Die Fahrt ins Weltall‘ (The Journey into Space). Shortly after, Ley helped to found the German Society for Space Travel and continued publishing several books promoting spaceflight. Also, Ley was editor of the Rocket Society’s journal ‘Die Rakete‘ (The Rocket). [1,2] ‘The Possibility of Interplanetary Travel‘ or as originally titled Die ‘Möglichkeit der Weltraumfahrt‘ was published by Willy Ley in 1928 and highly influenced the production of Fritz Lang’s film ‘Woman in the Moon‘. Oberth and Ley were both consulted for the film. While Oberth was appointed to create a small rocket to be launched in the film’s premiere. However, this was never realized. Nevertheless, Fritz Lang later recalled the work together with Willy Ley as very fruitful: “The work he had done as consultant and advisor… was amazing. The models of the spaceship, really a highly advanced model of a rocket, the trajectories and the orbits of the modular capsule from the earth, around the earth, and to the moon and back… were so accurate that in 1937 the Gestapo confiscated not only all models of the spaceship but also all foreign prints of the picture”. [2,3] Unfortunately, Willy Ley had to leave Germany due to the rise of the Nazi Party in 1935 and the German Rocket Society collapsed. Ley departed for the United States under the auspices of the American Rocket Society. He became a member of the Society and a citizen of the United States in 1944. Also, he continued writing works on astronautics and astro-history, which are considered classics in the field. However, Ley also noticed that the general enthusiasm over the possibility of manned rocket flight in the U.S. was not a big as in Germany. In order to change this, he began writing articles and books promoting manned spaceflight and it’s practicability in the relatively near future. He also wrote one of the earliest books on rocketry for the general American public and expressed his belief that rockets would soon be able to carry humans into space, and even to the Moon. To his best selling works belongs ‘The Conquest of Space’, published in 1949. It is believed that this text paved the way for many further ideas on the possibilities of space travel. Conquest of Space after the concept of Willy Ley was released as a science fiction movie in 1955. It depicts the first voyage to the planet Mars [2,3]. At yovisto, you may be interested in a video interview with Willy Fey.'],\n",
       " [52,\n",
       "  'The Unfortunate Inventions of Charles Cros.  Charles Cros (1842-1888). On October 1, 1842, French poet and inventor Charles Cros was born. He developed various improved methods of photography including an early color photo process. He also invented improvements in telegraph and paleophone technology. But lacking financial resources, he was unable to patent his devices before Thomas Edison and others developed the idea and started production. Émile-Hortensius-Charles Cros was born in Fabrezan, Aude, France, 35km to the East of Carcassonne. In 1860, he began studies in medicine, but he soon abandoned them for a life of literary and scientific pursuits. It is referenced that he had designed an automatic telegraph and displayed it at the World Fair of 1867. But, he is much better known for having “almost” invented color photography and sound recording. In 1869 Cros published a theory of color photography in which he proposed that a single scene could be photographed through glass filters colored red, yellow, and blue. The three negatives obtained through those filters could be developed to produce positive impressions that contained varying amounts of the filter’s antichromatic colors green, violet, and orange. The three positive impressions, when superimposed on one another would recompose the original colors of the photographed scene. Cros’s proposals, which anticipated the subtractive method of modern photography, were similar to more influential ideas advanced about the same time by Louis Ducos du Hauron. The same day, May 7, 1869, Charles Cros and Louis Ducos du Hauron presented their method of creating colour photographs to the French Society of Photography. They had not been in communication beforehand and each knew nothing about the other’s research. Cros ended up conceding the invention to Ducos Du Hauron, despite having sent his paper to the French Academy of Sciences on December 2, 1867. Ducos du Hauron had patented the idea on November 28, 1868, almost a full year later.[2] In 1869 he published an opuscule entitled “A Study of the Means of Communicating With Other Planets.” It was published as a little brochure and the author sent copies to the Academy of Sciences and the newspapers. Cros was convinced that pinpoints of light observed on Mars and Venus, probably high clouds illuminated by the sun, were the lights of large cities on those planets. He spent years petitioning the French government to build a giant mirror that could be used to communicate with the Martians and Venusians by burning giant lines on the deserts of those planets. He was never convinced that the Martians were not a proven fact, nor that the mirror he wanted was technically impossible to build.[3] However, Cros is perhaps most famous as the man who almost, but not quite, invented the phonograph. No one before Charles Cros had thought of reproducing sound by making an apparatus capable of registering and reproducing sounds which had been engraved with a diaphragm. He named his invention the Paleophone (voix du passé). On April 30, 1877, three months before Thomas Edison’s invention of the phonograph, Cros submitted a sealed envelope containing a letter to the Academy of Sciences in Paris explaining his proposed method. The letter stated, “A lightweight index is fixed to the center of figure of a vibrating membrane, it ends with a tip […] based on a blackened surface flame. This surface is integral with a disc driven by a double movement of rotation and linear progression. The system is reversible: when the tip makes ironing in the furrow membrane restores the original acoustic signal.“ In his letter, after having shown that his method consisted of detecting an oscillation of a membrane and using the tracing to reproduce the oscillation with respect to its duration and intensity, Cros added that a cylindrical form for the receiving apparatus seemed to him to be the most practical, as it allowed for the graphic inscription of the vibrations by means of a very fine-threaded screw. However, the Abbé Lenoir, a clergyman–science writer, described the Cros process in an article published in “la semaine du Clergé” on October 10, 1877, giving the name phonographe.[2] Before Cros had a chance to follow up on this idea or attempt to construct a working model, Edison introduced his first working phonograph in the US, who used a cylinder covered in tinfoil for his first phonograph, patenting this method for reproducing sound on January 15, 1878. Edison and Cros apparently did not know of each other’s work in advance. As a literary figure, Cros frequented the salons of Parisian Symbolists and Décadents. With those devotees of the avant-garde, he aspired to create a type of poetry that, through lyrical, rhythmic language and striking imagery, would succeed in evoking the sensations and emotions of the artist. Befriended with Verlaine and Rimbaud he was known to frequent many of the popular Parisian cafés at the time and in 1873 Charles Cros wrote one of the most beautiful poems relating to absinthe of all times, “Lendemain”, part of his book of poems, “Le Coffret de santal”. With Flowers, and with Women, With Absinthe, and with this Fire, We can divert ourselves a while, Act out our part in some drama. Absinthe, on a winter evening, Lights up in green the sooty soul; And Flowers, on the beloved, Grow fragrant before the clear Fire. Later, kisses lose their charm Having lasted several seasons; And after mutual betrayals We part one day without a tear. We burn letters and bouquets. And fire takes our bower; And if sad life is salvaged Still there is Absinthe and its hiccups. The portraits are eaten by flames. Shrivelled fingers tremble. We die from sleeping long With Flowers, and with Women. Cros’s poetical work brought as little reward and recognition as did his inventions, and he died dispirited and alcoholic. In honour of his contribution to sound recording, the Académie Charles Cros in Paris awards annual prizes for the year’s best musical recordings.[2] At yovisto you can watch a TEDx talk in which Thomas Edison’s great grand niece, Sarah Miller Caldicott, will retrace her famous relative’s footsteps and explore his timeless methods in a talk that will inspire and inform.'],\n",
       " [53,\n",
       "  'Étienne de Condillac and the Importance of Language in Logical Reasoning.  Étienne Bonnot de Condillac (1714-1780).  On September 30, 1714, French philosopher and epistemologist Étienne Bonnot de Condillac was born. A leading advocate in France of the ideas of John Locke de Condillac further emphasized the importance of language in logical reasoning, stressing the need for a scientifically designed language and for mathematical calculation as its basis. Étienne de Condillac was born at Grenoble as the youngest of three brothers to Gabriel Bonnot, Vicomte de Mably, and Catherine de La Coste. “Condillac” was the name of an estate purchased by his father in 1720. He is said to have had very poor eyesight and a weak physical constitution, factors that so retarded his intellectual development that as late as his twelfth year he was still unable to read. His education began only in his teens, first under the direction of a local priest, then at Lyons, later as seminarian in Paris, at Saint-Suplice and at the Sorbonne. He took holy orders in 1740 at Saint-Sulpice church in Paris and was appointed as Abbot of Mureauand, but did no pastoral work. [1] Condillac published two main philosophical works: the Essay on the Origin of Human Knowledge of 1746, and the Treatise on Sensations of 1754, both of which were devoted to expositing his views on the role of experience in the development of our cognitive capacities. In his works La Logique (1780) and La Langue des calculs (1798), Condillac emphasized the importance of language in logical reasoning, stressing the need for a scientifically designed language and for mathematical calculation as its basis.[2] As a philosopher, Condillac gave systematic expression to the views of John Locke, previously made fashionable in France by Voltaire. In retrospect, Condillac’s importance is both in virtue of his work as a psychologist, and his systematic establishment of Locke’s ideas in France. Like Locke, Condillac maintained an empirical sensationalism based on the principle that observations made by sense perception are the foundation for human knowledge. In the Traité des sensations, Condillac questioned Locke’s doctrine that the senses provide intuitive knowledge. He doubted, for example, that the human eye makes naturally correct judgments about the shapes, sizes, positions, and distances of objects. Examining the knowledge gained by each sense separately, he concluded that all human knowledge is transformed sensation, to the exclusion of any other principle, such as Locke’s additional principle of reflection.[2] According to Condillac, all sensation is affective, that is, causes pain or pleasure. Sensations, consequently, are the source of all active faculties. Need, for example, is the result of the privation of some object whose presence is demanded either by nature of habit. Need, subsequently, directs all energy towards this missing object. This directionality, Condillac claimed, is what we call desire. Will is absolute desire, made vigilant by hope. In Paris Condillac spent some years spent living the life of a man of letters in Paris and was involved with the circle of Denis Diderot, the philosopher who was co-contributor to the Encyclopédie. He developed a friendship with Jean Jacques Rousseau, which lasted in some measure to the end of his life. Together with his brother Gabriel, who became the well-known political writer known as Abbé de Mably, Condillac introduced Rousseau to an intellectual circle. Condillac’s relations with unorthodox philosophers did not injure his career. He had already published several works when the French court sent him to Parma to educate the orphan duke Prince Ferdinand of Parma, then a child of seven years. In 1768, on his return from Italy, Condillac was elected to the Académie française. Contrary to the popular idea that he attended only one meeting, he was a frequent attendee until two years before his death. Near the end of his life, Condillac turned his attention to politics and economics. His economic views, which were presented in Le Commerce et le gouvernement, were based on the notion that value depends not on labour but rather on utility. The need for something useful, he argued, gives rise to value, while prices result from the exchange of valued items.[2] Finding the irreligious climate of Parisian intellectual society offensive, he retired to spend his last years at Flux, near Beaugency on the Loire River. He died there on 3 August 1780. At yovisto, you can learn more about Condillac’s age of enlightenment in the talk of Gresham College Prof. Justin Champion on ‘Why the Enlightenment still matters today‘.'],\n",
       " [54,\n",
       "  'Fritz Kahn and the Mensch Maschine.  The Original Poster of the Industrial Palace From: Fritz Kahn. Das Leben des Menschen Franckh’sche Verlagshandlung, Stuttgart On September 29, 1888, German Jewish physician Fritz Kahn was born. He is best known for his publication of popular science books and especially for his illustrations, which pioneered infographics. Fritz Kahn was born in Halle, Germany and grew up with Jewish orthodox traditions and a decent education. In his early years, the Kahn family relocated several times and even lived in the United States for quite a while before settling in Berlin. The young Fritz enrolled at the University of Berlin in order to study medicine and also heard numerous lectures in various sciences. He specialized in gynecology and began published several scientific works for national newspapers and magazines. However, World War I started and Fritz Kahn became a combat medic. During his free time, he also worked on his then very popular book ‘The Milky Way’. Back in Berlin, Kahn was appointed surgeon and obstretician in a private hospital and created his successful books ‘The Cell’ as well as ‘The Jews as a Race and Cultural People’. Also, Kahn released the highly illustrated five-volume series ‘The Life of Man’. Quickly, Kahn became a very well known bestseller author. [1] In ‘The Life of Man’, an oversize poster version of one of his suggestive illustrations as an aside was published. It showed the interior workings of the upper part of a human body with the help of machine parts. While the figure is identified as human by its silhouette and its profile of a human face looking to the right, the installations in the body’s interior appear as an industrial complex. When looking at the image, it becomes clear that the illustration assembles specific machinery to represent a particular organ and its function within its natural place. For instance, the ventilation system stands for the lungs and the mechanical break-up of substances along the chain of conveyer belts represents the digestive tract. [2] In the meantime, Germany faced an increasing antisemitic atmosphere and the author founded a Jewish humanistic lodge and became chairman of the Jewish Senior Aid. Unfortunately, Kahn was expelled from Germany in early 1933. The Nazis also did not hesitate to burn his books, confiscate them and ban them with their “list of harmful and unwanted writing“. In the following years, Kahn resettled several times. He first emigrated to Palestine in order to continue his career and release his internationally best selling book ‘Our Sex Life’. In this period, he also published to remakes of ‘The Life of Man’, but unfortunately, his illustrations were abused in Germany for a short version including a new chapter with racist and antisemitic content. After living in Bordeaux for a short time, the restless man then had to escape via Portugal to the U.S. in 1941, which he accomplished with the help of his friend Albert Einstein. There, Kahn’s restart was a bit easier due to the English translation of his various works, especially his masterpiece Man in ‘Structure and Function’. Two further books were then published in Switzerland. [1] At yovisto, you may be interested in a video on The Anatomy of Movement of a Violin Player at the University of Stanford.'],\n",
       " [55,\n",
       "  'William F. Friedman and the Art of Cryptology.  William F. Friedman (1894-1969). On September 1894, US cryptologist William F. Friedman was born. He is considered one of the world’s greatest cryptologists, who helped decipher enemy codes from World War I to World War II. Friedman was born as Wolfe Frederick Friedman, then part of imperial Russia, now Chisinau, capital of Moldova, as the son of Frederick Friedman, a Jew from Bucharest who worked as a translator and linguist for the Russian Postal Service, and the daughter of a well-to-do wine merchant. Friedman’s family fled Russia in 1892 to escape the virulent anti-semitism there, ending up in Pittsburgh, Pennsylvania. Like many other too, Friedman was introduced to cryptography already as a child while reading Edgar Allan Poe‘s famous short story “The Gold-Bug“. Actually, I also heart of ciphers and secret writings for the first time as a child with the very same story of an adventure where the protagonists after deciphering a secret message were lead to a buried treasure. Friedman studied at the Michigan Agricultural College and received a scholarship to work on genetics at Cornell University. In September 1915, Friedman joined Fabyan’s Riverbank Laboratories outside Chicago, a private research laboratory. As head of the Department of Genetics. Besides other industrial and agricultural topics, there was a cipher department at Riverbank studying the “Baconian Cipher,” i.e. secret messages which Sir Francis Bacon had allegedly hidden in various texts during the reigns of Elizabeth I and James I and Friedman became interested in the study of codes and ciphers. When Riverbank was asked to train the military in the use of codes, Friedman was assigned as the principal instructor. Friedman served as a lieutenant in G6A2, the crypt unit of the American Expeditionary Forces during World War I, as the personal cryptographer for General John J. Pershing. He returned to the US in 1920 and published an eighth monograph, “The Index of Coincidence and its Applications in Cryptography“, considered by some to be the most important publication in modern cryptography to that time. His texts for Army cryptographic training were well thought of and remained classified for several decades. In 1921 he became chief cryptanalyst for the War Department and later led the Signals Intelligence Service(SIS)—a position he kept for a quarter century. In 1929 he was selected to be the head of the newly organized Signal Intelligence Service (SIS). There, he created the organizational foundations of a cryptologic structure which evolved into the Army Security Agency (ASA) in World War II. In the process, he led the transition from paper and pencil cryptology into the modern era characterized by the application of machines to both cryptography and cryptanalysis.[1] On the outbreak of World War II Friedman became involved in Magic, the codename given for the American operation to break the Japanese diplomatic and military codes. The Communication Special Unit (US Navy) and the Signals Intelligence Section (US Army) worked together in monitoring the traffic of coded messages sent by the Japanese Government and the Imperial Headquarters to their commanders at sea and in the field. In 1939 Japan began using a new cipher machine invented by Jinsaburo Ito. Nicknamed the Purple Machine, the code was not broken until September 1940 by Friedman and his team. However, because of the large volume of intelligence being received by the staff of Magic, they were unable to give adequate warnings about the proposed attack at Pearl Harbor. With increases in the number of people working at Magic they were able to discover the attack plan at the Battle of Midway. This enabled Admiral Chester Nimitz to use this information to fight off a much larger force and halt the Japanese offensive in the Pacific.[2] Following World War II, Friedman remained in government signals intelligence. In 1949 he became head of the cryptographic division of the newly formed Armed Forces Security Agency (AFSA) and in 1952 became chief cryptologist for the National Security Agency (NSA). Friedman produced a classic series of textbooks, “Military Cryptanalysis“, which was used to train NSA students. During his early years at NSA, he encouraged it to develop what were probably the first super-computers, although he was never convinced a machine could have the “insight” of a human mind. Friedman also spent much of his free time trying to decipher the famous Voynich Manuscript, written sometime between 1403–1437. However, after four decades of study he finally had to admit defeat, contributing no more than an educated guess as to its origins and meaning. At yovisto you can learn more about cryptology in the lecture of Gresham College Prof. Raymond Flood on ‘Public Key Cryptography: Secrecy in Public‘.'],\n",
       " [56,\n",
       "  'The Travels of William Dampier.  Map of the East Indies from Dampier’s “A New Voyage Round the World”, published in 1697.  On September 5, 1651, British explorer and natural historian William Dampier was probably born. He was the first Englishman to explore parts of what is today Australia, and the first person to circumnavigate the world three times. He has also been described as Australia‘s first natural historian. William Dampier was the son of a farmer and took part in two voyages to Newfoundland and Java before joining the Royal Navy. In 1683, he joined a group of buccaneers bound for the Pacific by way of Cape Horn. Three years later he set out upon his first crossing of the Pacific as one of the crew of the Cygnet. Before the explorer returned to England, he also visited the Philippines and the islands of the eastern archipelago. He then returned along with his journals via the Cape of Good Hope. His experiences were written down in a book titled “A New Voyage Round the World” and were published in 1697 and 1699. They highly increased his reputation and he was given the command of the expedition prepared for exploring the south seas. Dampier was appointed captain of the 26-gun warship HMS Roebuck and sailed from England towards New Holland via the Cape of Good Hope [2,3]. Dampier followed the Dutch route to the Indies, reaching the Australian mainland and recorded some of the Australian flora and fauna. The crew then reached Lagrange Bay, recordning further specimens. After a while however, the Roebuck was in such a bad shape, that caused the crew to founder on the homeward passage, preventing Dampier from pursuing his original plan of examining the seas east and south of New Guinea and depriving him of the honour of discovering the east coast of Australia. The ship ran aground in 1701 and the crew had to be picked up in order to return to England in April, 1701. Shortly after their return from the expedition, Dampier faced a law suit for removing his lieutenant, George Fisher, from the ship and jailing him in Brazil. He was charged for cruelty, docked his pay for the voyage, and dismissed from the Royal Navy [2]. However, Dampier was appointed commander of the 26-gun ship St George, with a crew of 120 men to act against French and Spanish interests. Dampier and his men were successful in capturing a number of small Spanish ships along the coast of Peru. They were released later on and the St George was supposed to make an attempt on the Manila galleon, the main object of the expedition. The ship was sighted unprepared, but by the time the captain and his officers were done arguing over their way of attacking the ship, it got its guns fully loaded. The St George suffered severe damages and while only 30 men stayed on the ship, the rest of the crew took a captured barque across the Pacific to Amboyna in the Dutch settlements. The ship was highly undermanned and had to be abandoned in Peru and Dampier was able to return back to England at the end of 1707 [1,4]. Dampier’s last voyage began in 1708 and he was appointed sailing master on the privateer Duke under Woodes Rogers. During the mission, the Scottish sailor Alexander Selkirk was rescued and good worth of £19.2 million on this day were plundered. However, William Dampier died as a poor man around 1715. Even though Dampier’s sailing and leadership abilities were somewhat questionable, he was immensely popular as an author. Dampier set new standards in travel literature and influencing for instance Swift and Defoe. His writings were acknowledged for their wealth of detail and were of interest in the field of science and literature [1,2]. At yovisto, you may be interested in a video lecture about Early Modern England and its developments in politics, religion, and society between 1688 and 1714 by Prof. Dr. Keith Wrightson at Yale University.'],\n",
       " [57,\n",
       "  'Louis Henry Sullivan – the ‘Father’ of the Skyscaper.  Chicago Auditorium Building by Sullivan and Adler.  On September 3, 1856, American architect Louis Henry Sullivan was born. Sullivan is identified with the aesthetics and innovation of early skyscraper design. Called the “Father of Modernism”. Sullivan studied architecture at the Massachusetts Institute of Technology starting at the age of only 16. Already one year later, he moved to Philadelphia and was hired by architect Frank Furness. Sullivan continued his career in Chicago, where he took part in the building boom following the Great Chicago Fire of 1871. He became a partner of Dankmar Adler in 1879, which was probably a turning point in his career. At first, their reputation as theater architects increased nation wide. Especially the Auditorium Building in Chicago caused the partners quite some fame. It consisted of a large theater, a hotel, and an office building with a 17-story tower including commercial storefronts at the ground level of the building fronting Congress and Wabash Avenues. This period was probably one of Sullivan’s most productive. The business partners became widely known for their outstanding office buildings like the Wainwright Building in St. Louis and the Chicago Stock Exchange Building. The limits of engineering considering tall buildings in the early 19th century depended on the strength of the walls, until cheap, versatile steel was developed. It became quickly possible to create tall, slender buildings with a strong and relatively lightweight steel skeleton. The new steel weight-bearing frame also enabled the architects to include larger windows causing more daylight to actually reach the interior spaces. With all these new options and new techniques, Sullivan was now able to create a whole new style of architecture. He decided to simplify the appearance of the building by breaking away from historical styles, using his own intricate floral designs, in vertical bands, to draw the eye upwards and emphasize the building’s vertical form. It was also important for him to relate the shape of the building to its specific purpose, which turned out successful. One of his trademarks became the terra cotta ornaments he installed in several buildings. Sullivan earned such a great reputation that he is often referred to as the father of skyscrapers, even though several other architects achieved this previously, especially John Wellborn Root is to mention, who created the Masonic Temple Tower which os often referred to as the originators of skyscrapers. For the Chicago World’s Fair in 1893, Sullivan built a massive Transportation Building and huge arched Golden Door, which stood out for its multicolored facade in the white city. This was one of the only buildings that caused Sullivan a great recognition outside the United States. In 1894, due to financial difficulties, Adler and Sullivan dissolved their company and from there, Sullivan faced difficult times. He lacked of further contracts and it is assumed that he also faced a depression. Louis Henry Sullivan passed away on April 14, 1924 in Chicago. At yovisto, you may be interested in a video lecture on How Calculus if changing Architecture by'],\n",
       " [58,\n",
       "  'Ernst Curtius and the Excavation of Olympia.  Olympia, draft by Friedrich Thiersch, 1879.  On September 2, 1814, German archaeologist and historian Ernst Curtius was born, who directed the excavation of Olympia from 1875-1881, the most opulent and sacred religious shrine of ancient Greece and site of the original Olympic Games. Ernst Curtius was born in Lübeck, Germany, and entered the University of Bonn in the 1830s. In this period, it is assumed, that Curtius discovered his interest in the Greek culture and he was acquainted with Friedrich Gottlieb Welcker, who highly influenced the young student and taught him in classical studies. In 1834, the Curtius moved to Göttingen where he studied under Karl Otfried Müller. The teacher was known to be enthusiastic about the field of archeology in combination with art. To complete his studies, Curtius moved to Berlin, but was highly disappointed from the city, the people, and especially the museums. He described Berliners as unreliable and spoiled, and the museums as poorly equipped. However, he continued his archaeological studies and increased his interests in ancient vases [1,2]. Curtius was invited to teach in Greece starting in 1837, as the home schooling the children of a befriended teacher. It is known that Curtius put great efforts in learning the language and enjoyed the high culture even though he had only little time for archaeological studies in the first year. Curtius returned to Berlin in early 1841 and earned his doctoral degree and in 1844, he was appointed professor at the University of Berlin. His now famous talk on Olympia took place in 1852 in Berlin and he initiated the first excavations in the area. Curtius became professor of archaeology in Göttingen, after Eduard Gerhard passed away. In 1875, the excavations at Olympia started and were directed by Ernst Curtius. Already in December of the same year, the first statues were exposed. Soon, the famous Heraion, or also known as the Temple of Hera was located. The Temple of Hera was destroyed by an earthquake in the early 4th century AD and never rebuilt. In modern times, the temple is the location where the torch of the Olympic flame is lit, by focusing the rays of the sun. Hermes of Praxiteles and many other statues were found. For his outstanding achievements, Cutius was asked to join the Prussian order Pour le Mérite for Science and Art. At yovisto, you may be interested in a video lecture on Greek Mythology by Ken Dowden.'],\n",
       " [59,\n",
       "  'Sergei Winogradsky and the Science of Bacteriology.  Sergei Winogradsky (1856 – 1953).  On September 1, 1856, Ukrainian microbiologist, ecologist and soil scientist Sergei Nikolaievich Winogradsky was born, who pioneered the cycle of life concept. He helped to establish bacteriology as a major biological science. Sergei Winogradsky was born in Kiev, which belonged to the Russian Empire. The young man finished his secondary education with the gold medal and entered the Imperial Conservatoire of Music in St Petersburg in 1875 to study piano. However, he decided to study chemistry and botany about two years later and was admitted to the University of Saint Petersburg, where he studied under Nikolai Menshchutkin and Andrei Sergeevich Famintzin. After receiving his master degree in 1884, Winogradsky continued his career at the University of Strasbourg and earned a great reputation for his work on sulfur bacteria. Winogradsky developed a method of culturing Beggiatoa by imitating its natural environment on glass slides and silica gel and he observed that the cells were rods and not, as it was previously assumed, pleomorphic [1]. The scientist settled in Zurich around 1888 and began investigating the process of nitrification, identifying the genera Nitrosomonas and Nitrosococcus, which oxidizes ammonium to nitrite, and Nitrobacter, which oxidizes nitrite to nitrate. Winogradsky’s interest in nitrification continued throughout his career and he isolated several genera of nitrifying bacteria. The type species for the genus Nitrobacter, N. winogradskyi was named after the scientist. Years later, Winogradsky’s daughter Helen worked on nitrogen-oxidizing bacteria at the Pasteur Institute. She isolated and described the new genera Nitrosogloea and Nitrosocystis. In 1933, she coauthored a paper with her father on Nitrosospira [1,2]. Winogradsky returned to St. Petersburg around 1891 and was shortly after appointed director of the Institute of Experimental Medicine and editor of the journal, Archives of Science. In this period, he identified the obligate anaerobe Clostridium pasteurianum, which is capable of fixing atmospheric nitrogen and he was elected honorary member of the Moscow Society of Naturalists. Winogradsky retired from his post in 1905 and accepted a position as head of agricultural bacteriology at the Pasteur Institute at an experimental station at Brie-Comte-Robert near Paris, France. He retired from his active work life in 1940. At yovisto, you may be interested in a video lecture about the History of Microbiology by Gilles Bolduc.'],\n",
       " [60,\n",
       "  'Sir Bernard Lovell and the Radioastronomy.  Sir Bernard Lovell (1913-2012). On August 31, 1913, English physicist and radio astronomer Sir Bernard Lovell was born. He was a pioneer in radar and radio telescopes and especially renowned for creating the Jodrell Bank radio telescope, the only antenna that could track rockets in space in the early years of the space race between the United States and the Soviet Union. Born at Oldland Common, Bristol in 1913, as the son of Gilbert and Emily Laura Lovell, Bernard Lovell’s childhood hobbies and interests included cricket and music – mainly the piano. He attended Kingswood Grammar School, now King’s Oak Academy, before he studied physics at the University of Bristol, where he obtained a bachelor of science degree in 1934, and a PhD in 1936 on the electrical conductivity of thin films. At this time he also received lessons from Raymond Jones, a teacher at Bath Technical School and later organist at Bath Abbey. The church organ was one of the main loves of his life, apart from science and cricket. After a year as an assistant lecturer in physics at the University of Manchester, he became a member of the cosmic-ray research team at that institution, working in this capacity until the outbreak of World War II in 1939. During World War II Lovell worked for the Air Ministry, doing valuable research in the use of radar for detection and navigation purposes for which he was named an Officer of the Order of the British Empire (OBE) in 1946.[1] Returning to the University of Manchester in 1945 as a lecturer in physics, Lovell acquired a surplus army radar set for use in his research on cosmic rays. Because interference from the surrounding city hampered his efforts, he moved the equipment, which included a searchlight base, to Jodrell Bank, an open field located about 30km south of Manchester near Goostrey in Cheshire. Shortly thereafter authorities at the university agreed to provide him with a permanent establishment at the site, which already belonged to the university’s botany department, and to sponsor the construction of his first radio telescope, for which he used the searchlight base as a mounting. In the course of his experiments, he was able to show that radar echoes could be obtained from daytime meteor showers as they entered the Earth’s atmosphere and ionised the surrounding air. With University funding, he constructed the then-largest steerable radio telescope in the world, which now bears his name – the Lovell Telescope. Completed in 1957, the telescope – known initially as Mark 1 and renamed the Lovell Telescope on its 30th anniversary – dominates the surrounding countryside and continues to make huge contributions to the science of astronomy.[2] The Mark 1 telescope was the only instrument that could both detect the first Soviet and American satellites and transmit instructions to them. Oddly enough as it now seems, the need for such a telescope had escaped both the telecommunications industry and the military leaders of both superpowers. Despite its spectacular success, which included tracking the Sputnik 1 satellite mission in 1957, Lovell went through a lot of troubles concerning the funding of the radio telescope. The main problem was to find sufficient funds to meet the rising costs of the project at times of government cuts. Thus in 1955 the project found itself £250,000 in debt. The Department of Scientific and Industrial Research agreed to find half if Lovell could raise the rest. A public appeal failed to raise more than £65,000 and it required a strong public press campaign to move the Treasury to meet the outstanding costs in 1960, three years after the telescope was first used. [3] In 1951, Lovell became professor of radio astronomy at Manchester University and the founder and first director of Jodrell Bank Experimental Station . In 1958 he gave the Reith Lectures, for the BBC, entitled The Individual and the Universe. Beginning in 1958, Lovell carried out much research on the characteristics of flare stars. In 1960, he began collaborating with Fred Whipple of the Smithsonian Astrophysical Observatory in this work. In 1955 he was elected a fellow of the Royal Society; in 1960 he received the Royal Medal of the society. Lovell was knighted in 1961 for his important contributions to the development of radio astronomy, At yovisto you can learn more about radio astronomy in the lecture of Prof. Walter Briskin from Princeton Institute of Advanced Studies on ‘AstroGPU – Real-time Digital Signal Processing in Radio-Astronomy‘'],\n",
       " [61,\n",
       "  'Fred Whipple and the Dirty Snowballs.  Fred Whipple (1906-2004). On August 30, 2004, American astronomer Fred Lawrence Whipple passed away. Amongst his achievements, he discovered some asteroids and comets, came up with the “dirty snowball” cometary hypothesis, and designed the Whipple shield. Fred Whipple was born on November 5, 1906, in Red Oak, Iowa, as the son of a farmer. An early bout with polio ended his ambition of being a professional tennis player. Whipple studied at Occidental College in Southern California, then majored in mathematics at the University of California at Los Angeles, graduating in 1927. Intrigued by an astronomy course he encountered, Whipple changed his area of study to astronomy and earned a doctorate degree in 1931.[1] While in graduate school, he helped map the orbit of the then newly discovered dwarf planet Pluto. His first job out of college was at Harvard University, where he inspected the telescopes’ photographic plates to make sure the cameras were operating correctly. He studied the trajectories of meteors, confirming that they originated within the solar system rather than from interstellar space. In 1933, he discovered the periodic comet 36P/Whipple and the asteroid 1252 Celestia. He also discovered or co-discovered five other non-periodic comets. Whipple found that nearly all visible meteors are made up of fragile material from comets, and that none can be shown to come from beyond the solar system. During World War II he co-invented chaff—aluminum fragments—to foil radar and protect planes.[2] He was awarded a Certificate of Merit for this in 1948. In 1950, in the same year he became professor of astronomy at Harvard, Whipple proposed his famous “dirty snowball” model for comet nuclei (originally he it”icy conglomerate” hypothesis of comet composition). He suggested that comets have icy cores inside thin insulating layers of dirt, and that jets of material ejected as a result of solar heating were the cause of orbital changes. The basic features of this hypothesis were confirmed in 1986 when spacecraft flew past comet Halley, however the exact amount (and thus the importance) of ices in a comet is an active field of research, with most of the recently obtained data pointing to a low contribution of ices to a comet’s mass. [2] Whipple also anticipated the era of artificial satellites and organized the members of Operation Moonwatch to track them. These groups were the only ones prepared and ready to make observations when the Soviet Union unexpectedly launched Sputnik I in 1957. His work on tracking artificial satellites led to improved knowledge of the shape of the earth and greatly improved positions on earth. Whipple directed the Smithsonian Astrophysical Observatory (SAO) from 1955 to 1973, before it joined with the Harvard College Observatory to form the Harvard-Smithsonian Center for Astrophysics (CfA). In the late 1960s, Whipple selected Mount Hopkins in southern Arizona as the site for a new SAO astronomical facility. Whipple was part of the group that initiated a novel and low-cost approach to building large telescopes first realized in the construction of the Multiple Mirror Telescope, a joint project of SAO and the University of Arizona. Mt. Hopkins Observatory was renamed Fred Lawrence Whipple Observatory in 1981. [3] Whipple died in 2004, aged 97. At yovisto you can learn more about astronomy in a popular lecture by Neil deGrasse Tyson at the University of Washington in Seattle.'],\n",
       " [62,\n",
       "  'Werner Forssmann and the dangerous Self Experiment in Cardiac Catheterization.  Werner Forssmann (1904 – 1979).  On August 29, 1904, German surgeon and Nobel Laureate Werner Forssmann was born. He is best known for the development of cardiac catheterization, which was developed by him in a dangerous self experiment. Werner Forssmann was born in Berlin and grew up with his mother, grandmother, and his uncle who was a physician. Forssmann was admitted to the School of Medicine at Friedrich-Wilhelms University where he studied the experiments performed by Claude Bernard, Auguste Chaveau, and and Etienne-Jules Marey. Also, Forssmann devoted his time to measuring and recording the blood pressure from the beating heart of a horse. Back then, he increased his interest in investigating the direct delivery of medications into the heart [1,3]. In 1929, Forssmann graduated and joined the Eberswalde Surgical Clinic. In this period, the scientist came to believe that with the help of a thin catheter, drugs could be directly injected into the major vessels of the heart. He assumed that this way, a failing heart could be resuscitated without serious invasive maneuvers like cardiac surgery or intracardiac puncture [1]. However, his supervisors refused permissions for a risky experiment like this and he began practicing the procedure on cadavers secretly as suggested by his friend, Richard Schneider, Head of Surgery [2]. After several successful experiments on the cadavers and himself, Forssmann inserted a lubricated catheter into his left cubital vein and pushed it up approximately 35 cm. This was performed with the help of Schneider who interrupted the procedure, think it was becoming too dangerous [1]. However, Forssmann had no motivation to give up at this point. He repeated the procedure a week later by himself. This time, the catheter was inserted 65cm. At first, he punctured the vein and pushed the catheter up until he sensed warmth at the venipuncture site. Then, the scientist walked to the radiology department where he located the catheter tip [2]. He was not able to push the catheter further into the right heart sections, because apparently, it was not long enough. In a scientific paper, Forssmann described his experiments and they turned out quite sensational, but also caused a large wave of criticism due to the high risks of the procedure. Shortly after, Forssmann was fired and he abadoned cardiology, continuing his career in urology [1,2]. The scientists André Cournand and Dickinson W. Richards used Forssmann‘s experiments and applied his technique on animals. Both scientists researched on the topic for 4 years and performed the first human cardiac catheterization in the United States. In a scientific paper, they also explained the usefulness and safety of the procedure. In 1956, he was awarded, together with André Cournand and Dickinson W. Richards, the Nobel Prize for Physiology or Medicine and he was, in the same year, appointed Honorary Professor of Surgery and Urology at the Johannes Gutenberg University, Mainz [3,4]. At yovisto, you may be interested in a video of an actual cardiac catheterization via the femoral artery by Dr. Michael Martinelli.'],\n",
       " [63,\n",
       "  'Antoine Cournot and the Mathematical Theory of Economics.  Antoine Cournot (1801 – 1877).  On August 28, 1801, French philosopher and mathematician Antoine-Augustin Cournot was born. He is considered being the first economist who applied mathematics to the treatment of economic questions. In 1838, he published Recherches sur les principes mathématiques de la théorie des richesses (Researches into the Mathematical Principles of the Theory of Wealth) which was a treatment of mathematical economics. Antoine Cournot was born in Gray, France and it is known that he was interested in politics from early age. By the age of 15, it is assumed that Cournot finished his education in Gray and read almost all works by Voltaire. He noted that all books he read in this period had a “decisive influence on all of his subsequent ideas and studies”. Despite his interests in mathematics, philosophy and politics, Cournot began studying law. Cournot continued his education in Besançon in order to study mathematics and was admitted at the École normale. In his later life, Cournot remembered this period as one of the happiest of his life [2,3]. Cournot was appointed professor of mathematics at Lyon in 1834. Four years later, he published ‘Recherches sur les principes mathématiques de la théorie des richesses‘, but unfortunately, his work stayed mostly unrecognized at this time. In the following years, the scientist simplified his theories and published them again in 1863 and 1876. I assume, every student of economics is aware of the Cournot-Nash-equilibrium and his theories on monopolies explained in this work. In the first chapters of his masterpiece, Cournot defines wealth and explains that all individuals of an economy seek to maximize their profits. The following chapters remain the most famous. After Cournot describes the demand curve, he discusses monopolies. This model is expanded in a way that he adds more competitors, leading to his famous oligopoly theory. However, his explanations on duopolies are described in detail including several graphics and calculations. Further topics of the masterpiece include tax theories on these models. Cournot admits that the wealth he defined at the beginning is not always beneficial to economic welfare [1]. It is assumed, that Antoine Cournot was influenced by Adam Smith‘s ‘Wealth of Nations‘, who described demand curves without exact definitions. Cournot’s findings are considered incredibly advanced. Still, the understanding of demand curves today is a little bit different. Most economic students would agree that the demand curve today is derived from the utility of the demanding party. Cournot however believed, that the demands of individuals are very subjective, and thus not to be expressed in formulas [1,3]. Even though Cournot was a scientist with a good reputation, his masterpiece was mostly ignored during his lifetime. Still, it is known that his influence on economists a few years later was significant. Especially Marshall and Walras are believed to be influenced by Cournot‘s theories. At yovisto, you may be interested in a lecture on Oligopoly by Jon Gruber at MIT.'],\n",
       " [64,\n",
       "  'Man Ray and the Art of Photograms.  Portrait of Man Ray and Salvador Dali, Paris by Carl Van Vechten.  On August 27, 1890, American modernist artist and photographer Emmanuel Radnitzky was born, better known as Man Ray. A significant contributor to the Dadaist and Surrealist movement, Man Ray produced major works in a variety of media but considered himself a painter above all. He was best known for his photography, and he was a renowned fashion and portrait photographer. Man Ray, born as Emmanuel Radnitzky, and grew up in Brooklyn, New York. During the 1910s, the entire family changed their surname to Ray and Emmanuel also changed his first name to Man while many referred to him as ‘Manny’. His family was mostly active in tailoring and also the children, including Man Ray, where included in the business. During his years in school, Man Ray also educated himself with museum visits where he studied numerous art works. Despite the fact, that the young Man Ray was offered a scholarship to study architecture, Man Ray already chose to become an artist. In his family’s apartment, he established his studio and it is believed, that he stayed there for about four years. To finance his dream, Ray became a technical illustrator in Manhattan. Even though Man Ray lived in New York City, he was mostly influenced by contemporary European works and his works showed many aspects of cubism. Also, Marcel Duchamp increased his interest in the movement of figures. His first known solo show took place in 1915 and one year later, Ray‘s first proto-Dada object, an assemblage titled Self-Portrait, was exhibited. The artist highly increased his interest in dadaism in this period, and he began creating mechanical and photographic methods of producing images. For instance, he combined a spray-gun with pen drawing. In 1920, he founded along with Duchamp, and Katherine Dreier the Société Anonyme, which became probably the first museum of modern art in the United States. Starting from 1921, Man Ray made his living in Paris and he increased his overall influence in the field of photography. Famous artists like James Joyce, Gertrude Stein, Jean Cocteau, Bridget Bate Tichenor, and Antonin Artaud, posed for Man Ray and his camera. In the 1930s, surrealist artist Méret Oppenheim posed nude for Ray in a famous photography series. Ray also created a photogram he named ‘rayographs’ he used to describe as ‘pure dadaism’. But, next to his ambitions in photography, the artist also directed a series of short films, which became known as Cinéma Pur. In the 1960s, Man Ray published his autobiography, which was again republished in 1999. He passed away in November 1976 and his wife, Juliet, organized a trust for his work and donated much of his work to museums. At yovisto, you may be interested in a video lecture on Dadaism and Duchamp by David Joselit.'],\n",
       " [65,\n",
       "  'Lee De Forest and the Audion.  Lee De Forest with two of his tubes.  On August 26, 1873, American inventor Lee de Forest was born. He is credited more than 180 patents. In 1906, de Forest invented the Audion, the first triode vacuum tube and the first electrical device which could amplify a weak electrical signal and make it stronger, making radio broadcasting, television, and long-distance telephone service possible, among many other applications. Lee De Forest knew that he wanted to become an inventor at very early age. It is known that he performed many experiments during his childhood and created several electrical and mechanical devices. The young De Forest wrote a letter to his father: “I intend to be a machinist and inventor, because I have great talents in that direction. In this I think you will agree with me. If this be so, why not allow me to so study as to best prepare myself for that profession? In doing this it would be much better to prepare myself for and take the Sheffield Scientific course“. Shortly after, he enrolled at the Sheffield Scientific School at Yale University in Connecticut in 1893, where he earned his Ph.D. with a dissertation on radio waves [1]. De Forest was hired by Western Electric, where he devised dynamos, telephone equipment, and early radio gear. He used the wireless telegraph which had earlier been introduced by Marconi and searched for a better detector or receiver and patented a device he called the ‘responder’. The inventor started his own business in 1902 called ‘De Forest Wireless Telegraph Company’, selling  radio equipment and demonstrating the new technology by broadcasting Morse code signals. However, he resigned as its president four years later. While Lee De Forest worked on the improvement of the wireless telegraph equipment, he modified the vacuum tube invented by John Ambrose Fleming and designed the Audion, and he used it to detect or receive code and voice messages. In the book, ‘Lee de Forest, King of Radio, Television, and Film’ it was said that “the patentable differences between this invention and that of Fleming are de Forest’s addition of the second battery between the plate and the earphone, called a ‘B’ battery, and the use of a telephone earphone instead of the galvanometer. These two very significant changes result in the ‘hearing’ of a signal as opposed to Fleming’s ‘seeing’ it using a visual indicator. These differences mean that only the de Forest version will be able to ‘hear’ the audio from the imminent invention of the radiotelephone” [1,2]. The inventor published the first known writings on how music could be send into homes using the wireless telephone, or the radio. He used his audion detector as a radio receiver and his audion amplifier to make small signals louder, and the oscillating audion as a transmitter. He set up a radio station in the Bronx in 1916, but without any financial success. In the 1920s, he worked on a system for producing motion pictures with sound, but unfortunately, the film industry became not really interested in his technology. However, when the industry later on adopted the concept of sound on film, a process very similar to De Forest’s was used [3]. For his contributions, Lee De Forest was awarded the 1922 Medal of Honor of the Institute of Radio Engineers and the 1946 Edison Medal from the AIEE. During his life time, the inventor filed almost 200 patents, but passed away as a poor man in 1961 [3]. At yovisto, you may be interested in a lecture by … on the book ‘Lee De Forest – King of Radio, Television, and Film‘'],\n",
       " [66,\n",
       "  'Elizabeth Montagu and the Bluestocking Society.  Montagu (seated middle) in company of other “Bluestockings” (1778).  On August 25, 1800, British social reformer, patron of the arts, salonist, literary critic, and writer Elizabeth Montagu passed away. She was one of the wealthiest women of her era and one of the founders of the Bluestocking Society, an informal women’s social and educational movement in England in the mid-18th century. Elizabeth Robinson grew up in a quite influential and wealthy family. She befriended Lady Margaret Harley in early years and spent a significant amount of time in her household, where important figures of the 1730s met and men and women were considered equal. She increased her interest in literature, when she began visiting her grandfather at Cambridge frequently, where he was occupied as the University’s Librarian [1,2]. In letters, Robinson sent to Harley in 1738, the young woman explained that she had no desire for marriage, as she saw marriage as expedient convention. In 1742, she married Edward Montagu who was a grandson of the first Earl of Sandwich and owned coal mines and estates in Northumberland, Yorkshire and Berkshire. However, it is assumed that both lived independent lives and also, he was twice as old as Elizabeth. Together, they had a son, who passed away in 1744. Following this event, Elizabeth Montagu became increasingly religious [1,3]. After Montagu had moved to London in 1850, she initiated so called ‘conversation parties’ and is believed to have said “I never invite idiots to my house” in this period. These events were soon called blue-stockings and they turned into elaborate evenings where literature was discussed. She also began hosting events of this kind in Bath, where she lived at various times in several houses. She became one of the three leading literary or blue-stocking hostesses, together with Elizabeth Vesey and Frances Boscawen. Dr. Johnson once wrote about Montagu, that “She diffuses more knowledge than any woman I know, or indeed, almost any man. Conversing with her, you may find variety in one“. She anonymously contributed 3 dialogs to Lyttelton’s Dialogues of the Dead in 1760 and published her book ‘An Essay on the Writings and Genius of Shakespeare compared with the Greek and French Dramatic Poets, with some Remarks upon the Misrepresentations of Mons. de Voltaire‘ at the end of the 1760s. Her work was a great success and her reputation as an author grew significantly. Unfortunately, her husband died in 1775 and Elizabeth Montagu decided to take control of the families’ interest. She proved to be a great business woman and it is believed that was always on good terms with her family [1]. At yovisto, you may be interested in a video titled “Searching for Shakespeare“.'],\n",
       " [67,\n",
       "  'Pliny the Elder and the Destruction of Pompeii.  John Martin’s Destruction of Pompeii and Herculaneum (1821).  On August 25, 79 AD, Roman author, naturalist and natural philosopher Pliny the Elder died, while attempting the rescue by ship of a friend and his family from the eruption of Mount Vesuvius that had just destroyed the cities of Pompeii and Herculaneum. Unfortunately, there don’t exist contemporary pictures or portaits of Pliny the Elder. Thus, I decided to show you an also imaginary picture of the destruction of Pompeii instead. Gaius Plinius Cecilius Secundus, known as Pliny the Elder, was a Roman scholar, encyclopedist, and nationalist who was born in 23 AD, in Novum Comum in Gallia Cisalpine (today Como, Italy). He completed his studies in Rome where he received education in literature, oratory, and law, as well as military training. In 46 AD at the age of 23, he began a military career by serving in Germany under Pomponius Secundus, rising the rank of cavalry commander.[1] Twelve years later, he returned to Rome. Legal advocate during the reign of emperor Nero (died in 68) he gained favor under Vespasian and assumed various official positions: he served as a procurator in Gaul, Africa and Spain, where he gained a reputation for integrity. He also served on the imperial council for both Vespasian and Titus. Despite his active public life, Pliny the Elder still found time to write enormous amounts of material. He was the author of at least 75 books, not to mention another 160 volumes of unpublished notebooks. His books included volumes on cavalry tactics, biography, a history of Rome, a study of the Roman campaigns in Germany (twenty books), grammar, rhetoric, contemporary history (thirty-one books), and his most famous work, his one surviving book, Historia Naturalis (Natural History), published in A.D. 77. Natural History consists of thirty-seven books including all that the Romans knew about the natural world in the fields of cosmology, astronomy, geography, zoology, botany, mineralogy, medicine, metallurgy, and agriculture.[1] Published during the last two years of Pliny‘s life, the Naturalis Historia is one of the largest works surviving from classical times. And, although it contains many mistakes, some due no doubt to the author’s untimely death, which prevented any revisions, there is a surprising level of accuracy. He states correctly, for example, that Venus is the only heavenly body, other than the sun and moon, that casts a visible shadow; or that a bird egg can be made flexible by placing it in vinegar and dissolving away its hard outer shell. Pliny’s writings offer not only insights into nature itself, but also into the Roman conception of nature, which differed substantially from our own.[2] Pliny the Elder did not marry and had no children. In his will he adopted his nephew, which entitled the latter to inherit the entire estate. An account of Pliny’s death is given in a letter from his nephew: He [Pliny the Elder] was at that time with the fleet under his command at Misenum. On August 24th [79 AD], about one in the afternoon, my mother asked him to look at a cloud of the most peculiar size and shape. He had been sunbathing earlier, which he had followed with a cold bath and a light lunch. He had then returned to his books. But he rose at once and went to high ground where he could get a better view of this remarkable phenomenon.[…] To a man of such learning as my uncle, this phenomenon seemed extraordinary and well worth investigation. He ordered a light ship prepared, and told me I could come along if I liked.[…]They tried to decide whether it would be wiser to remain inside their houses — which now were being shaken to their foundations with repeated, violent concussions from the eruption — or to flee to the open fields, where the stones and cinders rained down in such heavy showers that, although they were individually light, they seemed to threaten annihilation. […] They decided to go down to the shore to see whether they could escape by sea, but the waves were still running too high. There my uncle lay down on a sail that had been spread for him, and called twice for some cold water, which he drank. Then a rush of flame, with the reek of sulfur, made everyone scatter, and made him get up. He stood with the help of his servants, but at once fell down dead, suffocated, as I suppose, by some potent, noxious vapor. He had always had a weak respiratory tract, which was often inflamed and obstructed.[3] At Yovisto, Diana E. E. Kleiner explores the civic, commercial, and religious buildings of Pompeii as part of her lecture on ‘Roman Architecture‘. She is an art historian known worldwide for her expertise on the art and architecture of the ancient Romans.'],\n",
       " [68,\n",
       "  'Paul Nipkow and the Picture Scanning Technology.  Paul Nipkow (1860-1940). On August 22, 1860, German engineer Paul Gottlieb Nipkow was born. He is best known for having conceived the idea of using a spiral-perforated disk (the Nipkow disk), to divide a picture into a matrix of points, and became an early television pioneer. Nipkow was born on August 22, 1860, in Lauenburg (Lębork) in Pomerania, now in Poland. Inspired by the work of Guglielmo Marconi, Nipkow began thinking about the challenge of transmitting a visual image while still a student in Germany. While at school in Neustadt (Wejherowo), West Prussia, Nipkow began to experiment in telephony and the transmission of moving pictures. It was well known that any successful transmission device required three essential components: a device to translate the visual image into an electronic impulse, a second device to reassemble that impulse into an image again, and a third device by which to transmit the impulse from the first device to the second. In 1884, even before completing his degree, Nipkow had developed and patented a transmissions system that achieved all three requirements.[1] While still a student Nipkow conceived the idea of using a spiral-perforated disk (Nipkow disk), to divide a picture into a matrix of points. Accounts of its invention state that the idea came to him while sitting alone at home with an oil lamp on Christmas Eve, 1883. Alexander Bain, a Scottish inventor who had patented the electric clock, had transmitted images telegraphically in the 1840s but the Nipkow disk improved the encoding process. The Nipkow disk was a metal or cardboard disk that was perforated with twenty square holes arranged in a spiral so that each hole was a little closer to the center than the last. As Nipkow spun the disk, he shined a strong light through the holes and onto the subject. Because each hole was slightly offset, the image was scanned in a series of twenty horizontal lines.[1] Nipkow‘s Disk from his 1884 patent application Another important component of his invention was a selenium photocell used to transform differences in the intensity of light into electric current. The current could be transmitted to a receiver, where the image was reproduced with an identical disk that was synchronized with the first in front of a lamp whose brightness changed according to the received signal. Nipkow once used his device to transmit a visual image from London to Paris, but the system was never developed for commercial use. Ironically, at the time, investors could not foresee a practical use for it, and therefore, Nipkow received little recognition during his lifetime for the feat.[3] Nipkow applied for a patent in the imperial patent office in Berlin for his electric telescope. This was for the electric reproduction of illuminating objects, in the category “electric apparatuses”. German patent No. 30105 was granted on 15th January 1885, retroactive to 6th January 1884, the 30 marks fee being lent by his future wife. It was allowed to lapse after 15 years. Nipkow had taken a position as a designer in the Berlin-Buchloh Institute and did not continue further development of the electric telescope.[2] The first television broadcasts used an optical-mechanical picture scanning method, the method that Nipkow had helped create with his disk. The first inventor who used Nipkow’s disc successfully, creating the first television pictures in his laboratory in October 1925, was John Logie Baird. From 1937, when the infant BBC television service chose it above Baird’s mechanical system, total electronic picture scanning, based on the work of Manfred von Ardenne and the iconoscope invented by Vladimir Zworykin, became increasingly prevalent and Nipkow’s invention was no longer essential to further development of television. Today, the Nipkow disk is used extensively in reflected light confocal scanning microscopy to produce images that can be viewed in real time through the microscope eyepieces. At yovisto you can watch an RCA documentary on the history of television to learn more about the invention of television and its early days.'],\n",
       " [69,\n",
       "  'William Murdock ‘enlights’ the 19th Century.  William Murdock (1754 – 1839).  On August 21, 1754, Scottish engineer and inventor William Murdock was born. He was the first to make extensive use of coal gas for illumination and a pioneer in the development of steam power. William Murdock (sometimes also referred to as Murdoch) excelled in the field of math from early age and even studied the principles of mechanics and worked much with metal and wood while helping out in his fathers work. It is not quite clear, which achievements  Murdock really made in these years. It is assumed that he built a wooden horse with his father that he was responsible for the construction of a bridge. Also, it is believed that the young Murdock performed several experiments with coal gas, but this is not really proven. He got to know James Watt around 1777 and was hired in Birmingham due to his extraordinary abilities. Murdock was soon sent to Cornwall in order to erect and maintain Boulton & Watt engines, which he did perfectly, as Boulton later wrote. However, they were not the only company operating in the Cornwall area and it became soon clear that most of these companies started copying from each other. Murdock was appointed to undertake some inspections of their competitor’s engines and was sometimes threatened for doing so. But Murdock also spent a lot of time improving the Boulton & Watt engines and it is known that he discussed some further inventions with his employers. Unfortunately, his contract stated that all inventions he made belonged to the company and therefore, it is not exactly clear, which improvements he made in this period. In 1799, he invented a steam wheel that was a lot more efficient than any of its kind and due to the fact that his contract was amended by then, he was able to file this patent in his own name. To one of his most important inventions belongs the so called road locomotive in 1784. Nicolas-Joseph Cugnot was already known to have demonstrated a similar device even though it weighted more than 4 tonnes. Murdock built a working model on his own and on this day there are several accounts from witnesses who “saw the model steam carriage run around Murdock’s living room in Redruth in 1784“. This model had 3 wheels with the engine and boiler placed between the two larger back wheels. Murdock performed the first public demonstration in Great Britain, but he never really gained popularity for these achievements. However, Murdock is best known for his gas light. Many historians believe that his first experiments with gas took place in a cave in the early 1790s and first, he had to develop a method for the production and the capture of gas. He returned to Birmingham in 1798 where he continued his experiments and four years later, he performed a public exhibition of his lighting by illuminating the exterior of the Soho Foundry. Soon, companies like Philips gained their interest in illuminated their factories. Still, it is believed that he never really made much money from his invention, even though soon most towns in Britain were lit by gas. Murdock moved into a house in Birmingham, where he installed several of his inventions like the gas light, a doorbell that worked by compressed air and even a conditioning system. Around 1830, his partnership with Boulton & Watt came to an end. William Murdock passed away in 1839. At yovisto, you can watch John Merriman’s video lecture on the Industrial Revolution at Yale University.'],\n",
       " [70,\n",
       "  'Jöns Jacob Berzelius – One of the Founders of Modern Chemistry.  Jöns Jacob Berzelius (1779 – 1848).  On August 20, 1779, Swedish chemist Jöns Jacob Berzelius was born. Berzelius is considered, along with Robert Boyle, John Dalton, and Antoine Lavoisier, to be one of the founders of modern chemistry. In Sweden, Berzelius Day is celebrated on 20 August in honor of him. Jöns Jacob Berzelius was born in 1779 as the son of a teacher and was educated in Linköping, Sweden. His medical studies started in 1796 in Uppsala because this field of study was quite close to natural sciences and most likely provided a decent income. He studied under Anders Gustav Ekeberg, the chemist who discovered tantalum and after Berzelius left the university, his uncle organized him a job as a pharmacist. While in medical school at the University of Uppsala, he read about Alessandro Volta’s “electric pile” and while working at the Medevi mineral springs, a spa and health resort, Berzelius constructed one for himself from 60 zinc plates and 60 copper plates. His thesis for his medical degree was on the effect of electric shock on patients with various diseases, for instance paralysis. Even though he reported no improvement in his patients, his interest in electrochemical topics continued. In 1807 he was made a professor at the Medical College in Stockholm, which soon after became the Karolinsska Institute. A year later he began his long association with the Royal Swedish Academy of Sciences [1,3]. Berzelius intended to create a textbook for his medical students and performed a series of experiments which made him most famous. With these experiments, he managed to establish that the elements in inorganic substances are bound together in definite proportions by weight. His increasing interest in all kinds of compounds led to his discovery of numerous elements, such as cerium, selenium, and thorium. Selenium was named after the moon goddess selene by Berzelius [3]. Also, several students worked together with the scientist and discovered several elements as well, including lithium and vanadium. Berzelius was then able to determine the atomic weight of almost all elements and he was motivated to create a logical system of symbols (H, Cl, Ca …) [1,2]. Jöns Jacob Berzelius received 12 royal orders and was member of almost 100 academies and scientific societies around the globe. He was elevated to the nobility in 1818 and awarded the baronetcy in 1835. The scientist, who is on this day considered as one of the founders of modern chemistry passed away on August 7, 1848 [3]. At yovisto, you may be interested in a short documentary on Jöns Jacob Berzelius.'],\n",
       " [71,\n",
       "  'Philo Taylor Farnsworth and the Electronic Television.  Philo Taylor Farnsworth (1906 – 1971).  On August 19, 1906, American inventor and television pioneer Philo Taylor Farnsworth was born. As a pioneer in the development of electronic television, he counts responsible for taking all of the moving parts out of television inventions. Philo Taylor Farnsworth was born in Utah as the eldest of five children and moved to Idaho with his family, when he was about 12 years old. He was taught the legends of Edison and Bell by his father and quickly decided to become an inventor himself. The young boy convinced his chemistry teacher to teach him extra lessons and to let him attend more advanced courses. It has been delivered that the still 12-year old Farnsworth, bored of his household duties, created an electric motor which he connected with the mechanical washing machine. It is assumed that he developed his interest in electronic television at the age of only 14. He told his teacher Justin Tolman, how television should really work and sketched all of his ideas on the blackboard. Several years later, Farnsworth’s lawyer tried to track the teacher down to testify about what the young boy drew. After only two years of high school, he was allowed to attend Brigham Young University. Unfortunately, his father passed away shortly after and Farnsworth had to take care of his family from then on [1,2,3]. Farnsworth got to know Cliff Gardener, and together they opened a radio repair business in Salt Lake City, which failed. However, the young inventor became acquainted with Leslie Gorrell and George Everson, a pair of San Francisco philanthropists who were then conducting a Salt Lake City Community Chest fundraising campaign. They agreed to back Farnsworth’s early television research with an initial $6,000. He set up a laboratory in Los Angeles, where he performed his experiments [2]. He managed to build his first electronic camera, but for some reason it exploded during early testings. Farnsworth had to find new investors and managed to ‘broadcast’ the first pictures in 1927 [1]. Unfortunately, Vladimir Zworykin had already patented electronic television in 1923, which caused both, Farnsworth and the Radio Corporation of America, which Zworykin worked for, lots of troubles. The company increased its interest in the television market and bought Zworykin’s patents and a long law fight evolved between the parties. Even though Farnsworth is considered the winner of these battles, World War II was about to start right after and the demand for television devices decreased. After the war, he lost his patents since they were only valid for seven years. Still, the RCA promoted Vladimir Zworykin as the inventor of electronic television for many years [1]. Despite the fact, that Farnsworth was the man responsible for its technology, he appeared only once on a television program. On July 3, 1957, he was a mystery guest on the CBS quiz show I’ve Got A Secret. After the panel unsuccessfully tried to guess his secret “I invented electronic television”, he discussed his research projects for a while with the host and he said: “There had been attempts to devise a television system using mechanical disks and rotating mirrors and vibrating mirrors, all mechanical. My contribution was to take out the moving parts and make the thing entirely electronic, and that was the concept that I had when I was just a freshman in high school in the Spring of 1921 at age 14“. At yovisto, you may be interested in a short except from the show I’ve Got A Secret starring Philo Farnsworth.'],\n",
       " [72,\n",
       "  'Brook Taylor – Forerunner of Differential Calculus.  Brook Taylor (1685-1731). On August 18, 1685, English mathematician Brook Taylor was born. He is best known for Taylor’s theorem and the Taylor series, a method for expanding functions into infinite series. Brook Taylor was born in Edmonton to John Taylor of Bifrons House, Kent, and Olivia Tempest in 1685. It was the year when King Charles II passed away and his Roman Catholic brother succeeded him as King James II of England, the year of the Monmouth Rebellion, led by James Scott, 1st Duke of Monmouth, illegitimate son of Charles II. Newton was about to publish his Philosophiæ Naturalis Principia Mathematica (1687) and Leibniz’s most important mathematical writings were about to be published. Brook Taylor grew up not only to be an accomplished musician and painter, but he applied his mathematical skills to both these areas later in his life. He entered St John’s College, Cambridge, as a fellow-commoner in 1701, and took degrees of LL.B. and LL.D. in 1709 and 1714, respectively. Having studied mathematics, in 1708 he obtained a remarkable solution of the problem of the “centre of oscillation,” which, however, remained unpublished until May 1714, when his claim to priority was disputed by Johann Bernoulli. In 1712 Taylor was elected to the Royal Society, and acted as secretary to the society from 13 January 1714 to 21 October 1718. Clearly it was an election based more on the expertise which his tutors and others knew that Taylor had, rather than on his published results. Also in 1712 Taylor was appointed to the committee set up to adjudicate on whether the claim of Newton or of Leibniz to have invented the calculus was correct. [1] Taylor’s Methodus Incrementorum Directa et Inversa (1715) added a new branch to higher mathematics, now called the “calculus of finite differences“. Among other ingenious applications, he used it to determine the form of movement of a vibrating string, by him first successfully reduced to mechanical principles. The same work contained the celebrated formula known as Taylor’s formula, the importance of which remained unrecognized until 1772, when J. L. Lagrange proclaimed it the basic principle of the differential calculus. Between 1712 and 1724 Taylor published thirteen articles on topics as diverse as describing experiments in capillary action, magnetism and thermometers. He gave an account of an experiment to discover the law of magnetic attraction (1715) and an improved method for approximating the roots of an equation by giving a new method for computing logarithms (1717).[1] Taylor was married twice. His marriage in 1721 with Miss Brydges of Wallington, Surrey, led to an estrangement from his father, which ended in 1723 after her death in giving birth to a son, who also died. In 1725 he married—this time with his father’s approval—Sabetta Sawbridge of Olantigh, Kent, who also died in childbirth in 1730. However, his daughter, Elizabeth, survived. Taylor’s fragile health gave way and he fell into a decline, and died on 30 November 1731, aged 46. “As a mathematician he was the only Englishman, after Newton and Cotes, capable of holding his own with the Bernoullis; but a great part of the effect of his demonstrations was lost through his failure to express his ideas fully and clearly.”[2] Learn more about Calculus in the lecture of MIT Prof. Dr. Gilbert Strang on ‘Highlights of Calculus‘.'],\n",
       " [73,\n",
       "  'Hazel Bishop and the Long Lasting Lipstick.  Image: Flickr.  On August 17, 1906, US-American chemist Hazel Gladys Bishop was born. She is best known as the inventor of the first long lasting lipstick in 1949, an invention on which she founded a successful cosmetic company. Hazel Gladys Bishop graduated in 1929, earning a degree in chemistry. It is assumed that originally, Bishop intended to become a doctor, but instead left medical school and started her career in bio-chemistry. One year after earning her degree, the scientist began working at the New York State Psychiatric Hospital and Institute next to taking night school classes in biochemistry at the College of Physicians and Surgeons at Columbia University. It is known that Bishop has always been encouraged by her mother to open her own business one day, “even if it’s only a peanut stand“. After she had gained some working experience as a research assistant to dermatologist A. Benson Cannon, her goal was to create a new cosmetic formulation and during the 1930s she developed two products, a pimple concealer and mentholated tissues. Unfortunately, none of these products were successful on the market [1]. Apparently, lipstick has already been used in the Ancient Mesopotamia. It is assumed that Ancient Sumerian men and women invented the lipstick about 5000 years ago and decorated their faces, especially their lips and their eyes. Also, it is known that the women of the Indus Valley Civilization applied red tinted lipstick to their lips for decoration purposes. In the 16th century, it is assumed that lip coloring became popular in England and back then, it was made from beeswax and red stains from various plants. Even though lipstick became widely known in the western world as well during the 19th century, it was not really considered acceptable for respectable women, especially in Britain. It is assumed that the first commercial lipstick had been invented in 1884 in Paris [4]. After her first failures, Hazel Bishop intended to create a product for a broader target group and a study revealed that about 98% of women wore lipstick every day. The chemist began experimenting in order to create a nondrying, nonirritating, long-wearing lipstick, using her home kitchen as a laboratory. Her goal was to develop a smudge-proof and long lasting lipstick that would not smear on clothing. Her first experiments included staining dyes, oils, and molten wax and eventually, the “No-Smear Lipstick” was born. Bishop found financial support and the Hazel Bishop, Inc. was formed. The very first commercial run of the lipstick was produced, and it debuted at a fashion show given by the Barnard College Club of New York on November 4, 1949. The product appeared in regular stores shortly after and was an instant financial success [1]. The early advertisement said “Never again need you be embarrassed by smearing friends, children, relatives, husband, sweetheart” and after the first day, about 600 lipsticks were already sold [2]. The quite aggressive marketing campaign was led by Raymond Spector and by 1953, the company had captured about 25% of the lipstick market. Sadly, Bishop’s success did not last long. Her partner Spector bought out the stockholders and recapitalized the company. This way, her shares reduced to only 8%. She was fired from the company in 1954 and lost all of her incomes instantly. The former business owner had to agree to stay out of the cosmetics industry in the future. However, Bishop founded further companies, dealing with perfume and health cosmetics. During an interview, she said in 1963, that “I’m still essentially a chemist and I expect I shall always be one“. Hazel Bishop was elected fellow of the American Institute of Chemists in the 1950s, giving numerous lectures about the chemistry and cosmetics industry [3]. Hazel Bishop died on December 5, 1998. During an interview, she commented: “If you are willing to strive and have no fear of failure, you can never fail as long as you are on to the next step“. At yovisto, you may be interested in a “Hazel Bishop” television commercial from around 1950.'],\n",
       " [74,\n",
       "  'Pierre Mechain and the Meridian Survey Expedition.  Pierre Méchain (1744-1804).).  On August 16, 1744, French astronomer and surveyor Pierre François André Méchain was born. Together with Charles Messier, was a major contributor to the early study of deep sky objects and comets. He participated in the Meridian survey expedition in 1792 that produced measurements, which have served as the fundament of the metric system. Pierre Méchain was born in Laon, a medieval town in the Picardy region of northern France, as the son of the ceiling designer and plasterer Pierre François Méchain, a man of modest means, and Marie-Marguerite Roze. Pierre was educated by the Jesuits and as a young boy his aim was to become an architect, although his main hobby was astronomy. Méchain studied at the prestigious institution of the École Nationale des Ponts et Chaussées, founded to train civil engineers. But, studying there was expensive and Méchain’s father did not have the necessary resources to be able to support his son. Thus, Méchain had to interrupt his studies and take on the role of tutor to two young boys from a noble family.[1] However, his talents in astronomy were noticed by Joseph Jérôme Lalande, for whom he became a friend and proof-reader of the second edition of his book “L’Astronomie“. Seeing the benefits of having Méchain enter his profession, Lalande arranged a position for him in the cartography department in the Depôt de la Marine in Versailles in 1772 as assistant hydrographer, where he worked through the 1770s engaged in hydrographic work and coastline surveying. It was during this time that he met Charles Messier, who worked in the same department and apparently, they became friends. In the same year, he also produced his first astronomical work, a paper on an occultation of Aldebaran by the Moon and presented it as a memoir to the Academy of Sciences. M101 – discovered by Pierre Méchain on March 27, 1781, For the next ten years from 1780 to 1790 Méchain undertook surveys to produce maps and also worked in astronomy where he is particularly famed as a discoverer of comets. Some of the maps were produced for military purposes like those of Germany and north Italy which he worked on from 1780. Others, like that carried out in 1787 to find the precise distance between the Greenwich observatory in England and the Paris observatory, were part of an international project [1]. Méchain’s work on comets became of major importance in 1781 when he discovered two comets in the same year. As with all his comet discoveries, and with many comets discovered by others, he calculated their orbits. Between 1779 and 1782, he found 30 deep sky objects, 29 of which were original firsts. Among Méchain’s discoveries include M63, M65, M66, M68, M72, M75, M76, M78, and M102 through M107, the majority of which are galaxies and globular clusters. Interestingly, Méchain never set out to observe deep-sky objects. Like Messier, he was solely interested in cataloging objects that might be mistaken for comets; having done so, he was the second-most successful discoverer of comets of his time, after Messier himself. He was admitted to the French Académie des sciences in 1782, and was the editor of Connaissance des Temps from 1785 to 1792; this was the journal which, among other things, first published the list of Messier objects. In 1789 he was elected a Fellow of the Royal Society. Méchain’s most important mapping work was geodetic: the determination of the southern part of the meridian arc of the Earth’s surface between Dunkirk and Barcelona beginning in 1791. This measurement would become the basis of the metric system’s unit of length, the meter. He encountered numerous difficulties on this project, largely stemming from the effects of the French Revolution. He was arrested after it was suspected his instruments were weapons, he was interned in Barcelona after war broke out between France and Spain, and his property in Paris was confiscated during The Terror. He was released from Spain to live in Italy, then returned home in 1795. In 1799, he became the director of the Paris Observatory. Continuing doubts about his measurements of the Dunkirk-Barcelona arc led him to return to that work. This took him back to Spain in 1804, where he caught yellow fever and died. At yovisto, you may enjoy a video lecture at Gresham College titled ‘Clusters of Galaxies‘ by Carolin Crawford.'],\n",
       " [75,\n",
       "  'Louis de Broglie and wave nature of matter.  Louis de Broglie (1892 – 1987).  On August 15, 1892, French physicist and Nobel Laureate Louis de Broglie was born. He is best known for making groundbreaking contributions to quantum theory. He postulated the wave nature of electrons and suggested that all matter has wave properties. This concept is known as wave-particle duality or the de Broglie hypothesis. Louis de Broglie attended the Lycée Janson of Sailly and decided to continue his studies in literature, but then earned his degree in history in 1910. The scientist earned his degree in medicine three years later and was then conscripted for military service and posted to the wireless section of the army. He was stationed at the Eiffel Tower. When World War I was over, de Broglie spent another four years studying physics. He was especially interested in theoretical physics and completed his thesis titled Recherches sur la Théorie des Quanta (Researches on the quantum theory) at the Faculty of Sciences at Paris University and it was known to be highly influenced by the works of Albert Einstein. He later described his interest for theoretical physics: “I was attracted to theoretical physics by the mystery enshrouding the structure of matter and the structure of radiations, a mystery which deepened as the strange quantum concept introduced by Planck in 1900 in his research on black-body radiation continued to encroach on the whole domain of physics“. The ideas set out in de Broglie’s doctoral thesis, which first gave rise to astonishment owing to their novelty, were subsequently fully confirmed by the discovery of electron diffraction by crystals in 1927 by Davisson and Germer. They served as the basis for developing the general theory nowadays known by the name of wave mechanics, a theory which has utterly transformed our knowledge of physical phenomena on the atomic scale. The concept of matter waves in quantum mechanics reflects the wave–particle duality of matter. The waves became later known as de Broglie waves and in his theory, the scientist shows that the wavelength is inversely proportional to the momentum of a particle. Also, the frequency of matter waves, as deduced by de Broglie, is directly proportional to the total energy E (sum of its rest energy and the kinetic energy) of a particle [1,2]. De Broglie continued his career in publishing further scientific works teaching at Sorbonne. The Institut Henri Poincaré was just built in Paris in this period, and the scientist was offered to teach courses in theoretical physics there. He became the chair of theoretical physics at the Faculty of Sciences at the University of Paris in 1932 and it is known that many French and international students came to work with the brilliant de Broglie, who also supervised numerous doctoral theses [2]. Louis de Broglie devoted his work mostly to the study of the various extensions of wave mechanics. It is known that he put much effort into Dirac’s electron theory, the new theory of light, the general theory of spin particles, and applications of wave mechanics to nuclear physics and he authored over 25 books on these various fields of study. In 1929, he was awarded the Henri Poincaré medal at the Academie des Sciences and in the same year, the Swedish Academy of Sciences conferred on him the Nobel Prize for Physics “for his discovery of the wave nature of electrons”. The scientist was elected a member of the Academy of Sciences of the French Institute in 1933 and became its Permanent Secretary for the mathematical sciences three years later [1,3]. At yovisto, you may be interested in a short introduction to “What is Quantum” by Dr. John Preskill.'],\n",
       " [76,\n",
       "  'John Logie Baird and the Television.  John Logie Baird (1888-1946). On August 14, 1888, Scottish scientist and engineer John Logie Baird was born. He is considered the inventor of the world’s first television, the first publicly demonstrated colour television system, and the first purely electronic colour television picture tube. Born in Helensburgh, Argyll and Bute (then Dunbartonshire) on the west coast of Scotland, Baird was the youngest of four children of the Reverend John Baird, the Church of Scotland’s minister for the local St Bride’s church. Dogged by ill health for most of his life, he nonetheless showed early signs of ingenuity, rigging up a telephone exchange to connect his bedroom to those of his friends across the street [1]. He was educated at Larchfield Academy in Helensburgh; the Glasgow and West of Scotland Technical College (which later became the University of Strathclyde). In 1906 he went to study Electrical Engineering at Glasgow and West of Scotland Technical College. His degree course was interrupted by World War I and he never returned to graduate. Rejected as unfit for the forces because of his ill health condition, he served as superintendent engineer of the Clyde Valley Electrical Power Company. When the war ended he set himself up in business, as e.g., including the ‘Baird Undersock’ and jam-making in Trinidad [2], but only with mixed results. The development of television was the result of work by many inventors. Among them, Baird was a prominent pioneer and made major advances in the field. Baird moved to Hastings, on the south coast of England to follow his dream and built what was to become the world’s first working television set using items including an old hatbox and a pair of scissors, some darning needles, a few bicycle light lenses, a used tea chest, and sealing wax and glue that he purchased. In February 1924, he demonstrated to the Radio Times that a semi-mechanical analogue television system was possible by transmitting moving silhouette images. In July of the same year, he received a 1000-volt electric shock, but survived with only a burnt hand. By 1925, he moved to London and was ready to give the first public display of a working television at Selfridges in Oxford Street, London. Shoppers saw slightly blurred but recognizable images of letters. First known photograph of a moving image produced by Baird’s “televisor”, ca. 1926 At the heart of Baird’s system was a rotating disc containing spirals of holes (or lenses) through which a beam of light passed to scan the object. The poor quality of photocells limited Baird’s early equipment to sending shadows and outlines. He was able to apply for a patent on July 26, 1923, but although the BBC expressed interest, they would not participate in his work.[2] On January 26th, 1926, a viable television system was demonstrated using mechanical picture scanning with electronic amplification at the transmitter and at the receiver. It could be sent by radio or over ordinary telephone lines, leading to the historic trans-Atlantic transmissions of television from London to New York in February, 1928.[3] There were notable firsts, including a performance of Pirandello’s play, The Man with a Flower in His Mouth – the first play to be performed on television in Britain, on 14 July 1930. The first outside broadcast followed; the Derby was televised live in June 1931 and again the following year. Finally the BBC began to take television seriously, and on 22 August 1932, the BBC began a regular television service from basement studio BB in the new Broadcasting House using Baird’s system, albeit still experimental and still low-definition 30-line.[2] In 1936, the BBC started the world’s first regular high-definition service from Alexandra Palace using the Baird system, though it was abandoned one year later in favour of a system developed by Marconi-EMI. BY 1939, 20,000 television sets were in use in Great Britain, just 14 years after Baird’s first public demonstration of his system at work.[4] In 1939, he showed colour television using a cathode ray tube in front of which revolved a disc fitted with colour filters, a method taken up by CBS and RCA in the United States. In 1941, he patented and demonstrated a system of three-dimensional television at a definition of 500 lines. On 16 August 1944, he gave the world’s first demonstration of a fully electronic colour television display. Baird died at home in Bexhill-on-Sea on 14 June 1946. At yovisto you can watch an RCA documentary on the history of television with the Scotsman John Logie Baird giving the world`s first public demonstration of live, moving images in 1925.'],\n",
       " [77,\n",
       "  'The Art of Suspense – Alfred Hitchcock’s Cinema.  Alfred Hitchcock (1899 – 1980).  On August 13, 1899, English film director and producer Alfred Hitchcock was born. Reknowned as England’s best director, he pioneered many techniques in the suspense and psychological thriller genres. Hitchcock directed more than fifty feature films in a career spanning six decades and often is considered the most influential filmmaker of all time. Alfred Hitchcock enrolled at the London County Council School of Engineering and Navigation and became a draftsman and advertising designer with a cable company afterwards. During his time at the company, Hitchcock apparently submitted articles for the company’s in-house publication, The Henley Telegraph. He also started his interest in photography in this period and found a job as a title card designer at what would become Paramount Pictures and other film companies. Hitchcock came to Potsdam, Germany around 1924 to co-author the film The Blackguard and it is assumed that he was highly influenced by the works of Fritz Lang and F. W. Murnau. The first films, Hitchcock directed were financially unsuccessful until in 1926, when he produced his first thriller, The Lodger. The suspense film was about the hunt for a serial killer in London similar to Jack the Ripper and was an instant success [1,2]. About two years after releasing The Lodger, Hitchcock began working on another film that was later considered a milestone in filmmaking. The film is based on the play Blackmail by Charles Bennett and is about a woman from London who is blackmailed after killing a man that tries to rape her. After starting production as a silent film, British International Pictures decided to convert Blackmail into a sound film during filming. In it, Hitchcock began his long tradition of using famous landmarks for suspense sequences. Further films of the period include a musical film revue Elstree Calling and The Man Who Knew Too Much, which was released in 1934. One year later, The 39 Steps was produced and it was considered the fourth best British film of the 20th century, which also made Hitchcock incredibly popular in the United States. In the New York Times, a feature writer stated: “Three unique and valuable institutions the British have that we in America have not. Magna Carta, the Tower Bridge and Alfred Hitchcock, the greatest director of screen melodramas in the world“[1,3]. The director and producer moved to Hollywood and in the early 1940s, the film Rebecca, which won the Academy Award for Best Picture. In his early years in Hollywood, Hitchcock produced Shadow of a Doubt and it is assumed that it was his personal favorite of all his films. In the film, the young Charlotte Newton suspects her uncle Charlie Oakley of being a serial murderer and it was filmed in Northern California in 1942. A few years later, Hitchcock founded an independent production company through which he made his first film in color, Rope. However, after his 1949 production of Under Capricorn, he returned to black-and-white films for several years. In 1955, Hitchcock became a U.S. citizen and five years later, he produced his presumably best known film, Psycho. The film became popular for the famous shower scene, which features 77 different camera angles, and for the early death of the heroine. The film broke box-office records around the globe and was probably one of the most profitable black-and-white sound film ever made [3]. The master of suspense directed more than 50 feature films during his long career. Today, his work is admired worldwide, and he’s considered one of our finest directors. Although many of his landmark films remain copyrighted, some of his important works, particularly his early ones, have slipped into the public domain. At yovisto, you may enjoy the film Jamaica Inn from 1939.'],\n",
       " [78,\n",
       "  'Meet Sue, the Dinosaur.  Sue’s Skeleton on Display in the Chicago Fields Museum, photo: Connie Ma, wikipedia Usually, in our articles we focus on a person, a development, an invention, or an decisive moment in history. Today, a long dead animal will be the protagonist of our post. But, it’s the story of an extraordinary finding. On August 12, 1990, Sue, the largest and most complete Tyrannosaurus Rex skeleton found to date, was discovered by Sue Hendrickson in South Dakota. All kids love dinosaurs. When I was a boy, I made no exception to that rule. I knew the latin names of dozens of dinosaurs before I learned a second language in school. And what use was it for? I don’t know, because I cannot see any direct connecting link between my childhood love for paleontology and my profession as a computer scientist. But anyhow, let’s get back to our story. Although if you are not familiar with all the various types of dinosaurs, for sure you will know ‘T.Rex‘. Probably you remember the iconographic scene from Steven Spielberg’s ‘Jurassic Park‘, when the people in the Jeep were chased by a T.Rex running wild. This kind of dinosaur really is kind of impressive. And especially the specimen we are talking about with an overall length of more than 12 meters and a skull of the size of 1.5 meters. It was during the summer of 1990, when a group of workers from the Black Hills Institute searched for fossils at the Cheyenne River Indian Reservation, in western South Dakota near the city of Faith. By the end of the summer, the group had discovered Edmontosaurus bones and was ready to leave. However, before the group could depart, on August 12, a tire on their truck was deflated. While the rest of the group went into town to repair the truck, Sue Hendrickson decided to explore the nearby cliffs that the group had not investigated. As she was walking along the base of a cliff, she discovered some small pieces of bone. She looked above her to see where the bones had originated, and observed larger bones protruding from the wall of the cliff. President of the Black Hills Institute, Peter Larson determined that the bones were from a T. Rex. A closer examination of the site showed many visible bones above the ground and some articulated vertebrae. The crew began to uncover the bones and was really excited, as it became evident that much of the dinosaur had been preserved. Previously discovered T. Rex skeletons were usually missing more than half of their bones. It was later ascertained that Sue – named after her discoverer Sue Hendrickson – was a record 80 percent complete. The large size and the excellent condition of the bones were also surprising. The skull was nearly 1.5 meters long, and most of the teeth were still intact. Soon after the remains were found, a dispute arose over who was the legal owner of the bones. Originally, the Black Hills Institute had obtained permission from the owner of the land, Maurice Williams, to excavate and remove the skeleton, and had paid Williams $5,000 for the remains. After a lengthy trial, the court decreed that Maurice Williams retained ownership, and the remains were returned in 1995. Williams then decided to sell the remains, and contracted with Sotheby’s to auction the property. On October 4, 1997, the auction began at $500,000; less than ten minutes later, The Chicago Field Museum had purchased the remains with the highest bid of $8,362,500, where the mounted bones are on display now. Only Sue’s real skull was not incorporated into the mount as subsequent study would be difficult with the head 4 meters off the ground. At yovisto you can learn more about paleontology in the TED talk of Dr. Paul Sereno on ‘What can Fossils Teach Us?‘.'],\n",
       " [79,\n",
       "  'Richard Mead and the Understanding of Transmissible Diseases.  Richard Mead (1673–1754) Image Author: Mezzotint by R. Houston after A. Ramsay.  On August 11, 1673, English physician Richard Mead was born. His work, A Short Discourse concerning Pestilential Contagion, and the Method to be used to prevent it, was of historic importance in the understanding of transmissible diseases. Richard Mead was mostly educated at home by his father and a private tutor, who also lived with them. He moved to Leyden in 1692 in order to study at the local University and decided to travel to Italy along with his friends. His stay turned out longer than originally expected and the young scientist continued his studies of philosophy and physic at Padua. In 1695, Mead received his doctoral degree and visited Naples and Rome before returning to his birth place, Stepney. There, Mead’s father was a respected and established man who had much influence in the community. The young Mead also did a considerable amount of business and was highly supported by his father. In 1702, Mead gained reputation through his publication “Mechanical Account of Poisons” [1, 2]. For this masterpiece, Mead received much attention and was elected fellow of the Royal Society, where he later became counsil and in 1707, vice-president. He was appointed physician at St. Thomas’s hospital one year after his famous publication. Mead received the degree of doctor of medicine from Oxford University. Around the 1720s, Mead was appointed physician in ordinary to the King. Next to his activities as a physician, Mead became known as a wealthy man and philanthrope. Especially his patronage of literature and fine arts stayed in people’s minds [1]. During the seventeenth century, Europe began to adopt health measures that specifically addressed the presence of plague in private households. However, the Great Plague in 1665 led to an overall abandonment of previously used quarantine practices. In 1710, quarantine laws in England grew increasingly more stringent in response to outbreaks of plague in nearby countries and the Quarantine Act of 1710 was established which included a series of regulations concerning the observation and probable detention of all ships arriving in the kingdom of Great Britain from infected areas. The Act of 1710 included quite harsh penalties for those who violated the guidelines and instructed governmental officials to detain all ships including, passengers and their merchandise for the length of forty days. When the news about an epidemic in Marseilles in 1720 spread across Britain, Richard Mead was asked for advice by the government due to his great reputation. The Privy Council considered Mead an expert in quarantine and therefore, the most qualified for the task given his other credentials. In 1720 by request of the state, Mead published A Short Discourse Concerning Pestilential Contagion and the Methods to Be Used to Prevent It. The government incorporated Mead’s advices into the newly established Quarantine Act of 1721 [2]. In this work, Mead introduced three specific causes of the disease: infected air, infected persons, and the transportation of tainted goods from infected places. As a result of Mead’s studies, the Parliament decided to prohibit trade with countries suspected of infection for up to one full year. Also, in Mead’s opinion, the previous detention of passengers and merchandise were insufficient. Instead of the former method, which required passengers and merchandise to be quarantined aboard the ship or vessel on which they arrived, Mead recommended the construction of lazarets in order to receive ships and their goods during the process of isolation. The physician also advised that the burning of clothing and bedding belonging to infected persons and families should be performed [2,3]. Mead’s work on transmissible diseases went through nine editions, the last in 1744. In the last two editions, Mead added further elaborations of his earlier views and included references to Newton’s Optics and the Ether theory. Some of Mead’s practical recommendations for dealing with the plague were relatively new. References to his plague tract appeared in a number of medical and nonmedical works well beyond his lifetime [3]. At yovisto, you may be interested in a video lecture on The Black Death by Prof. Dr. Richard Evans at Gresham College.'],\n",
       " [80,\n",
       "  'Abu Ma’shar al-Balkhi – The Prince of Astrologers.  Abu Ma’shar al-Balkhi (787-886). Probably on August 10, 787, Persian astrologer, astronomer, and Islamic philosopher Abu Ma’shar al-Balkhi (Abu Ma’shar Ja’far ibn Muhammad ibn ‘Umar al-Balkhi) was born. He is thought to be the greatest astrologer of the Abbasid court in Baghdad. He wrote a number of practical manuals on astrology that profoundly influenced Muslim intellectual history and, through translations, that of western Europe and Byzantium. We’ve realized that our daily blog on History of Science somehow is focussed on the Western view of history and the World. Of course it’s because we ourselves are part of this Western world of science. Nevertheless, we should also include scientists and other people important for the history of science, who do not necessarily belong to this Western canon of science. Today, we begin with the famous Persian astrologer, astronomer, and philosopher Abu Ma’shar al-Balkhi. There is not really much known about the life of this Persian scientist. We know that Abu Ma‘shar was born in Balkh, (Afghanistan) and lived in Baghdad. Early in his work as an academic he studied the hadith. The hadith is a report of the teachings, deeds and sayings of the Islamic prophet Muhammad. He was antagonistic toward the Hellenistic tradition of philosophical sciences, and sought to stir popular opinion against his contemporary Al-Kind?, one of the champions of these sciences. By means of a ruse, Kind? sought to interest Abu Ma’shar in arithmetic and geometry. This apparently succeeded in mollifying Abu Ma’shar, who realized that to understand philosophical arguments he must study mathematics. Though he never became proficient in mathematics, he became interested in astrology, another of the Hellenistic sciences. Interestingly he started to study astrology at age 47, but this late start did not deter him because he was said to have lived to the ripe old age of 100 [2]. His works on astronomy are not extant, but information can still be gleaned from summaries found in the works of later astronomers or from his astrology works. All works on astronomy attributed to Abu Ma’shar are lost, and only his astrological works in Arabic are known to us. His writings were held up as models of astrological practice. For instance, they provided the Italian 13th century astronomer and astrologer Guido Bonatti with a frequently cited source in his summa of Medieval Astrology, the Liber Astronomia (c. 1282). According to other sources, also the father of English literature Geoffrey Chaucer was familiar with Abu Ma’shar’s writings. One can almost say that Abu Ma’shar established the standard practice for Medieval Astrology in general with additional input from Masha’allah, Ptolemy and Dorotheus [1]. It was Abu Ma’shar who arranged for the translation into Arabic of Ptolemy‘s great treatise on astronomy, thereafter known by its Arabic title as the Almagest. The first type is works that provide an introduction to astrology, as e.g. his 106?chapter work, Kit?b al-mudkhal al-kab?r, which he wrote “for the establishment of astrology by sufficient arguments and proofs.” Not since Ptolemy‘s Tetrabiblos had philosophical proofs of astrology been argued; Abu Ma’shar philosophical basis was Aristotelian physics, which he had acquired through Kind?’s circle.[2] His introduction to astrology which received many translations to Latin and Greek starting from the 11th-century. It had significant influence on Western philosophers, like Albert the Great. The second part of his astrological writings focussed on historical astrology. Most prominent is his Kit?b al-milal wa??l?duwal (“Book on religions and dynasties“), is in eight parts in 63 chapters probably also his most important work, commented on in the major works of Roger Bacon, Pierre d’Ailly, and Pico della Mirandola. The third and final type of writings is Abu Ma’shar works on genethlialogy, the science of casting nativities. The large number of extant manuscripts suggests its high popularity in the Islamic world. Overall, he is said to have written some fifty other books, which are all lost. At yovisto you can learn more about astronomy in a popular lecture by Neil deGrasse Tyson at the University of Washington in Seattle.'],\n",
       " [81,\n",
       "  'Ernest Lawrence and the Cyclotron.  The Cyclotron at Berkeley Laboratory with Ernest Lawrence (3rd from left) Image: Science Museum London On August 8, 1901, pioneering American nuclear scientist Ernest Orlando Lawrence was born. He was awarded the 1939 Nobel Prize in Physics for his invention of the cyclotron. He is also known for his work on uranium-isotope separation for the Manhattan Project, and for founding the Lawrence Berkeley Laboratory and the Lawrence Livermore Laboratory. Ernest Lawrence grew up in South Dakota. His parents were offsprings of Norwegian immigrants and taught at the high school in Canton, South Dakota. His mother, Gunda, remembered his enormous curiosity when he was still a child. Apparently, the two-year-old Lawrence managed to light a fire with matches and burn down all of his clothes. His mother further remembered that “Ernest was always of a happy disposition and life to him seemed to be one thrill after another, but he was also always persistent and insistent!“. With his high school friends, Lawrence built a very early short-wave radio transmitting station and later applied his experiences to the acceleration of protons [1,2]. Lawrence enrolled at the University of South Dakota and sold kitchenware to farming households in order to finance his education. This training was later helpful, when Lawrence had to sell scientific projects to government officials and funding agencies. After earning his Bachelor degree, the young physicist enrolled at the University of Minnesota in order to finish his master studies and he moved to Yale, where Lawrence received his Ph.D. in 1925. Before even turning 27 years old, Lawrence accepted an associate professor position at Berkeley, where he became the institution’s youngest full professor three years later [1]. In 1936 he became Director of the University’s Radiation Laboratory as well, remaining in these posts until his death [3]. It is assumed that while reading a scientific paper by Rolf Widerøe about a device that produced high-energy particles, he was inspired to work on a more compact accelerator that would fit into the Berkeley laboratories. The very first cyclotron he constructed was apparently only 10cm in diameter and consisted of brass, wire, and sealing wax. In this period, Lawrence and his research group built a bigger machine. Lawrence then provided the equipment needed for experiments in high energy physics and he received his patent for the cyclotron in 1934, which he assigned to the Research Corporation. He was invited to the 1933 Solvay Conference to give a presentation on the cyclotron and Lawrence extended the apparatus to a 37-inch cyclotron in June 1937. Two years later, it was used for the first time to bombard iron and produce its first radioactive isotopes. In the same year, the first cancer patient received neutron therapy from the cyclotron. Ernest Lawrence was awarded the Nobel Prize in physics in 1939 and was the first at Berkeley to become a Nobel Laureate. The scientists was also known as an incredibly prolific writer. Most of his work was published in The Physical Review and the Proceedings of the National Academy of Sciences. He was decorated with numerous awards and prizes including Medal for Merit and he held honorary doctorates of thirteen American and one British University, the University of Glasgow [3]. Ernest Orlando Lawrence passed away on August 27, 1958. At yovisto, you may be interested in a video lecture on Particle Accelerators at Berkeley University by Professor Norman.'],\n",
       " [82,\n",
       "  'Victor Franz Hess and the Cosmic Radiation.  Hess back from his balloon flight in August 1912.  On August 7, 1912, Austrian physicist Victor Franz Hess provided evidence of a high-altitude radiation in one of his balloon rides, which later was called cosmic radiation. Together with Carl Anderson, he received the 1936 Nobel Prize in Physics for the discovery of cosmic radiation. Victor Franz Hess was educated in Graz, Austria. There, he attended the grammar school and the University of Graz. At the Physical Institute in Vienna, Hess worked in the field of radioactivity and was supported by Professor von Schweidler. He was active at the Institute of Radium Research of the Viennese Academy of Sciences between 1910 and 1920 and was appointed Extraordinary Professor of Experimental Physics at the Graz University after his discovery of the cosmic radiation [1]. Back then, scientists wondered, why the air in electroscopes-instruments for detecting electrical charges became electrically charged no matter how well the containers were insulated. First, they believed that radioactivity from ground minerals was responsible, but then, the effect would have diminished at a height of about 300 meters. It was the German physicist Theodor Wulf, who measured around 1910 ionization at the bottom of the Eiffel Tower and a remarkably higher ionization at the top. Hess then speculated that the source of ionization could be located in the sky rather than the ground [2]. First, Hess determined 500m as the possible height at which ground radiation would stop producing ionization and started designing instruments that could not be damaged by temperature and pressure changes. The scientist then made ten ascents in a balloon between 1911 and 1913. He found out that ionization soon ceased to fall off with height and began to increase rapidly. At a height of several miles, the ionization was a few times greater than at the earth’s surface. He concluded, therefore, that “a radiation of very high penetrating power enters our atmosphere from above“. On April 12, 1912, Hess made an ascent during an almost total eclipse of the sun and he concluded that since ionization did not decrease during the eclipse, the sun could not itself be the main source of the radiation. Hess’s theory about rays from space did not receive general acceptance at the time he proposed it. However, his findings were supported by Robert Andrews Millikan in 1925, who also named the phenomenon “cosmic rays“. From there, further research topics on particle and nuclear physics were established. Carl David Anderson discovered the positron and muon in cosmic rays and received the Nobel Prize in physics, along with Victor Franz Hess in 1936 [2]. At yovisto, you may learn more about “Cosmic Radiation – a showstopper for space exploration?” in a lecture by Marco Durante'],\n",
       " [83,\n",
       "  'Girolamo Fracastoro’s Germ Theory.  Girolamo Fracastoro (ca. 1476 – 1553).  On August 6, 1553, an Italian physician, poet, and scholar in mathematics, geography and astronomy Girolamo Fracastoro passed away. Fracastoro subscribed to the philosophy of atomism, and rejected appeals to hidden causes in scientific investigation. He is known for his proposal of a scientific germ theory for how diseases are transmitted. Fracastoro’s ideas helped make unpopular public health measures more accepted, such as destroying animals, or thorough cleaning or burning of infected possessions during a plague. His ideas preceded the work of Louis Pasteur and Robert Koch by more than 3 centuries. Girolamo Fracastoro was born in Verona and was able to study in Padua literature, mathematics, astronomy, philosophy, and medicine. In Padua, he became a lecturer of logic and later conciliarius anatomicus. He was elected to the College of Physi\\xadcians in 1505, but moved to Incaffi after a plague outbreak. There, Fracastoro started working on his famous poem Syphilis [1] and in 1546, he wrote De contagione et contagiosis morbis et eorum curatione libri tres (The three books on contagion, contagious diseases and their cure), which highly increased his fame as a figure in the history of medicine [2]. The exact origin of syphilis is not clear, even on this day. Fracastoro however, believed in contrast to contemporary scientists, that the disease had existed previously but had been forgotten. Many believed that syphilis had been brought back from the Americas by Columbus, had been spread throughout Spain and France, and had been brought to Italy with the invasion of Charles VIII in 1494. Fracastoro assumed that syphilis resurfaced be\\xadcause of certain astrological conditions. In his opinion, the disease was spread by some kind of ‘seed’ in the air, which many historians believe to be a forerunner or germ theory. According to Fracastoro, the body is made up of numerous invisible particles that are passed in contagion, corrupting the new body. He distinguishes three different types of contagion. Contagion by direct contact, through the air, and by carriers such as soiled clothing and linen. He decided, that syphilis belonged to the second category and explained that the ‘seeds’ originated in the air, entered the body, germinated, and became ready for contagion. Fracastoro furtherly asumed that the use of cold, drying-out medicines guaiacum might cure the disease [1]. Fracastoro’s explanation of the transmission of syphilis and further contagious diseases was seen as a pioneering perspective in microbiology. Although microorganisms had been mentioned as a possible cause of disease by the Roman scholar Marcus Varro in the 1st century BC, Fracastoro’s was the first scientific statement of the true nature of contagion, infection, disease germs, and modes of disease transmission. Fracastoro’s theory was widely praised during his time, but its influence decrea, and it fell into general disrepute until an experimental version was later elaborated by German physician Robert Koch and French chemist Louis Pasteur [2,3]. At yovisto, you may be interested in a Hollywood-produced melodramatic short film that deals with prophylaxis, diagnosis and clinical treatment of syphilis.'],\n",
       " [84,\n",
       "  'Joseph Carey Merrick – the Elefant Man.  Joseph Carey Merrick (1862-1890). On August 5, 1865, Joseph Carey Merrick was born. Sometimes incorrectly referred to as John Merrick, Joseph Carey Merrick was an English man with severe deformities who was exhibited as a human curiosity named the Elephant Man. He became well known in London society after he went to live at the London Hospital. You might have heard of Merrick from David Lynch’s popular film ‘The Elefant Man’, released in 1980 starring Anthony Hopkins. Joseph Merrick was born in Leicester, Leicestershire, as one of four siblings and had no outward symptoms of any disorder for the first few years of his life. As he grew, a noticeable difference between the size of his left and right arms appeared and both his feet became significantly enlarged. His skin appeared thick and lumpy, he developed an enlargement of his lips, and a bony lump grew on his forehead. At some point during his childhood he fell and damaged his hip. This injury became infected and left him permanently lame. The Merrick family explained his symptoms as the result of his mother Mary’s being knocked over and frightened by a fairground elephant while she was pregnant with Joseph. The concept of maternal impression — that the emotional experiences of pregnant women could have lasting physical effect on their unborn children — was still common in 19th century Britain. Merrick held this belief about the cause of his affliction for his entire life. When he was 10, his mother died and his father soon remarried. Merrick left school at 13, which was quite usual for that time, but had difficulty finding employment. Merrick was becoming a greater financial burden on his family and eventually, his father secured him a hawker’s licence which enabled him to earn money selling items from the haberdashery shop, door to door. But, Merrick’s facial deformities rendered his speech increasingly unintelligible and prospective customers reacted with horror to his physical appearance. Being severely beaten by his father and feeling rejected by his family, he left home for good. In late 1879, aged 17, Merrick entered the Leicester Union Workhouse. After four years in the workhouse and after several futile trials to get work, Merrick contacted a showman and proposed that he should exhibit him as the Elephant Man. In London he was exhibited in a penny gaff shop on Whitechapel Road, directly across the street from the London Hospital. One day he was visited there by a surgeon named Frederick Treves, who invited Merrick to be examined and photographed. After getting on tour in Europe, Merrick was robbed by his road manager and abandoned in Brussels. He eventually made his way back to London. Unable to communicate, he was found by the police to have Frederick Treves’ card on him, who took Merrick back to the London Hospital. Although his condition was incurable, Merrick was allowed to stay at the hospital for the remainder of his life. Treves visited him daily and the pair developed quite a close friendship. Merrick also received visits from the wealthy ladies and gentlemen of London society. Merrick’s condition gradually deteriorated during his four years at the London Hospital. His facial deformities continued to grow and his head became even more enlarged. Merrick died on 11 April 1890, aged 27. The official cause of death was asphyxia, although Treves, who dissected the body, said that Merrick had died of a dislocated neck. He believed that Merrick — who had to sleep sitting up because of the weight of his head — had been attempting to sleep lying down, to “be like other people”. You can learn more about Neurofibrimatosis in the presentation of Dr. Maria T. Acosta, MD on ‘Neurofibrimatosis Type I – Information for Families‘.'],\n",
       " [85,\n",
       "  'Nicolas-Jacques Conté and the Pencil.  Nicolas-Jacques Conté (1755-1805). On August 4, 1755, French painter, inventor, army officer and balloonist, Nicolas-Jacques Conté was born. Among others, he is credited with the invention of the modern pencil. Moreover, some consider him one of the greatest inventive minds of the eighteenth century. He distinguished himself for his mechanical genius which was of great avail to the French army in Egypt. Napoleon Bonaparte called him “a universal man with taste, understanding and genius capable of creating the arts of France in the middle of the Arabian Desert.” Nicolas-Jacques Conté was born at Saint-Céneri-près-Sées (now Aunou-sur-Orne) in Normandy, France, as one of six children. He was the descendent of a family of farmers who had cultivated the same fields for over two hundred years. Of his family we know little except that one of his brothers took over the responsibilities of the estate after the death of his father, while the other left the household to establish his own farm. Two of his sisters became nuns at the Hotel Dieu de Sées. It is related that, at the age of nine, Conté fashioned a violin with a knife as his sole tool. If the story is true, it records the earliest indication of his later accomplishments. One of his distinctive traits was the ability to imagine, design, and fabricate beyond the normal limitations of the equipment available to him. He was given a job as assistant to the gardener at the Hotel Dieu de Sées, where he was also given the task of aiding a painter who was commissioned to decorate the chapel of the convent with a series of panels. He worked at grinding pigment and cleaning brushes and began to learn about painting by observation. When the painter fell ill, Conté asked if he might try his hand. He argued that he should be allowed to do one panel which, if considered unsuccessful, could be painted over. Needless to say, the trial was acceptable and he completed the decoration of the chapel. The beginning of his career as an artist was assured.[1] One of his early interest while still at Sées was in the newly developing science of aeronautics. He made at least one hot air balloon which he flew in the public square. He contributed to the improvement of the production of hydrogen gas, as well as the treatment of the gas bag of the balloon itself. He also took up portrait painting, from which he derived a considerable income. Passionately interested in mechanical arts and science, he began displaying his inventive faculty during the French Revolution. In 1794, as director of the Aerostatic (Montgolfiers) school he taught chemistry, physics and mechanics. He lost the left eye in an explosion experimenting with gases and varnish. Later he invented a telegraphic system for long distance communication in balloons. Prior to Conté’s time pencils had almost all been made from lumps of pure graphite, mined from the Borrowdale mine in England and sawed into strips that were then encased in wood. In 1794 all this changed when Conté, already a famous inventor and scientist was charged by his patron, Carnot, to invent a substitute for the now expensive and difficult to come by pure English graphite. The French Republic was at that time under economic blockade and unable to import graphite from Great Britain, the main source of the material. It took him just 8 days to produce a workable lead. In just over a week he had invented what was to become known as the Conté process: a way to make pencil leads from powdered graphite and clay that us still, essentially, used today. Previous attempts to use graphite in powdered form (perhaps from material extracted from low quality ore in poorer mines, or in an attempt to use the waste products generated by sawing and cutting) had always foundered but Conté worked out how to mix graphite in powdered form with clay, and bake it, in such a way that not only did he produce a usable lead, but was able to make leads in varying degrees of hardness. As well as his process for mixing leads, Conté is also generally credited with inventing the machinery needed to make round leads, and he can truly be said to be the creator of the pencil. Indeed, for about 100 years, pencils in France were known as the crayons Conté and of course pencils continue to be made with the Conté brand name to this day [2]. After improving the barometer he parted with the scientific expedition to Egypt organized by Napoleon Bonaparte. There, Nicolas Jacques started his participation in the conquest of Egypt by inventing a tan method to avoid the fast rusting of metals provoqued by the egyptian weather. He studied the physics of mirages and the arts and production methods of the Egyptian people. During the Cairo’s rebellion most of the instruments of the Arts and Sciences commission were lost. Conté said “We have no instruments; it is simple, we are going to reconstruct them“. He played an important role in developing many different procedures including fabrication of cardboard, coins, powder, windmills, chirurgical instruments, telescopes, cannon carriages for the desert, ovens and many other instruments. Moreover, he also participated in the reproduction of the Rossette stone by chalcography. The reproduction that was the basis for Champollion’s work on Egyptian hieroglyphes. No wonder that Napoleon said about him “Conté was able to recreate the French arts in the middle of Arabian deserts“. In 1801, coming back to France, Conté directed the elaboration of “Description de l’Égypte“, a wonderful work about Egypt. He invented an engraving machine for the illustrations of the Description. On December 5, 1805, he died from an aneurism at the age of 50. Learn more about the creativity of innovators and inventors in the TED talk of Elizabeth Gilbert on ‘A different way to think about creative genius‘.'],\n",
       " [86,\n",
       "  'Richard Arkwright – the Father of the Industrial Revolution.  Portrait of Sir Richard Arkwright by Mather Brown.  On August 3, 1792, Sir Richard Arkwright passed away. He was a self-made man and a leading entrepreneur during the early Industrial Revolution. Arkwright’s achievement was to combine power, machinery, semi-skilled labour and the new raw material (cotton) to create mass-produced yarn. His skills of organization made him, more than anyone else, the creator of the modern factory system. Later in his life Arkwright was also known as ‘the Father of the Industrial Revolution‘. Richard Arkwright was educated by his cousin and later apprenticed to a barber. In the 1750s, he invented waterproof dye for wigs. He increased his interest in spinning and carding machinery that could turn raw cotton into thread. However, industrial production of cotton was not really possible back then. Lewis Paul invented a carding machine in 1748 that required a lot of human labor, while James Hargreaves’s spinning Jenny was suitable to produce only the weaker thread or the woof. Arkwright began working on an improved version of a spinning machine and along with the clockmaker John Kay, he was able to the water frame which produced a stronger length-wise thread [1,2]. Arkwright and Kay patented their work and Arkwright used nearly all of his savings to do so. The inventor turned to water-powered energy and built, along with Jedediah Strutt and Samuel Need, the first successful water-powered cotton mill and presumably, the first modern factory in the world. He went on to improve the cotton production process and patented improved carding machine which along with other inventions enabled him to increase the production of high quality thread at a lower cost. Soon, he set up new mills throughout Britain and became one of the most successful entrepreneurs of the Industrial Revolution [1]. In the following period, the inventor and businessman had to face several accusations by contemporary inventors to have stolen their ideas and technologies. Arkwright lost his patent for the water frame and his carding machine from 1785. Still, he had been very well established in this field of business and was knighted by King George III in 1786 [1]. Only six years later, the inventor passed away as a very wealthy man. Even though he has been accused of stealing many ideas, it is no doubt that his status as a well established inventor and his contribution to the Industrial Revolution are significant. Samuel Slater later brought Arkwright’s manufacturing system to America and managed to build a water-powered cotton mill there, which was an important development in the industrialization of the US [1,2]. At yovisto, you may be interested in a video lecture on the Industrial Revolution by John Merriman at Yale University.'],\n",
       " [87,\n",
       "  'John Tyndall and the Physics of Air.  John Tyndall (1820-1893). caricatured as a preacher in the magazine Vanity Fair, 1872.  On August 2, 1820, British physicist John Tyndall was born. His initial scientific fame arose in the 1850s from his study of diamagnetism. Later he made discoveries in the realms of infrared radiation and the physical properties of air. As the most prominent example, he was able to demonstrate why the sky is blue. John Tyndall was born in Leighlinbridge, County Carlow, Ireland, where his father was a local police constable. He attended the local schools in County Carlow until his late teens, and was probably an assistant teacher near the end of his time there. Subjects learned at school notably included technical drawing and mathematics with some applications of those subjects to land surveying. In 1839, he was hired as a draftsman by the government’s land surveying mapping agency in Ireland and England. In the decade of the 1840s, a railroad-building boom was in progress, and Tyndall’s land surveying experience was valuable and in demand by the railway companies, who employed Tyndall in railway construction planning. In 1847 he began to teach mathematics at Queenwood College Hampshire. In 1848 Tyndall went to study in Germany where he was one of the first British subjects to receive the new Ph.D. at Marburg. His years in Germany while still a young man turned Tyndall into something of a naturphilosophisch romantic pantheist [1]. He stayed at Marburg for a further year doing research on magnetism. In summer 1951, Tyndall returned to England, where he first continued his experimental work on magnetism and diamagnetic polarity, which soon made Tyndall known among the leading scientists of the day. He was elected a Fellow of the Royal Society in 1852. In 1853, he attained the prestigious appointment of Professor of Natural Philosophy (Physics) at the Royal Institution in London, due in no small part to the esteem his work had garnered from Michael Faraday, the leader of magnetic investigations at the Royal Institution, whose successor be became at the Royal Institution after Faraday’s retirement. In 1859 Tyndall began to study the capacities of various gases to absorb or transmit radiant heat. He showed that the main atmospheric gases, nitrogen and oxygen, are almost transparent to radiant heat, whereas water vapour, carbon dioxide and ozone are such good absorbers that, even in small quantities, these gases absorb heat radiation much more strongly than the rest of the atmosphere. Tyndall concluded that water vapour is the strongest absorber of heat in the atmosphere and is the principal gas controlling surface air temperature by inhibiting leakage of the Earth’s heat back into outer space. He declared that, without water vapour, the Earth’s surface would be ‘held fast in the iron grip of frost’ – the greenhouse effect. In 1869 Tyndall discovered the scattering of light by dust and large molecules, now known as the Tyndall Effect. He noticed that a beam of light, visible as it passed through ordinary laboratory air, disappeared when it entered a flask of pure filtered water. He now passed a light beam through filtered air and got the same result – no beam. He deduced that light bounces off little particles and into our eyes, allowing us to see the beam. He found that different sized particles scattered light in different ways. Tyndall suggested that the sky is blue because molecules in the atmosphere preferentially scatter the sun’s blue rays. [3] John Tyndall combined his glacier researches with mountaineering, at which he became expert. In 1860 he made the first ascent of the Weisshorn, and he climbed Mount Blanc, the highest alpine peak, several times. He narrowly missed being the first person to summit the Matterhorn (he was third), and made numerous other difficult climbs throughout the Alps. Mountaineering gained the status of a sport partly because of his popular narratives, including his Glaciers of the Alps (1860) and Hours of Exercise in the Alps (1871) [2]. Tyndall made many other contributions to science. For example he invented the fireman’s respirator and his invention of the light pipe led to the development of fibre optics. Tyndall married Louisa Hamilton at the age of 56. Insomnia plagued Tyndall, and this, combined with general ill-health, led to his resignation from the RI in 1887. As his insomnia got worse he experimented with a variety of drugs. He died in 1893 from an accidental overdose of chloral administered by Louisa. Learn more about gasses in the yovisto lecture of Prof. Sylvia Ceyer from MIT’s Open Course Ware on ‘Kinetic Theory – Behavior of Gases‘. >'],\n",
       " [88,\n",
       "  'Maria Mitchell and the Comets.  Maria Mitchell (1814-1889). On August 1, 1814, American astronomer Maria Mitchell was born who, in 1847, by using a telescope, discovered a comet which as a result became known as “Miss Mitchell’s Comet“. Maria Mitchell was born in Nantucket, Massachusetts, USA, among nine brothers and sisters to William Mitchell and Lydia Coleman Mitchell, both Unusual for that time, Maria Mitchell’s parents as Quakers valued education and insisted on giving her the same quality of education that boys received. Additionally, Nantucket’s importance as a whaling port meant that wives of sailors were left for months and sometimes years to manage affairs while their husbands were at sea, thus fostering an atmosphere of relative independence and equality for the women who called the island home. After attending Elizabeth Gardener’s small school in her earliest childhood years, Maria attended the North Grammar school, where William Mitchell was the first principal. When Maria was eleven, her father built his own school, were she was a student and also a teaching assistant to her father. At home, Maria’s father taught her astronomy using his personal telescope. At age twelve already, she aided her father in calculating the exact moment of an annular eclipse. After her father’s school had to close, she attended Unitarian minister Cyrus Peirce’s school for young ladies. Later she worked for Peirce as his teaching assistant before she opened her own school in 1835 at age 17 to train girls in science and math. She made the decision to allow non-white children to attend her school, a controversial move as the local public school was still segregated at the time. One year later, she was offered a job as the first librarian of the Nantucket Atheneum, where she worked for 20 years, reading as many books as she could when the library was closed [1]. While she spent her days reading, she spent her nights observing the sky with her father. William had built an observatory on top of the nearby Pacific Bank, where he was the principal officer, and this served as a catalyst for her achievements in astronomy. On October 1, 1847, at the age of 29, Maria Mitchell discovered a new comet with a mere two-inch telescope, which illustrates her true skill as an astronomer. After some controversy with an Italian man who claimed the discovery, she was awarded the international medal for this achievement. The comet was named “Miss Mitchell’s Comet“. Today, the designation of this comet is C/1847 T1. As a result, she became the first woman elected to the American Academy of Arts and Sciences in 1848. Just 30 at the time, she would be the only woman thus recognized for almost a century into the future. Two years later, she also became one of the members of the American Association for the Advancement of Science. She worked for the U.S. Nautical Almanac Office where she calculated tables for the positions of the planet Venus and even went on a travel to Europe together with the family of Nathaniel Hawthorne, the great American short story writer and novelist [2]. Maria Mitchell, who also became interested in politics and committed herself in issues of women’s rights abolition of slavery, became the very first professor hired for the Vassar College in 1865, and was also named as the Vassar College Observatory’s director. An interesting part of her career was that despite the experience she had along with her reputation and expertise, her salary was still less compared to other younger male professors. Because of this, she asked for a raise and as she deserved, she got it. She continued her research by studying the surfaces of Jupiter and Saturn, and by photographing stars. In 1869 she was the first women elected to the American Philosophical Society and in 1873 she helped found the American Association for the Advancement of Women, serving as the society’s president from 1874 to 1876. In 1873 she attended the first meeting of the Women’s Congress. She retired in 1888 due to poor health, and after her death in 1889, the Maria Mitchell Observatory in her birth town of Nantucket was named in her honor [3]. At yovisto you can learn more about astronomy in a popular lecture by Neil deGrasse Tyson at the University of Washington in Seattle.'],\n",
       " [89,\n",
       "  'Stephanie Kwolek and the Bullet-proof Vests.  Stephanie Kwolek (1923 – 2014) Image: Chemical Heritage Foundation.  On July 31, 1923, American polymer chemist Stephanie Louise Kwolek was born. She is best known for her invention of poly-paraphenylene terephthalamide – better known as Kevlar. Stephanie Kwolek inherited her love for fabrics and sewing from her mother. Before thinking about chemistry, Kwolek thought, she might become a fashion designer, but her mother warned her she would probably starve in that business because she was such a perfectionist [1,4]. Fortunately, her interest in chemistry and medicine evolved as she grew older. When she graduated from the women’s college of Carnegie-Mellon University, she applied for a position as a chemist with the DuPont Company, among other places. Her job interview with W. Hale Charch, who had invented the process to make cellophane waterproof and who was by then a research director, was a memorable one. After Charch indicated that he would let her know in about two weeks whether she would be offered a job, Kwolek asked him if he could possibly make a decision sooner since she had to reply shortly to another offer. Charch called in his secretary and in Kwolek’s presence dictated an offer letter. In later years, she suspected that her assertiveness influenced his decision in her favor. At DuPont, the polymer research she worked on was so interesting and challenging that she decided to drop her plans for medical school and make chemistry a lifetime career [1,2]. During her time at DuPont, Kwolek was engaged in projects searching for new polymers as well as a new condensation process that takes place at lower temperatures, about 0? to 40?C. The lower-temperature polycondensation processes, which employ very fast-reacting intermediates, make it possible to prepare polymers that cannot be melted and only begin to decompose at temperatures above 400°C. When she was in her mid-40s, Kwolek was assigned a project to scout for fibers capable of performing in extreme conditions. This assignment involved preparing intermediates, synthesizing aromatic polyamides of high molecular weight, dissolving the polyamides in solvents, and spinning these solutions into fibers. At one point, Kwolek discovered that a large number of of these rod-like polyamides‘ molecules formed liquid crystalline solutions and that these solutions can be spun directly into oriented fibers of very high strength and stiffness [1]. Testing the fibers in 1965, it was found that they were about five times as strong as steel of equal weight and resistant to fire. The potential on the market was discovered shortly after at DuPont and the institute apparently spent $500 million to develop Kevlar [3]. Pieces of Kevlar helmet used to help absorb the blast of a grenade The fibers have found their way into all corners of the modern world. It has been used in car tires, boots for firefighters, hockey sticks, cut-resistant gloves, fiber-optic cables, fire-resistant mattresses, armored limousines and even canoes. It is used in building materials, making them bomb-resistant. Safe rooms have been built with Kevlar to protect a building’s occupants during hurricanes, and of course, bullet proof vests were introduced to police departments in 1975. A DuPont spokeswoman estimated that since the 1970s, 3,000 police officers have been saved from bullet wounds through the use of equipment reinforced with Kevlar [3]. Stephanie Kwolek received seveeral awards for invention of the technology behind Kevlar fiber. She received the National Medal of Technology in 1996 and one year later, the Perkin Medal, presented by the American Section of the Society of Chemical Industry. Both prizes were known to be rarely awarded to women. In 1999, she also received the Lemelson-MIT Lifetime Achievement Award. She has served as a mentor for other women scientists and participated in programs that introduce young children to science [2,3]. Stephanie Kwolek passed away on June 18, 2014. At yovisto, you may enjoy a video interview with Stephanie Kwolek, who talks about her experience as a female scientist and her major discoveries.'],\n",
       " [90,\n",
       "  'Marius and the Battle of the Raudine Plain.  Giovanni Battista Tiepolo The battle of Vercellae, 1725-1729.  On July 30, 101 BC, the Battle of the Raudine Plain took place, the Roman victory of Consul Gaius Marius over the invading Germanic tribe of the Cimbri near the settlement of Vercellae in Cisalpine Gaul. The entire tribe of the Cimbri was virtually wiped out and the plans of the Germanic tribes of an invasion of Rome was put to an end. Well, then raise your hands if you have ever heart about the Battle of Vercellae. I don’t see many. Then let me tell you the story about this important event, at least important for the progress of the Roman Empire. Just try to image if the Germanic plans to invade Rome would have been successful and possibly the Roman Empire as we know it would never have come into existence. History would have taken a completely different term…and probably I would also not be writing this blog. The Battle of Vercellae was the last and decisive battle between the migratory Germanic tribe of the Cimbri and the Romans. We do not know what caused the Cimbri to leave their settlements at the Northern Sea together with the tribes of Teutons and Ambrones and to wander throughout Europe looking for new settlement area. It was the Cimbri, who had separated from the other tribes and penetrated Northern Italy, which belonged to Roman Territory. They had defeated the Romans in several battles, such as the Battle at Noreia (113 BC) and the battle of Arausio (105 BC). The Roman commander Quintus Lutatius Catulus had the task to secure the Alpine passes. But as the Cimbri flooded over the Alpes, he gave up the passes and retreated behind the river Etsch. The Cimbri attacked the last defenders beyond the Etsch. In full admiration of the Roman courage, they granted the defenders free passage. Nevertheless, they devastated the entire landscape. In the meantime, Roman consul Gaius Marius, who had successfully defeated the Teutons the previous year in the battle of Aqua Sextiae, moved with his troops to Northern Italy to unite with the troops of Catulus. His soldiers were part of the reformed army, i.e. they had to carry all equipment and military gear by themselves – therefore they were also called ‘muli Mariani’ (mules of Marius). The leader of the Cimbri, Boiorix, made a peace proposal to Marius. The Cimbri would not fight against the Romans if they were allowed to keep the land. Marius rejected and instead, he brought forward the captive king of the Teutons, Teutobod. Up to this time, the Cimbri did not know about the defeat of the Teutons. Now, Boiorix called Marius to determine the battle ground, and Marius decided for the Raudine Plain, 5 km from Vercelli. The 13,000 strong Cimbri cavalry rode onto the battlefield. Behind them came the 197,000 strong infantry. Marius made a final sacrifice to the gods. According to Plutarch “Marius washed his hands, and lifting them up to heaven, vowed to make a sacrifice of 100 beasts should victory be his.”The Romans got into position first, therefore the sun would be reflecting off the Roman’s armor. The Cimbri thought the sky was on fire. Sensing their sudden anxiety, the Romans attacked. The Cimbri cavalry were taken completely by surprise by the Roman cavalry. The Cimbri were forced back. The Roman legionnaires than engaged the Cimbri infantry. The Cimbri were very unnerved by this. Plutarch writes that the Romans now were able to slaughter the enemy with ease. Boiorix and his noblemen made a last stand in which they were all killed. The Romans had won a complete and stunning victory. The victory of Vercellae put an end to Germanic plans to invade Rome. The Cimbri were virtually wiped out, with the Romans claiming to have killed 140,000 and captured 60,000, including large numbers of women and children. Politically, this battle had great implications for Rome as well. It marked a continuation in the rivalry between Marius and Sulla, which would eventually lead to the first of Rome’s great civil wars. But this is already another story… At yovisto you can learn more about the times of the Roman Republic in the lecture of Melinda Cole Klein from the series ‘Imperial Empires’.'],\n",
       " [91,\n",
       "  'Dorothy Hodgkin and the Structure of Penicilin.  Dorothy Hodgkin (1910 – 1994).  On July 29, 1994, British chemist and Nobel Laureate Dorothy Mary Hodgkin passed away. She advanced the technique of X-ray crystallography, a method used to determine the three-dimensional structures of biomolecules. Among her most influential discoveries are the confirmation of the structure of penicillin. Dorothy Crowfoot’s (late Hodgkin’s) interest in chemistry started around the age of only 10. Her parents were involved in education projects in Egypt and Sudan and during a visit, their daughter was allowed to study and analyze some chemicals with a friend of the family. Also, when she was attending the Sir John Leman School, she was allowed to join the boys as they studied chemistry. By the end of her early schooling, she had already decided that chemistry was something she wanted to pursue. Also, it is assumed that her time in Sudan played a big role in her future career. She was able to help with excavations and studied pebbles with a portable mineral analysis kit, which pushed her fascination and interest in crystals and minerals. This experience almost made her give up chemistry and replace it with archaeology instead. Then she was given a copy of “Concerning the Nature of Things” by Sir William Henry Bragg when she was 15, and she was intrigued at the thought of being able to study the properties of atoms and molecules using x-rays. She began studying chemistry at Somerville College, Oxford University and continued at the University of Cambridge to earn her PhD with John Desmond Bernal, who had worked for five years with the senior Bragg [1]. Hodgkin and Bernal used X-ray crystallography to determine the three-dimensional structure of several complex organic molecules important to the functioning of living organisms [2]. To Hodgkin’s most important contributions to the science of chemistry belongs presumably the determination of the structures of penicillin, insulin, and vitamin B12. She determined the exact structure of penicillin in 1945. The results contradicted general scientific thought at the time and therefore put researchers on the right path to developing further and more sophisticated uses for penicillin-based antibiotics, including the development of semisynthetic versions. In the 1950s, the scientist and her colleagues published an analysis of vitamin B12 which expanded the understanding of how this vital nutritional component functions and how it is utilized by the human body. Hodgkin spent years honing and improving the available methods to penetrate the mysteries of ever-more complicated structures. After 35 years of work, the internal structure of insulin was solved [3]. She received the Nobel Prize in chemistry “for her determinations by X-ray techniques of the structures of important biochemical substances”. Also, she was the third woman ever to win the prize in chemistry, after Marie Curie and Irène Joliot-Curie [2]. Next to her research studies, Dorothy Hodgkin was highly involved in humanitarian projects including the welfare of scientists and people living in nations defined as adversaries by the United States and the United Kingdom in the 1960s and 1970s, for example, the Soviet Union, China, and North Vietnam. She was also the chair of the Pugwash movement, which dealt with potential dangers raised by scientific research [2]. At yovisto, you may be interested in a video lecture by Georgina Ferry, Dorothy Hodgkin’s biographer. She explains the story of the structure of penicillin and the personal and professional challenges, Hodgkin faced during her years of research.'],\n",
       " [92,\n",
       "  'Karl Popper and the Philosophy of Science.  Karl Raimund Popper (1902-1994). On July 28, 1902, Austrian-British philosopher Sir Karl Raimund Popper was born. He is generally regarded as one of the greatest philosophers of science of the 20th century. Popper is known for his rejection of the classical inductivist views on the scientific method, in favour of empirical falsification: A theory in the empirical sciences can never be proven, but it can be falsified, meaning that it can and should be scrutinized by decisive experiments. Karl Raimund Popper was born in Vienna to Simon Siegmund Carl Popper, a lawyer from Bohemia and Jenny Schiff Popper, who was of Silesian and Hungarian descent. All of Karl Popper’s grandparents were Jewish, but the Popper family converted to Lutheranism before Karl was born. They understood this as part of their cultural assimilation, not as an expression of devout belief. Karl’s father was a bibliophile who had 12,000–14,000 volumes in his personal library. By the time, Vienna claimed to be the cultural epicentre of the western world. Karl attended the local Realgymnasium, where he was unhappy with the standards of the teaching, and, after an illness which kept him at home for a number of months, he left to attend the University of Vienna in 1918. However, he did not formally enrol at the University by taking the matriculation examination for another four years. In 1919 he became heavily involved in left-wing politics, joined the Association of Socialist School Students, and became for a time a Marxist. However, he was quickly disillusioned with the doctrinaire character of the latter, and soon abandoned it entirely. He also discovered the psychoanalytic theories of Siegmund Freud and Alfred Adler, and listened entranced to a lecture which Albert Einstein gave in Vienna on relativity theory. The dominance of the critical spirit in Einstein, and its total absence in Marx, Freud and Adler, struck Popper as being of fundamental importance: the pioneers of psychoanalysis, he came to think, couched their theories in terms which made them amenable only to confirmation, while Einstein’s theory, crucially, had testable implications which, if false, would have falsified the theory itself [1]. Popper had a rather melancholic personality and took some time to settle on a career; he obtained a primary school teaching diploma in 1925, took a Ph.D. in philosophy in 1928 and qualified to teach mathematics and physics in secondary school in 1929. The dominant philosophical group in Vienna at the time was the Wiener Kreis, a circle of ‘scientifically-minded’ intellectuals including Rudolf Carnap, Otto Neurath, Viktor Kraft, and Hans Hahn with the principal objective to unify the sciences. For his part, Popper became increasingly critical of the main tenets of logical positivism. He articulated his own view of science, and his criticisms of the positivists in “Logik der Forschung” in 1934 (translated by Popper himself twenty-five years later under the title The Logic of Scientific Discovery), which gained him an enormous reputation and had a tremendous impact on the scientific community. “In point of fact, no conclusive disproof of a theory can ever be produced; for it is always possible to say that the experimental results are not reliable or that the discrepancies which are asserted to exist between the experimental results and the theory are only apparent and that they will disappear with the advance of our understanding. If you insist on strict proof (or strict disproof) in the empirical sciences, you will never benefit from experience, and never learn from it how wrong you are.” (Karl Popper) Due to the rise of fascism in Austria as well as in Germany and the steady growth of anti-Semitism, Popper was forced to leave Austria. In 1937, he went to New Zealand and taught philosophy as a senior lecturer at the University of Canterbury. After the Second World War, he went to London, first as reader in logic and scientific method, then in 1949 became a professor of logic and scientific method at the London School of Economics, a post which he held until 1969. Many visits as a guest professor in the United States followed, amongst them the William James Lectures at Harvard in 1950.[2] Popper’s relations with many of his most devoted students were now often stormy and, with the exception of one or two cases, tended to end in open hostility. Popper had become intolerant of dissent and also inclined to misunderstand the nature of his own contribution to the philosophy of science. He believed that he had solved the problem of how scientific knowledge is generated and established. In reality he had merely moved the problem one step forward and so opened an entirely new problem. In demonstrating that all scientific knowledge is only provisional and hypothetical, he had invited doubts as to the degree to which it genuinely corresponded to reality. These doubts were pursued by Thomas Kuhn and led him to a relativism which never gained Popper’s approval.[3] He had public debates with Ernst Bloch and Theodor Adorno, two of the most popular luminaries of Continental philosophy in the 1950s and 1960s, and in 1972 he published his third major book, Objective knowledge, in which he established a close link between his philosophy of science and the development of neo-Darwinism. He was knighted in 1965. Popper continued to think and write until the very last years of his life. He died on 17 September 1994 in Croydon, Surrey. At yovisto, you can listen to an excerpt of Sir Karl Popper’s ‘Science as Falsification‘ from his 1963 book ‘Conjectures and Refutation’.'],\n",
       " [93,\n",
       "  'Rosalind Franklin and the Beauty of the DNA Structure.  Rosalind Franklin (1920-1958). On July 25, 1920, British biophysicist and X-ray crystallographer Rosalind Elsie Franklin was born. She made the first clear X-ray images of DNA’s structure. Her work was described as the most beautiful X-ray photographs ever taken. Franklin’s ‘Photo 51’ informed Crick and Watson of DNA’s double helix structure for which they were awarded a Nobel Prize. Rosalind Franklin was born in Notting Hill, London, as the second of five children into an affluent and influential British Jewish family. From early childhood, Franklin showed exceptional scholastic abilities. She was educated at St Paul’s Girls’ School where she excelled in science, Latin and sports. From the age of 15 on, she knew already that she wanted to become a scientist. Rosalind Franklin enrolled at Newnham College, Cambridge, in 1938 and studied chemistry. In 1941, she was awarded Second Class Honors in her finals, which, at that time, was accepted as a bachelor’s degree in the qualifications for employment. When she graduated, Franklin was awarded a research scholarship to do graduate work. She spent a year in R.G.W. Norrish’s lab without great success. Norrish recognized Franklin’s potential but he was not very encouraging or supportive toward his female student. She went on to work as an assistant research officer at the British Coal Utilisation Research Association, where she studied the porosity of coal—work that was the basis of her 1945 Ph.D. thesis “The physical chemistry of solid organic colloids with special reference to coal.” [1] CURA was a young organization and there was less formality on the way research had to be done. Franklin worked fairly independently, a situation that suited her. Franklin worked for CURA until 1947 and published a number of papers on the physical structure of coal. Franklin’s next career move took her to Paris from 1947 to 1950. An old friend introduced her to Marcel Mathieu who directed most of the research in France. He was impressed with Franklin’s work and offered her a job as a “chercheur” in the Laboratoire Central des Services Chimiques de l’Etat. Here she learned X-ray diffraction techniques from Jacques Mering. In 1951, Franklin was offered a 3-year research scholarship at King’s College in London. With her knowledge, Franklin was to set up and improve the X-ray crystallography unit at King’s College. Maurice Wilkins was already using X-ray crystallography to try to solve the DNA problem at King’s College. Franklin arrived while Wilkins was away and on his return, Wilkins assumed that she was hired to be his assistant. It was a bad start to a relationship that never got any better. [2] Wilkins‘ mistake, acknowledged but never overcome, was not surprising given the climate for women at the university then. Only males were allowed in the university dining rooms, and after hours Franklin’s colleagues went to men-only pubs. But Franklin persisted on the DNA project. J. D. Bernal called her X-ray photographs of DNA, “the most beautiful X-ray photographs of any substance ever taken.” Between 1951 and 1953 Rosalind Franklin came very close to solving the DNA structure. She was beaten to publication by Crick and Watson in part because of the friction between Wilkins and herself. At one point, Wilkins showed Watson one of Franklin’s crystallographic portraits of DNA. When he saw the picture, the solution became apparent to him, and the results went into an article in Nature almost immediately. Franklin’s work did appear as a supporting article in the same issue of the journal.[3] A debate about the amount of credit due to Franklin continues. What is clear is that she did have a meaningful role in learning the structure of DNA and that she was a scientist of the first rank. Franklin moved to J. D. Bernal’s lab at Birkbeck College, where she did very fruitful work on the tobacco mosaic virus. She also began work on the polio virus. In the summer of 1956, Rosalind Franklin became ill with cancer. She died less than two years later. Franklin was never nominated for a Nobel Prize. She had died in 1958 and was therefore ineligible for nomination to the Nobel Prize in 1962 which was subsequently awarded to Crick, Watson, and Wilkins in that year. The award was for their body of work on nucleic acids and not exclusively for the discovery of the structure of DNA. Watson has suggested that ideally Wilkins and Franklin would have been awarded the Nobel Prize in Chemistry. At yovisto you may enjoy the video lecture ‘You say you want a revolution: DNA analysis methods‘ by Prof. Dr. Qiang Zhou from Berkeley University.'],\n",
       " [94,\n",
       "  'The Plays of George Bernard Shaw.  George Bernard Shaw (1856-1950). On July 26, 1856, Irish playwright and co-founder of the London School of Economics George Bernard Shaw was born. As a writer, his main talent was for drama, and he wrote more than 60 plays. He is the only person to have been awarded both a Nobel Prize in Literature (1925) and an Oscar (1938). George Bernard Shaw was born in Synge Street, Dublin, to George Carr Shaw, an unsuccessful grain merchant and sometime civil servant, and Lucinda Elizabeth Shaw, a professional singer. His education was irregular, due to his dislike of any organized training. When Shaw was just short of his sixteenth birthday, his mother left her husband and son and moved with Vandeleur Lee to London, where the two set up a household, along with Shaw’s older sister Lucy. After working in an estate agent’s office for a while he moved to London as a young man (1876), where he established himself as a leading music and theatre critic in the eighties and nineties and became a prominent member of the Fabian Society, for which he composed many pamphlets [1]. Together with Beatrice and Sidney Webb, Shaw had founded the Fabian Society, a socialist political organization dedicated to transforming Britain into a socialist state, not by revolution but by systematic progressive legislation, bolstered by persuasion and mass education. The Fabian society would later be instrumental in founding the London School of Economics and the Labour Party. In 1891, at the invitation of J.T. Grein, a merchant, theatre critic, and director of a progressive private new-play society, The Independent Theatre, Shaw wrote his first play, Widower’s Houses. Shaw’s first plays were published in volumes titled “Plays Unpleasant” (containing Widowers’ Houses, The Philanderer and Mrs. Warren’s Profession) and “Plays Pleasant” (which had Arms and the Man, Candida, The Man of Destiny and You Never Can Tell). The plays were filled with what would become Shaw’s signature wit, accompanied by healthy doses of social criticism, which stemmed from his Fabian Society leanings. These plays would not go on to be his best remembered, or those for which he had high regard, but they laid the groundwork for the oversized career to come [2]. In 1897 Shaw attained his first commercial success with the American premiere of The Devil’s Disciple, which enabled him to quit his job as a drama critic and to make his living solely as a playwright. In 1898, after a serious illness, Shaw resigned as theatre critic, and moved out of his mother’s house (where he was still living) to marry Charlotte Payne-Townsend, an Irish woman of independent means. Although Shaw was occasionally linked with other women, this marriage lasted until Charlotte’s death in 1943 [3]. The Norwegian playwright Henrik Ibsen had a great influence on Shaw’s thinking. For a summer meeting of the Fabian Society in 1890, he wrote The Quintessence of Ibsenism (1891), in which he considered Ibsen a pioneer, “who declares that it is right to do something hitherto regarded as infamous.” Pygmalion, by Bernard Shaw, by far his most popular work, was first performed in 1913. “Although Shaw claimed that he had written a didactic play about phonetics, and its anti-heroic protagonist, Henry Higgins, is indeed a speech professional, what playgoers saw was a high comedy about love and class, about a cockney flower-girl from Covent Garden educated to pass as a lady, and the repercussions of the experiment… The First World War began as Pygmalion was nearing its hundredth sell-out performance, and gave Shaw an excuse to wind down the production.“, according to one of the leading experts on Shaw, Stanley Weintraub [4]. During World War I, Shaw’s anti-war pamphlets and speeches made him very unpopular as a public figure. In Heartbreak House (performed 1920) he exposed the spiritual bankruptcy of the generation responsible for the carnage. Next came Back to Methuselah (1922) and Saint Joan (1923), acclaim for which led to his receiving the Nobel Prize for Literature for 1925. Shaw continued to write plays and essays until his death in 1950 at the age of 94. At yovisto you can learn more about George Bernard Shaw in the educational Encyclopedia Britannica production ‘Shaw vs. Shakespeare I: The Character of Caesar‘'],\n",
       " [95,\n",
       "  'Thomas Say and his Love for Beetles.  On July 27, 1787, American self-taught naturalist, entomologist, malacologist, herpetologist and carcinologist Thomas Say was born. A taxonomist, he is widely considered the father of descriptive entomology in the United States.   Thomas Say attended Westtown Boarding School near Philadelphia and his father discouraged him from the pursuit of natural history, trying to interest him instead in the family apothecary business and around 1812, Say even entered into partnership with apothecary John Speakman, but the enterprise failed very soon [2]. His interest in natural history was stimulated by his great-uncle, William Bartram. Say was a cofounder of the Academy of Natural Sciences of Philadelphia in 1812 and served a curator from 1812 to 1826 and as professor of zoology in the Museum of Philadelphia from 1821 to 1825 [1]. During his career, Thomas Say took part in several expeditions. In 1819 - 1820, Major Stephen Harriman Long led an exploration to the Rocky Mountains, which Say accompanied as a zoologist. The expedition party searched for the headwaters of the Red River, made maps of the uncharted Louisiana Territory, and located areas for military posts to protect the American fur trade. Unfortunately, Thomas Say\\'s journal entries from the expedition were stolen by soldiers, who apparently left the party during the expedition. However, records of the expedition were still published and large collections of the flora and fauna of the area were described. Say himself, collected and described several species including the collared lizard, which is on this day the official state lizard of Oklahoma [1].   The scientist became curator of the American Philosophical Society and then professor of natural history at the University of Pennsylvania in 1822. He took part in another expedition the year after, functioning as zoologist and paleontologist to St. Peter’s River at the headwaters of the Mississippi. The expedition made it all the way up to Lake of the Woods in Canada and across the northern portion of Lake Superior. Say managed to collect enough insect specimens to accurately represent North America in his American Entomology, or Descriptions of the Insects of North America, which was published in three volumes between 1824 and 1828 [2].   Say\\'s scientific reputation grew after he published the first volume and he is now considered as the father of American entomology and conchology. After finishing this work, Say went on to publish another definitive work, on American shells, and approached the subject with the same spirit of adventure and reverence that informed his work on insects. As he wrote, \"It is an enterprise that may be compared to that of a pioneer or early settler in a strange land,\" and he did much to advance Americans\\' understanding of the natural world they encountered as they moved inexorably across the continent [3].   At yovisto, you may be interested in a video lecture on \"International Entomology: Changing the World, One Bug at a Time\" by Rick Foster.'],\n",
       " [96,\n",
       "  'Joseph Nicollet and the Upper Mississippi River.  On July 24, 1786, French geographer, astronomer, and mathematician Joseph Nicolas Nicollet was born. He is best known for mapping the Upper Mississippi River basin during the 1830s. Nicollet’s maps were among the most accurate of the time and they provided the basis for all subsequent maps of the American interior Jean-Nicolas Nicollet was born in Cluses, Savoy, France. He was very bright, showing aptitude in mathematics and astronomy that earned him a scholarship to the Jesuit college in Chambéry and led him to begin teaching mathematics at age 19. Wishing to further his education, he went to Paris and attended the École Normale Supérieur. He taught in Paris for a brief period before, in 1817, becoming secretary and librarian at the Paris Observatory. At the Observatory he continued his education, studying under mathematician Pierre-Simon Laplace. He continued teaching mathematics and, in 1818, he gives his posts as Astronomer attached to the Royal Observatory in Paris and Professor of Mathematics at the College of Louis-Le-Grand. Working at the observatory, Nicollet discovered a comet and built a reputation as an expert in astronomy and physical geography. Afterward, he worked as a mathematics professor at the Collège Louis-le-Grand during the 1820s [1]. Nicollet rapidly made a fine reputation for himself both as a teacher and as a mathematical astronomer at the Observatory, receiving the Legion of Honour for his excellent work. Using his mathematical skills, he applied the principles of mathematical probability to the stock market believing that he could make his fortune. His probability considerations did not allow for the French Revolution of 1830 which caused the stock market to crash. Nicollet was ruined financially. Penniless, he emigrated to the United States in 1832. Nicollet hoped to boost his reputation among European academics through his work in the United States. He intended to make a “scientific tour” of the country and had a goal of using his expertise to accurately map the Mississippi River Valley. He arrived in Washington, D.C., where he met with scientists and government officials, discussing scientific surveys of the country. Nicollet traveled to New Orleans, from where he intended to proceed to St. Louis, Missouri. But, because of a cholera outbreak, travel became difficult. After a delay of 3 years, Nicollet finally arrived in St. Louis in 1835. Upon his arrival in St. Louis, Nicollet gained support for his plan to map the Mississippi River from the American Fur Company and the wealthy Choteau family. Overall, Nicollet led three expeditions exploring the Upper Mississippi, mostly in the area that is now Minnesota, North Dakota and South Dakota. Nicollet was frequently ill due to his weak constitution and exposure to the elements. He was nothing if not determined and, after studying the southern portion of the river, he turned his attention to the location of the source of the river. In the summer of 1836, he arrived at Fort Snelling, where he was taken in by Indian Agent Lawrence Taliaferro’s family, who provided Nicollet with all the supplies he needed for his visit to the source of the river. As travelling north on the river with a few companions, he continued making notes on his geographical position and drawing the landscape [2]. In this first expedition, Nicollet explored the Mississippi to its source of Lake Itasca and the nearby Mississippi tributary, the St. Croix River. The results of this expedition corrected an error in Zebulon Pike’s 1805 map, which placed the mouth of the Crow Wing River too far to the west, rendering all maps of this area inaccurate. In his second expedition in 1838, his goal was to map the area between the Mississippi and Missouri Rivers in order to correct the western maps affected by Pike’s mistake. A third expedition took Nicollet northwest from Iowa along the Missouri River toward Fort Pierre, South Dakota. On September 11, 1839, Nicollet returned to Washington, D.C. where he worked on consolidating the information collected during the expeditions. He fully intended to return to Minnesota to continue his work, but failing health led to his death in Washington in 1843. Later that year, a book containing much of his work, Map of the Hydrographical Basin of the Upper Mississippi, was published. At yovisto, we don’t have a video lecture about Joseph Nicollet. But, you can learn more about the Mississippi river in the 1951 documentary ‘People along the Mississippi‘.'],\n",
       " [97,\n",
       "  'Isaac Singer and the Sewing Machine.  Woman working with singer machine (ca. 1914) Image Source: Library of Congress.  On July 23, 1875, American inventor, actor, and entrepreneur Isaac Merrit Singer passed away. He made important improvements in the design of the sewing machine and was the founder of the Singer Sewing Machine Company. Isaac Merritt Singer was born in 1811 in Pittstown, New York and worked as a mechanist, starting from the age of 12. He joined a traveling theater group when he was 19 and continued his work as a machinist between performances. Singer invented a rock drill in 1839 and sold the patent for $2000 shortly after. He founded his own acting group and toured through the Unites States until they ran out of money. [3] Singer now managed to find financial supporters for his patented machine for carving wooden type for printing presses and he moved to Boston in order to work on his machine in Orson Phelp’s machine shop. Phelps held a license to build sewing machines for the Lerow Blodgett Company. Unfortunately for Singer, his carving machine was not successful, because most printers had switched to metal type. One day, Phelps asked Singer for help with one of his Lerow Blodgett sewing machines. The inventor agreed and immediately found ways to improve the machines. It is said that it took Singer only 11 days to create a new and significantly better machine compared with with Lerow & Blodgett’s. He redesigned the sewing machine in a way that it could stitch continuously in curved lines. He replaced the needle bar on an arm hanging over the table and introduced the foot pedal instead of a hand crank. Phelps, Singer, and the financial supporter Zieber formed a company and the inventor received a patent for his machine in 1851. [1] Shortly after, Singer got rid of his partners and sided with a lawyer named Clark, who helped the inventor through a series of law suits. A patent pool was then created by which all parties were able to profit. However, Singer’s profit was the largest since his machine enjoyed the most success on the market. Already in the early 1860s, Singer’s sewing machines turned out to be the most successful in the world. Many assume that the triumph on the market was due to the high quality of the machines as well as the liberal credit terms, the company offered to its customers. In 1863, the Singer Manufacturing Company was founded and Singer himself moved to England. At that time, Singer was no longer involved in the manufacturing process and he passed away on July 23, 1875. [1] In 1855, a Singer sewing machine was awarded a first prize at the World’s Fair in Paris. The success of the machines grew even more, when the company opened large showrooms, for instance at the Broadway in New York City. The company also introduced interchangeable parts and reduced the machines’ size and weight through the years. By 1880, an Edison electric motor was used to drive some Singer sewing machines and large factories across Europe and the Americas have been opened. By 1927, the first Singer Sewing Centers opened, offering sewing courses and enjoying a large success as well.[2] At yovisto, you may be interested in a Singer Sewing Machine commercial from the 1950s.'],\n",
       " [98,\n",
       "  'Friedrich Bessel and the Distances of Stars.  Friedrich Wilhelm Bessel (1784-1846). [1].  On July 22, 1784, German mathematician and astronomer Friedrich Wilhelm Bessel was born. He is probably best known for his works in mathematics, where he discovered the eponymous Bessel-functions, which are critical for the solution of certain differential equations. Friedrich Wilhelm Bessel was born in Minden, Westphalia (today Germany), as second son of a civil servant. Bessel attended the Gymnasium in Minden for four years but he did not appear to be very talented, finding Latin difficult, although he later succeeded in teaching the ancient language to himself. At the age of 14 Bessel was apprenticed to the import-export concern Kulenkamp at Bremen. At first Bessel received no salary from the firm. The business’s reliance on cargo ships led him to turn his mathematical skills to problems in navigation. This in turn led to an interest in astronomy as a way of determining longitude. In 1804 Bessel wrote a paper on Halley’s comet, calculating the orbit using data from observations made by Thomas Harriot and William Lower in 1607 [2]. This brought him to the attention of a major figure of German astronomy at the time, Heinrich Wilhelm Olbers, the leading comet expert of his time. Olbers recognised at once the quality of Bessel’s work and Olbers gave Bessel the task of making further observations to carry his work further. The resulting paper, at the level required for a doctoral dissertation, was published on Olbers’ recommendation. From that time on Bessel concentrated on astronomy, celestial mechanics and mathematics. In 1806 Bessel accepted the post of assistant at the Lilienthal Observatory, which gave him valuable experience observing planets, in particular Saturn, its rings and satellites. He also observed comets and continued his study of celestial mechanics. In January 1810, at the age of 26, Bessel was appointed director of the new founded Königsberg Observatory by King Frederick William III of Prussia. There he published tables of atmospheric refraction derived from James Bradley’s observations of the positions of 3222 stars made around 1750 at Greenwich (Bradley was English Astronomer Royal from 1742 to 1762), which he had already began in 1807. While the observatory was still in construction Bessel elaborated the Fundamenta Astronomiae based on Bradley’s observations. It was not possible for Bessel to receive a professorship without first being granted the title of doctor. A doctorate was awarded by the University of Göttingen on the recommendation of Gauss, who had met Bessel in Bremen in 1807 and recognized his talents. Since 1819 Bessel determined the position of over 50,000 stars assisted by some of his qualified students. With this work under his belt, Bessel was able to achieve the feat for which he is best remembered today: he is credited with being the first to use parallax in calculating the distance to a star. Bessel showed in 1838 that 61 Cygni, a star barely conceivable with the naked eye, apparently moved in an ellipse every year. This back and forth motion, called the annual parallax, could only be interpreted as being caused by the motion of Earth around the Sun. Astronomers had believed for some time that parallax would provide the first accurate measurement of interstellar distances—in fact, in the 1830s there was a fierce competition between astronomers to be the first to measure a stellar parallax accurately. In 1838 Bessel publicly announced that 61 Cygni had a parallax of 0.314 arcseconds; which, given the diameter of the Earth’s orbit, indicated that the star is 10.3 lightyears away (by today’s measurement of 11.4 lightyears, Bessel’s estimation did only deviate by ca. 10%). Another major discovery by Bessel was that the two bright stars Sirius and Procyon execute minute motions that could be explained only by assuming that they had invisible companions disturbing their motions. The existence of such bodies, now named Sirius B and Procyon B, was confirmed with more powerful telescopes after Bessel’s death [3]. Besides these activities, he was ordered to undertake a geodetical survey of East Prussia (“Ostpreussische Gradmessungen”). From the differences between geodetical and astronomical coordinates, Bessel derived the figure of Earth as an oblated spheroid with ellipticity 1/299.15 (Bessel Normal Ellipsoid). Bessel also contributed significantly to mathematics and invented the so-called Bessel functions (also called cylindrical functions) in 1824. Bessel died in Königsberg on March 17, 1846 at age 62 from a long mysterious disease which we now know was probably intestine cancer. At yovisto you can learn more about astronomy in a popular lecture by Neil deGrasse Tyson at the University of Washington in Seattle.'],\n",
       " [99,\n",
       "  'Jean Picard and his Love for Accuracy.  Jean-Félix Picard (1620 – 1682).  On July 21, 1620, French astronomer, cartographer and hydraulic engineer Jean-Félix Picard was born. He is regarded as the founder of modern astronomy in France. He introduced new methods, improved the old instruments, and added new devices, such as Huygens‘ pendulum clock to record times and time intervals. Jean-Félix Picard was born as a son of a bookseller and was allowed to study at the Jesuit Collège Royal Henry-Le-Grand, which was considered one of the best educational centers in France. It is assumed that he left the institution without a degree and moved to Paris due to the unstable situation in France. In Paris, he met the well established astronomer and mathematician Pierre Gassendi. He motivated Picard to study astronomy and Picard was allowed to assist with observations of solar and lunar eclipses. Picard became a professor of astronomy, as it is assumed, in 1655. He continued his career at the College de France in Paris, but unfortunately, there is no published work by Picard known from this period. However, it is known that he exchanged letters with Christian Huygens, Ole Rømer, and Giovanni Cassini and it is assumed that he was highly respected as a scientist at that time. Also, he became one of the first members of the Academie Royal des Sciences one year after its founding in 1666. Between 1669 and 1670, Picard was the first person to measure the size of the Earth to a reasonable degree of accuracy, building on Maurolycus’ methodology and Snellius’ mathematical discoveries. Picard was honored with a pyramid at Juvisy-sur-Orge for his significant scientific effort. He was able to achieve this by measuring one degree of latitude along the Paris Meridian using triangulation along thirteen triangles stretching from Paris to the clock tower of Sourdon, near Amiens. His measurements produced a result of 110.46 km for one degree of latitude, which gives a corresponding terrestrial radius of 6328.9 km. The polar radius has now been measured at just over 6357 km. This was an error only 0.44% less than the modern value. This was another example of advances in astronomy and its tools making possible advances in cartography. Picard was the first to attach a telescope with crosswires to a quadrant, and one of the first to use a micrometer screw on his instruments. The quadrant he used to determine the size of the Earth had a radius of 38 inches and was graduated to quarter-minutes. The sextant he used to find the meridian had a radius of six feet, and was equipped with a micrometer to enable minute adjustments. These equipment improvements made the margin of error only ten seconds, as opposed to Tycho Brahe’s four minutes of error. This made his measurements 24 times as accurate. It is believed that Isaac Newton used this value in his theory of universal gravitation. Picard’s method and measurements were the topic of his Mesure de la terre, published in 1671. He was also an important member of the team that began to compile a map of France based on scientific principles and he became a major figure in the development of scientific cartography. In 1673 he was at the Paris observatory collaborating with Cassini, Rømer, and La Hire on the institute’s regular project of observations. Picard directed his attention to other projects of the Académie such as the surveying operations at Marly and Versailles. For example he became active in the problem of supplying Versailles with water. He also performed barometric experiments and became generally more and more active in the field of physics. Picard published scientific papers on hydraulics and optics. He made several suggestions to improve the telescope and left behind manuscripts on dioptrics. At yovisto, you may be interested in a video on the CNES mission, named after the French scientist Jean-Félix Picard. CNES’s Picard microsatellite is designed to simultaneously measure parameters such as the Sun’s speed of rotation, radiated power, sunspots, figure and diameter, in order to better understand its inner workings.'],\n",
       " [100,\n",
       "  'Sir John Reith and the BBC.  On July 20, 1889, John Charles Walsham Reith, 1st Baron Reith, was born. Sir John Reith was the first General-Director of the British Broadcasting Corporation and regarded as one of BBCs founding fathers. His concept of broadcasting as a way of educating the masses marked for a long time the BBC and similar organizations around the world. John Reith was the founder of the BBC. He was its first general manager when it was set up as the British Broadcasting Company in 1922; and he was its first director general when it became a public corporation in 1927. He created both the templates for public service broadcasting in Britain; and for the arms-length public corporations that were to follow, especially after World War Two. Reith fought off the politicians’ attempts to influence the BBC, while offering the British people programmes to educate, inform and entertain. John Charles Walsham Reith was born on July 20th 1889 at Stonehaven, Kincardineshire, UK, as the youngest, by ten years, of seven children. His family were holidaying there from Glasgow, where his father George was a minister in the Free Church of Scotland. Reith was educated at The Glasgow Academy then at Gresham’s School, Holt, Norfolk. His father refused to support any further education and apprenticed him as an engineer at the North British Locomotive Company. Serving in World War I, Reith was struck in the cheek by a bullet in October 1915, at which time he was a Lieutenant, and transferred to the Royal Engineers, where he resigned his Territorial Army commission in 1921 in the rank of a captain. Reith had no broadcasting experience when he replied to an advertisement in The Morning Post for a General Manager for an as-yet unformed British Broadcasting Company in 1922. He later admitted that he felt he possessed the credentials necessary to manage any company. In his new role, he was “confronted with problems of which I had no experience: Copyright and performing rights; Marconi patents; associations of concert artists, authors, playwrights, composers, music publishers, theatre managers, wireless manufacturers.“. Slowly but surely, Reith began to advance into the unknown medium of public radio transmission, organising, experimenting and innovating. Realising the almost unlimited possibilities of broadcasting, and that it must eventually become a public service, he began to shape his organisation in that direction. The two of the main objects of Reith’s policy were to establish the independence of the BBC from any form of interference and to build an unassailable programme. In 1925 the Government appointed a committee under the chairmanship of Lord Crawford to consider the future of British broadcasting, where Reith prepared a plan for a public broadcasting service. According to his plans, news presentations would always be of the highest quality, and Sunday observance was strictly enforced. When the General Strike broke out in 1926, and the value of broadcasting as a governmental and political instrument became apparent, Winston Churchill and others in the Government wanted to commandeer the organisation for the emergency. Reith refused to comply, maintaining the BBC’s independence. He won the argument, but made an enemy of Churchill for years to come. Actually, the BBC was part-share owned by a committee of members of the wireless industry. Although opposed by some (including in Government), the BBC became a corporation in 1927 and Reith was knighted the same year. Reith’s autocratic approach became the stuff of BBC legend. His preferred approach was one of benevolent dictator, but with built-in checks to his power. In 1938, with his work for broadcasting completed and his ideals established as traditions, he resigned to become managing director of Imperial Airways. But, two years later, when Britain was at war, he left this post to become Minister of Information under Prime Minister Neville Chamberlain. When Churchill succeeded Chamberlain in May 1940, old animosities prevailed and he was quickly transferred, first to the Ministry of Transport and then to the Ministry of Works and Buildings. He was also elevated to the House of Lords, becoming Baron Reith of Stonehaven. After the war, his sense of purpose was revived in his chairmanships of the Commonwealth Telecommunications Board, from 1946 to 1950, and the Colonial Development Corporation, 1950 to 1959. When the BBC introduced the Reith Lectures in 1947 it was honouring the Corporation’s debt to the man whose far-sightedness and clarity of purpose in early British broadcasting had demanded technical inventiveness and social conscience in equal proportions. At the age of 81, John Reith died in Edinburgh after a fall in 1971. This is a British Pathé newsreel of MS. Sir John Reith, Minister of Information speaking at the Cinematography Exhibitors Association in 1940.'],\n",
       " [101,\n",
       "  'The Dancers of Edgar Degas.  Ballet Class (1873) by Edgar Degas.  On July 19, 1834, French artist Edgar Degas was born, famous for his paintings, sculptures, prints, and drawings. He is especially identified with the subject of dance; more than half of his works depict dancers. He is regarded as one of the founders of Impressionism, although he rejected the term, and preferred to be called a realist. Edgar Degas graduated from school in 1853 and turned his room into an artist’s studio. Despite the fact, that he was expected to become a lawyer, Degas enrolled at the École des Beaux-Arts and studied drawing there with Louis Lamothe. The young artist traveled to Italy in 1856, where he lived with his aunt’s family in Naples. In this period, Degas drew and painted numerous copies of works by Michelangelo, Raphael, Titian, and other Renaissance artists, but he usually selected from an altarpiece a detail that had caught his attention, a secondary figure, or a head which he treated as a portrait. After a three year stay in Italy, Degas moved into a Paris studio to begin painting “The Bellelli Family“, one of his early masterpieces. However, the painting remained unfinished until 1867. The artist created several history paintings, like Young Spartans around 1860 or Scene of War in the Middle Ages, but unfortunately, they received only little attention. After the Franco-Prussian War in 1870, Degas stayed in New Orleans, Louisiana, where he created A Cotton Office, the only painting that was purchased by a museum in his lifetime. Beginning from 1874, the artist depended for the first time in his life on sales of his artwork for income and in this period, he produced probably his greatest work. He joined the group that soon became known as the Impressionists. Together, they mounted eight art shows. However, Degas did not feel that he had much in common with the artists, painting landscapes outdoors such as Monet. Also he disliked being called an impressionist. Degas started painting women at work including milliners and laundresses in the late 1860s, shifting from his initial forays into history painting to an original observation of contemporary life. Mlle. Fiocre in the Ballet La Source, exhibited in the Salon of 1868, was his first major work to introduce a subject with which he would become especially identified, dancers. In many subsequent paintings, dancers were shown backstage or in rehearsal, emphasizing their status as professionals doing a job. His interest in portraiture led him to study carefully the ways in which a person’s social stature or form of employment may be revealed by their physiognomy, posture, dress, and other attributes. In his paintings of dancers and laundresses, he reveals their occupations not only by their dress and activities but also by their body type. His ballerinas exhibit an athletic physicality, while his laundresses are heavy and solid. In his later years, the artist also developed a high interest for photography. He often took pictures of friends, mostly indoors, and other images depicted dancers and nudes. As the years passed however, Degas became more and more isolated. The Dreyfus Affair controversy brought his antisemitic leanings to the fore and he broke with all his Jewish friends. In later life, Degas regretted the loss of those friends. It is assumed that he ceased working in 1912. Edgar Degas passed away on September 27, 1917. At yovisto, you can learn more about Edgar Degas’ art in the short lecture on the Milliners.'],\n",
       " [102,\n",
       "  'William Makepeace Thackeray’s deft Skewering of Human Foibles.  William Makepeace Thackeray (1811-1863). On July 18, 1811, English novelist William Makepeace Thackeray was born. He was famous for his satirical works, particularly Vanity Fair, a panoramic portrait of English society. During the Victorian era, Thackeray was ranked second only to Charles Dickens, but he is now much less read and is known almost exclusively for Vanity Fair, which has become a standard fixture in university courses and has been repeatedly adapted for movies and television. Thackeray, an only child, born in Calcutta, India, where his father Richmond Thackeray was secretary to the board of revenue in the British East India Company. William’s father died in 1815, which caused his mother, Anne Becher, to send him to England, where he was educated at schools in Southampton and Chiswick and then at Charterhouse School. In 1829, he went to Trinity College, Cambridge, but never too keen on academic studies, he left the University already in 1830, though some of his earliest writing appeared in university publications The Snob and The Gownsman. He travelled for some time on the continent, visiting Paris and Weimar, where he met Johann Wolfgang von Goethe. After his return to England and a futile trial to study law, by age 21 he came into his inheritance but he squandered much of it on gambling and by funding two unsuccessful newspapers, for which he had hoped to write. Forced to consider a profession to support himself, he turned first to art, which he studied in Paris, but did not pursue it except in later years as the illustrator of some of his own novels and other writings. Everything changed after he married in 1836. Now he began “writing for his life”, as he put it, turning to journalism in an effort to support his young family. He primarily worked for Fraser’s Magazine, a sharp-witted and sharp-tongued conservative publication, for which he produced art criticism, short fictional sketches, and two longer fictional works, Catherine and The Luck of Barry Lyndon, where he explored the situation of an outsider trying to achieve status in high society. Later, he began writing for the newly created Punch magazine, where he published The Snob Papers, later collected as The Book of Snobs, a work that is responsible for the modern meaning of the word “snob”. Unfortunately, tragedy stuck his personal life, when his wife became mentally ill. She eventually deteriorated into a permanent state of detachment from reality, unaware of the world around her, and she ended up confined in a home near Paris. Thackeray became a de facto widower, never establishing another permanent relationship. It was in 1847, his novel Vanity Fair: A Novel without a Hero was published, which made him a celebrity, equal of Dickens. In that novel he was able to satirise whole swaths of humanity while retaining a light touch. It also features his most memorable character, the engagingly roguish Becky Sharp. Unlike Thackeray‘s other novels, it remains popular with the general reading public. His health worsened during the 1850s. He could not break his addiction to spicy peppers, further ruining his digestion. On 23 December 1863, after returning from dining out and before dressing for bed, Thackeray suffered a stroke and was found dead in his bed. At yovisto you can learn more about life and society in the Victorian era in the lecture of Prof. Rickard J. Evans from Gresham College.'],\n",
       " [103,\n",
       "  'The World of Lyonel Feininger.  Collage consisting of a section of a newspaper page of the “San Francisco Examiner” (1925) from left: Galka Scheyer, Lyonel Feininger, Wassily Kandinsky, Paul Klee and Alexej Jawlensky On July 17, 1871, German-American painter Lyonel Charles Feininger was born. He became a leading exponent of Expressionism and especially Cubism. Lyonel Feininger was born into a family of musicians. His father was the famous German violinist and composer Karl Feininger and his mother, Elizabeth Feininger was an American pianist and singer. Feininger himself visited Germany for the first time at the age of 16, when his parents gave several concerts in Europe and he was allowed to stay in order to attend an art school in Hamburg. He continued his studies at ‘Königliche Akademie’ in Berlin one year later and started drawing for newspapers and publishers in the area. Feininger decided to leave Germany and enrolled at the Académie Colarossi in Paris. It was also in Paris, where Feininger met Robert Delaunay and Henri Matisse in 1906 and in the same year he published the famous newspaper comics “The Kin-der-Kids” and “Wee Willie Winkie’s World“, which appeared in the Chicago Sunday Tribune. The strips were noted for their great humor and graphic experimentation. He also worked as a commercial caricaturist for 20 years for various newspapers and magazines in both the USA and Germany. The artist began creating ‘serious’ fine arts at the age of 36 and got the chance to exhibit his works at Paris’ “Salon des Artistes Indépendants“. It is assumed that shortly after, Feininger gathered his first experiences with cubism. He met numerous famous artists at this point and became associated with German expressionist groups, like “Die Brücke“, “Novembergruppe“, “Gruppe 1919″, “Blaue Reiter“, and “Die Blaue Vier“. His very first solo exhibit was at Sturm Gallery in Berlin in 1917 where he exhibited 45 paintings and 66 other works. When Walter Gropius founded the Bauhaus in Germany in 1919, Feininger was his first faculty appointment, and became the master artist in charge of the printmaking workshop. In this period, Feininger spent most of his summer vacations at Benz, on the German island of Usedom, where he was highly inspired. Feininger continued paining pictures of Benz for all of his life, even after returning to the United States. In 1921, while still teaching at Bauhaus, the artist also composed a fugue and moved to Dessau in 1926 in order to work at the newly established Bauhaus school. However, Feininger and his family had to leave Germany in 1937 as the situation with the growing Nazi Party became unbearable for them, the party declared his work to be “degenerate”. The Nazis confiscated almost 400 of his works from public collections and exhibited them as “degenerate art” in Munich after he had already moved to the United States. Feininger started to teach at Mills College and began his collection of Manhattan motives. He also produced a large body of photographic works between 1928 and the mid-1950s. He kept his photographic work within his circle of friends, and it was not shared with the public in his lifetime. Lyonel Feininger passed away on January 13, 1956. His sons, Andreas Feininger and T. Lux Feininger became noted artists themselves, the former as a photographer and the latter as a photographer and painter. At yovisto, you may learn more about cubism in Clare Barry’s talk Picasso and Braque`s Cubist Experiment: “Like mountain climbers roped together”'],\n",
       " [104,\n",
       "  'Pavel Cherenkov and the Blue Light.  Pavel Cherenkov (1904 – 1990).  On July 15, 1904, Soviet physicist Pavel Alekseyevich Cherenkov was born. He shared the Nobel Prize in physics in 1958 with Ilya Frank and Igor Tamm for the discovery of Cherenkov radiation, made in 1934. Cherenkov radiation is a faint blue light emitted by electrons passing through a transparent medium when their speed exceeds the speed of light in that medium. This sounds pretty weird, doesn’t it. With Einstein he have learned that nothing exceeds the speed of light. But Cherenkov radiation caused by particles faster than the speed of light? Well, it depends of the medium in which the light is distributing. In water as e.g. the speed of light is slower than in vacuum. But, let’s get back to Cherenkov… Cherenkov was born in 1904 in present day Voronezh Oblast, Russia. He enrolled at Voronezh State University, where he graduated in 1928, and became senior researcher at the Lebedev Institute of Physics two years later. In 1959, the professor of experimental phyiscs was appointed head of the institute’s photo-meson processes laboratory. He remained a professor for fourteen years. In 1970, he became an Academician of the USSR Academy of Sciences. Cherenkov made his most important discovery in 1934. He observed the emission of blue light from a bottle of water subjected to radioactive bombardment. This sounds trivial at first, but associated with charged atomic particles moving at velocities faster than the speed of light in the local medium, it proved to be of great importance in subsequent experimental work in nuclear physics, and for the study of cosmic rays. It was later on named the Cherenkov effect. Cherenkov radiation is widely used to facilitate the detection of small amounts and low concentrations of biomolecules. Also, it can be used to detect high-energy charged particles. In pool-type nuclear reactors, high-energy electrons are released as the fission products decay. The glow continues after the chain reaction stops, dimming as the shorter-lived products decay. Furthermore, when a high-energy gamma photon or cosmic ray interacts with the Earth’s atmosphere, it may produce an electron-positron pair with enormous velocities. The Cherenkov radiation from these charged particles is used to determine the source and intensity of the cosmic ray or gamma ray. Cherenkov radiation can also be used to determine properties of high-energy astronomical objects that emit gamma rays, such as supernova remnants and blazars. Pavel Cherenkov also shared in the development and construction of electron accelerators and in the investigation of photo-nuclear and photo-meson reactions. He passed away on January 6, 1990. At yovisto, you may be interested in a video lecture on the “High Energy Universe” by Rene Ong.'],\n",
       " [105,\n",
       "  'The Conversational Eloquence of Madame de Staël.  Madame de Staël (1766-1817). On July 14, 1817, French woman of letters of Swiss origin Anne Louise Germaine de Staël-Holstein, commonly known as Madame de Staël, passed away. She was one of Napoleon’s principal opponents. Celebrated for her conversational eloquence, she participated actively in the political and intellectual life of her times. Her works, both critical and fictional, made their mark on the history of European Romanticism. She was a remarkable woman, and not all men of her time did really well get along with her, as e.g. Napoleon, Goethe, or Schiller. Anne Louise Germaine Necker was born on April 22, 1766, in Paris, France as the only daughter of the prominent Swiss banker and statesman Jacques Necker, who was the Director of Finance under King Louis XVI of France. Her mother was Suzanne Curchod, hostess of one of the most popular salons of Paris, who intended to educate her daughter according the principles of J.-J. Rousseau and to endow her with the intellectual education and Calvinist discipline of her own Protestant pastor father. She usually brought Germaine as a young child to sit at her feet in her salon, where the sober intellectuals took pleasure in stimulating the brilliant child. After Jacques Necker’s dismissal from office, they resided in 1784 in Coppet at Château, her father’s estate on Lake Geneva, which she later would make famous. Soon Germaine’s parents became impatient for her to marry. But, the difficulty now in France was thatthey are said to have objected to her marrying a Roman Catholic, which definitely limited the number of available candidates. Finally, she married Baron Erik Magnus Staël von Holstein in 1786, who was first an attaché of the Swedish legation, and then minister. The husband was 37, the wife 20. Madame de Staël was accused of extravagance. This was a mere legal formality, however, and on the whole the marriage seems to have been acceptable to both parties, neither of whom had any affection for the other. Overall, de Staële was striking rather than beautiful with a flamboyant style of dress. She is described as being tall, but rather clumsy. Actually, there is the story where she tripped over her train when she made her debut at court and fell on her face. She had abundant black hair, large hazel eyes, beautiful shoulders, and a generous bosom. While not a great beauty, she was vivacious and more important, a witty conversationalist, not afraid to share her opinions. She began writing novels strongly supporting the ideals of Rousseau and favored constitutionalism in politics. Her novels were bestsellers and her literary criticism was highly influential. Her first child, a boy, was born in 1790 the week before Necker finally left France in unpopularity and disgrace; and the increasing disturbances of the Revolution made her privileges as ambassadress very important safeguards. She fled the September massacres in 1792, and then moved to Coppet Castle, where she gathered round her a considerable number of friends and fellow-refugees, the beginning of the salon which at intervals during the next 25 years made the place so famous. It was during these years that Madame de Staël was of chief political importance. And it was also the time that she became regarded by contemporary Europe as the personal enemy of Napoleon Bonaparte. It displeased Napoleon that Madame de Staël should show herself recalcitrant to his influence. But it probably pleased Madame de Staël to quite an equal degree that Napoleon should apparently put forth his power to crush her and fail. Both personages had a curious touch of theatricality. “Madame,” the general informed the lady in question, “I do not want women mixed up in politics.” “You are perfectly right,” came the reply, “but in a country where their heads are cut off, it is only natural for them to want to know why.” (Exchange between Napoleon Bonaparte and Madame de Staël.) She formed the nucleus of a liberal resistance that so embarrassed Napoleon that in 1803 he had her banished to a distance of 64km from Paris. From December 1803 to April 1804 she made a journey through Germany, culminating in a visit to Weimar, already established as the shrine of Johann Wolfgang von Goethe and Friedrich von Schiller. In Berlin she met August Wilhelm von Schlegel, who was to become, after 1804, her frequent companion and counselor. Meanwhile Madame de Staël, persecuted by the police, fled from Napoleon’s Europe. Having married a young Swiss officer, “John” Rocca in 1811, she went to Austria and, after visiting Russia, Finland, and Sweden, arrived in England in 1813. She was received with enthusiasm, although reproached by such liberals as Lord Byron for being more anti-Napoleonic than liberal. On the Bourbon Restoration in 1814, Madame de Staël returned to Paris but was deeply disillusioned: the fall of Napoleon had been followed by foreign occupation and had in no way reestablished liberty in France. During the Hundred Days she escaped to Coppet and in September 1815 set out again for Italy. In 1816 she returned to spend the summer at Coppet, where she was joined by Lord Byron, in flight from England after his unhappy matrimonial experience. A strong friendship developed between the two writers. Madame de Staël lived only two years following Napoleon’s defeat. By coincidence, de Staël died in Paris on July 14, 1817 – Bastille Day – the day commemorating one of the first events of the French Revolution. At yovisto you can learn more about Goethe and his philosophical conception of the world in Prof Fred Amrine’s lecture ‘Kicking away the ladder‘'],\n",
       " [106,\n",
       "  'August Kekulé and the Carbon Ring Structure.  August Kekulé (1829 – 1896).  On July 13, 1896, German organic chemist Friedrich August Kekulé passed away. Being one of the world’s leading chemists of his time, he is best known for devising the ring structure of carbon atoms in organic molecules and became the principal founder of the theory of chemical structure. August Kekulé was born on September 7, 1829 in Darmstadt as son of a civil servant. After graduating from secondary school, in 1847 he attended the University of Giessen. At first, he wanted to study architecture but was convinced to continue with chemistry by the lectures of Justus von Liebig. After graduating, he took postdoctoral fellowships in Paris, Chur, Switzerland, and London. Shortly after, Kekulé was appointed full professor at the University of Ghent and later on at Bonn, where he remained for the rest of his career. Kekulé was the principal formulator of the theory of chemical structure and in his work, he was highly influenced by the work of Williamson, Edward Frankland, William Odling, Auguste Laurent, and Charles Adolphe Wurtz. The famous theory covers three main parts, the idea of atomic valence, the ability of carbon atoms to link to each other and the determination of the bonding order of all of the atoms in a molecule. The theory explained by Kekulé, provided a whole new perspective and clarity on analytic and especially synthetic work. Also, this contribution be Kekulé paved the way for organic chemistry. Kekulé’s idea of assigning certain atoms to certain positions within the molecule, and schematically connecting them was mainly based on chemical reactions he observed. One of the main ideas about his structural chemistry was that the number of valences of a given element was invariant. However, numerous exceptions followed and it was then found out that valences were fixed at certain oxidation states. Periodic acid for example could, according to Kekulé’s structure theory, be represented by the chain structure I-O-O-O-O-H. The modern structure of periodic acid has all four oxygen atoms surrounding the iodine in a tetrahedral geometry. To one of Kekulé’s biggest contributions to chemistry belongs his work on the structure of benzene. His first paper on the topic was published in 1865 and in it, he suggested that the structure contained a six-membered ring of carbon atoms with alternating single and double bonds. After this work by Kekulé, a new understanding of benzene, and hence of all aromatic compounds, proved to be so important for both pure and applied chemistry after 1865 that in 1890 the German Chemical Society organized an appreciation in Kekulé’s honor, celebrating the twenty-fifth anniversary of his first benzene paper. There, Kekulé spoke of the creation of the theory and he said that he had discovered the ring shape of the benzene molecule after having a reverie or day-dream of a snake seizing its own tail. This vision, he said, came to him after years of studying the nature of carbon-carbon bonds. At yovisto, you may be interested in a video lecture on Benzene and Aromaticity at the University of Berkeley by Professor Vollhardt.'],\n",
       " [107,\n",
       "  'Pablo Picasso’s Guernica.  Pablo Picasso’s Guernica, 1937, Museo Reina Sofia, Madrid, Spain.  On July 12, 1937, Pablo Picasso presents his famous painting Guernica for the very first time at the Spanish Pavilion at the Paris International Exposition. It was created in response to the bombing of Guernica, a Basque Country village in northern Spain, by German and Italian warplanes at the behest of the Spanish Nationalist forces on 26 April 1937 during the Spanish Civil War. Guernica has become one of today’s most famous pieces of art. I’m sure you have already some reproduction of Picasso’s Guernica somewhere. I remember there was a picture of it also in one of the textbooks we used for German classes back in school. Of course it is an impressive piece of modern art, but what makes it so special is of course the history that is connected with it. We already had an article about Pablo Picasso, one of the most influential artists of the 20th century. BTW, we also had to remove a Picasso video from our yovisto archive because of copyright reasons. Let’s keep fingers crossed that we don’t do any wrong with our Guernica post… The little town of Guernica, which is the name giver for the picture, is a Basque Country village in northern Spain. It was in the 1930s during the Spanish Civil war, when on April 26, 1937, an aerial attack was carried out by planes of the German Luftwaffe “Condor Legion” and the Italian Fascist supporting the Nationalist forces of General Franco during the Spanish Civil War. The bombing caused widespread destruction and numerous civilian deaths. It is considered one of the first raids in the history of modern military aviation on a defenseless civilian population. The bombing shocked and inspired many artists, among them the most famous Pablo Picasso. By the time, Picasso was living in Paris. He had last visited his home country Spain in 1934 and would never return. In January 1937, Picasso was originally commissioned by the Spanish Republican government to create a large mural for the Spanish display at the 1937 World’s Fair in Paris. However, it was only on May 1, having read an eyewitness account by Times journalist George Steer that he abandoned his initial project and started sketching a series of preliminary drawings for the mural-size painting, which he would finish in early June 1937. Guernica is completely colored in grey, black and white, and it is a huge painting, 3.5 meters high and 7.8 meters wide painted in oil. The painting shows suffering people, animals, and buildings wrenched by violence and chaos. But as a rule, a picture tells more than a thousand words. You should simply click on the image above and have a look for yourself. There is this interesting story, that while living in Nazi-occupied Paris during World War II, one German officer allegedly asked Picasso, upon seeing a photo of Guernica in his apartment, “Did you do that?” Picasso responded, “No, you did.” Interpretations of Guernica vary widely and contradict one another. Therefore, I will spare you a debate about art criticism. When pressed to explain his thoughts and intentions expressed in Guernica, Picasso said: “…this bull is a bull and this horse is a horse… If you give a meaning to certain things in my paintings it may be very true, but it is not my idea to give this meaning. What ideas and conclusions you have got I obtained too, but instinctively, unconsciously. I make the painting for the painting. I paint the objects for what they are.” After the exhibition at the 1937 World’s Fair, the San Francisco Museum of Art gave the work its first public, free appearance in the United States in 1939, then it moved to the Museum of Modern Art in New York City. The painting traveled extensively in the United States; between 1953 and 1956 it was shown in Brazil, at the first-ever Picasso retrospective in Milan, Italy, and then in numerous other major European cities, before returning to MoMA for a retrospective celebrating Picasso’s seventy-fifth birthday. Under great pressure from a number of observers, MoMA finally ceded the painting to Spain in 1981. Guernica has become a cultural icon that speaks to mankind not only against war but also of hope and peace. At yovisto, you can learn more about Picasso’s artwork in Francoise Gilot’s talk ‘An Encounter with Picasso‘ at the Metropolitan Museum of Art.'],\n",
       " [108,\n",
       "  'Samuel Goudsmit and the Electron Spin.  George Uhlenbeck, Hendrik Kramers, and Samuel Goudsmit in 1928.  On July 11, 1902, Dutch-born U.S. physicist Samuel Abraham Goudsmit was born. He is best known for the formulation of the concept of electron spin together with George Eugene Uhlenbeck. It led to recognition that spin was a property of protons, neutrons, and most elementary particles and to a fundamental change in the mathematical structure of quantum mechanics. If you not happen to be a physicist, you probably will never have heard that electrons have a spin. Well, electrons are not literally spinning balls of charge, but they do have intrinsic angular momentum. Spin angular momentum is real angular momentum. The angular momentum of a spin-1/2 particle like an electron is never zero. But, let’s go back one more step. In 1891, the Irish physicist, George Stoney, believed that electricity should have a fundamental unit. He called this unit the electron and the electron as the first sub-atomic particle was discovered by J.J. Thomson in 1897. Besides its electric charge and mass, an electron has one more key property, which is called “electron spin“. Two types of experimental evidence which arose in the 1920s suggested this additional property of the electron. One was the closely spaced splitting of the hydrogen spectral lines, called fine structure. The other was the Stern-Gerlach experiment which showed in 1922 that a beam of silver atoms directed through an inhomogeneous magnetic field would be forced into two beams. Both of these experimental situations were consistent with the possession of an intrinsic angular momentum and a magnetic moment by individual electrons. Classically this could occur if the electron were a spinning ball of charge, and this property was called electron spin. Samuel Goudsmit was born in The Hague, Netherlands, as son of Jewish parents Isaac and Marianne Goudsmit. As he was proud to claim throughout his life, his father was a small manufacturer of water closets fixtures while his mother ran a millinery shop. Samuel Goudsmit started his professional life at the University of Leyden during the earliest days of quantum mechanics as a student of Paul Ehrenfest, a theoretical physicist, who made major contributions to the field of statistical mechanics and its relations with quantum mechanics. Ehrenfest was both, an outstanding scientist as well as a gifted pedagogue. Under Ehrenfest’s tutelage Goudsmit published his first scientific paper already at age 19 in 1921 in the prestigious journal “Die Naturwissenschaften“. In 1925 Goudsmit together with his fellow graduate student George Uhlenbeck were assigned by Ehrenfest to work for a quick update on “what was currently happening in physics”. Thus, while being a graduate student, Goudsmit and Uhlenbeck discovered the spin on the electron. In 1927 after receiving their PhD, Goudsmit and Uhlenbeck together moved to the United States where they continued their physics careers until death. From 1927 to 1946, Goudsmit served as a Professor at the University of Michigan. He was also the scientific head of the Alsos Mission and successfully reached the German group of nuclear physicists around Werner Heisenberg and Otto Hahn at Hechingen (then French zone) in advance of the French physicist Yves Rocard. As part of the Manhattan Project, Alsos was designed to assess the progress of the Nazi atomic bomb project. Goudsmit published in 1947 his conclusion that the Germans did not get close to creating a weapon, which he attributed to the inability of science to function under a totalitarian state. His other conclusion, that the German scientists simply did not understand how to make an atomic bomb, has been disputed by later historians. After the war he was briefly a professor at Northwestern University and from 1948-1970 was a senior scientist at the Brookhaven National Laboratory. In 1974, Goudsmit moved to the faculty of the University of Nevada in Reno, where he remained until his death four years later. At yovisto, you may learn more about particle physics in the inside tour of the world` biggest supercollider LCH at the CERN research institute, given by physicist Brian Cox.'],\n",
       " [109,\n",
       "  'Camille Pissaro and the Impressionistic Art Movement.  Camille Pissarro (1830-1903). On July 10, 1830, Danish-French Impressionist and Neo-Impressionist painter Camille Pissaro was born. His importance resides in his contributions to both Impressionism and Post-Impressionism. He acted as a father figure not only to the Impressionists but to all four of the major Post-Impressionists, including Georges Seurat, Paul Cézanne, Vincent van Gogh and Paul Gauguin. Jacob Abraham Camille Pissarro was born on the island of St. Thomas in the Danish West Indies (since 1917 the US Virgin Islands) to Frederick and Rachel Pissarro, a merchant of Portuguese Jewish descent. At age twelve Camille’s father sent him to boarding school in France. He studied at the Savary Academy in Passy near Paris. While a young student, he developed an early appreciation of the French art masters. However, when he returned to St. Thomas at age 17, his father preferred that he worked in his business and gave him a job working as a cargo clerk. He took every opportunity during those next five years at the job to practice drawing during breaks and after work. Pissarro was attracted to political anarchy, an attraction that may have originated during his years in St. Thomas. In 1852, he traveled to Venezuela with the Danish artist Fritz Melbye, who inspired Pissarro to take on painting as a full-time profession, becoming his teacher and friend. In 1855, Pissarro left for Paris, where he began working as assistant to Anton Melbye, Fritz Melbye’s brother, and studied at various academic institutions under a succession of masters, such as Jean-Baptiste-Camille Corot, Gustave Courbet, and Charles-Francois Daubigny. The Harvest, 1882, Bridgestone Museum of Art, Tokyo In 1859 Pissarro’s first painting was accepted and exhibited. His other paintings during that period were influenced by his tutor Camille Corot. He and Corot both shared a love of rural scenes painted from nature. It was by Corot that Pissarro was inspired to paint outdoors, also called “plein air” painting. Camille left his home in Louveciennes to move to England during the Franco-Prussian War and the Commune (1870-71) and, with Claude Monet, he painted a series of landscapes around Norwood and Crystal Palace as well as studying English landscape painters in the museums. On returning home to Louveciennes at the end of the war a year later, Camille discovered that only 40 of his 1500 paintings – almost twenty years’ work – remained undamaged. In the summer of 1871 Camille settled in Pontoise where he was to remain for the next ten years, gathering a close circle of friends around him. Paul Cézanne repeatedly came to stay with him and under Camille’s influence learned to study nature more patiently. In the early 1870s Pissarro devoted a great deal of thought to the idea of creating an alternative to the Salon, a plan he discussed with Monet, Renoir, and others. They devised the idea of a society with a charter based on that of a local bakers’ union, and by January 1874 Pissarro helped found a cooperative along these lines. In April of that year the group held their first exhibition at the studio of the photographer Félix Nadar in Paris, at 35 Boulevard des Capucines, a show that became known as the first Impressionist exhibition, which shocked and “horrified” the critics, who primarily appreciated only scenes portraying religious, historical, or mythological settings. In 1871, Pissarro married Julie Vellay, a maid in his mother’s household. Of their eight children, one died at birth and one daughter died aged nine. The surviving children all painted, and Lucien, the oldest son, became a follower of William Morris. The Boulevard Montmartre on a Winter Morning, 1897, Metropolitan Museum of Art By the 1880s, Pissarro began to explore new themes and methods of painting to break out of what he felt was an artistic “mire”. As a result, Pissarro went back to his earlier themes by painting the life of country people. This period also marked the end of the Impressionist period due to Pissarro’s leaving the movement. It was Pissarro’s intention during this period to help “educate the public” by painting people at work or at home in realistic settings, without idealising their lives. In 1885 he met Georges Seurat and Paul Signac, both of whom relied on a more “scientific” theory of painting by using very small patches of pure colors to create the illusion of blended colors and shading when viewed from a distance. Adapting this Neo-impressionistic or Pointilistic style, Pissarro’s sales dipped as well as his rate of production. The family suffered considerably. Pissarro eventually turned away from Neo-Impressionism, claiming its system was too artificial. But, once he threw off the shackles of this labor-intensive direction, his natural verve reignited and his production soared. So did his prices and by the end of 1890s, the family enjoyed a comfortable income. In his older age Pissarro suffered from a recurring eye infection that prevented him from working outdoors except in warm weather. As a result of this disability, he began painting outdoor scenes while sitting by the window of hotel rooms. He often chose hotel rooms on upper levels to get a broader view. Pissarro died in Paris on 13 November 1903 and was buried in Père Lachaise Cemetery. At yovisto you can learn more about Impressionism in the lecture of Dr. Parme Giuntini, Director of Art History at Otis College of Art and Design, on Impressionism.'],\n",
       " [110,\n",
       "  'John Wheeler and the Golden Age of General Relativity.  Eckehard W. Mielke together with John Archibald Wheeler in 1985 Image: Eckard Mielke.  On July 9, 1911, American theoretical physicist John Archibald Wheeler was born. Wheeler worked with Niels Bohr in explaining the basic principles behind nuclear fission as well as with Albert Einstein, with whom he tried to achieve Einstein’s vision of a unified field theory. He is also known for popularizing the term black hole, and for coining the terms quantum foam, and wormhole. John Wheeler earned his doctorate degree from the John Hopkins University in 1933 and his dissertation was on the theory of the dispersion and absorption of helium. In his early years as a scientist, Wheeler worked at the University of North Carolina until he moved to Princeton University. He became the director of the Center for Theoretical Physics at the University of Texas in 1976 and kept this position until retiring in 1986. However, Wheeler eventually returned to Princeton as a professor emeritus. The scientist supervised more PhD as well as senior undergraduate theses than any other professor in the Princeton physics department. In 1937, Wheeler introduced the S-matrix, which relates the initial state and the final state of a physical system undergoing a scattering process and became an important tool in particle physics. Also, the scientist collaborated with Nils Bohr on the liquid drop model of nuclear fission. He interrupted his academic career to participate in the development of the atomic bomb during the Manhattan Project, working at the Hanford Site in Washington, where several large nuclear reactors were constructed to produce the element plutonium for atomic bombs. In later years, Wheeler also worked on the development of the more powerful hydrogen bomb under the nuclear weapons program. John Wheeler returned to Princeton and increased his interest in mathematical extensions to the Theory of General Relativity. He introduced the concept and the word wormhole to describe hypothetical “tunnels” in space-time. Unfortunately, the subject of general relativity was not very much respected, being detached from experiment. However, Wheeler made great efforts in the revival of the research field and his as well as his students’ work made significant contributions to the Golden Age of General Relativity. The so called golden age includes many of the concepts and terms which continue to inspire the imagination of gravitation researchers and the general public. At the same time, in a closely related development, the study of physical cosmology entered the mainstream and the Big Bang became well established. Major research topics included the role of curvature in general relativity, the importance of black holes, and “precision tests” of gravitation theories. Wheeler’s work in general relativity included the theory of gravitational collapse. He was also a pioneer in the field of quantum gravity with his development of the Wheeler–DeWitt equation, which is the equation governing the wave function of the Universe, as he called it. John Wheeler passed away on April 13, 2008. He was awarded the Wolf Prize in Physics in 1997. At yovisto, you may be interested in a short interview with John Wheeler himself.'],\n",
       " [111,\n",
       "  'Alfred Binet and the Intelligence Test.  Alfred Binet (1857 – 1911).  On July 8, 1857, French psychologist Alfred Binet was born. He was a pioneer in the field of intelligence testing of the normal mind. He took a different approach than most psychologists of his day: he was interested in the workings of the normal mind. He invented the first practical intelligence test, the Binet-Simon scale rather than the pathology of mental illness. After earning a law degree in 1878, Alfred Binet became more and more interested in psychology, he started educating himself on the topic at the National Library in Paris. He soon became fascinated with the ideas of John Stuart Mill, who believed that the operations of intelligence could be explained by the laws of associationism. Binet eventually realized the limitations of this theory, but Mill’s ideas continued to influence his work. Binet was appointed to his first formal position as a researcher at a neurological clinic, Salpêtrière Hospital, in Paris from 1883–1889. Jean-Martin Charcot, who was back then the director of the clinic, became his mentor. Binet started to publish further works and managed to increase his reputation. Binet increased his interest in development, after his daughters Marguerite and Armande were born in the 1880s. He called Armande a subjectivist and Marguerite an objectivist, and developed the concepts of introspection and externospection in an anticipation of Carl Jung’s psychological types. In the following years, Binet published numerous books and scientific papers on his interests which are assumed to have highly influenced Jean Piaget. Binet’s research with his daughters helped him to further refine his developing conception of intelligence, especially the importance of attention span and suggestibility in intellectual development. He continued as a researcher and later director of the Laboratory of Experimental Psychology at the Sorbonne. The position enabled him to pursue his studies on mental processes. Also, Theodore Simon applied to do doctoral research under Binet’s supervision, which was the beginning of their long, fruitful collaboration. When Binet was asked to join a committee psychologically studying children, it became his duty to distinguish ‘normal’ children from children with learning difficulties. His work was published as “L’Etude experimentale de l’intelligence” (Experimental Studies of Intelligence) in 1903. He continued his research on this topic and also started including Simon in his intelligence tests. In 1905, a new test for measuring intelligence was introduced and simply called the Binet–Simon scale. In 1908, they revised the scale, dropping, modifying, and adding tests and also arranging them according to age levels from three to thirteen. They managed to develop a variety of tasks they found representative for the abilities of children various ages. Their scale included thirty tasks of increasing difficulty. The first and most easy tasks assessed for example whether or not a child could follow a beam. Then, children were required to point at certain body parts, repeat numbers or sentences and to state the difference between pairs of things or reproduce drawings from memory. The hardest question was: “My neighbor has been receiving strange visitors. He has received in turn a doctor, a lawyer, and then a priest. What is taking place?” For the practical use of determining educational placement, the score on the Binet-Simon scale would reveal the child’s mental age. In 1908, the Simon-Binet scale was introduced in the U.S. and extended to the Stanford-Binet scale. Binet published the third version of the Binet-Simon scale shortly before his death in 1911. The Binet-Simon scale became very popular around the world and in 1984, the journal Science 84 picked the Binet-Simon scale, as one of twenty of this century’s most significant developments or discoveries. At yovisto, you may be interested in a video on Intelligence as part of the lecture series ‘Introduction to Psychology’ by Professor William Knapp.'],\n",
       " [112,\n",
       "  'Rudolf Wolf and the Sunspots.  Rudolf Wolf (1816.1893).  On July 7, 1816, Swiss astronomer and astronomical historian Rudolf Wolf was born. Wolf’s main contribution was the discovery of the 11 year sunspot cycle and he was the co-discoverer of its connection with geomagnetic activity on Earth. Johann Rudolf Wolf was born in Fällanden, near Zurich, to Regula Gossweiler and Johannes Wolf, who was a minister in the Church. After studying at the Zurich Industrieschule, Wolf attended the University of Zurich, and moved to Vienna in 1836, studying there for two years before going to Berlin in 1838, where he attended lectures by Encke and Dirichlet. In 1838 he visited Carl Friedrich Gauss, then in the following year he became a lecturer in mathematics and physics at the University of Bern. In addition, he became professor of astronomy there in 1844, and director of the Bern Observatory in 1847. In 1855 he accepted a chair of astronomy at both the University of Zurich and the Federal Institute of Technology in Zurich. Wolf was greatly impressed by the discovery of the sunspot cycle by Heinrich Schwabe, an amateur astronomer in Dessau where he worked as a pharmacist. Schwabe observed the Sun because he was trying to find a planet inside the orbit of Mercury. His idea was to detect it when it crossed the disk of the Sun so he began to make a systematic record of the spots on the Sun, every day when visibility allowed, beginning in 1826. By 1843 he had begun to suspect that there was some regularity in the sunspots he was recording and published Solar Observations during 1843 in which he suggested that sunspots might follow a period of about 10 years. Wolf, who at that time was in Bern, was fascinated and in 1847 he began his own observational record of sunspots. In the following year he devised a system which is now known as ‘Wolf’s sunspot numbers‘. This system, which gave a weighted number of sunspots where groups of sunspots were given a higher weight, is still in use for studying solar activity by counting sunspots and sunspot groups. By 1868 Wolf had a more or less reliable sunspot number reconstruction back to 1745, and pushed his reconstruction all the way back to 1610, although the paucity of data effectively rendered these older determinations far less reliable. From this data Wolf was the first to calculate an accurate length of the cycle, obtaining a value of 11.1 years. Wolf also was the first to note the possible existence in the sunspot record of a longer modulation period of about 55 years. In 1852 he became was the co-discoverer of the connection between the sunspot cycle and geomagnetic activity on Earth. Wolf and others also noted a similar correspondence between sunspot cycle and frequency of auroral activity. Wolf then sought a similar peridiocity in various meteorological phenomena, but without conclusive results. He continued to publish reports on sunspot numbers until his death. At yovisto you can learn more about Solar eclipses in the presentation of Prof. Peter Cole about the 1919 Solar Eclipse Expedition where Eddington was able to give a proof for Einstein’s theory of general relativity.'],\n",
       " [113,\n",
       "  'Albert von Kölliker and the Origins of Embriology.  Rudolf von Kölliker (1817-1902). On July 6, 1817, Swiss anatomist and physiologist Albert von Kölliker was born. He was one of the founders of embryology. His thorough microscopic work on tissues enabled him to be among the first to identify their structure. He showed that they were made up of cells, that did not freely come into being, but must develop from existing cells. Rudolph Albert Kölliker was born in Zurich, Switzerland. His early education was carried on in Zurich, and he entered the university there in 1836. After two years, however, he moved to the University of Bonn, and later to that of Berlin, becoming a pupil of noted physiologists Johannes Peter Müller and of Friedrich Gustav Jakob Henle. He graduated in philosophy at Zurich in 1841, and in medicine at Heidelberg in 1842. The first academic post which he held was that of prosector of anatomy under Henle, but his tenure of this office was brief. In 1844 he returned to Zurich University to occupy a chair as professor extraordinary of physiology and comparative anatomy. In 1847 the University of Würzburg, attracted by his rising fame, offered him the post of professor of physiology and of microscopical and comparative anatomy. He accepted the appointment, and at Würzburg he remained thenceforth, refusing all offers tempting him to leave the quiet academic life of the Bavarian town, where he died on the 2nd of November 1905. Kölliker made substantial contributions to the study of zoology. While his earlier efforts were directed to the invertebrates, he soon passed on to the vertebrates, and studied the amphibians and mammalian embryos. He was among the first, if not the very first, to introduce into this branch of biological inquiry the newer microscopic technique the methods of hardening, sectioning and staining. By doing so, not only was he enabled to make rapid progress himself, but he also placed in the hands of others the means of a similar advancement. The remarkable strides forward which embryology made during the middle and latter half of the 19th century will always be associated with his name. His Lectures on Development, published in 1861, at once became a standard work. But neither zoology nor embryology furnished Kölliker’s chief claim to fame. He is best known for his contributions to histology, the knowledge of the minute structure of the animal tissues. Among his earlier results was the demonstration in 1847 that smooth or unstriated muscle is made up of distinct units, of nucleated muscle cells. In this work, he followed in the footsteps of his master Henle. A few years before this, there was doubt whether arteries had muscle in their walls. In addition, no solid histological basis as yet existed for those views as to the action of the nervous system on the circulation, which were soon to be put forward, and which had such a great influence on the progress of physiology. Kölliker and his fellow scientists were better able to undertake histological research than before because the microscope in Germany had been improved during the 1820s to such an extent that the obstacles which seventeenth century microscopists had encountered in their investigations had been overcome. The amateur scientist Antoni van Leeuwenhoek had observed nerve cells, but the microscopes which he used produced distorted images. The cells which he wanted to study did not stand out from the surrounding fluids or the background. In 1864 Kölliker revived Étienne Geoffroy Saint-Hilaire’s theory that evolution proceeds by large steps, under the name of heterogenesis. He was a critic of Darwinism and rejected a universal common ancestor, instead he supported a theory of common descent along separate lines. In Honor of his scientific achievements, Kölliker received the title of nobility “von Kölliker” and became a fellow of the Royal Society in 1860, which honored him in 1897 with their highest token of esteem, the Copley Medal. At yovisto, you may enjoy a video lecture on Human Embryology by Professor Steven Fink.'],\n",
       " [114,\n",
       "  'A. E. Douglass and the Dendrochronology.  Drill to take samples for dendrochronology from trees Image by Wikimedia User Hannes Grobe.  On July 5, 1867, American astronomer and archeologist A. E. (Andrew Ellicott) Douglass was born. He coined the name dendrochronology for tree-ring dating, a field he originated while working at the Lowell Observatory, Flagstaff, Arizona, by his discovery a correlation between tree rings and the sunspot cycle. A. E. Douglass was not the first, who suggested that a tree’s rings could determine its age. The first known record of the idea come from Leonardo da Vinci. However, Douglass was the first to use cross-dating methods successfully to determine a tree’s age. A. E. Douglass was born in Vermont in 1867 and later on enrolled at Trinity College in Connecticut. He continued his career at the observatory at Harvard University, which opened a completely new observatory in Peru. There, Douglass mainly observed planet Mars, which not only fascinated the American astronomer, but also the businessman, author, and astronomer Percival Lowell. Together, they established a new observatory in Flagstaff, Arizona. Through the years, Douglass came to realize, that there might be a connection between sunspots and the weather on Earth. Also Gregor Johann Mendel got this idea in this period. In 1904, Douglass observed the rings of several trees. He noticed that the structure of wider and smaller rings is equal in trees of the same kind and the same region. Douglass found out that in regions of higher precipitation, the rings were wider than in drier regions. Douglass also realized that historical buildings made of wood may give information on the weather conditions from over hundreds of years ago and dendrochronology was born. The astronomer established the Laboratory of Tree-Ring Research at the University of Arizona in 1937, where until this day visiting scholars and faculty at the lab have done notable work in the areas of climate change, fire history, ecology, archeology and hydrology. At yovisto, you may be interested in a video lecture by the Professor of Dendrochronology at the University of Arizona titled “Global Climate Change: The Evidence“.'],\n",
       " [115,\n",
       "  'Rube Goldberg’s complicated Machines.  Rube Goldberg (1883-1970). in 1916.  On July 4, 1883, American cartoonist, sculptor, author, engineer and inventor Reuben Garrett Lucius “Rube” Goldberg was born. He is best known for a series of popular cartoons depicting complicated gadgets that perform simple tasks in indirect, convoluted ways. Goldberg received many honors in his lifetime, including a Pulitzer Prize for his political cartooning in 1948. Reuben Lucius Goldberg was born July 4, 1883, in San Francisco, California, to Jewish parents Max and Hannah Goldberg, as the third of seven children. Rube began tracing illustrations when he was four years old, and first took professional drawing lessons when he was eleven. After graduating from the University of California Berkeley with a degree in engineering, Rube went on to work as an engineer for the City of San Francisco Water and Sewers Department. After six months Rube shifted gears and left the Sewers Department to become an office boy in the sports department of a San Francisco newspaper. While there he began to submit drawings and cartoons to the editor until he was finally published. Rube soon moved from San Francisco to New York to work for the Evening Mail drawing daily cartoons. His work entered syndication in 1915, beginning his nationwide popularity. By 1922, he was earning $100,000 a year. A prolific artist, Goldberg produced several cartoon series simultaneously, including Mike and Ike (They Look Alike), Boob McNutt, Foolish Questions, “Lala Palooza” and The Weekly Meeting of the Tuesday Women’s Club. The cartoons that brought him lasting fame involved a character named Professor Lucifer Gorgonzola Butts. In that series, Goldberg drew labeled schematics of the comical “inventions” that would later bear his name. Rube’s early years as an engineer informed his most acclaimed work. A Rube Goldberg contraption – an elaborate set of arms, wheels, gears, handles, cups and rods, put in motion by balls, canary cages, pails, boots, bathtubs, paddles and live animals – takes a simple task and makes it extraordinarily complicated. The first illustration depicting a “Rube Goldberg Machine” was an Automatic Weight Reducing Machine in 1914 using components such as a donut, bomb, wax, balloon and hot stove to trap an obese person in a sound and food proof prison, who had to lose weight before wriggling free. He used many simple subjects and made them humorous yet awfully complicated and tedious. This included scratching insect bites, scrubbing your back in a bath, opening a window, collecting mail and finding a ball. In 1931 the Merriam-Webster dictionary adopted the word “Rube Goldberg” as an adjective defined as accomplishing something simple through complicated means. Rube Goldberg believed that most people preferred doing things the hard way instead of using a more simple and direct path to accomplish a goal. In the words of the inventor, the machines were a “symbol of man’s capacity for exerting maximum effort to achieve minimal results.” In 1948 he was awarded the Pulitzer Prize for his editorial cartoon, “Peace Today,” which conveyed a warning against atomic weapons. He was the first cartoonist to ever be so honored. Later in his career, Goldberg was employed by the New York Journal American, and he remained there until his retirement in 1964. Goldberg died in 1970 at the age of 87. At yovisto you can learn more about Rube Goldberg in a Public domain film from the Library of Congress Prelinger Archive, and watch how Cartoonist Rube Goldberg creates a little animation to explain how fuel is converted to power in the modern automobile engine.'],\n",
       " [116,\n",
       "  'Ottmar Mergenthaler – a Second Gutenberg.  Ottmar Mergenthaler (1854-1899). Photo taken at age 25 in 1879.  On July 3, 1886, the first Linotype machine invented by German inventor Ottmar Mergenthaler commenced operation for the New York Tribune. The Linotype was the first device that could easily and quickly set complete lines of type for use in printing presses and revolutionized the art of printing. Along with letterpress printing, linotype was the industry standard for newspapers, magazines and posters from the late 19th century to the 1960s and 70s, when it was largely replaced by offset lithography printing and computer typesetting. The name of the machine comes from the fact that it produces an entire line of metal type at once, hence a line-o’-type, a significant improvement over the previous industry standard, i.e., manual, letter-by-letter typesetting using a composing stick and drawers of letters. The machine revolutionized typesetting and with it especially newspaper publishing, making it possible for a relatively small number of operators to set type for many pages on a daily basis. Before Mergenthaler’s invention of the linotype in 1884, no daily newspaper in the world had more than eight pages. Mergenthaler was born in 1854 in Hachtel, Württemberg, near Stuttgart, as the third son of a school teacher, Johann Georg Mergenthaler. Mergenthaler rejected his father’s wishes to become a teacher, choosing instead to work with machinery and make mathematical instruments. Thus, he was apprenticed to a watchmaker in Bietigheim for four years, before emigrating to the United States in 1872 to work with his cousin August Hahl in Washington, D.C. Mergenthaler eventually moved with Hahl’s shop to Baltimore, MD, where he became shop foreman. In 1876 he was approached by James O. Clephane, who sought a quicker way of publishing legal briefs, via Charles T. Moore, who held a patent on a typewriter for newspapers which did not work and asked Mergenthaler to construct a better model. Mergenthaler recognized that Moore’s design was faulty and two years later he assembled a machine that stamped letters and words on cardboard. Although a fire destroyed all his designs and models, he started to work on the invention again as he wrote to himself “more books — more education for all. At home we had no money for school books…” He found a supporter in Whitelaw Reid of the New York Tribune. Another fifty patents were required before Mergenthaler could show a more or less usable model to the New York Tribune on July 3, 1886. While riding on a train, the idea came to him: why a separate machine for casting and another for stamping? Why not stamp the letters and immediately cast them in metal in the same machine? By 1884 the idea of assembling metallic letter molds, called matrices, and casting molten metal into them, all within a single machine, was applied. Mergenthaler reportedly got the idea for the brass matrices that would serve as molds for the letters from wooden molds used to make “Springerle,” which are German Christmas cookies. As a boy he had carved a Springerle mold for his stepmother. Ottmar Mergenthaler demonstrates the Linotype, Drawing by J. Coggleshall Wilson, 1886 The first typesetting machine that was used commercially, known as “The Blower,” was demonstrated in the New York Tribune’s composing room in 1886. According to Mergenthaler’s son Herman, “When Tribune publisher Whitelaw Reid … saw Ottmar type on the keyboard and shortly after a thin metal slug bearing several words slid down into a tray, he exclaimed, ‘Ottmar, you’ve done it! A line o’ type!’ Thus the Linotype machine was born.“. In the printing office of the New York Tribune the machine was immediately used on the daily paper and a large book. As a result of his cost-, labor-, and time-saving machine and the attention it got via the Tribune, Mergenthaler’s business increased: he enlarged his Camden Street shop and expanded to an additional building on Preston Street to handle the flood of orders. Initially, The Mergenthaler Linotype Company was the only company producing linecasting machines, but around 1914 a linecasting machine would be produced by the competition — The Intertype Company. By 1904, there were 10,000 Linotypes in use, but by 1954 the number had skyrocketed to 100,000. During the 1970s and 1980s, Linotype and similar “hot metal” typesetting machines were retired and replaced with phototypesetting equipment and later computerized typesetting and page composition systems. In 1894, Mergenthaler contracted tuberculosis. Two years later, unable to stand the cold, he moved to the Southwest, first to Prescott, Arizona, and then to Deming, New Mexico. He returned to Baltimore in late 1897 after a fire destroyed his New Mexico house and the manuscript of his just-completed autobiography. He died of tuberculosis in Baltimore in 1899 at age only 45. Like Gutenberg, Mergenthaler revolutionized the art of printing. “The Eighth Wonder of the World” is what Thomas A. Edison called Mergenthalers seminal invention. At yovisto, you can learn more about the history of printing and the linotype technology in an educational video from the 1960s.'],\n",
       " [117,\n",
       "  'Hans Bethe and the Energy of the Stars.  Hans Bethe interviewed by journalists (1906 – 2005).  On July 2, 1906, German and American nuclear physicist and Nobel Laureate Hans Albrecht Bethe was born. Bethe helped to shape classical physics into quantum physics and increased the understanding of the atomic processes responsible for the properties of matter and of the forces governing the structures of atomic nuclei. Hans Bethe entered the University of Frankfurt in 1924, majoring in chemistry. However, after a few semesters, he was advised to continue his studies in theoretical physics under Arnold Sommerfeld at the University of Munich. Sommerfeld highly supported his talented new student through giving him copied of scientific papers and suggesting topics for Bethe’s PhD thesis. In 1929, the Bethe moved to Stuttgart in order to work at the local Technical University, where he published one of his most important scientific papers titled “The Theory of the Passage of Fast Corpuscular Rays Through Matter”. He created the famous ‘Bethe formula‘ influenced by Max Born’s interpretation of the Schrödinger equation. He created a more simplified formula for collision problems using a Fourier transform and submitted his paper for his habilitation. During his time at the University of Cambridge, where Bethe started in 1930, the scientists proved his great sense of humor through creating a hoax paper “On the Quantum Theory of the Temperature of Absolute Zero” along with the fellow post-doc colleagues, which caused quite a scandal in the scientific community and the responsible scientists were forced to apologize. In this period, Bethe also chose to work with Enrico Fermi and managed to find the exact solutions for the eigenvalues and eigenvectors of certain one-dimensional quantum many-body models. Bethe came to Germany for one year, but was forced to move to England due to the rise of the German National Socialist Party. He was offered a position as an acting assistant professor at Cornell University in 1934, where he published a series of three articles, which summarized most of what was known on the subject of nuclear physics until that time, an account that became informally known as “Bethe’s Bible“, and remained the standard work on the subject for many years. CNO Cycle Image: Wikimedia user Borb At a Conference of Theoretical Physics, Bethe heard a talk on stellar energy generation and Bengt Strömgren detailed what was known about the temperature, density and chemical composition of the Sun, and then challenged the physicists to come up with an explanation. By the end of the conference, Bethe, working in collaboration with Charles Critchfield, had come up with a series of subsequent nuclear reactions that explained how the Sun shines. However, he noticed that the processes in heavier stars was not explained and he began studying the relevant nuclear reactions and reaction cross sections, leading to his discovery of the carbon-oxygen-nitrogen cycle. These papers, co-authored with Critchfield, won a prize at New York Academy of Sciences and were subsequently published in the Physical Review. It was a breakthrough in the understanding of the stars, and would win Bethe the Nobel Prize in Physics in 1967. During World War II, Hans Bethe was head of the Theoretical Division at the secret Los Alamos laboratory which developed the first atomic bombs. There he played a key role in calculating the critical mass of the weapons and developing the theory behind the implosion method used in both the Trinity test and the “Fat Man” weapon dropped on Nagasaki in August 1945. He also played an important role in the development of the hydrogen bomb, though he had originally joined the project with the hope of proving it could not be made. Bethe later campaigned with Albert Einstein and the Emergency Committee of Atomic Scientists against nuclear testing and the nuclear arms race. After the war ended, Bethe returned to Cornell and participated in the Shelter Island Conference, the first major physics conference after the war. It was a chance for American physicists to come to together, pick up where they had left off before the war, and establish the direction of post-war research. There, Bethe was highly inspired to work on the famous Lamp shift, and at yovisto, you may enjoy an interview with Hans Bethe in which he explains his ideas on the topic.'],\n",
       " [118,\n",
       "  'Ignaz Semmelweis and the Importance of Washing Your Hands as a Doctor.  Ignaz Semmelweis (1818 – 1865).  On July 1, 1818, Hungarian physician of German extraction Ignaz Semmelweis was born. He is best known for his discovery of the cause of puerperal (“child bed”) fever and introduced antisepsis into medical practice by insisting on health workers rigorously handwashing between patients, and clean bed sheets. At first, Ignaz Semmelweis studied law at the University of Vienna, but switched to medicine shortly after, specializing in obstetrics. At the First Obstetrical Clinic of the Vienna General Hospital, where Semmelweis was employed, he had to examine patients each morning in preparation for the professor’s rounds, supervise difficult deliveries, and teach students of obstetrics. Back in the day, maternity clinics became quite common. Women could receive free medical care after giving birth, but had to function as subjects for the training of doctors and midwives. In Vienna, there were approximately two of those institutions while Semmelweis was still a young doctor. He began examining, why in one of the clinics the mortality rate due to puerperal fever was significantly higher than in the other. Semmelweis examined all the differences in techniques and even considered religious practices. He noticed that the clinic with the higher mortality rate offered a teaching service for students, the other instructed midwives only. The scientist also noticed that his friend, Jakob Kolletschka, died after getting cut during surgery and that his wound looked very similar to what he saw in his patients. Eventually, Semmelweis found out that the medical students carried “cadaverous particles” on their bodies and especially their hands after performing autopsies in the clinic. He concluded that these particles may cause childbed fever and introduced a policy of using a solution of chlorinated lime for washing hands before and after examining their patients. All students or doctors who enter the wards for the purpose of making an examination must wash their hands thoroughly in a solution of chlorinated lime which will be placed in convenient basins near the entrance of the wards. This disinfection is considered sufficient for this visit. Between examinations the hands must be washed in soap and water. This method became known as the “Semmelweis doctrine” and it was successful. Within a few months, the mortality rate due to puerperal fever shrank from 10% to 1.34%. However, not all of his colleagues enjoyed the new rules and Semmelweis even moved one step further. He proposed that the students performing dissections should not examine the living patients in the hospital beds in order to prevent the diease rather than ‘removing’ it. Unfortunately, the head of his department did not support the idea and refused to continue Semmelweis‘ contract at the hospital. In a huff, Semmelweis departed for Budapest immediately, where he was appointed head of the obstetrical service at the St. Rochus Hospital in Pest and managed achieve a mortality rate of 0.85% on a maternity service where puerperal fever had previously raged. In 1861, Semmelweis published his findings titled as “The Etiology, Concept, and Prophylaxis of Puerperal Fever” even though they were already announced to the profession in 1847 by his friend Ferdinand von Hebra, who was the editor of the Journal of the Royal Imperial Society of Physicians in Vienna. Many scientists began supporting Semmelweis’ doctrine and a lot of doctors, particularly in Germany, appeared quite willing to experiment with the practical hand washing measures that he proposed, but virtually everyone rejected his basic and ground-breaking theoretical innovation, that the disease had only one cause, lack of cleanliness. Soon Semmelweis’ doctrine was forgotten and ignored in the field of obstetrics, which disturbed Semmelweis incredibly while the mortality from puerperal fever on the services of some of these opposing Professors of Midwifery ranged as high as a barbarous 26% (for example in Würzburg). Semmelweis‘ eccentric behavior did definitely not make it any better. To a professor in Würzburg he wrote: Your teaching (that the Würzburg epidemic of childbed fever is caused by unknown atmospheric influences or puerperal miasma is false), and is based on the dead bodies of lying-in women slaughtered through ignorance. . . I have formed the unshakable resolution to put an end to this murderous work as far as lies in my power so to do. . . (If you continue teaching your students this false doctrine), I denounce you before God and the world as a murderer, and the History of Puerperal Fever will not do you an injustice when, for the service of having been the first to oppose my life-saving Lehre, it perpetuates your name as a medical Nero. In 1865, Ignaz Semmelweis died from an infected wound on his finger, received during a gynecological operation. He suffered from an extensive sepsis leading to his early death. By a tragic irony, Semmelweis died from the same disease as his friend, Kolletschka, whose death provided the clue to the prevention of puerperal fever. Posthumously, Semmelweis’ doctrine gained acceptance widely. Louis Pasteur’s work offered a theoretical explanation for Semmelweis‘s observations, the germ theory of disease. The “Semmelweis reflex” is on this day seen as a metaphor for a certain type of human behavior characterized by reflex-like rejection of new knowledge because it contradicts entrenched norms, beliefs or paradigms. At yovisto, you may enjoy a video lecture on the Germ Theory of Disease by Yale Professor Frank Snowden.'],\n",
       " [119,\n",
       "  'Adolf Furtwängler and Photographic Archeology.  Adolf Furtwängler (1853 – 1907).  On June 30, 1853, German archaeologist and historian Adolf Furtwängler was born. He revolutionized archeological science with his use of photography for documentation. His use of photography in research supplanted the use of drawings because a camera gives objective reproduction with more accuracy, which enabled fragments to be scrutinized, even when they were miles apart. Adolf Furtwängler grew up in a very educated family. His father was a classical scholar and schoolmaster. And also Adolf Furtwängler studied at the University of Leipzig and published his dissertation on “Eros in der Vasenmalerei”. In the following years, he worked in Italy and Greece, financially supported by the German Archeological Institute and was able to join Heinrich Schliemann’s excavations at Olympia. He completed his habilitation in 1878 under Reinhard Kekulé in Bonn. In 1879 he published together with his colleague Georg Loeschcke, “Mykenische Thongefäße”, a complete publication of the Mycennean pottery finds on Aegina, which was not only a valuable chronology but the first corpus of pottery finds in archaeology. This groundbreaking study established the difference between Mycenaean and Geometric pottery and contributed to the developing technique of identifying archaeological strata. As his reputation grew, Furtwängler received several job offers and was appointed assistant director at the Royal Museums of Berlin and as a privatdozent at the University of Berlin. In 1885, Furtwängler’s two-volume “Beschreibung der Vasensammlung im Antiquarium” (Writings on Vase Paining in Antiquity) appeared, a book describing over four thousand objects in a manner still emulated today. In the following years, Furtwängler published numerous brilliant works, he issued a study on Greek gems and their inscriptions, renewed the excavations at the temple of Aphaia in Aigina, and began issuing a corpus of Greek vases along with Karl W. Reichhold. Furtwängler also embarked on writing a history of ancient art, but contracted a case of dysentery in Aigina and died at age 54, cutting short a brilliant career. His students formed the most eminent of the next generation of classical art historians and archaeologists including Ludwig Curtius, Oskar Waldhauer, Georg Lippold, and Eduard Schmidt. In his active working years, photography was already widely established, but it was not used very often in scientific documentations. Most archeologists still relied on detailed drawings, however, a truly accurate and objective reproduction was only possible with a camera. Inspired by Johannes Overbeck, Furtwängler also began using photographs. His work “Masterpieces of Greek Sculpture” contained numerous large format images and Furtwängler managed to establish the art of photography in archeology. Photography enabled fragments to be compared closely, even when they were miles apart. Perhaps the most famous example of Furtwängler’s use of photography to reconstruct a statue, and identify it with descriptions by ancient authors, was the Athena which three authors say Pheidias cast in bronze for the islanders of Lemnos to dedicate on the Athenian Acropolis in the mid-5th century. Furtwängler was able to demonstrate that a marble head in Bologna belonged to a marble body in Dresden. The plaster cast in Oxford unites the two. Furtwängler concluded that the whole corresponded to descriptions by Pausanias and others of the ‘fair’ Athena who wore no helmet. The principal problem besetting the study of Greek sculpture was not the fragmentary condition but the lack of originals. Although ancient sources named famous sculptors and mentioned, or even described their work, most of the examples known to the 19th century were copies. At yovisto, you may be interested in a short video lecture on the History of Photography.'],\n",
       " [120,\n",
       "  'Rembert Dodoens and the Love for Botanical Science.  Rembert Dodoens (1516-1585). On June 29, 1516, Flemish physician and botanist Rembert Dodoens (Dodonaeus) was born. His seminal work Stirpium historiae pemptades sex sive libri XXX (1583) is considered one of the foremost botanical works of the late 16th century. He divided plants into 26 groups and introduced many new families. Rembert Dodoens was born under the name Rembert Van Joenckema in Mechelen, Spanish Netherlands, today Flanders, Belgium. Later, he changed it to Dodoens (“son of Dodo”), Dodo being a form of the first name of his father, Denis Van Joenckema. The name was latinized into Dodonaeus, from which the French, who were ignorant of its origins, further transformed it into Dodonée. Dodoens studied at the municipal college of Mechelen and went from there to the University of Louvain in 1530, where he studied medicine, cosmography and geography. According to the custom of the time, Dodoens then traveled extensively. Between 1535 and 1546 he was in Italy, Germany, and France. After these Wanderjahren he returned to Mechelen. In 1548 Dodoens published a first book on cosmography, while in the same year he became one of the three municipal physicians of Mechelen. During this time Dodoens composed a treatise on physiology (published later) and began his botanical works. In the beginning of the sixteenth century, it was still believed that no plants existed other than those described by Dioscorides in his Materia medica of the first century AD. The great progress of natural sciences in the sixteenth century was helped by the discovery of printing and by the use of wood-block illustrations. Dodoens was a follower of the leading botanists of his time: Otto Brunfels and Sprengel, the “German fathers of botany,” as well as Jerome Bock and Leonhard Fuchs. In 1552, Dodoens’ first botanical work De frugum historia was published, a short treatise on cereals, vegetables, and fodders. In 1554, Dodoens also published, as Cruydeboek, a Dutch version of Leonard Fuchs‘ De stirpium historia, a national herbarium devoted to species indigenous to the Flemish provinces with 715 images. The merit of this book was that rather than proceeding by alphabetical order, as Fuchs had done, Dodoens grouped the plants according to their properties and their reciprocal affinities. Dodoens treated in detail especially the medicinal herbs, which made this work, in the eyes of many, a pharmacopoeia. The book was translated first into French in 1557 by Charles de L’Ecluse (Histoire des Plantes), into English (via L’Ecluse) in 1578 by Henry Lyte (A new herbal, or historie of plants), and later into Latin in 1583. In his times, it was the most translated book after the Bible. Dodonea viscosa, named in honor of Rembert Dodoens Dodoens turned down a chair at the University of Leuven in 1557. In 1574 he left Mechelen for Vienna, where he had been appointed physician to the emperor Maximilian II. In Cologne, he published in one volume a dissertation on wine and medical observations (1980) and synoptic tables on physiology (1581). Then, he went to Antwerp, where in 1582 he supervised the printing of his Stirpium historiae pemptades sex sive libri XXX. In this elaborate treatise, Dodoens’ most important scientific work, he divided plants into twentysix groups and introduced many new families, adding a wealth of illustration. He then became professor in medicine at the University of Leiden in 1582, and remained there until his death. Dodoens is commemorated in the plant genus Dodonaea, which was named after him by Carolus Linnaeus. At yovisto, you can learn more about botany in the video lecture on ‘Human Livelihoods Depend on Wild Flowers: Kew’s Millennium Seed Bank explained‘.'],\n",
       " [121,\n",
       "  'Maria Goeppert Mayer and the Nuclear Shell Model.  Maria Goeppert Mayer (1906-1972). On June 28, 1906, German-born Physicist Maria Goeppert Mayer was born. She was awarded the Nobel Prize in Physics for proposing the nuclear shell model of the atomic nucleus. She was the second female Nobel laureate in physics, after Marie Curie. Maria Goeppert was born in Kattowitz, a city in Prussia, the only child of Friedrich Goeppert and his wife Maria. At age 4, she moved with her family to Göttingen when her father was appointed as the professor of pediatrics at the University of Göttingen. Goeppert was educated at the Höhere Technische Schule in Göttingen, a school for middle-class girls who aspired to higher education. In 1921, she entered the Frauenstudium, a private high school run by suffragettes that aimed to prepare girls for university. This school closed its doors during the economic inflation, but the teachers continued to give instructions to the pupils. Maria Goeppert finally took the abitur examination in Hannover, in 1924, being examined by teachers she had never seen in her life. In the Spring of 1924, Goeppert entered the University of Göttingen, where she studied mathematics. A purported shortage of women mathematics teachers for schools for girls led to an upsurge of women studying mathematics at a time of high unemployment, and there was even a famous female professor of mathematics at Göttingen, Emmy Noether. But, most girls were only interested in qualifying for their teaching certificate and not in scientifc research. But, soon Maria Goeppert found herself more attracted to physics than to mathematics. This was the time when quantum mechanics was young and exciting. Thus Goeppert chose to pursue a Ph.D. in theoretical physics. In her 1930 doctoral thesis she worked out the theory of possible two-photon absorption by atoms. There were three Nobel Prize winners on the doctoral committee, Max Born, James Franck and Adolf Windaus. Nobel Laureate Eugene Wigner later described the thesis as “a masterpiece of clarity and concreteness“. At the time, the chances of experimentally verifying her thesis seemed remote, but the development of the laser permitted the first experimental verification in 1961 when two-photon-excited fluorescence was detected in a europium-doped crystal. To honor her fundamental contribution to this area, the unit for the two-photon absorption cross section is named the Goeppert Mayer (GM) unit. Shortly before she had met Joseph Edward Mayer, an American Rockefeller fellow working with James Franck. In 1930 she went with him to the Johns Hopkins University in Baltimore. This was the time of the depression, and no university would think of employing the wife of a professor. But she kept working, just for the fun of doing physics. There was little interest in quantum mechanics at Johns Hopkins, but Goeppert Mayer worked with Karl Herzfeld, collaborating on a number of papers. In 1939, Mayer took up a position at Columbia University, where the chairman of the Physics Department, George Pegram, arranged for Goeppert Mayer to have an office, but again she received no salary. Nevertheless, she had the chance to work together with physicist Enrico Fermi. In December 1941, Goeppert Mayer took up her first paid professional position, teaching science part-time at Sarah Lawrence College, and soon after she joined the Manhattan Project, where she researched the chemical and thermodynamic properties of uranium hexafluoride and investigated the possibility of separating isotopes by photochemical reactions. In February 1945, Goeppert Mayer decided to join Edward Teller’s research group at the Los Alamos Laboratory. In the late 1940s, Goeppert Mayer developed a mathematical model for the structure of nuclear shells, which she published in 1950. Her model explained why certain numbers of nucleons in an atomic nucleus result in particularly stable configurations. These numbers are what Eugene Wigner called magic numbers. Three German scientists, Otto Haxel, J. Hans D. Jensen, and Hans Suess, were also working on solving the same problem, and arrived at the same conclusion independently. In 1963, Goeppert Mayer, Jensen, and Wigner shared the Nobel Prize for Physics “for their discoveries concerning nuclear shell structure.” She was the second female Nobel laureate in physics, after Marie Curie. At yovisto you may enjoy the video ‘The three lives of Marie Curie‘ by Dr. Serge Plattard.'],\n",
       " [122,\n",
       "  'Sophie Germain and the Chladni Experiment.  Sophie Germain (1776 – 1831).  On June 27, 1831, French mathematician, physicist, and philosopher Marie-Sophie Germain passed away. She is best known for her work in number theory and contributions to the applied mathematics of acoustics and elasticity. Her work on Fermat’s Last Theorem provided a foundation for mathematicians exploring the subject for hundreds of years after. Because of prejudice against her gender, she was unable to make a career out of mathematics, but she worked independently throughout her life. There is not much known about Sophie Germain’s early life. Many historians believe that she was the daughter of a pretty wealthy silk merchant while others assume, her father used to be a goldsmith. Clear is however, that she was born in 1776 in Paris. When the French Revolution started in France, Germain was 13 years old and it is widely assumed that she had to stay inside due to safety reasons and that she spent a lot of time in her father’s library to keep herself entertained. Among the books that attracted her interest the most was apparently J. E. Montucla’s “L’Histoire des Mathématiques”. Next to mathematics, the young woman also started to teach herself in Greek and Latin in order to understand the works of Newton and Euler. Furtherly, it is believed that Germain studied “Le Calcul Différentiel” by Jacques Antoine-Joseph Cousin, who highly encouraged her in her studies during a visit. However, it is widely assumed that Gemain had lots of trouble convincing her parents from her new passions, who first did not approve her studies and apparently even took away her materials until realizing that she was really serious about it. When the École Polytechnique opened, Sophie Germain was about 18 years old and of course, as a woman not allowed to attend any courses. However, she managed to study the lecture notes and started sending own works to the faculty member Joseph Louis Lagrange under the name of a former student. When Lagrange requested a meeting with the student, her real identity was revealed and luckily, the scientist became her mentor, impressed by Germain’s brilliance. Soon, she started corresponding with Adrien-Marie Legendre in order to discuss number theory and later on also elasticity. Also the well established mathematician published some of her work in a later edition of the “Théorie des Nombres”. In this period, Sophie Germain also started corresponding with Gauss who admired her courage and intelligence. However, at some point, Gauss and Germain’s correspondence stopped and she became more and more interested in the Ernst Chladni and his experiments. The German scientist is probably best known for his research on vibrating plates and the calculation of the speed of sound for different gases. Germain heard of a contest sponsored by the Paris Academy of Sciences concerning Chladni’s experiments with vibrating metal plates and the goal was “to give the mathematical theory of the vibration of an elastic surface and to compare the theory to experimental evidence“. Lagrange then commented that a solution to the problem would require the invention of a new branch of analysis and thus, Germain became the only person to enter the competition. After having submitted her paper in 1811, Germain did not win the prize even though “the experiments presented ingenious results“. After two more extensions of the competition, Germain consulted the judge Denis Poisson, who shortly after published his own research results on elasticity, not mentioning Germain’s help in any sentence. When Sophie Germain submitted her third work on the topic in 1816, she became the first woman to win a prize from the Paris Academy of Sciences even though the judges were again not completely satisfied as her method was not believed to be accurate enough and relied on incorrect equations from Euler. However, even though she had won the prize, Germain was still not able to attend the Academy’s sessions as a woman until two years later, the befriended Joseph Fourier acquired tickets for her. At yovisto, you may be interested in a video demonstration of the Chladni Experiments by Harvard University.'],\n",
       " [123,\n",
       "  'Lyman Spitzer and the Space Telescope.  Lyman Spitzer (1914-1997). photo: NASA.  On June 26, 1914, American theoretical physicist, astronomer and mountaineer Lyman Strong Spitzer was born. Researching in star formation and plasma physics, he is probably best known for being the first to conceive the idea of telescopes operating in outer space. Thus, he is also the namesake of NASA’s Spitzer Space Telescope. Well mountaineer and astronomer at the same time, I guess we never had a fellow like Lyman Spitzer up to now. As a mountaineer, he made the first ascent of Mount Thor with David Morton in 1965. Never heard of Mount Thor or Thor’s Peak? Well, it is part of the Baffin Mountains in Canada with an elevation of 1,675m. It features the Earth’s greatest vertical drop of 1,250m, with the cliff overhanging at an average angle of 15 degrees from vertical. Despite its remoteness, this feature makes the mountain a popular rock climbing site. But, let’s focus on Spitzer and his scientific work. Lyman Spitzer was born to a Presbyterian family in Toledo, Ohio, the son of Lyman Strong Spitzer and Blanche Carey. Spitzer graduated from Scott High School, then attended Phillips Academy in 1929 and went on to Yale College, where he graduated in 1935 being a member of Skull and Bones. During a year of study at Cambridge University, he was influenced by Arthur Eddington and the young Subrahmanyan Chandrasekhar. Returning to the U.S., Spitzer earned his MA from Princeton University in 1937 and his PhD in 1938, under the direction of Henry Norris Russell. Spitzer was just beginning his career when he published a short paper in 1946 — more than a decade before the launch of the first satellite. He proposed the development of a large, space-based observatory that would not be hindered by Earth’s atmospheric distortion and span a broad range of wavelengths. According to a new theory in Spitzer’s day, stars were powered by nuclear fusion. Calculations showed that our sun could burn for billions of years this way. But more massive stars would burn for only a few hundred million years. So, Spitzer theorized that stars were being created in the modern era, and that the intergalactic medium, a dark and mysterious place, held the reservoir of matter to create new stars. Scientists found evidence of this matter with large, ground-based optical telescopes. Yet the proof, Spitzer knew, would be found in the ultraviolet observations of young, hot stars. The Earth’s atmosphere blocks most ultraviolet radiation, so to observe these hot stars, scientists needed to send a UV detector above at least most of the atmosphere. Spitzer continued to write seminal theoretical papers. Sounding rockets were piercing the atmosphere with X-ray and ultraviolet detectors, and a balloon carried an optical telescope above most of the atmosphere, as Spitzer had hoped. The showpiece of Spitzer’s own space astronomy work at Princeton was NASA’s Copernicus Orbiting Astronomical Observatory, launched in 1972. Spitzer was the principal investigator for this ultraviolet telescope. Copernicus did indeed find evidence of hot, young stars in dense clouds that block optical light but not all the ultraviolet light, and made many other key findings. The success of Copernicus helped secure Hubble’s funding as well as Spitzer’s legacy. By the 1970s, the astronomy community gave the “large space telescope” high priority in a major report, which led NASA to begin a Phase A study of a 3-meter telescope in 1973. More importantly, Spitzer helped convince Congress to fund the project, which ultimately became the 2.4-meter Hubble Space Telescope. Spitzer was instrumental in the design and development of the Hubble Space Telescope. Even after Hubble’s launch in 1990, Spitzer remained deeply involved in the program. Not only did he make some important astronomical observations with the telescope that was essentially his brainchild, but he also spent a great deal of time — right up until the end of his life in 1997 — analyzing Hubble data. At yovisto you can learn more the Hubble Space telescope based on Lyman Spitzer’s idea. Observations made by the Hubble Space Telescope over the last two decades have given us significant new insights into our Universe.'],\n",
       " [124,\n",
       "  'Hermann Oberth’s Dream of Space Travel.  Dr. von Braun and Professor Hermann Oberth are honored by the Berlin Technical University 1963.  On June 25, 1894, Austro-Hungarian-born German physicist and engineer Hermann Oberth was born. He was the first, who when thinking about the possibility of spaceships grabbed a slide-rule and presented mathematically analyzed concepts and designs. Maybe you have already heard of the ‘Oberth Effect‘. In interplanetary spaceflight, the Oberth effect is used in a powered flyby where the application of an impulse, typically from a rocket engine, close to a gravitational body can result in a higher change in kinetic energy and final speed. The effect is named after Hermann Oberth, who one of the founding fathers of rocketry and astronautics. Already in his youth, Hermann Oberth was highly influenced by the works of Jules Verne and increased his interests in rocket science and aeronautics ever since. He attempted a mathematical prove, that Jules Verne’s “method” of shooting astronauts to the moon with a canon would not be possible and he came to realize that a journey to the moon could only be achieved with extremely powerful rockets. However, Oberth enrolled at the University of Munich studying medicine. In 1914, he joined the first World War and returned to the university in 1918. During the war, he designed his first rocket powered with ethanol and oxygen. One year later, he began his studies of physics and finished his dissertation on rockets, which was declined because there were no experts who could even evaluate his work. However, his work was published anyway in 1923 and faced a great success. In his work, Oberth published a description of all elements needed to create fuel for multistage rockets. In 1927, the German amateur rocket association “Verein für Raumschiffahrt” was established. Hermann Oberth became a member and managed to network with numerous engineers interested in rocket technologies. The works of Oberth and his colleagues including Wernher von Braun, Ernst Stuhlinger, Helmut Gröttrup, and Walter Thiel in this period formed the foundations of rocket engineering and are considered the very early milestones in space flight. Oberth received the German citizenship in 1939 and worked under the name Fritz Hann at the Army Research Center in Pennemünde, Germany. There, he was also involved in the V2-Program. When the war was over, Oberth worked on several rocket-engineering projects in Switzerland, the USA and Germany. In this period, Oberth was involved in writing the study, “The Development of Space Technology in the Next Ten Years” and published his ideas on a lunar exploration vehicle, a “lunar catapult”, and on “muffled” helicopters and airplanes. In 1960, Oberth returned to the USA as a technical consultant on the Atlas rocket program. At yovisto, you may be interested in a historical documentation on Hermann Oberth and Wernher von Braun’s achievements in rocketry and astronautics.'],\n",
       " [125,\n",
       "  'Martin Perl and the Tau.  Martin Lewis Perl (*1927) photo: nobelprize.org.  On June 24, 1927, American physicist and Nobel Laureate Martin Lewis Perl was born. He is best known for his discovery of the tau lepton, a subatomic massive particle with a negative charge. The tau, which he found in the mid-1970s, was the first evidence of a third “generation” of fundamental particles. The tau lepton (?, also called the tau particle, tauon or simply tau) is an elementary particle similar to the electron, with negative electric charge and a spin of 1?2, but with 3477 times the mass. Together with the electron, the muon, and the three neutrinos, it is classified as a lepton. Two main classes of leptons exist: charged leptons (also known as the electron-like leptons), and neutral leptons (better known as neutrinos). Charged leptons can combine with other particles to form various composite particles such as atoms and positronium, while neutrinos rarely interact with anything, and are consequently rarely observed. Tau leptons have a very short lifetime of 2.9×10?13 s and a mass of 1776.82 MeV/c2 (compared to 105.7 MeV/c2 for muons and 0.511 MeV/c2 for electrons). Since their interactions are very similar to those of the electron, a tau can be thought of as a much heavier version of the electron. Because of their greater mass, tau particles do not emit as much bremsstrahlung radiation as electrons; consequently they are potentially highly penetrating, much more so than electrons. However, because of their short lifetime, the range of the tau is mainly set by their decay length, which is too small for bremsstrahlung to be noticeable: their penetrating power appears only at ultra high energy. Let’s take a look on the discovery of the Tau and the man who succeeded to find it. Martin Perl was born on June 24, 1927 in New York City, New York to a family of Jewish emigrants to the US from the Polish area of Russia. Perl is a 1948 chemical engineering graduate of Brooklyn Polytechnic Institute. After graduation, he worked for the General Electric Company, as a chemical engineer in a factory producing electron vacuum tubes. To learn about how the electron tubes worked, Perl signed up for courses in atomic physics and advanced calculus at Union College in Schenectady, New York, which led to his growing interest in physics, and eventually to becoming a graduate student in physics in 1950. Martin Perl received his Ph.D. from Columbia University in 1955, where his thesis described measurements of the nuclear quadrupole moment of sodium, using the atomic beam resonance method that his advisor Isaac I. Rabi had won the Nobel Prize in Phyics for in 1944. Perl spent 8 years at the University of Michigan, where he worked on the physics of strong interactions, using bubble chambers and spark chambers to study the scattering of pions and later neutrons on protons. Seeking a simpler interaction mechanism to study, Perl started to consider electron and muon interactions. He had the opportunity to start planning experimental work in this area when he moved in 1963 to the Stanford Linear Accelerator Center (SLAC), then being built in California. He was particularly interested in understanding the muon: why it should interact almost exactly like the electron but be 206.8 times heavier, and why it should decay through the route that it does. Perl chose to look for answers to these questions in experiments on high-energy charged leptons. In addition, he considered the possibility of finding a third generation of lepton through electron-positron collisions. The tau was finally detected in a series of experiments between 1974 and 1977 by Perl with his colleagues at the SLAC-LBL group. They were able to collide electrons and positrons at higher energies than had previously been possible, initially at up to 4.8 GeV and eventually at 8 GeV, energies high enough to lead to the production of a tau/antitau pair. Because of the very short lifetime of the tau, these particles decayed within a few millimetres of the collision. Hence Perl and his coworkers did not detect the tau directly, but rather discovered anomalous events where they detected either an electron and a muon, or a positron and an antimuon. The symbol ? that was chosen for tau was derived from the Greek ?????? (triton, meaning “third” in English), since it was the third charged lepton discovered. Martin Perl won the Nobel Prize in 1995 jointly with Frederick Reines. The prize was awarded “for pioneering experimental contributions to lepton physics”. Perl received half “for the discovery of the tau lepton” while Reines received his share “for the detection of the neutrino” At yovisto, you may learn more about particle physics in the inside tour of the world` biggest supercollider LCH at the CERN research institute, given by physicist Brian Cox.'],\n",
       " [126,\n",
       "  'Deodat de Dolomieu and the Love for Rocks.  Déodat de Dolomieu (1750 – 1801).  On June 23, 1750, French geologist Déodat Gratet de Dolomieu was born. He is best known for his field research in mineralogy. The mineral and the rock dolomite and the largest summital crater on the Piton de la Fournaise volcano were named after him. Déodat de Dolomieu grew up in the Alps of southeastern France and showed early interest in his surrounding nature. However, he started a military career when he was only 12 years old and even fought a duel, killing a fellow member of the Maltese Order in later years. Soon, the young Dolomieu became known as highly attracted to women, especially among the nobility. He was made a corresponding member of the Royal Academy of Sciences and played a significant role in the intellectual progress of France. De Dolomieu spent much of his time collecting minerals and visiting mining areas and categorizing geological data across Europe. He had a great interest in volcanoes, but was soon convinced, that water played a major role in shaping the surface of the Earth through a series of prehistoric, catastrophic events. During one of his voyages to the Alps of Tyrol, De Dolomieu discovered a calcareous rock which, unlike limestone, did not effervesce with weak hydrochloric acid. The geologist published his findings in the French science magazine “Journal de Physique” in 1791 and one year later, the rock was given the name dolomite by the Swiss chemist Nicolas-Théodore de Saussure. Still, De Dolomieu was not the first to describe the mineral, earlier descriptions came from Linnaeus, who was the first to note the fact that this rock resembled limestone but does not effervesce with dilute acid. In the meantime, Dolomieu advanced in rank in the Knights of Malta and was promoted to Commander in 1780. In the same year, he retired from active military service, partly due to the fact that his liberal political leanings which were unpopular among the conservative nobility, ruling the Order. From then on, De Dolomieu devoted all his life to science and traveling. Around 1795, De Dolomieu accepted the position of Professor of Natural Sciences at the École Centrale Paris and started to write the mineralogical section of the Encyclopédie Méthodique. In the following year, he was appointed Inspector of Mines and Professor at the École Nationale Supérieure des Mines de Paris, where his portrait is still displayed in the library. His extensive mineral collection is today housed at the Muséum National d’Histoire Naturelle of Paris. Only three years after his career as professor started, De Dolomieu had developed a great international reputation and he was considered as one of the most important geologists of his time. Napoleon Bonaparte, whom De Dolomieu supported since the beginning of the French Revolution, invited the scientist to join the expedition accompanying Bonaparte’s invasion of Egypt, as part of the natural history and physics section of the Institut d’Égypte. Unfortunately for him, De Dolomieu fell ill and was forced to return home, but when his ship got caught in a heavy storm, he sought refuge in Italy, where he was then considered a prisoner of war. The imprisonment of a world-famous scientist, under such bad conditions, was abhorrent to the intellectual community of Europe. He was released in 1801 and immediately intended to resume his scientific studies, but due to heavy illnesses resulting from the imprisonment, Déodat de Dolomieu died on 28 November of the same year. At yovisto, you may be interested in a video lecture by John merriman, who talks about Napoleon Bonaparte and the French Revolution, that highly influenced Deodat de Dolomieu thoughout his lifetime.'],\n",
       " [127,\n",
       "  'The Discovery of Charon.  Artist’s concept of Charon seen from the surface of Pluto.  On June 22, 1978, US astronomer John Christy discovered Charon, the largest moon of Pluto. Although there was a discussion after the reclassification of Pluto as a dwarf, Charon is not in the list of dwarf planets currently recognized by the IAU. On June 22, John Christy had examined the magnified images of the former planet Pluto, taken with the 61-inch Flagstaff telescope two months prior. He noticed a periodically appearing elongation, which was confirmed shortly after. During subsequent studies, it was determined that the bulge was due to a smaller accompanying body. Also, it was noticed that the periodicity of the bulge corresponded to Pluto’s rotation period. Between 1985 and 1990, Pluto and Charon entered a five-year period of mutual eclipses and transits and all doubts about Charon could be abolished. A few weeks after the United States Naval Observatory astronomer James Christy had discovered Pluto’s largest moon, Charon, his achievement was officially announced by the International Astronomical Union. Charon is half a big as Pluto and it is assumed that its surface consists mostly of water ice. Also, scientists believe that Charon has no atmosphere. However, there are several theories on Charon’s internal structure. It is believed that Charon was created by a giant impact into Pluto’s icy mantle and that it therefore consists of an icy body, containing less rock by proportion than its partner Pluto. One theory suggests, that Charon has a rocky core and an icy mantle, others believe Charon to be of uniform composition throughout. Pluto and Charon are considered gravitationally locked, which means that each object keeps the same face towards the other. Due to the fact that neither object orbits the other, many scientists argued that Charon should be considered as a dwarf planet itself, however, the International Astronomical Union stated that Charon is considered to be just a satellite of Pluto. A side view of the Pluto-Charon system Image: Stephanie Hoover   At yovisto, you may be interested in a video lecture on ‘Pluto, Eris and the Dwarf Planets of the Outer Solar System‘ by Professor Mike Brown.'],\n",
       " [128,\n",
       "  'Franz Kruckenberg’s Schienenzeppelin.  Kruckenberg’s Schienenzeppelin Image: Franz Jansen.  On 21 June 1931, Franz Kruckenberg’s Schienenzeppelin (rail zeppelin) set a new world railway speed record of 230.2 km/h (143.0 mph) on the Berlin–Hamburg line between Karstädt and Dergenthin, which was not surpassed by any other rail vehicle until 1954. The famous Schienenzeppelin was anticipated by the design of the Aerowagon, an experimental high-speed railcar fitted with an aircraft engine and propeller traction. The railcar from germany was built in 1930 near Hannover by Franz Kruckenberg and finished in fall of the same year. It was about 15m long and had two axles. Originally, the railcar had two conjoined BMW petrol aircraft engines powering a four bladed propeller. The body of the Schienenzeppelin was streamlined, having a great resemblance to the era’s popular Zeppelin airships, and it was built of aluminum in aircraft style to reduce weight. The railcar could carry up to 40 passengers and its interior was designed in Bauhaus-style. On May 10, 1931 the railcar reached speeds of 200 km/h for the first time and this achievement was reported across the German media immediately. The great success on June 21 was achieved with Kruckenberg steering the rail zeppelin himself and afterwards, the vehicle was displayed in Berlin. In 1932 Kruckenberg began a new project with the rail car involving significant modifications. It was given a completely new front end while the rear axle remained as it was. The aircraft engine was still used, but the power transmission was hydraulic through two Föttinger Fluid Drives for both directions of travel. Also, a pointed fairing was installed in place of the propeller. Kruckenberg completed this design in November 1932. During test drives in 1933, the new railway reached speeds of 180 km/h. Even though, Kruckenberg’s designs never really went into ‘mass’ production, his designs found their way into later DRG railcar designs. His last version of the rail vehicle was produced in 1934 and it was sold to the Deutsche Reichsbahn (German Imperial Railway) and dismantled in in order to re-use its material for military purposes. Unfortunately, the use of propellers in crowded railway stations was found too dangerous and due to its construction, it would have been difficult to pull additional wagons to form a train. Furthermore, Safety concerns have been associated with running high-speed railcars on old track network, with the inadvisability of reversing the vehicle, and with operating a propeller in close proximity to passengers. The famous Schienenzeppelin in Berlin Image: German Federal Archive At yovisto, you may be interested in a historic video documentation on Kruckenberg’s Schienenzeppelin.'],\n",
       " [129,\n",
       "  'Gerald Hawkins and the Secret of Stonehenge.  Stonehenge, photo: wikipedia.  On June 20, 1928, English astronomer and author Gerald Stanley Hawkins was born. He is best known for his work in the field of archaeoastronomy. In 1965 he published an analysis of Stonehenge in which he was the first to propose its purpose as an ancient astronomical observatory used to predict movements of sun and stars. Gerald Hawkins was born in Great Yarmouth and studied physics and mathematics at the University of Nottingham. In 1952 he took a PhD in radio astronomy, studying under Sir Bernard Lovell at the University of Manchester. In 1957 Hawkins became professor of astronomy and chairman of the department at Boston University in the United States. He wrote widely on numerous subjects, including tektites, meteors and the steady-state universe theory. Hawkins first saw Stonehenge in 1953, when working at nearby Larkhill camp. One of the most famous sites in the world, Stonehenge is the remains of a ring of standing stones set within earthworks. It is in the middle of the most dense complex of Neolithic and Bronze Age monuments in England and was built anywhere from 3000 BC to 2000 BC. Hawkins had read that the monument was aligned on midsummer sunrise, a fact first noted by William Stukeley in the 18th century, and made much of by Sir Norman Lockyer in 1906. Hawkins applied the technological resources of the university to studying the astronomical alignments of ancient megalithic sites. He fed the positions of standing stones and other features at Stonehenge into an early IBM 7090 computer and used the mainframe to model sun and moon movements. This was at a time when computers were rare and glamorous. Asking that age’s technological wonder to decipher the ancient world’s icon was – according to The Guardian “a gesture of timely genius“. The journal Nature published Hawkins’s first results in 1963 and in his 1965 book, Stonehenge Decoded, Hawkins argued that the various features at the monument were arranged in such a way as to predict a variety of astronomical events. The computer, Hawkins argued, showed Stonehenge to be a neolithic “computer-observatory” for predicting eclipses of the sun and moon. All over the world, newspapers praised Hawkins and his computer for rewriting prehistory. Stone-age savages were revealed as skilled scientists. By interpreting Stonehenge as a giant prehistoric observatory, Hawkins‘ work re-assessed what had previously been seen as a primitive temple. The archaeological community was no so happy with Hawkins‘ interpretation. His theories were criticized by such noted historians as Richard Atkinson, who denounced the book as being “…tendentious, arrogant, slipshod, and unconvincing“. Atkinson himself had directed excavations at Stonehenge for the Ministry of Works between 1950 and 1964. Unfortunately because of an extremely heavy administrative burden arising from service on many committees throughout his career the written reports of the excavations at Stonehenge were not complete before his retirement. However, Hawkins‘ book was a commercial success. It was especially popular amongst the members of 1960s counter culture, who found that it followed a similar “wisdom of the ancients” line explored by Alexander Thom, a Scottish engineer most famous for his theory of the Megalithic yard, categorization of stone circles and his studies of Stonehenge and other archaeological sites. Hawkins‘ theories still inform popular opinion of Stonehenge although archaeologists are cautious to accept them. Many scholars accept that the importance of astronomical alignment and large complexes being planned and constructed to fulfill cosmology has been demonstrated at other prehistoric sites, such as the Snake Mound and Cahokia in the United States. Hawkins later examined the Nazca lines in Peru, and concluded there was not enough evidence to support an astronomical explanation for them. He also studied the temple of Amun at Karnak. He continued to study Stonehenge up until his death in 2003. At yovisto you can learn more about Stonehenge in the lecture of Prof. Jeanne Willette from Otis College of Art and Design on “Stonehenge”'],\n",
       " [130,\n",
       "  'Ernst Boris Chain and his Research on Antibiotics.  Sir Ernst Boris Chain (1906-1979).  On June 19, 1906, German-born British biochemist and Nobel Laureate Sir Ernst Boris Chain was born. He is best known for being one of the founders of chemical and medical research on antibiotics, esp. on Penicillinum. “Science, as long as it limits itself to the descriptive study of the laws of nature, has no moral or ethical quality and this applies to the physical as well as the biological sciences.” (Sir Ernst Boris Chain, in ‘Social Responsibility and the Scientist’, New Scientist, 22 October 1970, 166.) Ernst Boris Chain was born in Berlin, the son of Margarete (née Eisner) and Michael Chain, a Russian-born Jewish immigrant who became a chemical engineer and built a successful chemical plant. The death of Michael Chain in 1919, coupled with the collapse of the post-World War I German economy, depleted the family’s income so much that Margarete Chain had to open up her home as a guesthouse. One of Chain’s primary interests during his youth was music, and for a while it seemed that he would embark on a career as a concert pianist. Ernest B. Chain was educated at the Luisengymnasium, Berlin, where he soon became interested in chemistry, stimulated by visits to his father’s laboratory and factory. He next attended the Friedrich-Wilhelm University, Berlin, where he graduated in chemistry in 1930. He was from an early age interested in biochemistry and after graduation he worked for three years at the Charité Hospital, Berlin, on enzyme research. After the Nazis came to power, Chain knew that he, being Jewish, would no longer be safe in Germany. He left Germany and moved to England, arriving on 2 April 1933 with ?10 in his pocket. Geneticist and physiologist J.B.S Haldane helped him obtain a position at University College Hospital, London. He began working on phospholipids (a major component of all major biological membranes) as a PhD student at Fitzwilliam House, Cambridge University under the direction of Sir Frederick Gowland Hopkins. In 1935, he accepted a job at Oxford University as a lecturer in pathology. During this time he worked on a range of research topics, including snake venoms, tumor metabolism, lysozymes, and biochemistry techniques. In 1939, he joined Howard Florey to investigate natural antibacterial agents produced by microorganisms – among them penicillin. This led him and Florey to revisit the work of Alexander Fleming, who had described penicillin nine years earlier. They mistakenly thought these substances were all enzymes like lysozyme. While Florey and Chain were assembling grants to support their research, work was begun on penicillin. Chain and Florey went on to discover penicillin’s therapeutic action and its chemical composition. He also theorized the structure of penicillin, which was confirmed by X-ray crystallography done by Dorothy Hodgkin. For this research, Chain, Florey, and Fleming received the Nobel Prize in 1945. Chain, along with another chemist, Edward Penley Abraham, worked out a successful technique for purifying and concentrating penicillin. The keys seemed to lie in controlling the pH of the “juice,” reducing the sample’s temperature, and evaporating the product over and over (essentially freeze-drying it). In this early process many gallons of mold broth were used to produce an amount just large enough to cover a fingernail. This excruciatingly inefficient process was later improved on by Norman Heatley — another biochemist on the research team assembled by Florey — and a succession of other scientists. Towards the end of World War II, Chain learned his mother and sister had perished in the war. Soon after World War II, Chain moved to Rome, to work at the Istituto Superiore di Sanità (Superior Institute of Health). There, he productively combined a biochemical research department and a fermentation pilot plant. In 1957 a consulting relationship with a group of scientists from the Beecham Group, who came to Rome especially to benefit from Chain’s biochemical insights and the facilities there, resulted in the isolation of the atomic groupings central to the penicillin molecule. He returned to Britain in 1964 as the founder and head of the biochemistry department at Imperial College London, where he stayed until his retirement, specializing in fermentation technologies. In honor of his scientific achievements he was knighted soon after in 1969. Always a person of many interests and projects, in his later life, his Jewish identity became increasingly important to him. He became a member of the board of governors of the Weizmann Institute of Science in 1954, and later a member of the executive council. His views were expressed most clearly in his speech ‘Why I am a Jew’ given at the World Jewish Congress Conference of Intellectuals in 1965. At yovisto you can learn more about infectious diseases and the importance of penicillin from a lecture by Dr. Lucy Shapiro from Berkeley on ‘Emerging Infectious Diseases and Global Health‘.'],\n",
       " [131,\n",
       "  'Jürgen Habermas and Communicative Rationality.  Jürgen Habermas (born 18 June 1929) Author: Wolfram Huke.  On June 18, 1929, German sociologist and philosopher Jürgen Habermas was born. Widely recognized as one of the world’s leading intellectuals, Habermas is perhaps best known for his theories on communicative rationality and the public sphere. Jürgen Habermas grew up during World War II and was highly influenced by the post-war period and especially the Nuremberg Trials, during which he was exposed to the depth of Germany’s moral and political failure under National Socialism. During his time as a graduate student, Habermas noticed that most German philosophers had failed to understand nor to criticize National Socialism. His negative experience regarding the relation between politics and philosophy motivated his further research on the pragmatic and democratic traditions. Also in this period, Habermas met Karl-Otto Apel for the first time, who influenced his philosophical thoughts significantly. He first received great media attention through his critical review on Heidegger’s “Introduction to Metaphysics“. In 1954, Habermas finished his dissertation on the conflict between the absolute and history in Schelling’s thought and started a journalism career at the “Frankfurter Allgemeine Zeitung” and several other newspapers. Shortly after however, Habermas received a scholarship and started working for Max Horkheimer and Theodor W. Adorno and was highly influenced in his thoughts on Marxism by the German American philosopher, sociologist, and political theorist Herbert Marcuse. Still, Habermas gained first serious public attention by the scientific community with the 1962 publication if his habilitation “Structural Transformation of the Public Sphere“. Habermas was appointed professor for sociology and philosophy at the University of Frankfurt in 1964, where he published his work “Knowledge and Human Interests”, in which he first attempts to provide a systematic framework for an interdisciplinary critical social theory. In the early 1970s, Habermas moved to Munich where he became along with Carl Friedrich von Weizsäcker the co-director of the Max-Planck-Institut. He received the Theodor-W.-Adorno-Prize in 1980 and published his masterpiece “The Theory of Communicative Action” one year later. The two volume work contains critical studies of the theories of rationality that informed the classical sociologies of Weber, Durkheim, Parsons, and neo-Marxist critical theory. The two volumes are “Reason and the Rationalization of Society”, which establishes a concept of communicative rationality, and “Lifeworld and System: A Critique of Functionalist Reason”, which creates the two level concept of society and lays out the critical theory for modernity. The work has inspired many responses by social theorists and philosophers, and in 1998 the International Sociological Association listed this work as the eighth most important sociological book of the 20th century. In Volume 2, Habermas introduces a definition of the process of communicative rationality: this is communication that is “oriented to achieving, sustaining and reviewing consensus – and indeed a consensus that rests on the intersubjective recognition of criticisable validity claims“. The result of the theory is a conception of reason that Habermas sees as doing justice to the most important trends in twentieth century philosophy, while escaping the relativism which characterizes postmodernism, and also providing necessary standards for critical evaluation. Habermas’ theory has been criticized for being utopian and idealistic by Foucalut and Caloun. Further scientists, such as Cohen and Fraser, criticized that the theory was blind to issues of gender, race, ethnicity, and sexuality, and that it ignored the role of conflict, contest, and exclusion in the historical constitution of the public sphere. At yovisto, you may be interested in a video lecture by Jürgen Habermas on ‘Myth and Ritual‘'],\n",
       " [132,\n",
       "  'Sir Francis Drake’s discovery of Nova Albion.  New Albion. English galleon “Golden Hinde” by Sir Francis Drake. Oil on canvas by Simon Kozhin.  On June 17, 1579, English explorer Sir Francis Drake raised a claim for a new land that he thought he had discovered during his circumnavigation of the world and named it “Nova Albion“. But he was not the first. Already in 1542, Spanish conquistador Juan Rodríguez Cabrillo had landed there and raised a claim for the Spanish crown. He founded a place he called San Miguel, later renamed to San Diego. But, it should take a while until the land on the Pacific coast should become more interesting for the European colonists under the name “Alta California“, today’s state of California. In his early years, Francis Drake was apprenticed to his family’s neighbor, who was the master of a barque used for coastal trade transporting merchandise to France. He became incredibly satisfied with the young man’s work and bequeathed the barque to Drake at his death. Drake began his very first journeys to the Americas, when he was only 23 years old and he was trapped by the Spaniards in the Mexican port of San Juan de Ulúa, but managed to escape. Further journeys to the West Indies may have followed in the early 1570s, but only little is known about them. In 1577, Francis Drake was appointed to start an expedition against the Spanish along the Pacific coast of the Americas. He departed in Plymouth in November, facing bad weathers soon. Drake and his crew were forced to take refuge in Falmouth, Cornwall, from where they returned to Plymouth for repair. The crew left again in December with over 160 men and additional ships. However, they faced new hardships during their crossing of the Atlantic Ocean and lost several men already. He made landfall at the gloomy bay of San Julian at today’s Argentina. There, they had to burn their ship Mary and decided to remain the winter before attempting the Strait of Magellan. The only three remaining ships then sailed towards the southern tip of South America and the crew made it to the Pacific where one ship was destroyed in storms, which caused another return to England, leaving the Pelican which continued its journey to the south. His lone flagship was renamed to Golden Hind in honor of Sir Christopher Hatton. They sailed north along the Pacific coast of South America, attacking Spanish ports and pillaging towns. Some Spanish ships were captured, and Drake used their more accurate charts. Near Lima, Drake captured a Spanish ship with a great amount of gold on board and he chased down another ship that proved to be his most profitable capture. After these ‘achievements’, Drake turned north in order to find and raid another ship, but instead, he landed on the coast of California on 17 June, 1579. There, he landed, repaired and restocked his vessels, then stayed for a time, keeping friendly relations with the Coast Miwok natives. He claimed the land in the name of the Holy Trinity for the English Crown, called Nova Albion. It is also assumed that he left several men there in order to found a small colony. However, in the 1540, the wester coast of North America had been partially explored by Juan Rodriguez Cabrillo, who sailed for the Spanish, but as England was in conflict with Spain, Drake decided to claim the region. Spain had claimed the entire Pacific coast of the Americas since the Inter caetera papal bull of 1493, reinforced in 1513 when Vasco Núñez de Balboa formally claimed all lands adjoining the Pacific Ocean for the Spanish Crown. However, England did not recognize the authority of the Inter caetera and Balboa’s claim covered a vast and mostly unknown area. However, Francis Drake was knighted after his return in 1581. But, in order to keep an uneasy peace with Spain, and to avoid having Spain threaten England’s other claims in the New World, Drake’s logs, charts, and other writings were confiscated. The discovery and claim of New Albion was then considered a state secret. At yovisto, you may be interested in a video lecture on the Age of Discovery'],\n",
       " [133,\n",
       "  'Barbara McClintock and Cytogenetics.  Barbara McClintock (1902-1992). On June 16, 1902, American cytogeneticist Barbara McClintock was born. She is one of the world’s most distinguished cytogeneticists and received the 1983 Nobel Laureate in Physiology or Medicine. Maybe, firt of all you might ask, what is cytogenetics. Well, cytogenetics is a branch of genetics that is concerned with the study of the structure and function of the cell, especially the chromosomes. Chromosomes, as being a single piece of coiled DNA containing many genes, regulatory elements and other nucleotide sequences, were first observed in plant cells by Karl Wilhelm von Nägeli in 1842. Their behavior in animal (salamander) cells was described by Walther Flemming, the discoverer of mitosis, in 1882. The name was coined by another German anatomist, von Waldeyer in 1888. Barbara McClintock was born Eleanor McClintock in Hartford, Connecticut, the third of four children born to physician Thomas Henry McClintock and Sara Handy McClintock. As a young girl, her parents determined that Eleanor, a “feminine” and “delicate” name, was not appropriate for her, and chose Barbara instead. Barbara was an independent child beginning at a very young age. She was described as a solitary and independent child, and a tomboy. The McClintock family moved to Brooklyn in 1908 and McClintock completed her secondary education there at Erasmus Hall High School, where she graduated early 1919. She wanted to continue her studies at Cornell University’s College of Agriculture, but her mother resisted sending McClintock to college, for fear that she would be unmarriageable. Luckily, her father intervened just before registration began, and she matriculated at Cornell in 1919. Barbara McClintock’s interest in genetics began when she took her first course in that field at Cornell University in 1921. When McClintock began her career, scientists were just becoming aware of the relationship between heredity and events they could actually examine in cells under the microscope. She served as a graduate assistant in the Department of Botany for three years from 1924-27 and in 1927, following completion of her graduate studies, was employed as an Instructor, a post she held until 1931. McClintock’s cytogenetic research focused on developing ways to visualize and characterize maize chromosomes. In 1931, McClintock and Harriet Creighton demonstrated that cytological recombination of marked chromosomes correlated with recombination of genetic traits (genes). Barbara McClintock had a hard time finding work. Even after she was hired at the University of Missouri, she quit after a short time because the biology chairperson told her that as a woman she would never be hired as a full professor. Finally in 1942, Carnegie Institute offered her a research position in their Department of Genetics. The Institute gave McClintock a cornfield, laboratory, and the ability to focus solely on research, where she spent the next 43 years studying genetic mutations by examining changes in plants and pigments in kernels of maize. While studying maize, McClintock noticed changing patterns of coloration in the kernels between generations, leading her to infer that the reason genetic material changes between generations is that genes move around on the chromosomes. Gregor Mendel’s principles of heredity were still fairly new at the time and acceptance of his principles was not widespread yet. McClintock’s discovery was generally ignored by the male scientific world. She continued her career in cytogenetics studying the mechanics and inheritance of broken and ring (circular) chromosomes of maize. During her cytogenetic work, McClintock discovered transposons, that is the ability of genes to change position on the chromosome, a find which eventually led to her Nobel Prize in 1983. McClintock was recognized throughout her career as one of the most distinguished scientists of the 20th century. In 1944, she became the third woman elected to the National Academy of Sciences. She was the first woman to become president of the Genetics Society of America, to which she was elected in 1945. In 1971, President Richard M. Nixon awarded McClintock the National Medal of Science. At the age of 81, she was awarded the Nobel Prize in Physiology or Medicine for her “discovery of mobile genetic elements.” She was the first woman to receive an unshared Nobel Prize in that category. At yovisto, you may be interested in the video lecture Mendel, Hardy, Weinberg by Mike Moser at Berkeley.'],\n",
       " [134,\n",
       "  'Niemand hat die Absicht eine Mauer zu bauen!.  Waving over the Berlin Wall, photo: wikipedia You might wonder, why we have a German headline today. But, this is an original quote, and also a very famous one about the Berlin Wall… On June 15, 1961, first Secretary of the Socialist Unity Party and German Democratic Republic State Council chairman Walter Ulbricht stated in an international press conference, “Niemand hat die Absicht, eine Mauer zu errichten!” (No one has the intention of erecting a wall!) Of course you know that they did erect a wall in the middle of Berlin, which divided the German capital for almost 30 years. After the end of World War II in Europe, what remained of pre-war Germany west of the Oder-Neisse line was divided into four occupation zones, each one controlled by one of the four occupying Allied powers. In the same way the capital of Berlin was subdivided into four sectors despite the city’s location fully within the Soviet zone. Within two years, political divisions increased between the Soviets and the other occupying powers. These included the Soviets‘ refusal to agree to reconstruction plans making post-war Germany self-sufficient and to a detailed accounting of the industrial plants, goods and infrastructure already removed by the Soviets. Britain, France, the United States and the Benelux countries later met to combine the non-Soviet zones of the country into one zone for reconstruction and to approve the extension of the Marshall Plan. In 1948, following disagreements regarding reconstruction and a new German currency, Soviet leader Joseph Stalin instituted the Berlin Blockade, preventing food, materials and supplies from arriving in West Berlin. The former Western allies began a massive “airlift“, supplying West Berlin with food and other supplies until in May 1949, Stalin lifted the blockade, permitting the resumption of Western shipments to Berlin. On 7 October 1949, the German Democratic Republic (East Germany) was declared. East Germany differed from the Western counterpart, the Federal Republic of Germany, which developed into a Western capitalist country with a social market economy and a democratic parliamentary government. Continual economic growth starting in the 1950s fuelled a 20-year “economic miracle” (“Wirtschaftswunder“) and as West Germany’s economy grew, and its standard of living steadily improved, many East Germans wanted to move to West Germany. In the first 6 months of 1953 alone, more than 226,000 had already fled. Consequently, the inner German border between the two German states was closed, and a barbed-wire fence erected. The border between the Western and Eastern sectors of Berlin, however, remained open, although traffic between the Soviet and the Western sectors was somewhat restricted. This resulted in Berlin becoming a magnet for East Germans desperate to escape, and also a flashpoint for tension between the United States and the Soviet Union. In 1957, East Germany introduced a new passport law that reduced the overall number of refugees leaving Eastern Germany with the result of drastically increasing the percentage of those leaving through West Berlin from 60% to well over 90% by the end of 1958. Despite heavy penalties, but with no physical barrier and subway train access still available to West Berlin, such measures were ineffective. The emigrants tended to be young and well-educated, leading to the “brain drain” feared by officials in East Germany. An important reason that the West Berlin border was not closed earlier was that doing so would cut off much of the railway traffic in East Germany. With the construction of a new railway bypassing West Berlin, the Berlin outer ring, completed in 1961, closing the border became a more practical position. In particular the brain drain of professionals had become so damaging to the political credibility and economic viability of East Germany that the re-securing of the German communist frontier was imperative. Thus, on 15 June 1961, First Secretary of the Socialist Unity Party and GDR State Council chairman Walter Ulbricht stated in an international press conference, “Niemand hat die Absicht, eine Mauer zu errichten!“. It was the first time the colloquial term Mauer (wall) had been used in this context. The record of a telephone call between Nikita Khrushchev and Ulbricht on 1 August in the same year, suggests that it was from Khrushchev that the initiative for the construction of the wall came. What is beyond dispute, though, is that Ulbricht had pushed for a border closure for quite some time, arguing that East Germany’s very existence was at stake. Khrushchev had been emboldened by US President John F. Kennedy’s tacit indication that the US would not actively oppose this action in the Soviet sector of Berlin. On Saturday, 12 August 1961, while attending a garden party, Ulbricht signed the order to close the border and erect a wall. At midnight, the police and units of the East German army began to close the border and, by Sunday morning, 13 August, the border with West Berlin was closed. East German troops and workers had begun to tear up streets running alongside the border to make them impassable to most vehicles and to install barbed wire entanglements and fences along the 156km around the three western sectors, as well as the 43km that divided West and East Berlin. At yovisto, you can learn more about the border between the two former German states in the (German) short documentary from Deutsche Welle entitled “Eingemauert!” (walled in!) about the inner German Border.'],\n",
       " [135,\n",
       "  'Charles Augustin de Coulomb and the Electrostatic Force.  Charles Augustin de Coulomb (1736 – 1806) Portrait by Hippolyte Lecomte.  On June 14, 1736, French physicist Charles Augustin de Coulomb was born. He is best known for developing Coulomb’s law, the definition of the electrostatic force of attraction and repulsion, but also did important work on friction. The SI unit of electric charge, the coulomb, was named after him. Charles Augustin de Coulomb received a good education in mathematics, astronomy, chemistry and botany since both sides of his family were respected and quite wealthy which allowed Coulomb to be raised as a child of privilege. He went to school in the Collège Mazarin in Paris, but, after his father had made some poor decisions, the family faced financial difficulties and Coulomb moved along with his father to Montpelier, where he joined the Academy of Sciences and managed to present several papers, focusing mostly on topics in astronomy and mathematics. However, in 1760, Coulomb started his formal studies in Paris, completing them less than two years later and embarking on a long career within the Military Engineering Corps. His duties forced him to make several moves over the subsequent decades and during a longer stay in the West Indies, his health issued started to increase. He never fully recovered, even following his return to France in the early 1770s. Coloumb began to focus more and more in engineering and mechanics, which provided him with a firm foundation on which his later theoretical efforts were built. He submitted his first treatise to the Academy of Sciences in Paris in 1773, and many more would follow on topics ranging from mathematical solutions of engineering problems to studies of friction, elasticity, electricity and magnetism. About four years later, the scientist discussed the magnetic compass including a description of his torsion balance, which increased his reputation significantly. After a visit to Rochefort in the late 1770s, Coloumb was promoted to a Captain and employed at La Rochelle, the Isle of Aix and Cherbourg. In this period, Coulomb discussed his experiments with electrostatic forces and explained the inverse square law that they led Coulomb to posit. Similar to Isaac Newton’s inverse square law of gravitational force, Coulomb’s law states that the electric force between charged objects inversely depends upon the distance between the objects. That is, like gravity, the electric force acts in a line between two objects and decreases with the square of the distance between them. The primary difference between the law for gravity and that for electric force is that gravitation is influenced by the mass of the objects, whereas Coulomb’s law depends upon the charge of the objects involved. When the objects in question are both positively or both negatively charged, the forces between them are repulsive, but attractive forces arise between objects carrying opposing charges [1]. When the French Revolution started, Coulomb retired to a small estate which he possessed at Blois. He was recalled to Paris for a time in order to take part in the new determination of weights and measures and later became one of the first members of the French National Institute. Charles-Augustin de Coulomb passed away on August 23, 1806. At yovisto, you may be interested in an introduction to Coulomb’s Law and Electric Fields.'],\n",
       " [136,\n",
       "  'William Butler Yeats and Modern English Literature.  William Butler Yeats (1865-1939). photo: Alice Boughton, 1903.  On June 13, 1865, Irish poet William Butler Yeats was born. Yeats was a driving force behind the Irish Literary Revival and has become one of the foremost figures of 20th century literature. In 1923 he was awarded the Nobel Prize in Literature. William Butler Yeats was born in Sandymount, County Dublin, Ireland to John Butler Yeats, a lawyer and a well-known portrait painter. Yeats was educated in London and in Dublin, but he spent his summers in the west of Ireland in the family’s summer house at Connaught. The young Yeats was very much part of the fin de siècle in London; at the same time he was active in societies that attempted an Irish literary revival. He spent his childhood in County Sligo and in London. He returned to Dublin at the age of fifteen to continue his education and study painting, but quickly discovered he preferred poetry. Born into the Anglo-Irish landowning class, Yeats became involved with the Celtic Revival, a movement against the cultural influences of English rule in Ireland during the Victorian period, which sought to promote the spirit of Ireland’s native heritage. At a young age he was reading Dante Alighieri, William Shakespeare, John Donne and the works of William Blake and Percy Bysshe Shelley, recommended by his father and inspiration for his own creativity. A devoted patriot, Yeats found his voice to speak out against the harsh Nationalist policies of the time. 1885 was an important year in Yeats’s early adult life, marking the first publication, “The Isle of Statues“, a fantasy work that took Edmund Spenser for its poetic model in the Dublin University Review,and the beginning of his important interest in occultism. He read extensively on the subjects throughout his life, became a member of the paranormal research organisation “The Ghost Club” and was especially influenced by the writings of Emanuel Swedenborg. Also in 1885, Yeats met John O’Leary, a famous Irish patriot who had returned to Ireland after twenty years of imprisonment and exile for revolutionary nationalistic activities. O’Leary had a keen enthusiasm for Irish books, music, and ballads, and he encouraged young writers to adopt Irish subjects. Yeats, who had preferred more romantic settings and themes, soon took O’Leary’s advice, producing many poems based on Irish legends, Irish folklore, and Irish ballads and songs. In 1889, Yeats published The Wanderings of Orisin, based on the lyrics of the Fenian Cycle of Irish mythology and displays the influence of both Sir Samuel Ferguson and the Pre-Raphaelite poets. The Wanderings of Orisin was his first and probably the most extensive work, as he never attempted another. The poem was largely based upon the struggle of life, a theme that would frequently appear in his future works. During this period, he also wrote Poems (1895), The Secret Rose (1897) and The Wind Among the Reeds (1899). In 1885, Yeats became a co founder of the Dublin Hermetic Order and as a result, was made its chairman. At that time, he was also involved in the Theosophical Society and with Hermeticism. In 1894 Yeats became involved with the Irish Literary Theatre, later becoming its chief playwright, with many of his plays being performed there and at the Abbey Theatre, also known as the National Theatre of Ireland which opened in 1904. Yeats continued to publish throughout his life, and through the Cuala Press which he founded with his sisters in 1904, was also responsible for the publication of many other authors such as Ezra Pound. In 1889, Yeats met Maud Gonne, a poet, feminist and a fervent nationalist. Yeats became increasingly passionate about her who became his muse and source of unrequited love. He proposed marriage to her at least three times; in 1899, 1900 and 1901 and was rejected each time which was probably a result of his lack of enthusiasm to contribute in the revolutionary movement. In 1917, Yeats married a friend George Hyde Lees whom he had met in 1911 at the age of 51. She shared Yeats’ interest in mystical and esoteric subjects and helped him with the automatic writing. Despite a huge age difference the marriage proved happy and the couple had two children. Yeats was elected an Irish senator in 1922, a post he filled until his retirement in 1928. He received the Nobel Prize in Literature in 1923. His acceptance of the role and its responsibilities had been foreshadowed (predicted) in his poems Responsibilities (1914). The outbreak of civil war in Ireland in 1922 had heightened his conviction that the artist must lead the way through art, rather than through politics. In December 1923, Yeats was awarded the Nobel Prize in Literature, and was determined to make the most of the occasion. Yeats used the occasion of his acceptance lecture at the Royal Academy of Sweden to present himself as a standard-bearer of Irish nationalism and Irish cultural independence. Yeats died in Roquebrune, France, on January 28, 1939, where he had retired there because of ill health. He had the lines of one of his poems engraved on his tombstone in Ireland: “Cast a cold eye / On life, on death. / Horseman, pass by!” At yovisto you can learn more about William Butler Yeats in the lecture of Yale Prof Langdon Hammer on Modern Poetry.'],\n",
       " [137,\n",
       "  'The Diary of Anne Frank.  Anne Frank (1929-1941). On June 12, 1929, Annelies “Anne” Marie Frank was born. She is one of the most discussed Jewish victims of the Holocaust. Her wartime diary The Diary of a Young Girl gained international fame posthumously when published in 1947. The diary documents her experiences hiding during the German occupation of the Netherlands in World War II. After getting married, Anne’s parents Otto and Edith Frank settled in Frankfurt, Germany, where they soon had two children: Margot in 1926, and Anne in 1929. Due to the the economic crisis which also empowered Hitler’s NSDAP, Anne’s parents, who were Jewish, were looking for a means of escape. Life had simply become to dangerous in Germany and in early March 1933 they were able to reach a decision: through his brother-in-law Erich Elias Otto is given an opportunity to set up a company in the Netherlands. The Franks were among 300,000 Jews who fled Germany between 1933 and 1939. By February 1934, Edith and the children had arrived in Amsterdam, and the two girls were enrolled in school. The Frank sisters had highly distinct personalities, Margot being well-mannered, reserved, and studious, while Anne was outspoken, energetic, and extroverted. In May 1940, Germany invaded the Netherlands, and the occupation government began to persecute Jews by the implementation of restrictive and discriminatory laws; mandatory registration and segregation soon followed. Restrictions keep mounting, both for individuals and for Otto’s business. When Margot receives a call-up for a German work camp on 5 July 1942, Otto and Edith decide the dangers have become too great. They take their family into hiding in the hiding place they prepared months before. For her thirteenth birthday on 12 June 1942, Anne Frank received a book she had shown her father in a shop window a few days earlier. Although it was an autograph book, bound with red-and-white checkered cloth and with a small lock on the front, Frank decided she would use it as a diary, and began writing in it almost immediately. While many of her early entries relate the mundane aspects of her life, she also discusses some of the changes that had taken place in the Netherlands since the German occupation. The family was hiding in an attic apartment behind Otto Frank’s business, located at Prinsengracht 263 in Amsterdam, together with Otto’s business associate Hermann van Pels, along with his wife Auguste and their son Peter. In an effort to avoid detection, the family left a false trail suggesting they’d fled to Switzerland. A small group of Otto Frank’s employees risked their own lives to smuggle food, supplies and news of the outside world into the secret apartment, whose entrance was situated behind a movable bookcase. The group of later overall 8 people lived in constant fear of being discovered and could never go outside. They had to remain quiet during daytime in order to avoid detection by the people working in the warehouse below. Anne passed the time, in part, by chronicling her observations and feelings in a diary. Anne started each diary entry ‘Dear Kitty’ and what followed was an incredibly candid and eloquent account of her life in confinement, expressong her fear, boredom and confusion at the situation she found herself in. On August 4, 1944, the Gestapo (German Secret State Police) discovered the hiding place after being tipped off by an anonymous Dutch caller. This is when Anne’s diary suddenly ends. Anne and Margot were first sent to Auschwitz and then to Bergen-Belsen, where both sisters died of typhus in March 1945, just a few weeks before British troops liberated Bergen-Belsen on April 15, 1945. Anne was fifteen years old. Anne’s mother, Edith died in Auschwitz in early January 1945. Only Anne’s father, Otto, survived the war. Found in the secret apartment after the family was arrested, the diary was kept for Anne by Miep Gies, one of the people who had helped hiding the Franks. He gave Otto Frank the diary and a bundle of loose notes that she had saved in the hope of returning them to Anne. Anne’s diary was published after the war in many languages and is used in the curriculum of schools all over the world. Anne Frank has become a symbol for the lost promise of the children who died in the Holocaust. At yovisto, we also have a copy of a collection of footage material gathered by the US Department of Defense as part of the effort to conduct war crimes trials in the direct aftermath of World War II. Please be advised that this video might contain content that is not suitable for all ages.'],\n",
       " [138,\n",
       "  'The Hayden Geological Survey and the Yellowstone National Park.  The Annie, first boat ever launched on Yellowstone Lake Photo: William Henry Jackson.  On June 11, 1871, the Hayden Geological Survey of 1871 led by geologist Ferdinand Vandeveer Hayden began, which explored the region of northwestern Wyoming that later became Yellowstone National Park in 1872. Ferdinand Vandeveer Hayden graduated from the Albany Medical College in 1853. There he got to know the state geologist of New York, who highly influenced him to join in an exploration of Nebraska Territory, with Fielding Meek in order to study geology and collect fossils. In the next years, the young Hayden accompanied expeditions in the northern Missouri River areas with a partial sponsorship from the Smithsonian Institution. In the early 1850s, routes for railroads from the Mississippi to the Pacific coast had to be found and the the Pacific Railroad Survey bill was passed. As a result, federally funded Great Surveys undertaken by the Department of the Interior brought together explorers, engineers, scientists and topographers in a common effort to chart the western U.S. Ferdinand Hayden along with John Wesley Powell, Clarence King and George Wheeler were the leaders of these great surveys. By 1871, Hayden had selected the members of his survey team including scientists, a photographer, an artist, as well as friends and colleagues from other surveys. Lower Yellowstone Falls Photo: William Henry Jackson On June 8, 1871, the survey officially started in Ogden, Utah. The general route and the camping locations were determined by James Stevenson, the survey manager and director and Stephan Hovey, the wagonmaster. They traveled towards the Idaho Falls, as they are called today, and reached Virginia City, Montana at the beginning of July. Thomas Moran now joined the survey while others, including the botanist and the agricultural statistician and entomologist left the expedition due to health issues. At Fort Ellis, the party was able to resupply and they departed south along the Yellowstone River in the middle of July. Hayden began to realize that the route became too complex for the wagons by the time they had reached Paradise Valley. The expedition had to abandon the wagons at their base camp in the valley near Emigrant Gulch and proceeded towards Yankee Jim Canyon. The park region was entered on July 21 and the survey camped there for two days. During the longer camping periods, the scientists, photographers and topographers would venture out in small teams from the main party to collect specimens, make observations and document the flora, fauna, geology and geography of the land. In this regard, Dr. Hayden was just another scientist. In camp, the scientists would process and document their findings while preparing them for shipment to the Smithsonian Institution at the next available opportunity. Botanical specimens were pressed, dried and labeled. Mineral samples were trimmed, labeled and packaged for shipment. Photographs were cataloged and described. Correspondence was prepared to scientists in the East explaining the findings and progress of the survey. Additionally, the hunters would attempt to acquire enough game to sustain the party. Hayden and his men had to travel around Mount Washburn for three days in order to reach the source of the Yellowstone River on July 28. They camped as Cascade Creek and the photographer, Jackson, managed to take the first known photographs of the Yellowstone Falls. Also, the expedition members managed to build a small boat and it became the first known boat, which they named Annie, to sail on the waters of Yellowstone Lake. With the help of the boat, the scientists then explored the islands and take soundings of the lake. After moving on, the party spent quite some time in the Lower, Midway and Upper Geyser basins. In mid-August, they traveled around the southern and eastern sides of Yellowstone Lake and while camped at Steamboat Point, the party experienced two sizable earthquakes. Of course, the numerous sketches and paintings by Thomas Moran and the photographs by William Jackson count as an extremely important outcome of the expedition. However, the most important product of the expedition was Hayden’s lengthy report detailing the findings of his party. Hayden presented this report, the photos, sketches, and paintings to Senators, Congressmen, his superiors in the Department of the Interior, and nearly everyone else who could possibly influence the founding of a park. In December of the same year, a bill was introduced for the establishment of a park at the headwaters of the Yellowstone River and on March 1, 1872, President Ulysses S. Grant signed the bill into law, establishing the Yellowstone region as a public park. At yovisto, you may enjoy a video documentary titled “The Four Seasons of Yellowstone” from the 1970s.'],\n",
       " [139,\n",
       "  'Life and Legend of Frederick Barbarossa.  Frederick sends out the boy to see whether the ravens still fly Frederick I ‘Barbarossa‘ in a typical folk tale On June 10, 1190, Frederick I, emperor of the Holy Roman Empire and better known as Frederick Barbarossa passed away. He died by drowning in the river Saleph during the Third Crusade. He got the name Barbarossa from the northern Italian cities he attempted to rule: Barbarossa means “red beard” in Italian; in German, he was known as ‘Kaiser Rotbart‘, which has the same meaning. There was a time, when every German school kid knew the history of ‘Kaiser Rotbart‘, who had become a mythological figure, resting in his quiet rock tomb in the Kyffhäuser mountain. According to folk lore, the ravens will watch over his tomb and keep on circling over the Kyffhäuser, until he will awake from his thousand years sleep again to start his comeback. A legend, which was fostered by the literates of the romantic movement in 19th century Germany. But, there is also a historical figure behind the legend. Frederick was born in 1122. Frederick’s father was from the Hohenstaufen family, and his mother was from the Welf family, the two most powerful families in Germany. At age 25 he became Duke of Swabia in 1147, and shortly afterwards made his first trip to the East, accompanied by his uncle, the German king Conrad III, on the Second Crusade. The expedition proved to be a disaster, but Frederick distinguished himself and won the complete confidence of the king. When Conrad died in February 1152, only Frederick and the prince-bishop of Bamberg were at his deathbed. Both asserted afterwards that Conrad had, in full possession of his mental powers, handed the royal insignia to Frederick and indicated that Frederick, rather than Conrad’s own six-year-old son succeed him as king. On 4 March 1152 the kingdom’s princely electors in Frankfurt designated Frederick as the next German king, to be crowned King of the Romans at Aachen only several days later. The status of the German empire by that time was in disarray, its power waning under the weight of the Investiture controversy with Henry IV. The German monarchy was largely a nominal title with no real power. When Frederick I of Hohenstaufen was chosen as king in 1152, royal power had been in effective abeyance for over twenty-five years. The only real claim to wealth lay in the rich cities of northern Italy, which were still within the nominal control of the German king. In 1158 Milan, the chief city of Lombardy, revolted and over the Alps came an army of a hundred thousand German soldiers, with Frederick Barbarossa at their head. After a long siege the city surrendered, but soon it revolted again. The emperor besieged it once more and once more it surrendered. Its fortifications were destroyed and many of its buildings ruined. But even then the spirit of the Lombards was not broken. Milan and the other cities of Lombardy united in a league and defied the emperor. He called upon the German dukes to bring their men to his aid. All responded except Henry the Lion, duke of Saxony, Frederick’s cousin. Frederick is said to have knelt and implored Henry to do his duty, but in vain. Frederick’s campaign against the Lombards failed and his army was completely defeated. On 9 June 1156 at Würzburg, Frederick married Beatrice of Burgundy, thus adding to his possessions the sizeable realm of the County of Burgundy. He also declared himself the sole Augustus of the Roman world. In June 1158, Barbarossa prepared a large expedition to Italy. In the years since he was crowned, a growing rift had opened between the emperor and the pope. While Barbarossa believed that the pope should be subject to the emperor, Pope Adrian claimed the opposite. Marching into Italy, Barbarossa sought to reassert his imperial sovereignty. Sweeping through the northern part of the country, he conquered city after city and occupied Milan on September 7, 1158. As tensions grew, Adrian considered excommunicating the emperor, however he died before taking any action. In September 1159, Pope Alexander III was elected and immediately moved to claim papal supremacy over the empire. In response to Alexander’s actions and his excommunication, Barbarossa began supporting a series of antipopes. In 1166, Barbarossa attacked towards Rome at won a decisive victory at the Battle of Monte Porzio. His success proved short-lived as disease ravaged his army and he was forced to retreat back to Germany. Remaining in his realm for six years, he worked to improve diplomatic relations with England, France, and the Byzantine Empire. Though Barbarossa had reconciled with the pope, he continued to take actions to strengthen his position in Italy. In 1183, he signed a treaty with the Lombard League, separating them from the pope. After the Christians had held Jerusalem for eighty-eight years, it was recaptured by the Moslems under the lead of the famous Saladin , in the year 1187. There was much excitement in Christendom, and the Pope proclaimed another Crusade. Frederick immediately raised an army of Crusaders in the German Empire and with one hundred and fifty thousand men started for Palestine. He marched into Asia Minor, attacked the Moslem forces, and defeated them in two great battles. On 10 June 1190, Emperor Frederick’s career was put to an end when he drowned in the Saleph river. He had decided to walk his horse through the river instead of crossing the bridge that had been too crowded with troops. The current was too strong for the horse to handle, and his suit armour was too heavy for him to swim in: both were swept away and drowned. Some historians believe he may have had a heart attack that complicated matters. Some of Frederick’s men put him in a barrel of vinegar to preserve his body. In the Empire the dead emperor was long mourned and for many years the peasants believed that Frederick was not really dead, but was asleep in a cave in the Kyffhäuser mountain in Germany, with his gallant knights around him. He was supposed to be sitting in his chair of state, with the crown upon his head, his eyes half-closed in slumber, his beard as white as snow and so long that it reached the ground. “When the ravens cease to fly round the mountain,” said the legend, “Barbarossa shall awake and restore Germany to its ancient greatness.” Even today you will find references to the legendary emperor in literature. Umberto Eco made Frederick Barbarossa to one of his protagonists in his historical novel Baudolino. There, you can learn about Barbarossas constant quarrel with the Northern Italian city states, his departure for the Third Crusade and his death by drowning in the river Saleph. At yovisto you can learn more about the times of the Crusades in John Green’s crash course on World history, in lis lecture ‘The Crusades – Pilgrimage or Holy Wars‘.'],\n",
       " [140,\n",
       "  'Johann Gottfried Galle and Planet Neptune.  Neptune compared to Earth.  On June 9, 1812, German astronomer Johann Gottfried Galle was born. Galle actually was the first person to view the planet Neptune and know what he was looking at, by making use of the calculations of his fellow astronomer Urbain Le Verrier. Johann Gottfried Galle studied at the Friedrich-Wilhelms-Universität Berlin between 1839 and 1833 and started to work at the new Berlin Observatory two years later. There, he worked for 16 years and made several discoveries at the observatory. Galle made use especially of a Fraunhofer-refractor with 22,5 cm aperture. In 1838 he discovered an inner, dark ring of Saturn. From 2 December 1839 to 6 March 1840 he discovered three new comets. He completed his doctoral thesis on Ole Rømer’s observation of meridian transits of stars and planets on the days from 20 October to 23 October 1706 through critically discussing his findings. His dissertation was also sent to Urbain Le Verrier, who took one year to answer. In his returning letter, Le Verrier explained that he had been investigating the perturbations of the orbit of the planet Uranus and from this he derived the position of a still undiscovered planet. He was not alone with his observation, since also French astronomer Alexis Bouvard noticed changes in the orbit of Uranus which led him to deduce that its orbit was subject to gravitational perturbation by an unknown planet. Le Verrier asked Galle to search in the corresponding section of the sky and in collaboration with his assistant Heinrich Louis d’Arrest.  On September 23, 1846, Galle discovered a star of 8th magnitude, only 1° away from the calculated position, which was not recorded in the Berliner Akademischen Sternkarte. Over the following two evenings, the object could be determined as a planet through the measurement of its motion. Galle always refused to be acknowledged as the discoverer of Neptune and attributed the discovery to Le Verrier. After Neptune’s discovery, the planet was referred to as “the planet exterior to Uranus” or as “Le Verrier’s planet“. In England, Cambridge Observatory director James Challis put forward the name Oceanus. Galle then suggested the name ‘Janus‘, but later on, Le Verrier claimed his right to name his discovered planet Neptune. After further quarrels, the name became widely accepted in the international scientific community. In Roman mythology, Neptune was the god of the sea, identified with the Greek Poseidon. The demand for a mythological name seemed to be in keeping with the nomenclature of the other planets, all of which, except for Earth, were named for deities in Greek and Roman mythology. From its discovery in 1846 until the subsequent discovery of Pluto in 1930, Neptune was the farthest known planet. Upon Pluto’s discovery Neptune became the penultimate planet. However, in 2006, the International Astronomical Union defined the word “planet” for the first time, reclassifying Pluto as a “dwarf planet” and making Neptune once again the last planet in the Solar System. At yovisto, you may be interested in a short but highly interesting explanation of the Discovery of Neptune.'],\n",
       " [141,\n",
       "  'The Viking Raid on the Abbey of Lindisfarne.  Lindisfarne, painting by Thomas Girtin, 1798.  On 8 June, 793 AD, Vikings destroyed the abbey on Lindisfarne, a centre of learning that was famous across the continent. This event also is considered as the beginning of the Viking Age, when Scandinavian Norsemen explored Europe by its seas and rivers for trade, raids and conquest. Recently, this first Viking assault has gained more public interest because of the popular tv series “Vikings” (“Wrath of the Northmen”), in which the semi-legendary Ragnar Lodbrok organises and leads the 793 attack on the priory by a small band of Vikings who head west, arrive on the shores of Lindisfarne, and shortly thereafter conduct the raid. But, today we want to take a look on the historical facts. The Island of Lindisfarne (also called Holy Island of Lindisfarne or simply Holy Island) is a tidal island off the northeast coast of England. It constitutes the civil parish of Holy Island in Northumberland and has a recorded history from the 6th century. It was an important centre of Celtic Christianity under Saints Aidan, Cuthbert, Eadfrith and Eadberht. The northeast coast of England had been little settled in Roman times and apart from the Tyne valley and the wall, little affected during the centuries of nominal Roman occupation. King Ida (reigned from 547) started the sea-borne settlement of the coast establishing a urbs regia at Bamburgh across the bay from Lindisfarne. The conquest was not straight forward however, the Historia Brittonum recounts how in the 6th century, Urien, prince of Rheged, besieged the Angles led by Theodoric at the island for three days and three nights. The monastery of Lindisfarne was founded by Irish monk Saint Aidan, who had been sent from Iona off the west coast of Scotland to Northumbria at the request of King Oswald. The priory was founded before the end of 634 and remained the only seat of a bishopric in Northumbria for nearly thirty years. Lindisfarne became the base for Christian evangelising in the North of England. Monks from the Irish community of Iona settled on the island. Northumberland’s patron saint, Saint Cuthbert, who later also became bishop of Lindisfarne, was a monk and later abbot of the monastery, and his miracles and life are recorded by the Venerable Bede. An anonymous life of Cuthbert written at Lindisfarne is the oldest extant piece of English historical writing. At some point in the early 700s the famous illuminated manuscript known as the Lindisfarne Gospels, an illustrated Latin copy of the Gospels of Matthew, Mark, Luke and John, was made probably at Lindisfarne. In 793, the Viking raid on Lindisfarne caused much consternation throughout the Christian west. A description of the raid is recorded in “History of the Church of Durham” by the monk Simeon: On the seventh of the ides of June, they reached the church of Lindisfarne, and there they miserably ravaged and pillaged everything; they trod the holy things under their polluted feet, they dug down the altars, and plundered all the treasures of the church. Some of the brethren they slew, some they carried off with them in chains, the greater number they stripped naked, insulted, and cast out of doors, and some they drowned in the sea. The devastation of Northumbria’s Holy Island shocked and alerted the royal Courts of Europe to the Viking presence. Alcuin, a Northumbrian scholar in Charlemagne’s court at the time, wrote: Never before has such terror appeared in Britain as we have now suffered from a pagan race…The heathens poured out the blood of saints around the altar, and trampled on the bodies of saints in the temple of God, like dung in the streets. The Vikings robbed the monastery of all the valuables they could get their hands on, but there were two important treasures they overlooked – the beautiful, handwritten and illuminated bible “The Lindisfarne Gospels”, and the exquisite carved oak coffin containing the relics of St. Cuthbert. The Lindisfarne Gospels are today exhibited in the British Museum in London, while the relics of St. Cuthbert are kept in Durham Cathedral, where they were brought after the Viking raid. More than any other single event, the attack on Lindisfarne demonised perception of the Vikings for the next twelve centuries. Not until the 1890s did scholars outside Scandinavia begin to seriously reassess the achievements of the Vikings, recognizing their artistry, technological skills, and seamanship. In England, many monasteries were established on islands, peninsulas, river mouths and cliffs. Isolated communities were less susceptible to interference and the politics of the heartland. The amazement of the English at the raids from the sea must have been matched by the amazement of the raiders at such (to them) vulnerable, wealthy and unarmed settlements. These preliminary raids, unsettling as they were, were not followed up. The main body of the raiders passed north around Scotland. With the raid on Lindisfarne the Viking Age of Scandinavian history and expansion began. Viking navigators opened the road to new lands to the north, west and east, resulting in the foundation of independent settlements in the Shetland, Orkney, and Faroe Islands; Iceland; Greenland; and L’Anse aux Meadows, a short-lived settlement in Newfoundland, circa 1000. At yovisto you can learn more about the emergence of the Vikings from Scandinavia in the ninth and tenth centuries in the lecture ‘Vikings‘ from the series ‘The Early Middle Ages’ by Yale Prof Paul Freedman.'],\n",
       " [142,\n",
       "  'Robert Mulliken and the Molecular Orbitals.  Historical picture of Arthur Compton, Werner Heisenberg, Monk, Paul Dirac, Eckardt, Gale, Robert Mulliken, Friedrich Hund and Hoyt; Image by Wikimedia User GFHund On June 7, 1896, American physicist, chemist, and Nobel Laureate Robert Sonderson Mulliken was born. He is primarily responsible for the early development of molecular orbital theory, i.e. the elaboration of the molecular orbital method of computing the structure of molecules. Robert Mulliken truly followed in his father’s footsteps, who was a professor of organic chemistry at the Massachusetts Institute of Technology. While the young Robert Mulliken learned the name and botanical classification of plants, his excellent memory and general intelligencewas noticed. He managed to learn the German language so well in younger years that he was allowed to skip the course in scientific German in college. His interest in chemistry grew early as well. Mulliken helped with some of the editorial work when his father wrote his four-volume text on organic compound identification. Already as an undergraduate student at MIT, he conducted his first publishable research on the synthesis of organic chlorides. When he graduated, the United States had just entered World War I and the young scientist was drafted into the Army’s Chemical Warfare Service. One year after the war, he entered the Ph.D. program at the University of Chicago and received his doctorate based on research into the separation of isotopes of mercury by evaporation. There, he was also introduced to the world of the old quantum theory by the Nobel Prize-winning physicist Robert A. Millikan. Mulliken went to the University of Harvard in order to learn spectrographic technique from Frederick A. Saunders and quantum theory from E. C. Kemble. By that time, he was acquainted with several prominent scientists such as Robert Oppenheimer. In the later 1920s, he travelled through Europe to work with experts in quantum theory and spectroscopy like Schrödinger, Dirac, Born, Heisenberg, and Friedrich Hund, by whom he was highly influenced. Hund was back then the assistant of Max Born and had been working on quantum interpretation of band spectra of diatomic molecules, the same spectra which Mulliken had investigated at Harvard. They worked together in 1927 and as a result, both published the famous molecular orbital theory. It revolves around electrons, which are assigned to states that extend over an entire molecule. The theory became originally well known as the Hund-Mulliken theory, the term orbital was introduced by Mulliken in 1932 and about one year later, the theory had been accepted as valid and useful. However, the probably first quantitative use of molecular orbital theory was the 1929 paper of Lennard-Jones and in 1938, the British scientist Charles Coulson made the presumably first accurate calculation of a molecular orbital wavefunction on the hydrogen molecule. In the years after his masterpiece, Robert Mulliken taught at the New York University’s physics department. At this time, he was first recognized as a physicist as well and was appointed full professor at the University of Chicago in 1931. In 1936, he became the youngest member of the National Academy of Sciences. At yovisto, you may be interested in a video lecture introducing the Molecular Orbital Theory.'],\n",
       " [143,\n",
       "  'Thomas Mann and the Mann Family.  Thomas Mann (1875-1955). photo: Library of Congress.  On June 6, 1875, German novelist, short story writer, social critic, philanthropist, and Nobel Laureate Thomas Mann was born. His highly symbolic and ironic epic novels and novellas, are noted for their insight into the psychology of the artist and the intellectual. His older brother was the radical writer Heinrich Mann and three of his six children, Erika Mann, Klaus Mann and Golo Mann, also became important German writers. In Germany, his novells have become a canonical reference. Everybody knows the Buddenbrock family and the story of their decline from a wealthy merchant family to mere insignificance. Or the story of Hans Castorp, the eternal patient of the magic mountain, curing his tuberculosis – but in general also his mind – in Switzerland. Or do you know the infamous imposter Felix Krull, Thomas Mann’s last and unfinished novel? Well, let’s have a closer look on this literary giant of the 20th century. Mann was born Paul Thomas Mann in Lübeck, Germany and was the second son of Thomas Johann Heinrich Mann, a senator and a grain merchant, and his wife Júlia da Silva Bruhns, a Brazilian of German and Portuguese ancestry who emigrated to Germany when seven years old. Mann’s father died in 1891 and his trading firm was liquidated. The family subsequently moved to Munich. Mann attended the science division of a Lübeck Gymnasium (school). After finishing school rather ingloriously, he became a clerk in the office of a Munich insurance company whose director had been a friend of my father’s. Later, by way of preparing for a career in journalism, Thomas Mann studied history, economics, art history and literature at the Ludwig Maximillians University of Munich and Technical University of Munich. The start of his writing career was with a short story ‘Little Mr. Friedemann’ published in 1898. Mann started writing his first novel in 1896 ‘Buddonbrooks’, the a story about a merchant family which grabbed the interest of the public making Mann rich and famous. Buddenbrooks had gone through fifty editions in German before it was translated into English in 1924. American and British critics at the time compared it with John Galsworthy’s “The Forsyte Saga,” also telling the story of a family through several generations. What made Buddenbrooks particularly interesting to the literary student was the fact that the author, showing the social decline of a Luebeck Senatorial family, wove much of his own family history into the story. His reputation as a writer escalated with his novel ‘Death in Venice’ published in 1912. This book described the experiences of a writer who goes to Venice and falls in love with a young boy. Many of his works revolved around homosexual themes. However, Mann married Katia Pringsheim, who belonged to a strong wealthy Jewish background, and they had six children. In 1924, Mann finally published what many consider to be his greatest work, The Magic Mountain. The novel is set in a tuberculosis sanatorium in the Swiss Alps, a community that represents a microcosm of Europe directly before World War I. The protagonist, a healthy young man, comes to the sanatorium for a short visit, but ends up staying for seven years. Eventually, he finds fulfillment by leaving the community. The novel typifies the style that Mann is best known for: ironical, somber, and symbolic. In 1929, Mann had a cottage built in the fishing village of Nidden (Nida, Lithuania) on the Curonian Spit, where there was a German art colony and where he spent the summers of 1930–1932 working on Joseph and His Brothers, a tetralogy on the history of the biblical character. In 1933, while traveling in the South of France, Mann heard from his children Klaus and Erika in Munich, that it would not be safe for him to return to Germany. The family (except the two oldest children) emigrated to Küsnacht, near Zurich, Switzerland but received Czechoslovak citizenship and a passport in 1936. He then emigrated to the United States in 1939, where he taught at Princeton University. Although Mann was not a political writer, he was forced to move on a number of occasions for political reasons. He taught at Princeton University in New Jersey for two years, but moved to Pacific Palisades, California to join an expatriate community of German intelligentsia including the composer Arnold Schoenberg, dramatist Berthold Brecht, and Mann’s own brother, Heinrich. In his famous Doctor Faustus (1947), Mann retold the famous myth as a composer who sells his soul to the devil in return for fame. Based on his friend, composer Arnold Schoenberg, the work expresses Mann’s despair over German Nazism. After World War II, during the McCarthy era, Mann grew disillusioned with American politics and moved back to Europe in 1952. His most important German visit was in 1949, at the 200th birthday of Johann Wolfgang von Goethe, attending celebrations in Frankfurt am Main and Weimar, as a statement that German culture extended beyond the new political borders. Thomas Mann died in Zurich on August 12, 1955. At yovisto you can learn more about Thomas Mann in a seminar by the Goethe Institute Boston on Thomas Mann and his Stories.'],\n",
       " [144,\n",
       "  'The Bose-Einstein Condensate brings Quantum Theory to the Macroscopic Scale.  Velocity-distribution data (3 views) for a gas of rubidium atoms, confirming the discovery of a new phase of matter, the Bose–Einstein condensate. On June 5, 1995, the very first Bose-Einstein condensate was experimentally produced by Eric Cornell and Carl Wieman at the University of Colorado. A Bose–Einstein condensate (BEC) is a state of matter of a dilute gas of bosons cooled to temperatures very close to absolute zero. Under such conditions, a large fraction of the bosons occupy the lowest quantum state, at which point quantum effects become apparent on a macroscopic scale. For their achievements Cornell, Wieman, and Wolfgang Ketterle at MIT received the 2001 Nobel Prize in Physics. In the early 1920s Indian physicist Satyendra Nath Bose was studying the new idea that the light came in little discrete packets, today called “photons“. Bose assumed certain rules for deciding when two photons should be counted up as either identical or different. We now call these rules “Bose statistics” (or sometimes “Bose-Einstein statistics“). Bose first sent a paper to famous Albert Einstein on the quantum statistics of those light quanta. Einstein was so impressed that he translated the paper himself from English to German and submitted it for Bose to the Zeitschrift für Physik, which published it. Einstein major contribution then was his extension of Bose’s ideas to material particles, which he published in two other papers. The result of the efforts of Bose and Einstein is the concept of a Bose gas, governed by Bose–Einstein statistics, which describes the statistical distribution of identical particles with integer spin, now known as bosons. Bosonic particles, which include the photon as well as atoms such as helium-4 (4He), are allowed to share quantum states with each other. Einstein proposed that cooling bosonic atoms to a very low temperature would cause them to fall (or “condense”) into the lowest accessible quantum state, resulting in a new form of matter. If the atoms were cold enough, something very unusual was supposed to happen. It was so strange that Einstein was not really sure whether his solution was correct. In 1938 Fritz London proposed BEC as a mechanism for superfluidity in 4He and superconductivity, discovered in the same year by, Pyotr Kapitsa, John Allen and Don Misener. They discovered that helium-4 became a new kind of fluid, now known as a superfluid, at temperatures less than 2.17 K (the so-called lambda point). Superfluid helium has many unusual properties, including zero viscosity (the ability to flow without dissipating energy) and the existence of quantized vortices. It was quickly believed that the superfluidity was due to partial Bose–Einstein condensation of the liquid. But it took almost 60 years, until in 1995 the first gaseous condensate was produced by Eric Cornell and Carl Wieman at the University of Colorado at Boulder NIST–JILA lab, using a gas of rubidium atoms cooled to 170 nanokelvin (nK). For their achievements Cornell, Wieman, and Wolfgang Ketterle at MIT received the 2001 Nobel Prize in Physics. At yovisto, you can listen to Nobel Laureate Wolfgang Ketterle in the MIT documentation ‘The Coldest Place in the Universe‘ and learn more about the Bose-Einstein Condensate.'],\n",
       " [145,\n",
       "  'The First Pulitzer Prize.  On June 4, 1917, the very first Pulitzer Prizes were awarded. The Pulitzer Prize is an award for achievements in newspaper and online journalism, literature, and musical composition in the United States. It was established in 1917 by provisions in the will of American (Hungarian-born) publisher Joseph Pulitzer, and is administered by Columbia University in New York City. When Pulitzer offered the Columbia University money in order to set up the world’s first school of journalism in 1892, the president Seth Low refused it. A decade later the university finally agreed to found a school and establish journalism prizes, but Pulitzer’s dream was only fulfilled after his death. He left the institution $2,000,000 and the Columbia University Graduate School of Journalism. Five years later, Columbia organized the awards of the first Pulitzer Prizes in journalism after Pulitzer’s will. He specified “four awards in journalism, four in letters and drama, one in education, and four traveling scholarships”. In 1917, the winners of the Pulitzer Prize were selected by the Columbia University trustees. The winning award was given to French Ambassador Jean Jules Jusserand, who wrote the best book about American history. Herbert Bayard Swope won a $1000 prize for reporting. Swope produced a series of articles entitled “Inside the German Empire”. The articles formed the basis for a book released in 1917 entitled Inside the German Empire: In the Third Year of the War, which he wrote with the American lawyer and diplomat James W. Gerard. In the category biographies and autobiographies, the prize was awarded to Laura Richards and Maud Elliott for their work Julia Ward Howe, the famous American abolitionist, social activist, poet, and author. The New-York Tribune won the prize for the best editorial writing on the first anniversary of the sinking of the Lusitania. Over the years, more categories for the Pulitzer Prize were established and others were renamed because the common terminology changed, or the award has become obsolete, such as the prizes for telegraphic reporting, which was based on the old technology of the telegram. Every year, 102 judges are selected, by the Pulitzer Prize Board, to serve on 20 separate juries for the (currently) 21 award categories. However, the board can also decide to issue no award at all in a specific category. At yovisto, you may be interested in a video lecture by James McGrath Morris. His talk revolves around Pulitzer: A Life in Politics, Print and Power.'],\n",
       " [146,\n",
       "  'The First American to walk in Space – Edward White.  Edward White during Gemini 4 performing EVA.  On June, 3, 1965, Edward Higgins White becomes the first American to “walk” in space in the course of the Gemini 4 space mission. White is one of the three U.S. astronauts, who died along with his fellow astronauts Virgil “Gus” Grissom and Roger B. Chaffee during prelaunch testing for the first manned Apollo mission at Cape Canaveral. Edward White earned his Bachelor degree at the U.S. Military Academy and he was commissioned as a 2nd Lieutenant in the Air Force. After he had some experience in flight, he spent over three years in West Germany flying in the defense of NATO. White’s education in aeronautical engineering began in 1958 at the University of Michigan and he was appointed test pilot shortly after, gaining over 3000 flight hours with the Air Force. Project Gemini 4 became the very first multi-day space flight by the United States. The main objective was to show that it was possible for humans to remain in space for extended lengths of time. However, the four day orbit flight could not break the five day record set by the Soviet Vostok 5 two years before. Another main goal of the operation was the first American extra-vehicular activity (EVA), also known as “space walk“. The first human space walk of all times was performed by Soviet Alexei Leonov on Voskhod 2 in March 1965. However, this second objective was not officially decided until a day or two before the launch, as newspapers recorded. The attempt of the first space rendezvous was the third goal. Gemini 4 would attempt to fly in formation with the spent second stage of its Titan II launch vehicle, which unfortunately, was unsuccessful. For the first time, the launch of a spacecraft became a huge media event. An international audience from 12 European nations, could watch the lift-off on live television via the Early Bird satellite. Press interest, due to the satellite broadcast and the new center in Houston, proved to be so high that NASA had to lease buildings to accommodate the 1.100 print and broadcast journalists who requested accreditation. Edward White was chosen as Pilot of Gemini 4 along with Command Pilot James McDevitt. On June 3, 1965, White was finally able to make his first “steps” into space. Tied to a tether, White floated out of the spacecraft, using a hand held maneuvering unit. He floated away about five meters before experimenting with the maneuvering device while McDevitt took pictures. However, mission control feared that the pilots would cross the solar terminator and communication turned out to be increasingly difficult. As they did not want the space walk to be performed in the darkness, they decided that White had to go back in the spaceship. First, White did not want to return to the spaceship, because he enjoyed his experience so much. He tried to excuse his longer space walk with taking more pictures and McDevitt finally managed to coax him in. White replied: “I’m coming back in… and it’s the saddest moment of my life“. Eventually, the pilot returned to the ship and just at this moment, they entered darkness. Even though the re-entry and landing was rough, the pilots returned to Earth safely and were recovered by an American ship as they landed in the ocean. After the Gemini mission, Edward White was named the astronaut specialist for the flight control systems of the Apollo Command/Service Module. In 1966, he was selected as Senior Pilot for the first manned Apollo flight. The mission was then named Apollo 1. During a test of the spacecraft, which included a rehearsal of the launch countdown procedure, a fire broke out in the pure oxygen-filled cabin, killing all three pilots. Edward White passed away on January 27, 1967. At yovisto, you may be interested in a video showing the actual space walk of Edward White.'],\n",
       " [147,\n",
       "  'The Novels of Thomas Hardy.  Thomas Hardy (1840-1928). On June 2, 1840, English novelist and poet Thomas Hardy was born. A Victorian realist in the tradition of George Eliot, he was influenced both in his novels and in his poetry by Romanticism, especially William Wordsworth. Charles Dickens was his other source of influence, and like Dickens he was highly critical of much in Victorian society. Thomas Hardy was born in the village of Upper Bockhampton, located in Southwestern England. His father was a stone mason and a violinist, while his mother enjoyed reading and relating all the folk songs and legends of the region. At the age of eight, Hardy began to attend Julia Martin’s school in Bockhampton. However, most of his education came from the books he found in Dorchester, the nearby town. He learned French, German, and Latin by teaching himself through these books. Because Hardy’s family lacked the means for a university education, his formal education ended at the age of sixteen, when he became apprenticed to James Hicks, a local architect. Under Hicks’ tutelage, Hardy learned much about architectural drawing and restoring old houses and churches. Hardy loved the apprenticeship because it allowed him to learn the histories of the houses and the families that lived there. In 1862, he moved to London, where he enrolled as a student at King’s College London. He won prizes from the Royal Institute of British Architects and the Architectural Association. But Hardy never felt at home in London, because he was acutely conscious of class divisions and his social inferiority. However, during this time he became interested in social reform and the works of John Stuart Mill, maybe the most influential english-speaking philosopher of the 19th century. He was also introduced by his Dorset friend Horace Moule to the works of Charles Fourier, a French philosopher credited with having originated the word feminism, and Auguste Comte, one of the founders of the discipline of sociology and of the doctrine of positivism. Five years later in 1867, concerned about his health, Hardy returned to Dorset and decided to dedicate himself to entirely writing poetry and novels, though the first part of his career was devoted to the novel. At first he published anonymously, but when people became interested in his works, he began to use his own name. Like Dickens, Hardy’s novels were published in serial forms in magazines that were popular in both England and America. His first popular novel was Under the Greenwood Tree, published in 1872. The next great novel, Far from the Madding Crowd (1874) was so popular that with the profits, Hardy was able to give up architecture and marry Emma Gifford. Other popular novels followed in quick succession: The Return of the Native (1878), The Mayor of Casterbridge (1886), The Woodlanders (1887), Tess of the D’Urbervilles (1891), and Jude the Obscure (1895). In addition to these larger works, Hardy published three collections of short stories and five smaller novels, all moderately successful. However, despite the praise Hardy’s fiction received, many critics also found his works to be too shocking, especially Tess of the D’Urbervilles and Jude the Obscure. The outcry against Jude was so great that Hardy decided to stop writing novels and return to his first great love, poetry. Hardy’s long career spanned the Victorian and the modern eras. He described himself as a poet “who holds that if way to the Better there be, it exacts a full look at the Worst” and during his nearly 88 years he lived through too many upheavals — including World War I — to have become optimistic with age. Incredibly prolific, Hardy wrote fourteen novels, three volumes of short stories, and several poems between the years 1871 and 1897. From 1898 until his death in 1928 Hardy published eight volumes of poetry; about one thousand poems were published in his lifetime. Moreover, between 1903 and 1908 Hardy published The Dynasts—a huge poetic drama in 3 parts, 19 acts, and 130 scenes. Although Hardy’s novels were received badly by critics when they were first published, Hardy has been consistently recognized since his death as one of the great English novelists. He was an important influence on Modernism, and many later writers, including Virginia Woolf, D.H. Lawrence, and Robert Graves, named Hardy as influences. At yovisto you can learn more about the poetry ofThomas Hardy in the lecture of Prof Langdon Hammer from Yale University on ‘World War I Poetry in England‘.'],\n",
       " [148,\n",
       "  'Carnot and Thermodynamics.  Nicolas Léonard Sadi Carnot (1796-1832).  On June 1, 1796, French military engineer and physicist Nicolas Léonard Sadi Carnot was born. He is often described as the “father of thermodynamics“. In particular, Carnot gave the first successful theory of the maximum efficiency of heat engines. Carnot’s work attracted little attention during his lifetime, but it was later used by Rudolf Clausius and Lord Kelvin to formalize the second law of thermodynamics and define the concept of entropy. Sadi Carnot was the eldest son of Lazare Carnot and he was born in the Palais du Petit-Luxembourg. At the time of Sadi’s birth, his father was an eminent mathematician, military engineer, and a member of the Directory, the French Revolutionary government which lasted four years from November 1795 to November 1799. Sadi was named after a medieval Persian poet and philosopher called Sa’di of Shiraz. It was a time of unrest and political turmoil in France and, due the position of his father, whose fortunes changed dramatically many times, he was brought up in a totally unstable environment of interacting politics and science. At the age of 16, Sadi Carnot became a cadet in the École Polytechnique in Paris, which was intended to train engineers for military service, but its professors included such eminent scientists as André-Marie Ampère, François Arago, Joseph Louis Gay-Lussac, and Siméon Denis Poisson. After graduating in 1814, Sadi became an officer in the French army’s corps of engineers. Because his father Lazare had served as Napoleon’s minister of the interior during the “Hundred Days“, he was forced into exile after Napoleon’s final defeat in 1815. Therefore, also Sadi’s position in the army under the restored Bourbon monarchy of Louis XVIII became increasingly difficult. In 1819, Sadi transferred to the newly formed General Staff, in Paris. He remained on call for military duty, but from then on he dedicated most of his attention to private intellectual pursuits. He befriended the scientist Nicolas Clément and attended lectures on physics and chemistry. More and more, he became interested in understanding the limitation to improving the performance of steam engines, which led him to the investigations that became his Reflections on the Motive Power of Fire, published in 1824, considered the founding work of thermodynamics. Steam engines had achieved widely recognized economic and industrial importance, but there had been no real scientific study of them. Although there existed some intuitive understanding of the workings of engines, scientific theory for their operation was almost nonexistent. In 1824 the principle of conservation of energy was still poorly developed and controversial, and an exact formulation of the first law of thermodynamics was still more than a decade away; the mechanical equivalence of heat would not be formulated for another two decades. In his main work Reflections on the Motive Power of Fire Carnot sought to answer two questions about the operation of heat engines: “Is the work available from a heat source potentially unbounded?” and “Can heat engines in principle be improved by replacing the steam with some other working fluid or gas?” The book was plainly intended to cover a rather wide range of topics about heat engines in a rather popular fashion, the most important part of the book was devoted to an abstract presentation of an idealized engine that could be used to understand and clarify the fundamental principles that are generally applied to all heat engines, independent of their design. This resulted in a model thermodynamic system upon which exact calculations could be made. By idealizing the engine, he could arrive at clear and indisputable answers to his original two questions. In Carnot’s idealized model, the caloric transported from a hot to a cold body, yielding work, could be transported back by reversing the motion of the cycle, a concept subsequently known as thermodynamic reversibility. Carnot retired from the army in 1828, without a pension. He was interned in a private asylum in 1832 as suffering from “mania” and “general delirum”. He died during a cholera epidemic in 1832, at the age of only 36. Because of the contagious nature of cholera, many of Carnot’s belongings and writings were buried together with him after his death. As consequence, only a handful of his scientific writings survived. It is likely that Carnot would have made many more significant scientific contributions had his life not been so tragically short. His work was only taken seriously after his early death. Emile Clapeyron, a fellow student from Ecole Polytechnique translated Carnot’s book into mathematical terms and more than a decade later Rudolf Clausius and Lord Kelvin extended Carnot’s work into what is present day thermodynamics. At yovisto you might learn more about the principles behind steam engines and thermodynamics in the lecture videos of Prof. Ranamurti Shankar from Yale on ‘Fundamentals of Physics‘, where he also discusses the laws of thermodynamics.'],\n",
       " [149,\n",
       "  'The Poetry of Walt Whitman.  Walt Whitman (1819 – 1892). On May 31, 1819, American poet, essayist and journalist Walt Whitman was born. Whitman is among the most influential poets in the American canon, often called the father of free verse. A humanist, he was a part of the transition between transcendentalism and realism, incorporating both views in his works.  Walt Whitman ended his formal education at the age of 11 in order to work and support his large family financially. First, he was an office boy and later he was apprenticed at the weekly Long Island newspaper, the Patriot. It is assumed that occasionally, he was able to write filler material for the paper. Before he turned 16, Whitman took a position at the shop of Alden Spooner, editor of the leading Whig weekly newspaper the Long-Island Star, where he began attending theater performances, joined a town debating society, and and anonymously published some of his earliest poetry.  The young poet then moved to New York City in order to find some work as a compositor, but had some difficulties. After this failed attempt, Whitman moved back in with his family at Long Island and started a teaching career. In the following period, Whitman started an attempt to create his own newspaper, but was again forced to teach. Still, he published a series of ten editorials, called “Sun-Down Papers—From the Desk of a Schoolmaster“, between the winter of 1840 and July 1841. He went back to New York to work for several newspapers, with modest success. Still, he determined to become a poet and in 1850, he began writing what would become Leaves of Grass, a collection of poetry which he would continue editing and revising until his death. At the end of June 1855, Whitman surprised his brothers with the already-printed first edition of Leaves of Grass. Unfortunately, his brother George “didn’t think it worth reading”. However, the book received a good attention and was praised the most by Ralph Waldo Emerson, who wrote a flattering five-page letter to Whitman and spoke highly of the book to friends. The more critical responses tended to focus on the potentially offensive sexual themes.  Whitman was highly influenced by the Civil War. He was worried that his brother was wounded and made his way to find him. Luckily, George had only small wounds, but seeing the wounded soldiers and the heaps of their amputated limbs affected the author. Whitman volunteered as a nurse in army hospitals and published a book called ‘Memoranda During the War‘ about 12 years later. Whitman soon started working for the government, but was fired on June 30, 1865, presumably because of his 1860 edition of Leaves of Grass. However, his friend Douglas O’Connor highly protested and published a biased and exaggerated biographical study, The Good Gray Poet, in January 1866, which defended Whitman as a wholesome patriot, established the poet’s nickname and increased his popularity. Also important for Whitman’s fame in this period was the publication of “O Captain! My Captain!“, the famous poem on the death of Abraham Lincoln. Poems of Walt Whitman was published in 1868 in England, which became highly popular.  Due to his declining health, Whitman moved in with his brother and still was very productive in this period, publishing three versions of Leaves of Grass among other works. He was also last fully physically active in this house, receiving both Oscar Wilde and Thomas Eakins. After Whitman had moved into his own house, he prepared a final edition of Leaves of Grass, a version that has been nicknamed the “Deathbed Edition”.  Walt Whitman passed away on March 26, 1892  At yovisto, you may be interested in a video lecture on Walt Whitman and the Civil War by Terrence Pratt.'],\n",
       " [150,\n",
       "  'Elly Beinhorn and her Love for Aviation.  Elli Beinhorn arrives at Berlin Tempelhof in 1931 Image Source: German Federal Archive, Accession number:102-11633 On May 30, 1907, German aviatrix and stunt pilot Elly Beinhorn was born. In the 1930s she broke several long distance flight records including flying over three continents in a single day. When it comes to the history of aviation, there seem to be less gender issues compared to other technological disciplines, as our growing list of women aviation pioneers here at yovisto blog can proof (cf. below). We already reported on Amy Johnson and her flight to Australia as well as about famous Amelia Earhart, who got lost during one of her record breaking flights over the Pacific. Today, we want to draw the focus to a German aviatrix, Elly Beinhorn. There is actually also a personal connection with today’s story, because my grandmother made a piloting license for gliders back in the 1930s. From her tellings when I was a child, I know that she pretty much admired Elly Beinhorn as an example for her own ambitions. An only child, Elly Beinhorn was born into a merchant family in Hannover, Germany, where she grew up dreaming of travel and adventure in foreign lands. At the age of 20, she attended a lecture by famed aviator Hermann Köhl, who had recently completed a historic East-West Atlantic crossing, which must have been the initial spark that ignited her lifelong interest in aviation. On the next day, Elly was reporting to the president of the aviation club in Hannover to take flying lessons. But, he tried to persuade her that as being a woman she would have no chance to get a job as an aviator. Nevertheless, Elly was sticking to her idea. Her mother was crying and her father doubted about her reasoning. Against all odds, with funds from a small inheritance she moved to Spandau in Berlin where she took flying lessons, at Berlin-Staaken airport, under the tutelage of instructor Otto Thomsen. She soon made her solo flight in a small Klemm KL-20. With her money running out, it was suggested that she give aerobatic displays on the weekends. She found this financially rewarding, but personally unsatisfying. Long distance flying should become her real passion and in 1931 she seized the opportunity to fly to Portuguese Guinea, West Africa on a scientific expedition. On the return journey, engine failure resulted in a crash-landing in the Sahara. With the help of nomadic Tuareg tribesmen, Elly joined a camel caravan to Timbuktu. She subsequently returned to the crash site to recover parts of the plane. Word of her plight reached the French authorities and they sent a military two-seater plane to collect her. In April 1931, fully recovered, she was able to fly herself back to Berlin to a warm reception from the crowds. Soon after this, she embarked on another flight, her Klemm monoplane developing mechanical problems near Bushire, Persia. She found Moye Stephens, another pilot, in Bushire, who helped her fix the problem on her Klemm. Stephens and travel-adventure writer Richard Halliburton were flying around the world in a Stearman C-3B biplane, they called the Flying Carpet. She accompanied them on part of their flight, including the trip to Mount Everest. She flew on to Bali – and eventually Australia. In the process, she became only the second woman to fly solo from Europe to Australia, after Amy Johnson. Having landed in Darwin, North Australia, Elly headed down to Sydney, arriving in March 1932. Her plane was dismantled and shipped to New Zealand, then Panama where it was reassembled. There Elly resumed her flight, following the western coast of South America, where she was presented with a medal in Peru. An ill-advised trip across the Andes followed. The plane was dismantled once more in Brazil and shipped to Germany. Elly arrived in Berlin in June 1932. Now famous but in debt to the tune of 15,000 marks or more, she was pleasantly surprised to be awarded the Hindenburg Cup, 10,000 marks and several other monetary awards from the German aeronautical industry which enabled her to continue her career. She also continued to write articles and sell photographs of her travels to raise funds. Free of debt, she took off for Africa using a Heinkel He 71, flying down the east coast, then back up the west coast. The following year, Elly shipped the plane to Panama, then flew through Mexico and California before crossing the United States to Washington DC and Miami. Elly and the plane returned to Germany by ship, arriving in January 1935. She was now a true German heroine. On 29 September 1935 Elly attended the Grand Prix, held in the town of Brno in Czechoslovakia. She congratulated the winner, Bernd Rosemeyer, who seemed smitten with her. They danced together that night and were married on 13 July 1936. A true celebrity couple – an adventurous aviator and the fearless racing driver – they were the toast of Nazi Germany. Heinrich Himmler ordered a reluctant Bernd to become a member of the SS. Just ten weeks after the birth of their son in 1937, Rosemeyer was killed while attempting a speed record. As a national hero he was mourned by much of Germany. After World War II she briefly took up gliding due to the ban on powered flight in Germany. But she soon moved to Switzerland to continue flying planes. In 1979, at the age of 72, she surrendered her pilot’s licence. Elly Beinhorn died on 28 November 2007, at the age of 100. At yovisto, you may be interested in extracts of interviews with Elly Beinhorn herself [in German].'],\n",
       " [151,\n",
       "  'Johann Heinrich von Mädler and the First Accurate Map of the Moon.  The Moon.  On May 29, 1794, German astronomer Johann Heinrich von Mädler was born. He ist best known for producing the first exact map of the Moon, the Mappa Selenographica. Even though Mädler’s talents were discovered very early into his childhood. Unfortunately, his parents passed away very early and he had to care care of his younger siblings, even though he had always wished to study mathematics and astronomy. He financed his family though private tutoring and eventually managed to receive an official teaching licence. Starting from 1818, Mädler finally studied mathematics at the University of Berlin under the well known mathematician Martin Ohm. Also, he received many lessons in astronomy. His first published obervations were performed in 1822. In this period, Mädler also got to know the wealthy hobby astronomer Wilhelm Beer. Mädler taught the man in science and was able to use his private observatory, where he observed mostly the moon and later planet Mars together with Beer. The first accurate maps of Mars and the Moon were created in the 1830s. Mädler drew a huge map of the moon, which was published in 1834. In later years, smaller maps were also published and soon became standard reading in the scientific community. These works made Mädler very popular and his reputation as an astronomer increased, wherefore he was announced professor of astronomy in 1837. The scientists spent some time observing the Moon in Estonia in order to create an even bigger map, but unfortunately, the weather was not suitable most of the time and he was only able to make some detailed drawings. However, Mädler also found some time to perform observations on double stars and fixed stars. During his life as a scientist, Mädler also worked as a scoentific journalist and wrote about the young pioneer photographic pioneer Henry Fox Talbot. It is assumed that Mädler coined the term ‘photographie’ in 1839. At yovisto, you may be interested in a video lecture by Ross Beyer, who talks about “Making maps to explore the Earth, Moon, and Mars“.'],\n",
       " [152,\n",
       "  'Thomas Moore – Ireland’s National Bard.  Thomas Moore painting by Thomas Lawrence.  On May 28, 1779, Irish poet, singer, songwriter Thomas Moore was born. He is best remembered for the lyrics of “The Minstrel Boy” and “The Last Rose of Summer“. Moreover, he was responsible, with John Murray, for burning Lord Byron’s memoirs after his death. Thomas Moore had ambitions to become an actor from early age, as he appeared in plays with his friends in his early school years. He enrolled at Trinity College in 1795 in order to become a lawyer instead, since this was his mother’s wish. Even though his grades were good at the beginning, Moore put only few effort into his studies. His law studies then continued in London even though writing became his major passion. During his time in London, Moore’s works became increasingly popular. They included ‘The Harp That Once Through Tara’s Halls’ or ‘The Meeting of the Waters’: There is not in the wide world a valley so sweet, As the vale in whose bosom the bright waters meet; Oh, the last rays of feeling and life must depart, Ere the bloom of that valley shall fade from my heart. In the poem, Moore describes the river Avoca in County Wicklow, Ireland. It starts life as two rivers, the Avonmore and the Avonbeg. These join together at a spot called the Meeting of the Waters. In this period, the artist had already finished several ballads, which were published as Moore’s Irish Melodies in 1846 and 1852. His influence in literature and society grew and Moore soon managed to meet the Prince of Wales on several occasions. Also, he enjoyed the patronage of the Irish aristocrat Lord Moira in particular. Lord Moira was known to own a very large library in his house at Donnington Park in Leicestershire, which Moore visited quite often in this period. In the early 1800s, Moore became registrar to the Admiralty in Bermuda, but found his tasks not inspiring as he stated that there was not much to do and found that he did not have much in common with the society there. However, during his period in Bermuda, he wrote his Ode to Nea, which caused quite a scandal since it suggested a love affair. Very soon, Nea was identified with Hester Tucker, the young wife of one of his colleagues. In the following period, Moore travelled across the United States and Canada and developed a deeply critical view of the United States. He came to dislike Thomas Jefferson and the Democratic Party. During his journey in Canada, Moore wrote one of his most famous works, Canadian Boat Song. In 1804, he returned home. His book, Epistles, Odes, and Other Poems was published after his return and the criticisms of the United States in the book provoked outrage in America and led to a number of rebuttals. In Britain, the work led to Moore challenging the editor Francis Jeffrey to a duel. However, the duel was interrupted by the arrival of governmental officials. It was then reported that Moore’s opponent had been given an empty pistol and the persistent mockery of the author continued. Moore was especially angered by Lord Byron’s comment on the event. He wrote “on examination, the balls of the pistols, like the courage of the combatants, were found to have evaporated“. As a response, Moore wrote to Lord Byron, that unless the remarks were clarified Moore was prepared to fight Byron. But, when the two met each other, the dispute was settled and they became close friends. Beginning with the year 1806, Moore dramatically changed his style of writing. He started writing lyrics to a series of Irish tunes, in collaboration with John Stevenson. He became best known for these Irish Melodies which were enormously popular containing songs such as The Minstrel Boy, The Last Rose of Summer, Believe Me If All Those Endearing Young Charms and Oft, in the Stilly Night. Thomas Moore began another trip, this time across France, Switzerland, and Italy. In Venice, he briefly spent some time with Lord Byron, which is considered as their last meeting. Byron gave Moore his memoirs with instruction to publish them after his death. Moore was much criticized later for allowing himself to be persuaded to destroy Byron’s memoirs at the behest of Byron’s family because of their damningly honest content. Moore did, however, edit and publish Letters and Journals of Lord Byron, with Notices of his Life in 1830, six years after Byron’s 1824 death in Greece. In his later life, Thomas Moore settled in Wiltshire, England. He has become a novelist and biographer as well as a successful poet. In 1830 he sang in front of the future Queen Victoria in a duet with her mother, and later composed a song Sovereign Woman in her honor. Thomas Moore passed away on 25 February 1852. He is considered Ireland’s National Bard and many composers have set the poems of Thomas Moore to music, including Robert Schumann, Hector Berlioz, Charles Ives and many more. Also James Joyce cited many of his songs for example Silent, O Moyle! At yovisto you may enjoy the two part video lecture by Tim McGee talking about Lord Byron and English Romanticism in general.'],\n",
       " [153,\n",
       "  'Niccoló Paganini – the Devil’s Violinist.  Niccoló Paganini (1782 – 1840).  On May 27, 1840, Italian violinist and composer Niccolo Paganini passed away. He was the most celebrated violin virtuoso of his time, and left his mark as one of the pillars of modern violin technique. Already Paganini’s father made his living from music. He used to play the mandolin and also taught his third son Niccolò how to master the instrument. At the age of seven, the young boy moved to the violin and immediately turned out to be successful. He earned himself several scholarships and was taken to Parma by his father in order to being taught by the famous Alessandro Rolla, who sent him to his own teacher, Ferdinando Paer. At the age of 18, Paganini already worked as first violin of the Republic of Lucca and along with his incredible skills came his reputation as a womanizer and gambler. After playing at court for a while, Paganini toured through Genoa and Parma. His fame in the area was enormous, in contrast to the rest of Europe, where he was unfortunately only little known. However, things changed after a concert in Milan around 1813. Paganini became well known by further leading musicians and during his tour starting in Vienna in 1828, he became famous far beyond Italy’s borders. The musical genius played in Germany, Poland, Britain and France. In the following period however, Paganini faced serious problems concerning his health. He was reputed to have been affected by Marfan syndrome and additionally, the stress coming from the many concerts and his lifestyle took their toll. Even though he was officially cured quite fast, he had to cancel many concerts due to various health problems and it is also assumed that he suffered from a severe depression at some time. Around 1834, he retired from his career as a concert musician. He now devoted most of his lifetime to composing and publishing further works as well as teaching. Niccoló Paganini passed away on May 27, 1840 and he was buried in Parma several years later. His major works were presumably created between 1805 and 1809 and they are known for being technically imaginative. The solo piece Duetto Amoroso became known as one of his most brilliant, depicting the sighs and groans of lovers on the violin. It is assumed that Paganini influenced many musicians, such as Franz Liszt, Robert Schumann, Andrew Lloyd Webber, and George Rochberg. In 2013, a movie titled “The Devil’s Violinist” was released starring David Garrett as Niccoló Paganini. At yovisto, you may be interested in a concert of Niccolò Paganini’s Caprice No. 24 In A Minor, played by James Ehnes.'],\n",
       " [154,\n",
       "  'August von Parseval`s Airships.  Parseval in Augsburg source: German Federal Archive.  On May 26, 1906, August von Parseval succeeded launching his new airship at Berlin Tegel military field. In contrast to his rival Zepellin, Parseval’s airships – also in honor of their inventor called Parsevals – were non-rigid or semi-rigid airships, with little or no stiffening structure inside the fabric envelope. While studying in Augsburg, August von Parseval met his future business partner Hans Bartsch von Sigsfeld. Together, they made early developments of balloons. Von Parseval devoted his life to aeronautics pretty early and learned the principles autodidactic. His first developments were even used for military purposes, especially for reconnaissance and faced a big success for the engineer. They soon started building a navigable airship and it is assumed that the first successful models appeared around 1901. While trying to land one of the airship one year later a horrible accident occurred and Parseval’s partner Sigsfeld passed away. This resulted in a construction and developing break until 1905. As the development of engines moved forward, Parseval became able to use these for his airship. In the 1920s and 30s, the engineer built several keel-airship and Parseval also increased his interest in the construction of crafts heavier than air. His first experiments considering actual planes mainly took place on the water due to safety reasons. However, the first attempts were very unsatisfying and even after a complete re-developments, the planes would never lift off the water. On October 7, 1910, Parseval attempted another lift off. This time however, he made sure that the plane would have enough speed for lift off and was successful. In the following months, Parseval reached altitudes of approximately 75 meters, and distances of three to four kilometers. In 1911, the engineer retired from his experiments and started teaching the theories of flight that he had learned during his career. Between 1909 and 1919, about 22 airship were constructed under Parseval’s name. The engineer’s airship were very popular and seen as a great competition to Zeppelin. In order to stabilize his airship, Parseval used the ability to change the temperature of the gases inside the balloon. In contrast, Zeppelin had used huge metal rods. At yovisto, you may be interested in a video lecture by Randy Friedl on the Opportunities of Airships in Earth Science.'],\n",
       " [155,\n",
       "  'The First US Space Station Skylab.  Skylab as SL2 mission departs Image by NASA.  On May 25, 1973, the first crew of astronauts reached the US space station Skylab. Skylab was the first US space station and orbited Earth from 1973 to 1979. Already in the 1950s it was expected by space scientists, that a space station would be a necessary step in space exploration. Wernher von Braun envisioned a very large space station with room for about 80 people including astronomers, meteorologists and soldiers to guard the station. After the 1969 moon landing however, NASA was concerned about losing the numerous workers associated with the project. Therefore, von Braun, who was then head of NASA’s Marshall Space Flight Center then advocated for a smaller station in order to start the project soon. He proposed a concept that became widely known as ‘wet workshop’. The station was supposed to be built from the S-II second stage of a Saturn V. Inside the shell was a 10-foot (3.0 m) cylindrical equipment section. On reaching orbit, the S-II second stage would be vented to remove any remaining hydrogen fuel, then the equipment section would be slid into it via a large inspection hatch. Power was to be provided by solar cells lining the outside of the S-II stage. This concept was son succeeded by the ‘dry workshop’ due to financial cuts. The new plan simplified the interior for the station and also the living conditions for the astronauts were improved from previous missions. Space food was re-developed as previous astronauts found the taste and composition, in the form of cubes and squeeze tubes very unpleasant. The Orbital Workshop was renamed “Skylab” in 1970 and three years later, on May 14, it was launched by the modified Saturn V. Unfortunately, severe damage was sustained during the launch including the loss of the station’s micrometeoroid sun shade and one of its main solar panels. The first manned mission SL-2 involved repairs to the station, which included two space walks. In total, three manned missions were made to Skylab and the last crew returned on February 8, 1974. In this period, Skylab logged about 2,000 hours of scientific and medical experiments, 127,000 frames of film of the Sun and 46,000 of the Earth. When the missions were completed, the future of Skylab was highly debated. Several scientists proposed plans for reusing the station again in 1978 but the plans turned out quite risky, since the attitude control system needed refueling and that the station’s gyroscopes had failed. The re-entry of Skylab faced great media attention. The station’s debris landed southeast of Perth, Australia. At yovisto, you may be interested in an entertaining video on the 40th anniversary of Skylab by NASA.'],\n",
       " [156,\n",
       "  'Aviatrix Amy Johnson and the Flight to Australia.  Amy Johnson in India Image by Wikimedia User Dabbler.  On May 24, 1930, American aviatrix Ami Johnson safely landed in Darwin, Northern Territory, Australia after a 18.000km flight, becoming the first woman pilot to fly solo from England to Australia. Amy Johnson earned her Bachelor if Arts degree in economics at the University of Sheffield. She was introduced to flying and gained the “A” pilot licence in 1929, followed by the “C” licence shortly after. She was highly supported by her father and he also helped her to purchase her first plane, which she named “Jason”. She managed to fly from England to Australia in 1939 as the first known woman all by herself. On 5 May the pilot left London and landed in Darwin on 24 May. She flew about 18.000 km and immediately received great attention for her achievements. Johnson received the Harmon Trophy, which is usually awarded annually to the world’s outstanding aviator, female aviator, and aeronaut. In July 1931, Johnson and her co-pilot Jack Humphreys, became the first pilots to fly from London to Moscow in only one day. They completed the 2,830 km journey in approximately 21 hours and from there, they continued across Siberia and on to Tokyo, setting a record time for flying from Britain to Japan. The flight was completed in G-AAZV de Havilland DH.80 Puss Moth, named “Jason II”. Only one year later, the pilot set a solo record for the flight from London to Cape Town, South Africa in a Puss Moth, “G-ACAB”, named Desert Cloud. Her next flights were as a duo, she flew nonstop from Pendine Sands, South Wales, to the United States.However, their aircraft ran out of fuel and crash-landed in Bridgeport, Connecticut. In the accident, both pilots were injured, but received a ticker tape parade down Wall Street. Johnson was promoted to a First Officer around 1940, when she joined the Air Transport Auxiliary, which was responsible for transporting Royal Airforce aircraft around the country. Only one year later, the brave pilot flew an Airspeed Oxford for the ATA from Blackpool to RAF Kidlington near Oxford. She went off course in adverse weather conditions and it is assumed that she ran out of fuel. Johnson bailed out as her aircraft crashed into the Thames Estuary. Her parachute was spooted as she went down into the water and it is known that she was still alive at that point. However, conditions were poor and the woman faced a very heavy see and a strong tide. Also, snow was falling and it was intensely cold. During an attempt by a near by boat crew to rescue her, she died and her body could never be recovered. The circumstances under which the woman died are still quite a mystery. The exact reason for the flight is still a government secret and there is some evidence that besides Johnson and Fletcher, who attempted to rescue her, a third person was also seen in the water and also died. Who the third party was is still unknown. In 1999, it was officially reported, that Amy Johnson may have been shot down. Tom Mitchell, from Crowborough, Sussex claimed that “he reason Amy was shot down was because she gave the wrong colour of the day (a signal to identify aircraft known by all British forces) over radio“. Apparently, it became clear that it was Amy Johnson, who flew the plane only at the next day and Mitchell said that “the officers told us never to tell anyone what happened“. At yovisto, you may be interested in a historical video documentation on Amy Johnson.'],\n",
       " [157,\n",
       "  'The Legend of Bonnie and Clyde.  Bonnie Parker and Clyde Barrow between 1932 and 1934.  On May 23, 1934, the American robbers Bonnie and Clyde are ambushed by police and killed in Black Lake, Louisiana. Bonnie Elizabeth Parker and Clyde Chestnut Barrow became American pop folklore as outlaws and robbers when traveling the central United States with their gang during the Great Depression. Bonnie Elizabeth Parker got married to Roy Thornton shortly after they had dropped out of high school. The marriage was not considered as happy and they broke up quite soon even though they never got divorced. She worked as a waitress in Dallas and to her frequent customers belonged Ted Hinton, who would join the Dallas Sheriff’s Department in 1932 and participated in her ambush. Clyde Chestnut Barrow’s career as a criminal started when he was 17 and he first got arrested for the possession of stolen turkeys and for running from the police after failing to return a rental car on time. After several further crimes, he was sent to Eastham Prison Farm and there, he was sexually abused in and killed one man for doing so. His sister stated that “something awful sure must have happened to him in prison, because he wasn’t the same person when he got out“. Barrow continued his ‘career’ robbing grocery stores and gas stations, but it was said that “Barrow’s goal in life was not to gain fame or fortune from robbing banks, but to seek revenge against the Texas prison system for the abuses he suffered while serving time“. It is assumed that Bonnie and Clyde met on January 5, 1930. Clyde and his companions started a series of robberies in order to collect enough money and firepower to launch a raid of liberation against Eastham prison. They killed several people during their robberies including lawmen and by then, Clyde was accused of murder for the first time. Bonnie and Clyde brushed the law quite often already in this period. The gang attracted the police’s attention while discharging an automatic rifle while someone cleaned it. The officers assembled a five-man force in two cars on to confront what they suspected were bootleggers living in the garage apartment. The gang killed the detective and wounded another officer immediately and they fled the apartment while getting wounded themselves as well. The gang left most of their belongings including weapons, poems by Bonnie, undeveloped film rolls and official documents in the apartment. The group became quickly known as the Barrow Gang across the country. They continued their robberies ranging from Texas to Minnesota, not hesitating to kill or wound anyone. However, life got more and more difficult as the crimes continued. They avoided public places and got used to washing themselves in the rivers as well as preparing their food over camp fires. In 1933, the gang checked into the Red Crown Tourist Court in Missouri and started to attract attention through the way they dressed and behaved. Quickly, the police put the cabins under surveillance and shortly after the sheriff led a group of officers armed with Thompson submachine guns toward the cabins. This time, the gang was not as successful evading the law. One member was shot in the head and died a few days after surgery and another was captured. The remaining trio ranged far afield from their usual area of operations. When another member of the gang got arrested, Bonnie and Clyde were the only remaining gang members for a while. In January 1934, Clyde organized a jailbreak for Raymond Hamilton. During the attempt, prison officer Major Joe Crowson was shot, which resulted in a full power manhunt by the Texas and federal governments. Former Texas Ranger Captain Frank Hamer was contacted and persuaded to hunt down the Barrow Gang. In April of the same year, Bonnie and Clyde were accused of firing fatal shots at two young highway patrolmen and a 1000 USD reward was offered for the couple’s bodies. The public hostility towards the gang increased when a widower single father was killed. Hamer started tracking the gang in February, 1934 and studied their movements. The gang’s itinerary centered on family visits, and they were due to see their new partner’s family in Louisiana. Hamer expected this, and had obtained a quantity of civilian Browning Automatic Rifles and 20-round magazines with armor-piercing rounds. The posse concealed in the bushes, knowing the couple’s approximate location. When Clyde approached with his stolen Ford V8, the lawmen opened fire, killing Bonnie and Clyde while shooting a combined total of about 130 rounds. Researchers have said Bonnie and Clyde were shot more than fifty times and the officers inspected the vehicle and discovered an arsenal of weapons, including stolen automatic rifles, sawed-off semi-automatic shotguns, assorted handguns, and several thousand rounds of ammunition, along with 15 sets of license plates from various states. A large crowd gathered at the scene and policemen had to guard the bodies. Still, a woman managed to cut off bloody locks of Bonnie’s hair and pieces from her dress, which were then sold. One man even attempted to to cut off Clyde’s trigger finger. Within hours, the small town was estimated to swell in population from 2,000 to 12,000. At yovisto, you may be interested in video footage recorded shortly after the couple was shot.'],\n",
       " [158,\n",
       "  'Hergé and the Adventures of Tintin.  Hergé’s signature.  On May 22, 1907, Belgian cartonist Georges Prosper Remi, better known under his pen name Hergé, was born. His best known and most substantial work is the 23 completed comic books in The Adventures of Tintin series. Georges Prosper Remi grew up in the suburbs of Brussels, Belgium, which he considered as extremely boring. However, he developed a great interest in movies, especially the ones of Charlie Chaplin and Winsor McCay’s Gertie the Dinosaur. Furthermore, he enjoyed British and American novels like Huckleberry Finn, Treasure Island, Robinson Crusoe and The Pickwick Papers. He also began to sketch out scenes from his everyday life, which increased his enthusiasm in drawing. He was highly supported by his boy scout master, who published one of his drawings in a newsletter. Further publications in the Belgian boy scout newsletter followed and the young artist began experimenting with several pseudonyms, such as “Jérémie” or “Jérémiades“. “Hergé” is based on the pronunciation of his reversed initials (R.G.) and he first used his now famous pseudonym in December 1924. Hergé’s first published comic strip was titled “Les Aventures de Totor, C.P. des Hannetons” and revolved around the adventures of a Boy Scout patrol leader. He also sought guidance from an older cartoonist, Pierre Ickx, and together they founded the short lived Atelier de la Fleur de Lys, an organisation for Christian cartoonists. The young artist enrolled at in the École Saint-Luc art school, which he found boring and left after only one lesson. Due to his boredom, he enlisted for military service before he was called up, and in August 1926 was assigned to the Dailly barracks at Schaerbeek. He was still bored by the military training, but in his free time, he managed to continue sketching and producing episodes of Totor. When he met the editor of Le XXe Siecle, the Abbé Norbert Wallez, he was hired as a photographic reporter and cartoonist for the paper. In 1928, Wallez founded a newpaper supplement for children, Le Petit Vingtième. It appeared once a week and Hergé illustrated L’Extraordinaire Aventures de Flup, Nénesse, Puosette et Cochonet for the paper. However, he increasingly felt the need to publish a comic strip of his own. The front page of the 1 May 1930 edition of Le Petit Vingtième declared that “Tintin Revient!” (“Tintin Returns!”) from his adventure in the Soviet Union. The famous Tintin character was born. He was a Belgian boy reporter who traveled the world with his fox terrier, Milou. Although Hergé wanted to send his character to the United States, Wallez instead ordered him to set his adventure in the Soviet Union. The story was published as a series and even a book of Tintin’s adventured followed shortly after, which increased his fame even more. In his next adventure, the character was sent to Congo. Unfortunately, in later decades the story would be accused of racism, but at the time, it was un-controversial and popular. Tintin in America was serialized from September 1931 to October 1932. Hergé became quite famous and international newspapers started requesting his works. Further works of the period were The Lovable Mr. Mops and The Adventures of Tim the Squirrel Out West. From August 1934 to October 1935, Le Petit Vingtième serialised Tintin’s next adventure, The Blue Lotus. It was set in China and Hergé’s production work was highly influenced by his friend Zhang Chongren, a Catholic Chinese student. Zhang gave him lessons in Taoist philosophy, Chinese art, and Chinese calligraphy, influencing not only his artistic style but also his general outlook on life. Hergé added another character to his series, a young Chinese boy named Chang Chong-Chen who meets and befriends Tintin. The Blue Lotus has been widely considered as “Hergé’s first masterpiece“, due to high attention to accuracy, resulting in a largely realistic portrayal of China. In 1936, they also began production of Tintin merchandise, something Hergé supported,. He even developed the idea of an entire shop devoted to The Adventures of Tintin, which was accomplished about 50 years later. Hergé was mobilized as a reserve lieutenant during the Second World War and had to interrupt Tintin’s adventures. Le Petit Vingtième was shut down by the Nazi occupiers and Hergé launched The Crab with the Golden Claws, the first of six Tintin stories which he produced during the war. In the future, Hergé had to move the focus of Tintin’s adventures away from current affairs, in order to avoid controversy. Also, the comic strip was changed to a daily three- or four-frame strip instead of two complete pages every week. Therefore, Hergé had to introduce more frequent gags and faster-paced action. Hergé invented stories including an expedition to a meteorite, an intriguing mystery and treasure hunt, and a quest to undo an ancient Inca curse. During and after the German occupation Hergé was accused of being a collaborator because of the Nazi control of the paper, and he was briefly taken in for interrogation after the war. One of the last of Tintin’s adventures took place in Tibet. Tintin was sent to the Himalayas in search of Chang Chong-Chen, the Chinese boy he had befriended in The Blue Lotus. Hergé came to regard this highly personal and emotionally Tintin adventure as his favorite. Hergé’s financial success allowed him to travel across Europe, America, and Asia in his later working period. He passed away on 3 March 1983 and left the twenty-fourth Tintin adventure, Tintin and Alph-Art, unfinished. At yovisto, you may be interested in a video lecture titled “How to Create Characters” with an artist named Jazza.'],\n",
       " [159,\n",
       "  'Marcel Breuer – Master of Modernism.  A Ski Resort in France designed by Marcel Breuer.  On May 21, 1905, Hungarian-born modernist, architect and furniture designer of Jewish descent Marcel Breuer was born. Being one of the masters of Modernism, Breuer extended the sculptural vocabulary he had developed in the carpentry shop at the Bauhaus into a personal architecture that made him one of the world’s most popular architects at the peak of 20th-Century design. Marcel breuer (1905 – 1981) Marcel Breuer was one of the first students at the Bauhaus arts and craft school in Weimar, Germany. There, his talents were detected early and he became a faculty member of the school after it had moved to Dessau. Breuer was first recognized by the community for his steel furniture and he managed to make his living from these designs. Later on, Gropius assigned him Interiors at the 1927 Weissenhofsiedlung and led him to his first house assignment for the Harnischmachers in Wiesbaden in 1932. The designer moved to London due to the rise of the Nazi party in Germany in the 1930s. There, he was employed by Jack Pritchard at the Isokon company. The company was one of the earliest proponents of modern design in the United Kingdom and Breuer designed his Long Chair as well as experimented with bent and formed plywood there. His career moved on with F. R. S. Yorke. Breuer had designed several houses with the English Modernist before accepting the invitation by Gropius to follow his teacher and mentor to Massachusetts. Both designers created a completely new style of American housing, which was spread by their great collection of wartime students. The Geller House I of 1945 is one of the first to employ Breuer’s concept of the ‘binuclear’ house. It is characterized by separate wings for the bedrooms and for the living, dining, and cooking area. They are typically separated by an entry hall, and with the distinctive ‘butterfly’ roof. Breuer’s first two important institutional buildings were the UNESCO Headquarters in Paris in 1955. The projects were followed by nearly 100 houses in 30 years and he went through several design phases. Marcel Breuer passed away in 1981 in New York City. Breuer’s buildings were always distinguished by an attention to detail and a clarity of expression. He is widely considered one of the last true functionalist architects and he is believed to have shifted the bias of the Bauhaus from “Arts & Crafts” to “Arts & Technology”. Many pieces of modern, tubular steel furniture are still in use today, including the Cesca and Wassily chairs by Breuer himself. They are still in production and their origins can easily be traced back to the Breuer experiments of the mid-20’s. At yovisto, you may be interested in a video lecture on ‘Architecture in the Early 20th Century – Modernism‘ by Kenny Mencher.'],\n",
       " [160,\n",
       "  'Abraham Ortelius and the Theatrum Orbis Terrarum.  Ortelius World Map – Typus Orbis Terrarum 1570.  On May 20, 1570, Belgian cartographer and geographer Abraham Ortelius publishes the first modern atlas, the Theatrum Orbis Terrarum, in Antwerp. It consisted of a collection of uniform map sheets and sustaining text bound to form a book for which copper printing plates were specifically engraved. Abraham Ortelius was born in Antwerp, but grew up with his uncle after his father passed away at young age. In 1575, he was appointed geographer to the king of Spain on the recommendation of Arias Montanus, who vouched for his orthodoxy. During his life, Ortelius spent much time traveling through Europe and it is known that he spent much time in France, eastern Germany and Italy. However, Ortelius also started a career as a map engraver and entered the Antwerp Guild of Saint Luke as an illuminator of maps in 1547. He traded books, pints, maps, and even visited the book fair in Frankfurt and a print fair where he met the German cartographer, philosopher and mathematician Gerardus Mercator. The two men traveled to Trier, Lorraine, and Poitiers and Ortelius was highly influenced by Mercator and motivated to become a scientific geographer. Ortelius‘ famous first map, Typus Orbis Terrarum was published in 1564 and depicted a large wall map of the world. In the following years, he also published a map of Egypt, a plan of the Brittenburg castle on the coast of the Netherlands, and maps of Asia and Spain. An important milestone for Ortelius himself, but also for the research work in ancient geography was the masterpiece Synonymia geographica, published in 1578. In the expanded form of the work, Ortelius writes about the possibility of continental drift. This hypothesis was proven correct several centuries later. Alfred Wegener played a major role in the later research work on the topic around 1912. The first modern atlas, as it is called today, was published on 20 May 1570 and titled Theatrum Orbis Terrarum. It consisted of 53 maps and it was translated in several languages, such as Dutch, German, and French. During Ortelius‘ lifetime, 25 editions were published and several others followed posthumously. The masterpiece inspired a six volume work entitled Civitates orbis terrarum, edited by Georg Braun and illustrated by Frans Hogenberg with the assistance of Ortelius himself. In In 1573 Ortelius published seventeen supplementary maps under the title Additamentum Theatri Orbis Terrarum. Next to his maps, Ortelius also had a great interest and gathered an impressive collection of coins, medals and antiques, and this resulted in the book Deorum dearumque capita … ex Museo Ortelii. At yovisto, you may be interested in a short explanation of the Abraham Ortelius’ World Map from 1571.'],\n",
       " [161,\n",
       "  'Alcuin of York and the Carolingian Renaissance.  Carolingian Manuscript, Rabanus Maurus (left), with Alcuin (middle), dedicating his work to Archbishop Odgar of Mainz (right) On May 19, 804 AD, English scholar, ecclesiastic, poet and teacher Alcuin of York passed away. At the invitation of Charlemagne, he became a leading scholar and teacher at the Carolingian court. He wrote many theological and dogmatic treatises, as well as a few grammatical works and a number of poems. According to Einhard’s Life of Charlemagne, Alcuin was “the most learned man anywhere to be found”. Alcuin grew up in Yorkshire as the son of a nobleman. He attended the internationally well known school in York, mostly famous for its liberal arts, literature, and science, as well as in religious studies. He graduated, became a teacher and deacon in the church in the 750s. Even though he used to live his life as a monk, he was never ordained a priest or became a monk officially. It is assumed that he met Charlemagne for the first time in 781 in Parma. He convinced Alcuin to follow his invitation to Aachen, where he was appointed teacher of a renowned school. Later on, Alcuin is believed to have said that “the Lord was calling me to the service of King Charles“. He was welcomed at the Palace School of Charlemagne in Aachen around 782. The school was founded by Charles’ ancestors as a place to educate the royal children. Charlemagne also wanted to include liberal arts as well as religion. Alcuin not only taught the royal children, but also the king himself and his sons Pepin and Louis. Alcuin managed to create a personalized atmosphere of scholarship and learning, and the school became later well known as the “school of Master Albinus“. Alcuin had a great influence on the young elite of the area and was already considered as one of the greatest scholars of his time. Next to his teaching duties, he took his role as a religious and political advisor very seriously and his ideas were highly respected by the emperor. Alcuin tackled him over his policy of forcing pagans to be baptised on pain of death, arguing, “Faith is a free act of the will, not a forced act. We must appeal to the conscience, not compel it by violence. You can force people to be baptised, but you cannot force them to believe“. These arguments seem to have prevailed, because Charlemagne decided to abolish the death penalty for paganism in 797. Charlemagne was known to befriend many of his men at court and they used to refer to him as ‘David’. Also Alcuin found himself on intimate terms with Charlemagne and the other men at court. Alcuin returned to England in 790, but came back to help Charlemagne in the fight against the Adoptionist heresy which was at that time making great progress in Toledo. Alcuin is believed to have had contacts with Beatus of Liébana, from the Kingdom of Asturias, who fought against Adoptionism. He upheld the orthodox doctrine and obtained the condemnation of the heresiarch Felix of Urgel. Having failed during his stay in Northumbria to influence King Æthelred in the conduct of his reign, Alcuin never returned home. He continued working at Charlemagne’s court and retired from his duties in 796. Alcuin passed away on 19 May, 804. During his lifetime, Alcuin wrote numerous letters that are now an important source of information concerning the literary and social conditions of the time and a reliable authority for the history of humanism during the Carolingian age. Today, he is considered as the most prominent figure of the Carolingian Renaissance. At yovisto, you may be interested in a video lecture by Professor Paul Freedman, who discusses the Carolingian dynasty from its origins through its culmination in the figure of Charlemagne'],\n",
       " [162,\n",
       "  'Beaumarchais and Figaro\\'s Wedding.  On May 18, 1799, French playwright Pierre-Augustin Caron de Beaumarchais passed away. Bonmarchais, who also was a watchmaker, inventor, musician, diplomat, fugitive, spy, publisher, horticulturalist, arms dealer, satirist, financier, and revolutionary (both French and American), is best known for his theatrical works, most notably the three Figaro plays.   Born in the Rue Saint-Denis, Paris on 24 January 1732 as a provincial watchmaker\\'s son, Beaumarchais rose in French society and became influential in the court of Louis XV as an inventor and music teacher. At the time, pocket watches were commonly unreliable for timekeeping and were worn more as fashion accessories. In response to this, young Beaumarchais spent nearly a year researching improvements. In July 1753, at the age of twenty one, he invented an escapement for watches that allowed them to be made substantially more accurate and compact. One of his greatest feats was a watch mounted on a ring, made for Madame de Pompadour, a mistress of Louis XV. The invention was later recognised by the Academy of Sciences, but only after a dispute with Lepaute, the royal watchmaker, who attempted to pass off the invention as his own. The affair first brought Beaumarchais to national attention and introduced him to the royal court at Versailles.   In 1756, at age 24, Beaumarchais married a rich widow who died a year later. He found himself with a fortune -- the first of several he made and then lost. Musically talented, he became harp teacher to the daughters of Louis XV in 1759. In 1764 he made a journey to Spain to protect or vindicate his sister, who had been abandoned by her betrothed, Clavigo. His account of this mission in his Mémoires suggested the drama Clavigo to Goethe. He brought from Madrid a knowledge of things Spanish that was later of much use to him. He now turned to the drama, wrote Eugénie (1767), a fairly successful domestic drama, and Les deux amis, a decided failure in the pathetic vein. Meantime he had become engaged in financial speculations that led to lawsuits, and these to a series of Mémoires, appeals to the public that are among the most vigorous, audacious, clever, and witty polemics in literature. Their attack on judicial injustice gave them a universal interest. They were eagerly read and deepened the discontent with the existing state of society that was to culminate in the French Revolution.   Beaumarchais thus became a political personality. In 1776, after the remnants of George Washington\\'s American army had crossed the Delaware into Pennsylvania in 1776, and British troops prepared to seize the rebel capital of Philadelphia, Beaumarchais wrote to French foreign minister Vergennes: \"The Americans will triump, but they must be assisted in their struggle. We must . . . send secret assistance in a prudent manner to the Americans.\" France joined the American War of Independence against Britain officially in 1778, but Beaumarchais had already supplied arms to the American colonies. Beaumarchais was confidentially employed by Louis XV and later by Louis XVI; but before this he had snatched a sensational dramatic triumph out of failure by rearranging a comic opera into a five-act comedy-his Barbier de Séville (1775), Spanish in scene, but essentially French at the heart; the most famous comedy of the century, save only its sequel from the same hand.   The Barber of Seville and The Marriage of Figaro showed Beaumarchais sympathy for the lot of the under-privileged people and the lower classes. In both plays the hero is a valet, Figaro, who is more clever than his noble employers, especially his master Almavira. In these class-conscious plays Beaumarchais mocked aristocracy although he was well-aware of his dependance on its favour. This also created a constant tension in his dramas – much is said and much is written between the lines. Mozart\\'s opera version of the play was based on the libretto written by Lorenzo da Ponte. It gained a huge popularity. \"Here they talk about nothing but Figaro. Nothing is played, sung or whistled but Figaro,\" wrote Mozart to a friend from Prague. By his writings, Beaumarchais contributed greatly, though quite unconsciously, to hurry on the events that led to the French Revolution. When the French Revolution broke out, Beaumarchais was no longer the idol he had been a few years before. He was financially successful, mainly from supplying drinking water to Paris, and had acquired ranks in the French nobility.   Nevertheless, Beaumarchais pledged his services to the new republic. He attempted to purchase 60,000 rifles for the French Revolutionary army from Holland, but was unable to complete the deal. While he was out of the country, Beaumarchais was declared an émigré (a loyalist of the old regime) by his enemies. He spent two and a half years in exile, mostly in Germany, before his name was removed from the list of proscribed émigrés. He returned to Paris in 1796, where he lived out the remainder of his life in relative peace.   Although we don\\'t have anything directly related with Beaumarchais, at yovisto you can listen to a lively introduction into Mozart\\'s Magic Flute opera from San Diego Opera talk.'],\n",
       " [163,\n",
       "  'The Myserious Voynich Manuscript.  A page from the mysterious Voynich manuscript In 1912, Polish-born antiquarian and bibliophile Wilfrid Voynich bought a mysterious illustrated codex hand-written in an unknown writing system that may have been composed in Northern Italy during the Italian Renaissance. The eponymous Voynich manuscript has been studied by many professional and amateur cryptographers, but no one has yet succeeded in deciphering the text. Therefore, it has become a famous case in the history of cryptography. The manuscript counts about 240 pages in total, but it is assumed that several pages are missing. The text was written from left to right and patterns similar to those of natural languages were revealed by statistical analysis. Still, it was found that the manuscript’s “language” is quite unlike European languages since there are no words with fewer than two letters or more than ten and it seems to be more repetitive than typical European languages. Another difficult aspect is, that the lettering resembles European alphabets of the late 14th and 15th centuries, but the words do not seem to make sense in any language. It was found out that the manuscript probably consists of six sections and except the last one, every section and even almost every page contains various illustrations. The sections were examined concerning their content and given conventional names. The so called herbal section contains at least one plant on each page, which are not unambiguously identifiable. In the astronomical section, many diagrams can be found with suns, moons, and stars. Further sections are probably of biological, cosmological, and pharmaceutical purpose. It is assumed that the manuscript was created between 1404 and 1438 and the McCrone Research Institute in Chicago found that the paints in the manuscript were of materials to be expected from that period of European history. It was also suggested that the book originally belonged to Emperor Rudolf II and that at some point, Athanasius Kircher owned the book as well. When Wilfrid Voynich passed away, the manuscript was inherited by his widow and then changed the owners several times before it was donated to Yale University in 1969 where it was catalogued as “MS 408“. Since the day the examinations on the book started, the first hypothesis considering its author were developed. In a letter to Kircher, it was suggested that the author was the Franciscan friar and polymath Roger Bacon. However, this is not the only theory. Many historians came across the name Edward Kelly, who was a self-styled alchemist and claimed to be able to invoke angels through a shewstone and had long conversations with them. The angels’ language was called Enochian, after Enoch, the Biblical father of Methuselah. Several people have suggested that Kelley could have fabricated the Voynich manuscript to swindle the emperor. In concerns of the book’s langages, many hypothesis came up as well. It was suggested that the text could be a constructed language, others however prefer to believe that “the basis of the script was a very primitive form of synthetic universal language” (John Tiltman). Another theory is called the “letter-based cipher” theory. It suggest that the text contains a meaningful text in a European language, that was intentionally rendered obscure by mapping it to the Voynich manuscript “alphabet” through a cipher of some sort, an algorithm that operated on individual letters. This has been the working hypothesis for most twentieth-century deciphering attempts, including an informal team of NSA cryptographers. Further theories suggest that the text is made of a little-known natural language or that it contains a certain code to be looked up in a codebook. Unfortunately of all the theories, nothing was completely proven and the mystery of the manuscript had quite a cultural impact. Several books, and papers were written about the book itself and also fiction works were published. This includes Russel Blake’s “Voynich Cypher“. At yovisto, you may be interested in a video lecture on possible interpretations of the Voynich Manuscript by Stephen Bax.'],\n",
       " [164,\n",
       "  'The Phantastic Travels of Adelbert von Chamisso.  Adelbert von Chamisso (1781-1831). On January 30, 1781, German poet and naturalist of French Origin Adelbert von Chamisso was born. Some of his lyrics, ballads, and romances rank among the finest in German literature. He took part in Captain Kotzebue‘s Russian polar expedition (1815-18) and his 1835 published account of it ranges among the classics of travel. In the same way as Johann Wolfgang von Goethe, one of Germany‘s best known poets, Adelbert von Chamisso was as well a scientist as an author and artist. Today unfortunately, almost all Germans might have heart of Goethe, but only a few are familiar with Chamisso. On the other hand, Chamisso has his own island: Chamisso Island, a small island in Kotzebue Sound, Alaska. While Goethe‘s travels only led him to Italy once in a lifetime or to some Bohemian spas for health treatments, Chamisso as a botanist, travelled to the other side of the world collecting specimens. And as far as I know, Goethe has never written a science fiction story like Chamisso‘s ‘Peter Schlemihl‘s Miraculous Story‘. Adelbert von Chamisso was born as Louis Charles Adélaïde de Chamissot at Ante, in Champagne, France. Driven out by the French Revolution, his parents settled in Berlin, where in 1796 young Chamisso obtained the post of page-in-waiting to the Prussian queen, and in 1798 entered a Prussian infantry regiment as ensign. He had little education, and while in the Prussian military service in Berlin assiduously studied natural science for three years. In 1803, incollaboration with Varnhagen von Ense, he founded the Berliner Musenalmanach, in which his first verses appeared. Unfortunately, this enterprise was a failure, and, interrupted by the war, it came to an end in 1806. However, it brought him to the notice of many of the literary celebrities of the day and established his reputation as a rising poet. Shortly thereafter, upon the Peace of Tilsit in 1807 signed by Napoleon Bonaparte and Russian Tsar Alexander I, Chamisso‘s family was permitted to return to France. Nevertheless, young Chamisso remained in Germany and continued his military career. He had become lieutenant in 1801, and in 1805 accompanied his regiment to Hameln, where he shared in the humiliation of its treasonable capitulation in the following year. Placed on parole, he went to France, but both his parents were dead. In 1808 returning to Berlin he obtained his release from the service. Homeless and without a profession, he lived in Berlin until 1810, when, by intermediation of an old friend of the family, Chamisso was offered a professorship at the lycée at Napoléonville in the Vendée. On his way to France, he joined the intellectual circle of Madame de Staël, one of Napoleon‘s principal opponents, and followed her in her exile in Switzerland, where he devoted himself to botanical research. Illustration of Peter Schlemihl, who sold his shadow to the Devil After his return to Berlin, he published his famous narrative ‘Peter Schlemihl’s Miraculous Story‘, about a man who sold his shadow to the devil for a bottomless wallet, which has been translated into most European languages. The story, intended for children, was widely read and the character became a common cultural reference in many countries. People generally remembered the element of the shadow better than how the story ended, simplifying Chamisso‘s lesson to the idiom “don’t sell your shadow to the Devil.” In 1815, Chamisso was appointed botanist to the Russian ship Rurik, which Otto von Kotzebue commanded on a scientific voyage round the world. His diary of the expedition (Tagebuch, 1821) is a fascinating account of the expedition to the Pacific Ocean and the Bering Sea. During this trip Chamisso described a number of new species found in what is now the San Francisco Bay Area. Several of these, including the California poppy, Eschscholzia californica, were named after his friend Johann Friedrich von Eschscholtz, the Rurik’s entomologist. In return, Eschscholtz named a variety of plants, including the genus Camissonia, after Chamisso.   On his return in 1818 he was made custodian of the botanical gardens in Berlin, and was elected a member of the Academy of Sciences. In 1827, he published Views and Remarks on a Voyage of Discovery, and Description of a Voyage Round the World. Chamisso‘s travels and scientific researches restrained for a while the full development of his poetical talent, and it was not until 1829 that he turned back to literature. In collaboration with Gustav Schwab, and Franz von Gaudy, he brought out the Deutscher Musenalmanach, in which his later poems were mainly published. As a poet Chamisso‘s reputation stands high. Frauenliebe und -leben (1830), a cycle of lyrical poems set to music by Robert Schumann, by Carl Loewe, and by Franz Paul Lachner, is particularly famous. He died in Berlin at the age of 57. At yovisto you can learn more about Adelbert von Chamisso, who took part in a Russian expedition around the world on board the sailing ship Rurik from 1815 to 1818, in the video from the Natural History Museum Berlin.'],\n",
       " [165,\n",
       "  'Francis Baily and the Baily Beads.  Francis Baily (1774-1844). On May 15, 1836, English astronomer Francis Baily for the first time observed the so-called ‘Baily’s beads‘ during an eclipse of the Sun. For sure you know the effect, although you might not have seen it with your own eyes in nature. But, numerous photographs, pictures, and videos have been published, where the phenomenon can be watched. So what are Beailey’s beads? The Baily’s beads effect is a feature of total solar eclipses. As the moon “grazes” by the Sun during a solar eclipse, the rugged lunar limb topography allows beads of sunlight to shine through in some places, and not in others. Lunar topography has considerable relief because of the presence of mountains, craters, valleys and other topographical features. The irregularities of the lunar limb profile are known accurately from observations of grazing occultations of stars. Astronomers thus have a fairly good idea which mountains and valleys will cause the beads to appear in advance of the eclipse. While Baily’s beads are seen briefly for a few seconds at the center of the eclipse path, their duration is maximized near the edges of the path of the umbra, reaching 1–2 minutes. The most spectacular version is the diamond ring effect that is seen when only one bead is left; a shining diamond set in a bright ring around the lunar silhouette. The name of the phenomenon is in honor of Francis Baily who first provided an exact explanation of the phenomenon in 1836. Born 28th April 1774 in Newbury, Berkshire, the son of Richard Baily, a banker, Francis started a mercantile apprenticeship at the age of fourteen. After a tour in the unsettled parts of North America in 1796–1797 – his journal of his American adventures was posthumously edited and published by mathematician Augustus de Morgan in 1856, Baily entered the London Stock Exchange in 1799. As a financial expert he was very successful and also published several important works on various aspects of the financial world, such as Tables for the Purchasing and Renewing of Leases (1802), or The Doctrine of Interest and Annuities (1808). He succeeded in earning a fortune through diligence and integrity and retired from business in 1825, to devote himself wholly to his most favourite hobby: astronomy. Actually, Baily was a founding member of the Royal Astronomical Society in 1820, serving as its first secretary. “Baily Beads” at the Solar eclipse from 1999 In 1827, Baily received the Gold Medal of the Royal Astronomical Society for his preparation of the Society’s Catalogue of 2881 stars. Later, he even was elected as president of the society for four consecutive two-year terms prior to his death. Baily seemed to have been possessed with exactness and preciseness. Thus, he was outraged by the inaccuracies in the Nautical Almanac, the tables seamen used to determine longitude by the moon distance method so he edited and correct them for the Board of Longitude. Editing such tables is rather tedious work, but Baily even went one step further. While working on the Nautical Almanac he complained that there was no star catalogue available that met the standards of accuracy necessary for his work so he set out to correct the problem. Over the following years Baily edited, corrected and published the star catalogues of Ptolemaeus, Ulugh Beg, Tycho Brahe, Halley, Flamsteed, Hevelius, Mayer, Lacaille, and D’Agelet and Lalande. No wonder that he was rewarded the academy’s Gold medal again in 1843. Baily’s observations of “Baily’s Beads”, during an annular eclipse of the sun on 15 May 1836, at Inch Bonney in Roxburghshire, started the modern series of eclipse expeditions. His description of the phenomenon was so vivid as to attract an unprecedented amount of attention to the total eclipse of 8 July 1842, observed by Baily himself at Pavia. Baily died in London on 30 August 1844 and of course there is a crater on the Moon named after the most laborious astronomer. At yovisto you can learn more about Solar eclipses in the presentation of Prof. Peter Cole about the 1919 Solar Eclipse Expedition where Eddington was able to give a proof for Einstein’s theory of general relativity.'],\n",
       " [166,\n",
       "  'The Airplanes of Claude Dornier.  Claude Dornier in front of the Do K-3 image: German Federal Archive.  On May 14, 1884, German airplane builder and entrepreneur Claudius Dornier was born. His legacy remains in the few aircraft named after him, including the Dornier Do 18 and the 12-engine Dornier Do X flying boat, for decades the world’s largest and most powerful airplane. Dornier studied engineering at the Technical University of Munich and began his career in Karlsruhe in 1907. Unfortunately, his father fell very ill and could not take care of his wine shop anymore. Dornier now had to finance his entire family and take care of his father’s business. In 1910, he was hired by Luftschiffbau Zeppelin GmbH and he attracted attention through his brilliance in engineering, his innovative mind and economic success. He invented the rotatable zeppelin hangar and made significant contributions to the construction process of zeppelins. With the significant advancements of French engineers building aircraft heavier than air, Dornier’s interest in the topic increased as well. Count Ferdinand Zeppelin decided to go in two different directions. On the one hand he wanted to build very large aircraft and on the other hand he told Dornier to construct a flying boat. Along with his team of engineers, Dornier moved into a newly built hangar outside Friedrichshafen, where they built the flying boats Rs I – IV. In 1917, the engineer managed to transform his department into an independent company of the Zeppelin group. After the war, Dornier began building a six-passenger aircraft as well and performed the very successful maiden-flights in June, 1919. Dornier’s problems came up, when the general construction of military aircraft was prohibited in Germany. Fortunately, three of Dornier’s passenger aircraft remained and were built, but in 1920 any aircraft construction was banned. Dornier got creative and rented a small shed in Rohrschach, Switzerland, where he continued making more aircraft parts. Working from home with his team, they managed to improve his Gs I plane model, which was the foundation for the famous Do X flying boat that was developed in the later 1920s. However, with the starting economic crisis in fall 1929, the aircraft industry decreased dramatically. The economy of the aircraft industry started with the nomination of Hermann Göring as the German aeronautics commissioner. When Hitler came into power, the German Air Force was immediately expanded and Dornier had just finished the development of the Do F, an airplane that was described as a cargo plane but was really a bomber. After several changes, the bomber Do 13 was produced starting in 1933.  In the following years, Dornier also made profit from international deals with the Do 24, another flying-boat for maritime patrol, search and rescue. But next to military projects, the engineer also devoted much of his life time to improving his flying-boat models in order to cross the Atlantic Ocean and designed the Do 214. However, Germany got ready for war and projects like these were no longer allowed. The parts of the plane that were already built had to be destroyed and the development was completely put on ice. Dornier was now appointed to build only the military planes that were ordered by the government. The engineer faced difficult times after the war as well. Even though he was not seen as a threat by the Allied Forces, his company’s hangars and offices were destroyed or confiscated. In Switzerland and Spain he began to rebuild his business until he managed to return to Germany in the 1950s. At yovisto, you may be interested in a video documentation on the Do X, at the time the largest aircraft. It took off for its first Atlantic crossing on 5 November, 1930.'],\n",
       " [167,\n",
       "  'Igor Sikorsky and the Helicopter.  Igor Sikorsky in his VS-300 helicopter.  On May 13, 1940, Russian American aviation pioneer Igor Ivanovitsch Sikorsky made the maidenflight with his newly developed helicopter VS-300, which led to the R-4, the world’s first mass-produced helicopter in 1942. Sure we all know helicopters today. They have become an everyday object, although not everybody of us already had the chance to fly with a helicopter. Actually, I had the pleasure to fly as helicopter passenger during my time of service in the airforce. I really enjoyed flying on a low profile following the terrain, being also able to look down through the glass that was part of the bottom of the aircraft. The principle of a helicopter is that its wings are not fixed as for a plane. Instead the wings move (rotate) and create a lift. Thus, the helicopter is able to fly also vertically. The principle behind a helicopter actually is rather old. The earliest references for vertical flight have come from China. Since around 400 BC, Chinese children have played with bamboo flying toys. This bamboo-copter is spun by rolling a stick attached to a rotor. The spinning creates lift, and the toy flies when released. It was not until the early 1480s, when Leonardo da Vinci created a design for a machine that could be described as an “aerial screw”, that any recorded advancement was made towards vertical flight. His notes suggested that he built small flying models, but there were no indications for any provision to stop the rotor from making the craft rotate. In 1861, the word “helicopter” was coined by Gustave de Ponton d’Amécourt, a French inventor who demonstrated a small, steam-powered model. While celebrated as an innovative use of a new metal, aluminum, the model never lifted off the ground. In 1906, two French brothers, Jacques and Louis Breguet, began experimenting with airfoils for helicopters. In 1907, those experiments resulted in the Gyroplane No.1. Although there is some uncertainty about the dates, sometime between 14 August and 29 September 1907, the Gyroplane No. 1 lifted its pilot into the air about two feet (0.6 m) for a minute. The Gyroplane No. 1 proved to be extremely unsteady and required a man at each corner of the airframe to hold it steady. Helicopters were developed and built during the first half-century of flight, with the Focke-Wulf Fw 61 being the first operational helicopter in 1936. The Fw 61 broke all of the helicopter world records in 1937, and Nazi Germany used helicopters in small numbers during World War II for observation, transport, and medical evacuation. But it was not until 1942 that a helicopter designed by Russian-born engineer Igor Sikorsky reached full-scale production, with 131 aircraft built. By the time Igor Sikorsky competed with Lawrence LePageto to produce the U.S. military’s first helicopter. LePage received the patent rights to develop helicopters patterned after the Fw 61, and built the XR-1, an early American twin-rotor helicopter, winner of a United States Army Air Corps design competition held in early 1940. But, the flight testing of the XR-1 proved troublesome. Meanwhile, Sikorsky settled on a simpler, single rotor design, the VS-300, which turned out to be the first practical single lifting-rotor helicopter design. After experimenting with configurations to counteract the torque produced by the single main rotor, Sikorsky settled on a single, smaller rotor mounted on the tailboom. The cyclic control was found to be difficult to perfect, and led to Sikorsky locking the cyclic and adding two smaller vertical-axis lifting rotors to either side aft of the tail boom. By varying pitch of these rotors simultaneously, fore and aft control was provided. Roll control was provided by differential pitching of the blades. In this setup, it was found that the VS-300 couldn’t fly forward easily and Sikorsky joked about turning the pilot’s seat around. Sikorsky fitted utility floats (also called pontoons) to the VS-300 and performed a water landing and takeoff on 17 April 1941, making it the first practical amphibious helicopter. Developed from the VS-300, Sikorsky’s R-4 was the first large-scale mass-produced helicopter, with a production order for 100 aircraft. The R-4 was the only Allied helicopter to serve in World War II, when it was used primarily for rescue in Burma, Alaska, and other areas with harsh terrain. Total production reached 131 helicopters before the R-4 was replaced by other Sikorsky helicopters such as the R-5 and the R-6. In all, Sikorsky produced over 400 helicopters before the end of World War II. At yovisto you can learn more about the history of early helicopters in a short documentary produced for Encyclopedia Britannica, now part of the Prellinger archive on Helicopters from 1953.'],\n",
       " [168,\n",
       "  'Florence Nightingale – The Lady with the Lamp.  A hospital at Scutari where Nightingale worked 1856.  On May 12, 1820, celebrated British social reformer and statistician Florence Nightingale was born. She is best known for being the founder of modern nursing. She came to prominence while serving as a nurse during the Crimean War, where she tended to wounded soldiers. She was known as “The Lady with the Lamp” after her habit of making rounds at night. It is known that Florence Nightingale was a very well educated young woman and she realized the lack of opportunity for females in her social circle quite early. It is assumed that she had a very good relationship with her father, who was involved in anti-slavery movements. He was known to have respected his daughter as a friend and companion and supported her education highly. Florence started to visit people living in poverty and her interest in helping ill people increased highly in her early years. Florence often came to London to investigate possible occupations for women in the city’s hospitals. Unfortunately, nurses were not very much respected, since the occupation did not require a decent education at that time. Her visits became more frequent around 1844, but in this period, she also took time to travel to Egypt and Paris and she managed to get an introduction to a convent at Alexandria. She noticed that the disciplined and well-organised Sisters made better nurses than women in England. Following these events, Florence Nightingale attended the Institute of Protestant Deaconesses at Kaiserswerth, a training school for women teachers and nurses. Florence Nightingale (1820 – 1910) A major milestone in Florence Nightingale’s life was the beginning of the Crimean War in 1854. It was reported that sick and heavily wounded people suffered in English camps and in the media it was pointed out how different the conditions for wounded soldiers in French camps were. A shout out to all women in England was made to help the people of their country in need. Nightingale decided to go to the Crimea approximately in October of the same year and embarked with over thirty other nurses, reaching Scutari during the eve of the battle of Inkerman. Nightingale functioned as Superintendent of the Female Nurses in the Hospitals in the East, but everyone just called her the Lady in Chief. The headquarters for the newly arrived nurses was the barrack hospital at Scutari. The place was described as incredibly filthy and Nightingale explained that there was no water, soap, clothes or enough food when she arrived. The soldiers just laid there in their uniforms, spreading the infectious diseases. Next to the lack of sufficient supplies, the nurses also had to face the offensive behavior of the orderlies. Fortunately, Nightingale and her crew managed to improve the situation at the hospital. More and more support, supplies and food were sent and Nightingale established a vast kitchen and a laundry. Next to the full time job at the hospital, Nightingale also took time to take care of the soldiers’ families and made rounds, watching the wounded soldiers at night since she was the only nurse allowed in the wards. The men started calling her the Lady with the Lamp. Henry Wadsworth Longfellow then popularized the phrase with his poem Santa Filomena (extract): Lo! in that house of misery A lady with a lamp I see Pass through the glimmering gloom, And flit from room to room. With all the ill people in the hospital and the bad working condition for the doctors and nurses, many of them got sick or even passed away themselves. Also, the frost-bite and dysentery from exposure in the trenches before Sevastopol made the wards fuller than before and the death-rate increased to 42% by February 1855. Nightingale was not immune to the infectious diseases as well. When she visited Balaclava, she fell ill with the so called Crimean fever, but fortunately recovered and resumed her work in Scutari later on. In 1856, Florence Nightingale returned home and entered England without anyone noticing. She got the chance to meet Queen Victoria and Prince Albert, telling them about the miserable situation and then, a fund had been set up to found a training school for nurses. The Nightingale School and Home for Nurses was established at St. Thomas’s Hospital and she watched the progress of the new institution with practical interest even though she was asked to be its superintendent. Her health began to decline so she preferred to settle in London and retire from her busy work life. In this period, she published several works and reports on the army medical departments in the Crimea. In the following years, the first military hospital was established and an army medical college was opened at Chatham. Nightingale immediately offered to leave for India when the Indian Mutiny broke out in 1857. Even though her services were not required, she became interested in the sanitary condition of the army and people there. From her work, a Sanitary Department was established in the Indian government. She became familiar with many facets of Indian life and demanded that there should be improvements in health and sanitation there. Florence Nightingale passed away on 13 August 1910. At yovisto, you may be interested in a historical video lecture by Barbara Dossey on Florence Nightingale at the University of Alabama.'],\n",
       " [169,\n",
       "  'The very first Printed Book.  The frontispiece of the Diamond Sutra from Tang Dynasty China, the world’s earliest dated printed book, AD 868 (British Museum) On May 11, 868, the earliest dated printed book was issued, a Chinese copy of the so-called Diamond Sutra, one of the most important textbooks of Buddhism, originally written in the 1st c. AD. You might think the it was Johannes Gutenberg who invented modern printing. But, he didn’t. Sure, printing with metal movable types including a printing press and a suitable ink, but mostover a way to produce movable types in sufficient quality and sufficient number with few effort, this was Gutenberg’s most notable invention. Printing itself existed long before Gutenberg. Especially, if you think of woodcuts or so-called woodblock printing. The earliest woodblock printed fragments to survive are from China and are of silk printed with flowers in three colors from the Han Dynasty (before AD 220 ). It is clear that woodblock printing developed in Asia several centuries before Europe. The Chinese were the first to use the process to print solid text, and equally that, much later, in Europe the printing of images on cloth developed into the printing of images on paper (woodcuts). It is also now established that the use in Europe of the same process to print substantial amounts of text together with images in block-books only came after the development of movable type in the 1450s. Because Chinese has a character set running into the thousands, woodblock printing suits it better than movable type to the extent that characters only need to be created as they occur in the text. Although the Chinese had invented a form of movable type with baked clay in the 11th century, and metal movable type was invented in Korea in the 13th century, woodblocks continued to be preferred owing to the formidable challenges of typesetting Chinese text with its 40,000 or more characters. The oldest existing print done with wood-blocks is the Mugujeonggwang great Dharani sutra that is dated between AD 704 and 751. It was found at Bulguksa, South Korea in 1966. But, the print we focus today is a wood block printed copy in the British Library which, although not the earliest example of block printing, is the earliest example which bears an actual date. The book displays a great maturity of design and layout and speaks of a considerable ancestry for woodblock printing. The extant copy has the form of a scroll, about 5 meters long. The archaeologist Sir Marc Aurel Stein purchased it in 1907 in the walled-up Mogao Caves near Dunhuang in northwest China from a monk guarding the caves - known as the “Caves of the Thousand Buddhas“. The colophon, at the inner end, reads: Reverently made for universal free distribution by Wang Jie on behalf of his two parents on the 15th of the 4th moon of the 9th year of Xiantong [11 May 868]. This is more than 500 years before the Gutenberg Bible was first printed. How did the technique come to Europe and the Western world? Block-books, where both text and images are cut on a single block for a whole page, appeared in Europe in the mid-15th century. As they were almost always undated and without statement of printer or place of printing, determining their dates of printing has been an extremely difficult task. The technique of woodblock printing is found through East and Central Asia, and in the Byzantine world for cloth, and by AD 1000 examples of woodblock printing on paper appear in Islamic Egypt. Printing onto cloth had already spread much earlier, and was common in Europe by 1300. Around the 13th century the Chinese technique of blockprinting was transmitted to Europe, soon after paper became available in Europe. The print in woodcut, later joined by engraving, quickly became an important cultural tradition for popular religious works, as well as playing cards. Although many had believed that (European) block books preceded Gutenberg’s invention of movable type in the first part of the 1450s, it now is accepted that most of the surviving block books were printed in the 1460s or later, and that the earliest surviving examples may date to about 1451. They seem to have functioned as a cheap popular alternative to the typeset book, which was still very expensive at this stage. Block books continued to be printed sporadically up through the end of the 15th century and were then more and more replaced by their movable type alternatives that have become less expensive. At yovisto, you can learn more about the future of books in a video conversation of Dan Clancy and John Hollar on “Books, Google and the Future of Digital Print“.'],\n",
       " [170,\n",
       "  'Caspar Monge and the Geometry.  (1746 – 1818).  On May 10, 1746, French mathematician Gaspard Monge, Comte de Péluse was born. He is best known for being the inventor of descriptive geometry as the mathematical basis of technical drawing, and being the father of differential geometry. During the French Revolution Monge served as the Minister of the Marine, and was involved in the reform of the French educational system, helping to found the École Polytechnique. Monge, the son of a merchant, was taught at the college of the Oratorians at Beaune and the Collège de la Trinité at Lyon. When Monge was only 17 years old, he was appointed teacher of physics. He began to invent his own instruments in order to complete a large-scale plan of the city of Beaune. Monge’s work was very well received and it was displayed in the local library were it remained until today. A local engineer saw Monge’s masterpiece as well and he recommended the young scientist to the École Royale du Génie at Mézières where he started as a draftsman. However, Monge was unfortunately not allowed admission to the institution itself. He became widely known for his great manual skills, but his mathematical skills were not yet discovered. After a year at the École Royale, Monge was asked to produce a plan for a fortification in order to optimize the city’s defense. Instead of calculating the problems, Monge found his solutions through drawings. As a result of Monge’s work, his reputation grew dramatically. Monge was appointed instructor in experimental physics in 1770 and in 1786 he wrote and published his Traité élémentaire de la statique. Gaspard Monge was known to be a very strong supporter of the French Revolution. He accepted the office of Minister of the Marine in 1792. When the Committee of Public Safety made an appeal to the academics to assist in the defence of the republic, he applied himself wholly to these operations, and distinguished himself by his energy, writing the Description de l’art de fabriquer les canons and Avis aux ouvriers en fer sur la fabrication de l’acier. Monge made great contributions in the establishment of the school for public works, later on the École Polytechnique. There, Monge was appointed professor for descriptive geometry and later on even director of the institute. In the following period, Monge joined Napoleon Bonaparte’s expedition to Egypt, taking part in the scientific work of the Institut d’Égypte and the Egyptian Institute of Sciences and Arts. After Egypt, he followed Bonaparte to Syria and returned to France in 1798. Gaspard Monge passed away on 28 July, 1818 and in Beanue, a statue portraying him was erected a few years after. Monge is considered the father of differential geometry because of his work Application de l’analyse à la géométrie, in which he introduced the concept of lines of curvature of a surface in 3-dimensional space. He developed a general method of applying geometry to problems of construction. He also introduced two planes of projection at right angles to each other for graphical description of solid objects. These techniques were generalized into a system called géométrie descriptive, which is now known as orthographic projection, the graphical method used in modern mechanical drawing. At yovisto, you may be interested in a video lecture on Differential Geometry by Professor Wildberger.'],\n",
       " [171,\n",
       "  'Thomas Blood and the Crown Jewels of England.  Thomas Blood (1618 – 1680).  On May 9, 1671, Anglo-Irish officer and desperado Colonel Thomas Blood attempted to steal the Crown Jewels of England from the Tower of London. Not much is known about Thomas Blood’s early life. It is assumed that he was born to a successful blacksmith in Ireland. His father owned some land across the country and his grandfather was a member of the Parliament. Historians believe, that he went to England with the outbreak of the Civil War in 1642 and initially took up arms with the Royalist forces loyal to Charles I. However, as the conflicts went on, he switched sides, becoming a lieutenant in Oliver Cromwell’s Roundheads. When King Charles II was restored to the Crowns of the Three Kingdoms in 1660, Blood fled back to Ireland along with his entire family. However, he faced bad times considering his financial situation and attempted to cause insurrection along with his fellows in misery. Blood began to seek action and suggested to storm Dublin Castle, and kidnap the 1st Duke of Ormonde and Lord Lieutenant of Ireland for ransom. However, the plot was foiled and Blood escaped to the United Dutch Provinces, even though several of his collaborators were caught and executed. During his time in the Dutch Republic, Thomas Blood became got to know the 2nd Duke of Buckingham, wealthy George Villiers. Historians now believe that the Duke who used Blood in order to punish his own political and social adversaries. Blood returned to England soon even though he was still a wanted man. He changed his name and it is believed that he started working as a doctor. By this time, he came to realize that Ormonde had taken up residence at Clarendon House. On the night of 6 December 1670, Blood and his accomplices attacked Ormonde. He was dragged from his coach, and taken on horseback along Piccadilly with the intention of hanging him at Tyburn. A paper was pinned to his chest explaining reasons for his capture and execution. However, Ormonde managed to free himself and ran away. Thomas Blood was not suspected of the crime, even though a reward was offered for the capture of the attempted assassins. Not even one year later, Blood began to plan his next coup – the theft of the Crown Jewels. He visited the Tower of London dressed as a parson and accompanied by a woman who pretended to be his wife, willing to see the Crown Jewels. When they arrived, the woman feigned a stomach complaint and was taken care of by Master of the Jewel House, 77-year-old Talbot Edwards and his wife. A few days later, the thief returned to Edwards and became friends with his family, gaining their trust. He managed to convince Edwards to show the jewels to him and Blood attacked him in order to take off with the jewelry. Soon, the alarm was raised, but until this day, it is not completely known how this happened. It is assumed that Edwards’ son, Wythe shouted, “Treason! Murder! The crown is stolen!”. Blood and his gang fled but he was captured before reaching the Iron Gate. The crown was found but a few stones were missing. Blood then refused to answer to anyone, but the king and as a result he was not only pardoned but also given land in Ireland. The reasons for this decision remain unknown until this day. Thomas Blood passed away on 24 August, 1680. At yovisto, you may be interested in a video documentary on the attempted theft of the Crown Jewels by Thomas Blood.'],\n",
       " [172,\n",
       "  'Mary the Jewess and the Origins of Chemistry.  Mary the Prophetess (ca. 1st to 3rd century AD) Mary the Jewess (also known as Maria Prophetissima or Miriam the Prophetess) is a figure who first appeared in the works of the Gnostic Christian writer Zosimos of Panopolis, whose sources for this are not clear. On the basis of Zosimos’s comments, she lived between the first and third centuries A.D. She is credited with the invention of several kinds of chemical apparatus and is considered to be the first true alchemist of the Western world. The very first nonfictious alchemists of the Western world lived, as far as can be ascertained, in Hellenistic Egypt. Among these also was Mary the Jewess for whom our chief source is Zosimos of Panopolis, an early alchemist and Gnostic mystic from the end of the 3rd and beginning of the 4th century AD. He wrote the oldest known books on alchemy, of which quotations in the Greek language and translations into Syriac or Arabic are known. Unfortunately, Zosimus‘ misidentified Maria as ‘Mirjam’ the sister of Moses. Nevertheless, Zosimus‘ writing are our most important source for the history of alchemy in antiquity. He is one of about 40 authors represented in a compendium of alchemical writings that was probably put together in Byzantium (Constantinople) in the 7th or 8th century AD and that exists in manuscripts in Venice and Paris. Zosimos provided one of the first definitions of alchemy as the study of “the composition of waters, movement, growth, embodying and disembodying, drawing the spirits from bodies and bonding the spirits within bodies.” “One becomes two, two becomes three, and out of the third comes the one as the fourth.” (known as the ‘Axiom of Maria‘) We know very little about Mary and her life. Zosimos only described several of Mary’s experiments and instruments. In his writings, Mary is almost always mentioned as having lived in the past, and she is described as “one of the sages.” George Syncellus, a Byzantine chronicler of the 8th century, presented Mary as a teacher of the philosopher Democritus, whom she had met in Memphis, Egypt, during the time of Pericles. The famous 10th century index of Arabic books Kit?b al-Fihrist of Ibn al-Nadim cited Mary as one of the 52 most famous alchemists and stated that she was able to prepare caput mortuum, a purple pigment. The Roman philosopher Morieno called her “Mary the Prophetess,” and the Arabs knew her as the “Daughter of Plato” — a name which, in Western alchemical texts, was reserved for white sulfur. An alchemical balneum Mariae Although none of Mary’s writings have survived, some quotations credited to her are found in hermetic writings. The most notable of these are found in The Dialogue of Mary and Aros on the Magistery of Hermes, which is an extract made by an anonymous Christian philosopher. There are several alchemistical apparatuses which Maria either invented or which she gave a description of, according to Zosimos‘ writings. The tribikos was a kind of alembic with three arms that was used to obtain substances purified by distillation. The kerotakis is a device used to heat substances used in alchemy and to collect vapors. It is an airtight container with a sheet of copper upon its upper side and thus, it is an early predecessor of today’s pressure-cooker. The kerotakis was said to be a replication of the process of the formation of gold that was occurring in the bowels of the earth. Mary’s name survives in her invention of the bain-marie, which is extensively used in chemical processes for which a gentle heat is necessary. She also left us with several procedures, among them also the preparation of the philosopher’s stone. But, as always in alchemy, the description of procedures most times are more enigmatic than enlightening, as e.g. “Invert nature and you will find that which you seek.” (from the description of the preparation of the philosopher’s stone) At yovisto, you may be interested in a video lecture [in German] on Aspasia and Diotima as part of a lecture series featuring women in philosophy.'],\n",
       " [173,\n",
       "  'Carl Hagenbeck and the Modern Zoo.  Portrait Carl Hagenbeck and Walrus Pallas 1911.  On May 7, 1907, German merchant of wild animals Carl Hagenbeck founded Germany’s most successful privately owned zoo, the Tierpark Hagenbeck. He created the modern zoo with animal enclosures without bars that were closer to their natural habitat. Already his father, Gottfried Hagenbeck, who was originally a fish dealer started displaying and trading animals in the mid-19th century. In 1866, Carl Hagenbeck joined his father’s business and started to expand it to one of the biggest of its kind in Germany. During the early years of his business activities, Hagenbeck sent only a few expeditions to Africa in order to catch wild animals but soon he organized expeditions around the globe. In this period, Hagenbeck discovered a completely new business model, which is today seen as extremely controversial. He opened some sort of ‘human zoo‘ in 1875. The first exhibition included a demonstration of the Sami people. The spectators were able to see their “everyday life” at the exhibition area and the show became so successful, that Hagenbeck soon moved on to Berlin and Leipzig, Germany. He began displaying further groups including African families and Inuits. When Hagenbeck opened his modern zoo, he had more space and added more groups from various countries. Until this day, Hagenbeck it criticized for his ‘human zoo‘, because the exhibited people received extremely low wages and they were often confronted with false promises concerning their stay in Germany. Hagenbeck’s circus opened in 1887. Three years later he began to perform at several exhibitions with tamed wild animals. Hagenbeck also started planning his revolutionary zoo without barred cages, which he even filed a patent for. The modern zoo opened on 5 May 1907 in Stellingen, north of Hamburg, which still exists on this day. One of the most famous exhibitions in the famous zoo was the walrus Pallas you can see in the image above. The portrait was painted in 1911 and is still displayed at the ‘Hamburger Kunsthalle‘, a famous art museum in the city. Throughout the years, Hagenbeck’s concept of the modern zoo spread and was furtherly developed. Zoo directors also began making conservation a central topic and stopped the practice of having animals perform tricks for visitors. The very first safari park was opened in England in 1931. Visitors were able to drive through the enclosures and come into close proximity to the animals. However, the concepts of zoos in general stayed a controversial topic until this day. Mass destruction of wildlife habitat has yet to cease all over the world and many species are in danger of dying out. Today’s zoos hope to stop or slow the decline of many endangered species. Many zoos see their primary purpose as breeding endangered species in captivity and reintroducing them into the wild. Some critics say that zoos, no matter what their intentions are, are immoral and serve nothing but fill human leisure. However, zoo advocates argue that their efforts make a difference in wildlife conservation and education. Talking of conservation strategies in zoos, you may be interested in a video lecture on the conservation of the Spotted Owl at Sequoia Park Zoo by biologist Lowell Diller.'],\n",
       " [174,\n",
       "  'Adolph von Knigge and Human Relations.  Adolph von Knigge (1752 – 1796).  On May 6, 1796, Freiherr Adolph Franz Friedrich Ludwig Knigge passed away. In Germany, Knigge is best remembered for his book ‘Über den Umgang mit Menschen‘ (On Human Relations), a treatise on the fundamental principles of human relations that has the reputation of being the authoritative guide to behaviour, politeness, and etiquette. Knigge grew up to a nobel, but poor family and when his parents passed away in early age, he inherited their debts and was sent to Hannover in order to continue his studies. Knigge enrolled at the University of Göttingen in order to study law in 1769. Afterwards, he was appointed member of the court and assessor of the chamber of warfare of the city of Kassel. In later years, he changed the position and was appointed chamberlain in the city of Weimar. However, his interest in writing increased as much as his contempt for life on court. He moved to Frankfurt to devote most of his lifetime to literature. In his later life in Bremen, he became known as a supporter of the local culture scene, especially theater. In 1788, the very first edition of his book ‘Über den Umgang mit Menschen’, which is today simply known as ‘Knigge‘ was published. Further editions appeared in the following years and Knigge faced an instant success with his work and after his death, numerous editions followed with the introduction of behavior rules. The modern ‘Knigge‘ we know today was born. Now, we associate ‘Knigge‘ with good manners and behavior even though this is not, what the author intended. According to Knigge, the book gives an introduction to the social interactions influenced by the ideals of the enlightenment. Furthermore, the author discusses sociological and social-psychological topics. Knigge also gives insights into his historical, literary, and journalistic knowledge. The work consists of three major parts. In the first section, Knigge gives an introduction to human relations and he explains how a person interacts with others concerning their different natures and tempers. In the next part he describes these aspects concerning a person’s family followed by a description of a person’s interaction with animals. The book was translated into the English language and published in 1805 titled ‘Practical Philosophy of Social Life: Or the Art of Conversing with Men‘. In later years, Knigge’s work was increasingly mistaken as a guide to behavior and politeness. After Knigge’s death, the publisher expanded the original work with behavior rules, which even strengthened the ‘error’. At yovisto, you may be interested in a video lecture on the Age of Enlightenment. Professor Dustin Champion discusses, why the ideas of the period still matter today.'],\n",
       " [175,\n",
       "  'You Press the Button and We Do the Rest – George Eastman revolutionized Photography.  George Eastman (1854-1932). On May 5, 1885, George Eastman filed a patent for a “Roll Holder for Photographic Films“, which was the first film in roll form to prove practicable. Based on his newly invented roll film and a rather simple camera for that film, he established the Eastman Kodak Company, in Rochester, New York. It was one of the first firms to mass-produce standardized photography equipment. Ok, please hold on before you are writing me comments that George Eastman has not invented the roll film. Actually, already in 1881 a farmer in Cambria, Wisconsin, Peter Houston, invented the first roll film camera. His younger brother David, filed the patents for various components of Peter’s camera. He was issued an 1881 patent for a roll film holder which he licensed to George Eastman (it was used in Eastman’s Kodak 1888 box camera). Houston sold the patent outright to Eastman for $5000 in 1889. BTW, Roll film was also the basis for the invention of motion picture film in 1888 by the world’s first film-makers Eadweard Muybridge and a few years later by their followers Thomas Edison and the Lumière Brothers. But, today’s post deals with George Eastman. Eastman was born the youngest of three children on July 12, 1854, in Waterville, upstate New York to George Washington Eastman and Maria Eastman. George Sr. had started a small business school, Eastman Commercial College, in Rochester, where he moved the family in 1860. But he died suddenly when George Jr. was 8. To support the family, George’s mother had to take boarders. Thus, young George left school early and started working to add to the family income. He began as a messenger and office boy for insurance companies for only $3 a week and studied accounting at home to qualify for a higher salary, leading to a job as bookkeeper at the Rochester Savings Bank. At age 24, George planned to visit Santo Domingo, where a boom in land speculation was underway, and, on the advice of a colleague, decided to document the trip with photographs. But the photography equipment with all the required tools of the “wet plate” era alone was enormous, heavy and costly. The camera alone was as big as a microwave oven and needed a heavy tripod. And he carried a tent so that he could spread photographic emulsion on glass plates before exposing them, and develop the exposed plates before they dried out. Instead taking the trip, he began to research how to make photography less cumbersome and easier. After reading about a formula for a “dry plate” emulsion in a British magazine and with the help of two local amateur photographers – George Monroe and George Selden – , Eastman formulated a gelatin-based paper film and a device for coating dry plates. Plates coated with this emulsion remained sensitive after they were dry and could be exposed at leisure. Using a formula taken from one of these British journals, Eastman began making gelatin emulsions. He resigned from his bank job after launching his fledgling photography company in April 1880, because he had not only invented a dry plate formula, but had patented a machine for preparing large numbers of the plates. Eastman’s experiments were directed to the use of a lighter and more flexible support than glass. His first approach was to coat the photographic emulsion on paper and then load the paper in a roll holder. The holder was used in view cameras in place of the holders for glass plates. In 1884, Eastman hired William Hall Walker, a camera inventor and manufacturer, and together they designed the Eastman-Walker Roll Holder, which allowed photographers to advance paper film through a camera rather than handle individual plates. The roll holder came to define the basic technology of cameras until the introduction of digital photography in the late twentieth century. While the first Kodak camera was wildly popular with amateurs, the paper film used in it gave mediocre results. Henry Reichenbach, a chemist hired to work on emulsions, was asked to come up with a transparent, flexible film, and he succeeded in February 1889. In 1888 Eastman invented the word “Kodak” as a distinctive name for a film camera he was developing. He needed a strong, short, distinctive word that would also meet foreign trademark laws, and the letter “K” was a personal favorite of Eastman’s. According to him, “It became a question of trying out a great number of combinations of letters that made words starting and ending with ‘K.’ The word ‘Kodak’ is the result.” But, the overall success did not only come from inventing the new type of camera alone. Moreover, Eastman took care of the entire lifecycle of taking photographs. Thus, enabling also the Pre-loaded with enough film for 100 exposures, the Kodak camera could easily be carried and handheld during its operation. After the film was exposed (all the shots taken), the whole camera was returned to the Kodak company in Rochester, New York, where the film was developed, prints were made, new photographic film was inserted, and then the camera and prints were returned to the customer. “You press the button, we do the rest” promised George Eastman in 1888 with this advertising slogan for his Kodak camera. Eastman pioneered an employee dividend system that made his workers part-owners of the firm, and he gave millions of dollars to the Rochester Institute of Technology, University of Rochester, and Massachusetts Institute of Technology. In 1932, Eastman’s health started to fade and the age of 77 he shot himself in the head, leaving a note that read simply, “To my friends: My work is done. Why wait?” At yovisto you can learn more about the history of photography in the presentation of Nancy Crandall about the origins and beginnings of photography.'],\n",
       " [176,\n",
       "  'How the Pope divided the New World among Spain and the Rest of the World.  The Cantino planisphere of 1502 shows the line of the Treaty of Tordesillas. On May 4, 1493, Pope Alexander VI issued the papal bull ‘Inter caetera‘ (Among other [works]), which granted to Spain all lands to the “west and south” of a pole-to-pole line 100 leagues west and south of any of the islands of the Azores or the Cape Verde islands. In the late 15th century, Spain and Portugal had a quite difficult relationship due to their competing explorers and the wish to own as many colonial territories as possible along the African coast line. The previous years, several papal bulls were issued and the Spanish government came to realize the authority of these bulls. They initiated diplomatic discussions over the rights to possess and govern the newly found lands. Even though the Spanish and Portuguese delegates debated and negotiated for several months concerning this topic, they could not find any agreement. Spain then contacted Pope Alexander VI, who was known to be befriended with the Spanish King. They urged the pope to issue a new bull favorable to Spain. Alexander VI did so and issued four edicts in May 1493. The third superseded the first two, and the fourth, titled Inter caetera, superseded the third. A fifth edict, Dudum siquidem of 26 September 1493, supplemented the Inter caetera. The Inter Caetera was followed by the Treaty of Tordesillas and together they defined and delineated a zone of Spanish rights exclusive of Portugal. However, the agreement was illegal in relation to other states, even though Spain spent much time and effort to persuade further European leaders on the validity. At first, it was unclear whether lands to the east of the line would belong to Portugal. At this point, Portugal had reched Africa, but not yet India. These lands were given to Portugal through the Aeterni regis, a bull from 1481. But, in the bull Dudum siquidem, the pope granted Spain the territory in the eastern waters as well. These events led to the Treaty of Tordesillas between Spain and Portugal, about one year after the bull was issued. The treaty moved the line further west to a meridian 370 leagues west of the Portuguese Cape Verde Islands, now explicitly giving Portugal all newly discovered lands east of the line. The treaty also allowed the two countries to pass each other toward the west or east, and still possess whatever lands they were first to discover. An important effect of the combination of this papal bull and the Treaty of Tordesillas was that nearly all the Pacific Ocean and the west coast of North America were given to Spain. In response to Portugal’s discovery of the Spice Islands in 1512, the Spanish put forward the idea, in 1518, that Pope Alexander had divided the world into two halves. Further European states now claimed that the Pope had not the right to convey sovereignty of regions as vast as the New World. On this day, numerous groups, representing indigenous people of the Americas have organized protests and raised petitions seeking the repeal of the papal bull Inter caetera. They claim, the bull led to the subjugation of their folks, and they want to remind Catholic leaders of the record of conquest, disease and slavery in the Americas. At yovisto, you may be interested in a video lecture by Emily O’Brien, who talks about “The Good, the Bad, and the Ugly: Reflections on the Renaissance Papacy“.'],\n",
       " [177,\n",
       "  'SPAM Rules the Internet.  On May 3, 1978, the earliest documented spam (although the term had not yet been coined) was sent as a message advertising the availability of a new model of Digital Equipment Corporation computers sent by Gary Thuerk to 393 recipients on ARPANET. Today, spam has become a global issue that is not only restricted to email. There is spam in instant messaging, newsgroups, social networks, mobile phones, online gaming, search engines, blogs, wikis, video platforms, etc. Spam is simply everywhere in the internet. Spam is not only annoying, spam can also be dangerous, because can be used to spread computer viruses, trojan horses or other malicious software. Have you ever wondered, where the word comes from? Well here’s the story. According to the Internet Society and other sources, the term spam is derived from the 1970 Spam sketch of the BBC television comedy series Monty Python’s Flying Circus. The sketch is set in a cafe where nearly every item on the menu includes Spam canned luncheon meat. As the waiter recites the Spam-filled menu, a chorus of Viking patrons drowns out all conversations with a song repeating “Spam, Spam, Spam, Spam… lovely Spam! wonderful Spam!“, hence “Spamming” the dialogue. Spam is a canned precooked meat product made by the Hormel Foods Corporation, first introduced in 1937. While most people assume spam is short for “spiced ham,” only a handful of people know its true origin. The name was actually suggested in naming contest by Ken Daigneau, a Hormel VP’s brother, before the product was introduced in 1937. Daigneau won a naming contest and $100. Other theories include “special processed American meat” and “shoulders of pork and ham.” According to Brad Templeton, founder of ClariNet Communication Corporation, the first business on the Internet, the first email spam was sent out to all users on ARPANET, which had only several hundreds of users by the time. It was an ad for a presentation by Digital Equipment Corporation sent out by Gary Thuerk. Rather than send a separate message to each person, which was the standard practice at the time, he had an assistant, Carl Gartley, write a single mass e-mail. Reaction from the net community was fiercely negative, but the spam did generate some sales – and a new business method was born. It was not until 1993 that a USENET posting was called “spam.” In an attempt to implement a retro-moderation system that allowed posts to be deleted after they had been posted, Richard Depew accidentally created a monster. His software, ARMM, had a bug in it which caused it to post 200 messages to the newsgroup news.admin.policy. Readers of this group were making jokes about the accident, one person referring to the incident as “spamming.” Thus, spam received its name. The first major commercial spam incident started on March 5, 1994, when a husband and wife team of lawyers, Laurence Canter and Martha Siegel, began using bulk Usenet posting to advertise immigration law services. The incident was commonly termed the “Green Card spam“, after the subject line of the postings. Defiant in the face of widespread condemnation, the attorneys claimed their detractors were hypocrites and a that they had a free speech right to send unwanted commercial messages. Spam continues simply because it seems to work. According to a Commtouch report in the first quarter of 2010, there are 183 billion spam messages sent every day. More than 97% of all emails sent over the net are unwanted, according to a Microsoft security report. The most popular spam topic is “pharmacy ads” which make up 81% of email spam messages, followed by replicas, enhancers, phishing emails, university degrees, and online casinos. Advance fee fraud spam such as the “Nigerian connection” may be sent by a single individual from a cyber cafe in a developing country. Organized “spam gangs” operate from sites set up by the Russian mafia, including turf battles and revenge killings. Spam is also a medium for fraudsters to scam users into entering personal information on fake Web sites using emails forged to look like they are from banks or other organizations, such as PayPal. This is known as phishing. Targeted phishing, where known information about the recipient is used to create forged emails, is known as spear-phishing. Spamming is illegal. Sending spam violates the Acceptable use policy (AUP) of almost all Internet service providers. All the countries of the European Union have passed laws that specifically target spam. Today, every user can take measures against spam by setting up a spam filter. Today’s spam filters are often based on probabilistic techniques such as naive Bayes filtering. Bayesian filters rely on word probabilities. If a message contains many words that are used only in spam, and few that are never used in spam, it is likely to be spam. But, it has become a rat race. Spam provider are constantly weakening Bayesian filters by include lines of irrelevant, random words in their spam messages, a technique known as Bayesian poisoning. Thus, despite having switched on a spam filter that learns with every email I mark as spam, more than 50% of my daily email messages are still spam. Sometimes, I am afraid, where this will end… At yovisto, you can learn more about spam detection in a Google Tech Talk: “WITCH – A new approach for spam detection‘.'],\n",
       " [178,\n",
       "  'Johann Carolus and the First Newspaper.  Title page of the Relation aller Fürnemmen und gedenckwürdigen Historien from 1609 Most likely in late September 1605, the very first weekly printed newspaper was published by Johann Carolus in Straßburg, the contemporary boomtown of printing. Not much is known about Johann Carolus’ life or his way of becoming a publisher. Carolus was probably born on 26 March, 1575 and was taught mostly by private teachers in Straßbourg. The well young educated man was then apprenticed as a bookbinder. Carolus’ career basically started with his marriage to Anna Fröhlich. The woman not only became his partner for life but also his supporting business partner. Also, Carolus achieved the city’s right to found a company through the marriage. Only two years after their marriage, the young couple purchased a house. It was recorded that in their contract, Carolus already identified himself as “Buchführer”, meaning that he already was some sort of bookseller. It is also assumed that at this point, Carolus was often thinking of giving up the bookbinding entirely. Even though, Carolus and his wife were highly in debt already, they made another huge investment in July 1604. For the very large amount of 3.724 Gulden, they acquired Straßburg’s biggest printing house, which originally belonged to Thobias Jobin. It included three big printing presses, letters, a big load of paper as well as a whole warehouse full of unbound books. Carolus became widely known as a very brilliant businessman and he managed to even hire seven employees very soon after the investment. Still, the pressure on the young businessman increased and he had to think of new ways to guarantee a financial stability for his company. In 1604, Carolus started to deliver a very small amount of weekly news, which where copied by hand to a few people of the upper class. One year later, Carolus had another brilliant idea when he came to think that a much greater amount of people would like to read the weekly news. In order to reach more people, Carolus had to change the production procedure and figured out that he had to print and sell an enormous amount of newspapers in order to make profit. This was very risky since Carolus had no idea if that many people were willing to pay for it. Fortunately for him, the business model was very successful and he printed four to six pages every week. The first weekly printed newspaper was born and was titled ‘Relation aller Fürnemmen und gedenckwürdigen Historien‘. At the beginning, Carolus was the only editor of the newspaper and later on he was helped by a theologian. However, Carolus faced trouble after about three years of publishing. He published the news about financial difficulties of the government and only two days later it was decided that Carolus had to be more careful and before publishing anything critical, he was advised to consult the government. This became known as the first censorship incidence. After these conflicts, Carolus openly announced that more censorship in the future would may cause financial difficulties for his business. Carolus then estarted to censor his own articles and his business stayed successful. At yovisto, you may be interested in a TED talk titled ‘Free Press‘ by Sasa Vucinic.'],\n",
       " [179,\n",
       "  'Orson Welles’ Citizen Kane.  Citizen Kane – Theatrical Release Poster.  On May 1st, 1941, Orson Welles famous movie ‘Citizen Kane‘ premiered at RKO’s flagship theatre, Radio City Music Hall. The film was directed, co-written, produced by, and starring Orson Welles. It was nominated for Academy Awards in nine categories and won an Academy Award for Best Writing (Original Screenplay) by Herman Mankiewicz and Welles. Citizen Kane often is considered by critics, filmmakers and fans to be the greatest film ever made. “Rosebud…” (Opening line; his last word as Charles Foster Kane dies.) Welles’s notoriety following The War of the Worlds broadcast earned him Hollywood’s interest, and RKO offered him a rather unusual contract in 1939. The studio’s offer was to produce, direct, write, and act in two feature films, where the studio only had to approve the story and the budget if it exceeded $500,000. Welles, only 25 years of age, was allowed to develop the story without interference, cast his own actors and crew members, and have the privilege of final cut – unheard of at the time for a first-time director. There is dispute amongst historians regarding whose idea it was to use William Randolph Hearst as the basis for Charles Foster Kane. Welles claimed it was his idea while others claim that it was the idea of screenwriter Herman J. Mankiewicz. Mankiewicz had frequented Hearst’s parties until his alcoholism got him barred. Hearst had great influence and the power to retaliate within Hollywood, so Welles had Mankiewicz work on the script outside of the city. Welles‘ and Mankiewicz’s work at the studio with their new script evolved smoothly and scene after scene were shot on the set with a unique spontaneity. Many things have been said about the techniques, the groundbreaking methods and the special effects they used. They didn’t break every ground in techniques, many things they used had actually been achieved before, but they certainly refined it together and managed some amazing effects. The work of photographer Gregg Toland’s was especially instrumental for the film, unquestionable so, also Welles’s visual journey through the years of Charles Foster Kane, the aging masks used in his face, was something brand new in make-up art. They even hacked out floors to sink cameras deep down under floor level to get an extremely low angle, the way they showed ceilings, the way they worked with lights and shadows. In the end, Welles and his crew were in the process of seeking new inventive forms of how to make movies and they set completely new standards to cinematography. Among the most impressive techniques applied by Welles are the use of a subjective camera as well as unconventional lighting, including chiaroscuro, backlighting and high-contrast lighting, prefiguring the darkness and low-key lighting of future film noirs. Moreover there was the inventive use of shadows and strange camera angles, following in the tradition of German Expressionists in the style of F.W. Murnau. But what is most striking are the deep-focus shots with incredible depth-of field and focus from extreme foreground to extreme background. But, let’s have a look at the plot. Newspaper tycoon William Randolph Hearst, who lived at San Simeon in California, clearly influenced Charles Foster Kane’s character. This becomes obvious when we’re going through the film and follow Kane around as a journalist, as as a politician, as owner of the pleasure ground Xanadu. Citizen Kane tells the story of Charles Foster Kane whose arrogance had alienated him from everyone who loved him, and who had died alone inside the vast gothic pile of his lonely castle in Florida. The complex and pessimistic theme of a spiritually-failed man is told from several, unreliable perspectives and points-of-view by several different characters – the associates and friends of the deceased – providing a sometimes contradictory, non-sequential, and enigmatic portrait. Its the thought-provoking, tragic epic story of a ‘rags-to-riches’ child who inherited a fortune, taken away from his poor family and being raised by a banker, becoming a fabulously wealthy, arrogant, and energetic newspaperman. After two failed marriages and a transformation into a morose, grotesque, and tyrannical monster, his final days were spent alone and unhappy before his death in a reclusive refuge. Throughout the film the discovery and revelation of the mystery of the life of Charles Foster Kane is determined through a reporter’s search for the meaning of his single, cryptic dying word: “Rosebud“. Citizen Kane never did get a proper national release. It could not play in major theaters in many cities, because they were block-booked by the big studios, which boycotted the film. Of course it could not be advertised in the influential Hearst papers. And although the film was instantly hailed by many critics, it won only one Academy Award – which Welles shared with Herman J. Mankiewicz, for the screenplay, although it as originally nominated for nine awards. In a 1941 review, Jorge Luis Borges called Citizen Kane a metaphysical detective story, in that subject (both psychological and allegorical) is the investigation of a man’s inner self, through the works he has wrought, the words he has spoken, the many lives he has ruined. The film, budgeted at $800,000, received unanimous critical praise, although it was not a commercial success until it was re-released after World War II, found well-deserved recognition in Europe. In the United States, it was neglected and forgotten until its revival on television in the mid-1950s. RKO was one of the first studios to sell its library to television. At the same time, Welles returned to the New York stage, where he played King Lear, by which the movie gained new popularity. In 1958 finally, a poll of over 100 film historians named Citizen Kane one of the top ten greatest films ever made. Currently, Citizen Kane has a 100% rating at Rotten Tomatoes. Learn more about famous film director and actor Orson Welles at yovisto in an Question and Answer session at Boston University taken at 1979.'],\n",
       " [180,\n",
       "  'J. J. Thompson and the Electron.  J. J. Thomson (1856 – 1940).  On April 30, 1897, English physicist Joseph John Thomson gives the first experimental proof of the electron, which had been already theoretically predicted by Johnstone Stoney. Thomson was awarded the 1906 Nobel Prize in Physics for the discovery of the electron and for his work on the conduction of electricity in gases. Joseph John Thompson was born in 1856 in Manchester, England and was taught mainly in private schools at the beginning. In 1876, he enrolled at Trinity College, Cambridge where he received his Bachelor’s and Master’s degree. When Thompson became Cavendish Professor of Physics, Ernest Rutherford was among his students and later on, he succeeded Thompson in the post. Thompson was known to be an excellent teacher. Seven of his research assistants and his son were able to win the Nobel Prizes in physics. Thompson himself was awarded the famous prize in 1906 “in recognition of the great merits of his theoretical and experimental investigations on the conduction of electricity by gases.” Two years later, he was knighted. In 1918, Thompson became Master of the Trinity College in Cambridge. The fact that atoms were built up from a more fundamental unit was already suggested by scientists like William Prout or Norman Lockyer. However, J. J. Thompson was the first known scientist to suggest that the fundamental unit was over 1000 times smaller than an atom. Today, the subatomic particle is known as the electron. To achieve this discovery, Thompson used his explorations on the properties of cathode rays. He published his suggestion on 30 April 1897 following his discovery that Lenard rays could travel much further through air than expected for an atom-sized particle. At first, he estimated the mass of cathode rays through the heat that was generated when the rays hit a thermal junction. Then Thompson compared his result with the magnetic deflection of the rays. As a result, Thompson could suggest that cathode rays were more than 100 times lighter than the hydrogen atom and also, he concluded that their mass was the same in whichever type of atom they came from. He then concluded that the rays were composed of light and negatively charged particles, a universal building block of atoms. Thompson named the particles “corpuscles”, but scientists preferred the name electron which had been suggested by George Johnstone Stoney prior to Thompson’s discovery. One month after Thompson’s important announcement of the corpuscle he found that he could reliably deflect the rays by an electric field if he evacuated the discharge tube to a very low pressure. By comparing the deflection of a beam of cathode rays by electric and magnetic fields he obtained more robust measurements of the mass to charge ratio that confirmed his previous estimates. This became the classic means of measuring the charge and mass of the electron. Thomson believed that the corpuscles emerged from the atoms of the trace gas inside his cathode ray tubes. He concluded that atoms were divisible, and that the corpuscles were their building blocks. To explain the overall neutral charge of the atom, he proposed that the corpuscles were distributed in a uniform sea of positive charge. His model became widely known as the “plum pudding” model of atoms. Ernest Rutherford disproved this model later on with his famous gold foil experiment, which led to the discovery of the nucleus. J. J. Thomson’s cathode ray tube with electromagnetic deflection coils Next to this famous discovery, Thompson and his research assistant F. W. Aston channeled a stream of neon ions through a magnetic and an electric field. They measured its deflection and observed two patches of light on the photographic plate, which was placed in the path. They concluded, that neon is composed of atoms of two different atomic masses (isotopes), which was the first evidence for isotopes of a stable element. Also, Thompson’s separation of neon isotopes by their mass was the first example of mass spectrometry. In 1905, Thomson discovered the natural radioactivity of potassium and one year later he managed to demonstrate that hydrogen had only a single electron per atom. At yovisto, you may be interested in a very easily to understand lecture on the Discovery of the Electron by Tyler DeWitt.'],\n",
       " [181,\n",
       "  'Henri Poincaré – the Last Universalist of Mathematics.  Henri Poincaré (1854 – 1912).  On April 29, 1854, French mathematician, theoretical physicist, engineer, and a philosopher of science Henri Poincaré was born. He is often described as a polymath, and in mathematics as The Last Universalist since he excelled in all fields of the discipline as it existed during his lifetime. Jules Henri Poincaré was born near France and excelled in every class from the very beginning. It is assumed that his mother had a conversation with his teacher, when he was about 13 years old. The teacher told her that “Henri will become a mathematician … I would say a great mathematician“. However, when Poincare graduated in 1871 and only received the grade ‘fair’ in science. In mathematics, Poincare received zero points, it is assumed that he answered the wrong questions. Two years later, Poincare enrolled at the École Polytechnique and again, he excelled in every subject, but graduated only as the second in class due to his inability to draw. Poincare submitted a dissertation on partial differential equations and he was then put in charge of the course on differential and integral calculus at the University of Caen. In 1880, the mathematician made use of non-Euclidean geometry for the first time and resolved a problem in the theory of differential equations to the competition for the grand prize in mathematics of the Academy of Sciences in Paris. He was put on the faculty of sciences at the University of Paris and later on, he succeeded G. Lippmann in the chair of mathematical physics and probability. Poincare switched institutes and universities a lot in the next years, and in 1904, he became professor of general astronomy at the École Polytechnique. Poincare managed to make significant contributions to classical mechanics and even more important, he was able to publish a founding document in chaos theory. Poincare showed that general, the stability of n-body systems (like the solar system) cannot be demonstrated. In this context, he also proved his recurrence theorem. When working on the foundations of topology, Poincare became increasingly interested in what topological properties characterized a sphere. In 1900, he claimed that homology was sufficient to tell if a 3-manifold was a 3-sphere and four years later, he described a counterexample to this claim, a space now called the Poincaré homology sphere. The Poincaré sphere was the first example of a homology sphere Poincare now had to establish that the Poincaré sphere was different from the 3-sphere and he introduced a new topological invariant, the fundamental group. He was able to show, that the Poincaré sphere had a fundamental group of order 120, while the 3-sphere had a trivial fundamental group. In this way he was able to conclude that these two spaces were, indeed, different. Pointcare also wondered whether a 3-manifold with the homology of a 3-sphere and also trivial fundamental group had to be a 3-sphere. In November 2002, Russian mathematician Grigori Perelman published his outline of a solution of the Poincaré conjecture and four years later Perelman was awarded, but declined, the Fields Medal for his proof. In 2010, the Clay Mathematics Institute awarded Perelman the $1 million Millennium Prize in recognition of his proof, which he rejected as well. Poincaré became the president of the French Academy in 1906 and was elected to the Académie Française in 1908. During his lifetime, Henri Poincaré published over five hundred scientific papers and over thirty books. He passed away on July 17, 1912 in Paris. At yovisto, you may be interested in an entertaining video explaining the Poincare Conjecture and its importance for science.'],\n",
       " [182,\n",
       "  'Dennis Tito, Space Tourist.  Crew of Soyuz TM-32. (from left: Dennis Tito, Talgat Musabayev, and Yuri Baturin).  On April 28, 2001, American engineer and multimillionaire Dennis Tito joined the Soyuz TM-32 mission to the International Space Station ISS, spending 7 days, 22 hours, 4 minutes in space and orbiting Earth 128 times. He paid $20 Mio for his trip, which made him the very first space tourist in history. Who ever thought that space tourism would become possible? To travel in space simply for recreational, leisure or business purposes. Of course, up to now, traveling to space is only reserved for the very rich people, who are able to afford this luxury – flights brokered by Space Adventures to the International Space Station aboard a Russian Soyuz spacecraft have been US $20–40 million. But, with Space Ship One traveling to the border of outer space and experiencing zero gravity has become affordable for a few more but only the very richest. Will traveling to space ever become a mass phenomenon? Who knows. But, today, we will tell you the story of the very first space tourist Dennis Tito. The end of the Space Race, culminating in the Moon landings, decreased the emphasis placed on space exploration by national governments and therefore led to decreased demands for public funding of manned space flights. The Soviet space program was aggressive in broadening the pool of its cosmonauts by including cosmonauts selected from Warsaw Pact members. Also the U.S. space shuttle program included payload specialist positions which were usually filled by representatives of companies or institutions managing a specific payload on that mission, who did not receive the same training as professional NASA astronauts. In 1984, Charles D. Walker became the first non-government astronaut to fly, with his employer McDonnell Douglas paying $40,000 for his flight. After Perestroika in Russia, its space industry was especially starved for cash. The Tokyo Broadcasting System (TBS) offered to pay for one of its reporters to fly on a mission. For $28 million, Toyohiro Akiyama was flown in 1990 to space station Mir. At the end of the 1990s, MirCorp, a private venture that was by then in charge of the space station, began seeking potential space tourists to visit Mir in order to offset some of its maintenance costs. Dennis Tito, an American businessman and former NASA Jet Propulsion Laboratory scientist, became their first candidate. When the decision to de-orbit Mir was made, Tito managed to switch his trip to the International Space Station (ISS). In 1972, Dennis Tito had founded Wilshire Associates, a leading provider of investment management, consulting and technology services in Santa Monica, California, serving an international clientele representing assets of $71 billion. Wilshire relies on the field of quantitative analytics, which uses mathematical tools to analyze market risks. Despite a career change from aerospace engineering to investment management, Tito remained interested in space. Tito was accepted by the Russian Federal Space Agency as a candidate for a commercial spaceflight. Although, he met criticism from NASA before the launch, because NASA considered it inappropriate for a tourist to take a ride into space. When Tito arrived at the Johnson Space Center for additional training on the American portion of the ISS, NASA refused to provide training for Dennis Tito. Thus, later through an arrangement with space tourism company Space Adventures, Ltd., Tito joined the Soyuz TM-32 mission on April 28, 2001, spending 7 days in space, while he performed several scientific experiments in orbit useful for his company. Tito paid a reported $20 million for his trip. Dennis Tito should not be the last space tourist. Only about a year later South African entrepreneur Mark Shuttleworth followed him on board a Soyuz mission to the ISS. And the list of space tourists continues, although the costs have risen to almost $40 million for the trip. At yovisto, you can learn more about tourists in space in the lecture by Prof. Charles Simonyi at Princeton Institute of Advanced Studies on ‘Space Tourism‘.'],\n",
       " [183,\n",
       "  'Edward Whymper and the Matterhorn.  Matterhorn Image: Juan Rubiano.  On April 27, 1840, English mountaineer, explorer, illustrator, and author Edward Whymper was born. He is best known for the first ascent of the Matterhorn in 1865; four members of his party were killed during the descent. Edward Whymper was born in London, England as the second of eleven children. He learned and practiced wood-engraving starting at very young age. In order to draw scenery pictures for a London publisher in the central and western Alps, Whymper began exploring the scenery quite often. His works included an unsuccessful an illustration of an attempt to ascend Mont Pelvoux. Only one year later, Whymper eventually managed the mountain as one of the first of numerous expeditions which threw much light on the topography of an area at that time very imperfectly mapped. While standing on top of Mont Pelvoux, Whymper noticed that it was overtopped by a neighbouring peak, the Barre des Écrins, which was climbed by Whymper along with Horace Walker, A. W. Moore and guides Christian Almer senior and junior in 1864. In the following years, Whymper successfully finished expeditions in the Mont Blanc massif and the Pennine Alps. Matterhorn desaster drawn by Gustave Doré When Whymper decided to climb the Matterhorn, he already had a huge rival. Jean-Antoine Carrel, an Italian guide previously attempted to reach its summit but failed several times. He is supposed to have said that a native Italian should be the first to achieve this goal and not an English man like Whymper. By 1863, the Matterhorn remained as the last unconquered great alpine summit and an Alpine Society was planned in order to support the local climbers. However, Whymper’s party of eight team members started from Zermatt towards the ridge where they reached the base of the peak and continued up to 3380 meters where they managed to set the bivouac. After a longer rest, the group continued without ropes and reached the foot of the much steeper upper peak that lies above the shoulder. When the summit was close, Whymper and Michel Croz detached themselves and “ran a neck-and-neck race, which ended in a dead heat. At 1.40 p.m. the world was at our feet, and the Matterhorn was conquered. Hurrah! Not a footstep could be seen“. Standing at the top, Whymper saw his rival Carrel and his team about 200 metres below, still dealing with the most difficult parts of the ridge. Whymper and Croz yelled and poured stones down the cliffs to attract their attention. When seeing his rival on the summit, Carrel and party gave up on their attempt and went back to Breuil. However, a difficult part was still in front of Whymper and his team: the descent. Even though the men climbed down with great care, only one man moving at a time, one of them slipped and fell on Croz, who was in front of him. Croz, who was unprepared, was unable to withstand the shock. Both fell and pulled down the others. On hearing Croz‘ shout Whymper and his team member Taugwalder stood very firm but the rope broke. Whymper could only watch them slide down the slope, falling from rock to rock and finally disappearing over the edge of the precipice. After the catastrophe, the remaining men were able to secure themselves and continue the descent until reaching a safer place. They searched for traces that might lead to their companions, but stayed unsuccessful. On 15 July, 1865 they reached Zermatt. One day later, a rescue team left in order to recover the men’s bodies, but only three were found. After the accident, Edward Whymper had to answer numerous questions and was accused of having betrayed his companions and the guide Peter Taugwalder was accused, tried, and acquitted. Many accused him to have cut the rope between him and Lord Francis Douglas to save his life. As the catastrophe was very present in the world’s media, Queen Victoria even considered banning climbing to all British citizens but decided, after consultation, not to forbid mountaineering. At yovisto, you may be interested in a video lecture titled ‘Life at Top‘ by Kenton Cool at the University of Leeds.'],\n",
       " [184,\n",
       "  'John James Audubon’s Birds of America.  Carolina Parakeet amidst a leafy branch by John James Audubon.  On April 26, 1785, French-American ornithologist, naturalist, and painter John James Audubon was born. He was notable for his expansive studies to document all types of American birds and for his detailed illustrations that depicted the birds in their natural habitats. His major work, a color-plate book entitled The Birds of America (1827–1839), is considered one of the finest ornithological works ever completed. OK, who the heck is john James Audubon and why should I care? This is what you may possibly think, if you haven’t heart of him. Now, this is going to change. On December 6, 2010, a copy of The Birds of America was sold at a Sotheby’s auction for $11.5 million, the second highest price for a single printed book. This should give you some hint, that James Audubon’s work must have been considered something special. Therefore, let’s take a look at the life of this famous ornithologist and painter, especially on his best known major work of art, “The Birds of America“. Jean-Jacques Audubon was born in 1785 in Les Cayes in the French colony of Saint-Domingue (now Haiti) as illegitimate son on his father’s sugar plantation, Lieutenant Jean Audubon, a French naval officer from the south of Brittany. His mother died when the boy was a few months old. During the American Revolution, Lieutenant Jean Audubon had been imprisoned by the British Empire and after his release helped the American cause. Rising unrest in Saint-Domingue from African slaves, who greatly outnumbered French colonists, convinced Jean Audubon to return to France, where he succeeded to regularize the legal status of his children. In France during the chaotic years of the French Revolution and its aftermath, the younger Audubon grew up to be a handsome man. Raised by his stepmother, Mrs. Audubon, in Nantes, France, Jean-Jacques took a lively interest in birds, nature, drawing, and music. From his earliest days, Audubon had an affinity for birds and was encouraged by his father on his interest in nature. He loved roaming in the woods, often returning with natural curiosities, including birds’ eggs and nests, of which he made crude drawings.At age 12, Audubon went to military school and became a cabin boy. He quickly found out that he was susceptible to seasickness and not fond of mathematics or navigation, and soon ended his naval career. At age 18, Jean-Jacques Audubon boarded ship for immigration to the United States in 1803 to avoid conscription in the Napoleonic Wars. Adopting the Americanized name John James, Audubon adapted to America and lived as a country gentleman, on the family-owned estate at Mill Grove, near Philadelphia, hunting, fishing, and indulging in his passion for observing and drawing birds. While there, he met his wife, Lucy Bakewell and conducted the first known bird-banding experiment in North America, tying strings around the legs of Eastern Phoebes; he learned that the birds returned to the very same nesting sites each year. Audubon tried his luck at various endeavors in Ohio and Kentucky, and discovered that he was not suited for a life of business. Audubon set off on his epic quest to depict America’s birdlife, with nothing but his gun, artist’s materials, and a young assistant. Floating down the Mississippi towards New Orleans, he lived a rugged hand-to-mouth existence in the South while Lucy earned money as a tutor to wealthy plantation families. Thus, Audubon was able to devote himself to what he saw as his true calling, the painting of birds, while his wife managed to support the family. After failing to interest any American publishers in his ambitious plan to publish a book of paintings of American birds in 1826, Audubon sailed with his partly finished collection to England and became literally an overnight success. Highly regarded in British society as a natural unschooled genius. With his long hair and rough American clothes, he became something of a celebrity. His life-size, highly dramatic bird portraits, along with his embellished descriptions of wilderness life, hit just the right note at the height of the Continent’s Romantic era. Audubon found a printer for the Birds of America, first in Edinburgh, then London. To produce the book, Audubon’s images were etched on copper plates, and the resulting printed sheets were colored by artists to match Audubon’s original paintings. Eventually the book was sold to 161 subscribers, who paid the immense sum of $1,000 for what became four volumes. In total, Birds of America contained 435 pages featuring more than 1,000 individual paintings of birds. With the success of Birds of America, Audubon purchased a 14-acre estate along the Hudson River north of New York City. In 1843 Audubon set off on his last great expedition, visiting the western territories of the United States so he could paint American mammals. He traveled from St. Louis to the Dakota territory in the company of buffalo hunters, and wrote a book which became known as the Missouri Journal. John James Audubon was not the first person to attempt to paint and describe all the birds of America, but for half a century he was the young country’s dominant wildlife artist. His seminal Birds of America, a collection of 435 life-size prints, has become a standard in ornithology. Today, the name Audubon remains synonymous with birds and bird conservation the world over. At yovisto, you can take a short look at an original exemplar of John James Audubon’s Birds of America in a video presentation of the 1888 edition by Jacob Studer.'],\n",
       " [185,\n",
       "  'Claude Joseph Rouget de Lisle and the Marseillaise.  Claude Joseph Rouget de Lisle singing La Marseillaise.  On April 25, 1792, French army officier Claude Joseph Rouget de Lisle during the French Revolution composes the ‘Chant de guerre pour l’armée du Rhin‘ for the declaration of war against Austria. Under the name ‘La Marseillaise‘ his song later becomes the national anthem of France. I’m pretty sure that almost everybody knows the French national anthem, the so-called Marseillaise, simply because of its numerous references throughout music history as well as from movies. Above all, of course ‘All you need is Love‘ from The Beatles. But, there are not so many who know about the history of that unique song. Sure, some might know that it has something to do with the French Revolution. But, why is it called ‘La Marseillaise‘? Let’s take a look at the history of the French National Anthem. Allons enfants de la Patrie, Le jour de gloire est arrivé ! On 25 April 1792, the mayor of Strasbourg requested his guest Rouget de Lisle compose a song “that will rally our soldiers from all over to defend their homeland that is under threat“. That very evening, war was declared to Austria and Rouget de Lisle wrote Chant de guerre pour l’Armée du Rhin (English: “War Song for the Army of the Rhine“), and dedicated the song to Marshal Nicolas Luckner, a Bavarian in French service, who was Commander-in-Chief of Straßburg. Luckner was born in the small German village of Cham, where you can hear La Marseillaise played every day at noon by a carillon on the market place to this day. But why is it called La Marseillaise? The melody soon became the rallying call to the French Revolution and was adopted as La Marseillaise after the melody was first sung on the streets by volunteers (fédérés in French) from Marseille by the end of May. These fédérés were making their entrance into the city of Paris on 30 July 1792 after a young volunteer from Montpellier called François Mireur had sung it at a patriotic gathering in Marseille, and the troops adopted it as the marching song of the National Guard of Marseille. A newly graduated medical doctor, Mireur later became a general under Napoléon Bonaparte and died in Egypt during Napoleon’s Egyptian campaign at age 28. The song’s lyrics reflect the invasion of France by foreign armies (from Prussia and Austria) that were underway when it was written. Strasbourg itself was attacked just a few days later. The invading forces were repulsed from France following their defeat in the Battle of Valmy. As the vast majority of Alsatians did not speak French, a German version (Auf, Brüder, auf dem Tag entgegen) was published in October 1792 in Colmar. The Convention accepted it as the French national anthem in a decree passed on 14 July 1795, making it France’s first anthem. Later under Napoleon Bonaparte it lost this status and the song was banned outright in the following French restauration by Louis XVIII and Charles X, only being re-instated briefly after the French July Revolution of 1830. During the 19th and early 20th centuries, “La Marseillaise” was commonly recognized as the anthem of the international revolutionary movement. As such, it was also adopted by the Paris Commune in 1871. Eight years later, in 1879, it was finally restored as France’s national anthem, and has remained so ever since. As mentioned above, The Beatles were not the first to quote the Marseillaise in their music. In classical music, maybe Pyotr Ilyich Tchaikovsky’s reference in his famous 1812 Overture (written in 1882) might be the most famous. Tchaikovsky quoted “La Marseillaise” to represent the invading French army, followed by quoting the Russian national anthem to represent the Russian army. However, neither of these anthems was actually in use in 1812. At yovisto you can learn more about the times of the French Revolution in the lecture of Yale Prof. John Merrimen on ‘Maximilian Robespierre and the French Revolution‘.'],\n",
       " [186,\n",
       "  'Laurens Hammond and the Hammond Organ.  Hammond Organ model L-112 Image: Jake.  On April 24, 1934, American engineer and inventor Laurens Hammond filed US Patent 1,956,350 for an “electrical musical instrument“, his famous eponymous electric organ with the unique ‘Hammond sound’. Laurens was born in Illinois, USA, but moved to France after his father took his life. In  Europe, Hammond began to design some of his earliest inventions. By the age of 14, the boy had already designed systems for automatic car transitions. Unfortunately, when he sent his idea to Renault, it was rejected. At Cornell University, he studied mechanical engineering and became the Chief engineer of a company, manufacturing of marine engines. However, the engineer continued developing ideas for further inventions. In 1919, Hammond managed to invent a silent spring-driven clock, which allowed him to leave the company and make his living in New York. Hammond founded the Hammond Clock Company, which faced financial difficulties in the 1930s. In order to save his company, the engineer had to think of other inventions and products. Thus, an electric bridge table was developed and his famous organ followed shortly after. It is assumed that everything started out with a used piano the engineer purchased. He is supposed to have used it as a controller, making lots of noises. He was assisted by the company’s treasurer, who played the organ at a local church. The tonewheel generator went into production pretty soon and the patent was filed in 1934. The Hammond organ was built with only 25 instead of the standard 32 notes and it was revealed to the public in 1935. The first model to be purchased (Model A) was made available in the summer of the same year. The first customers were mainly churches, which is probably due to the fact that Hammond organs were much cheaper than the original wind-driven pipe organ. It is estimated that in the first three years, about 1700 churches purchased the model. Despite the initial success, Hammond did not believe that he could make enough money to support the company with the product and it was not targeted at the market. However, Hammond’s company started very active advertising soon. The Hammond Times, a newsletter that was even mailed out to subscribers. Often, it was demonstrated how families gathered around the instrument, suggesting that a Hammond organ could function as a central aspect of a family’s daily life. As the development of the organs continued, two main groups of instruments were established, console organs with two octaves and spinet organs with only one. Further models were built to fit the customer’s wishes. Even though, Hammond organs were originally intended for churches, the company came to realize more and more that the amateur home market was a far more lucrative business and they started manufacturing spinet organs in the late 1940s. The production of transistor organs began about two decades later and the Concorde, the company’s first integrated circuit model followed shortly after. By this time, Laurens Hammond was not the company’s president anymore. He left the position in 1955 and devoted his life more to researching and developing new ideas. Hammond retired in 1960 while holding 90 patents. The engineer passed away in 1973 and the company stayed in business until 1985. The Hammond name was purchased by the Suzuki Musical Instrument Corporation, which proceeded to manufacture digital simulations of the most popular tonewheel organs. This culminated in the production of the “New B-3″ in 2002, which provided an accurate recreation of the original B-3 organ using modern digital technology. Companies like Korg, Roland and Clavia also became successful in providing emulations of the original tonewheel organs. The sound of a tonewheel Hammond can also be emulated using modern software such as Native Instruments B4. At yovisto, you may be interested in a video about the building process of Hammond Organs.'],\n",
       " [187,\n",
       "  'The German Reinheitsgebot.  A crown cap, reading “500 Years of Reinheitsgebot in Munich.  On April 23, 1516, in the city of Ingolstadt in the duchy of Bavaria, Duke Wilhelm IV. and Duke Ludwig X of Bavaria publish a new law that contains regulations about the price and the ingredients of beer. These Regulations later are called the ‘Reinheitsgebot‘ ( German Beer Purity Law), which states that the only ingredients that could be used in the production of beer are water, barley and hops. The law was introduced at a meeting of an assembly of the Estates of Bavaria, at Ingolstadt, about 60 miles north of Munich. Next to the listed ingredients, the original law set the price of beer at one Pfennig per Maß. On this day however, the law is not longer active and was replaced by the Provisional German Beer Law, introduced in 1993. With the new law, some changes, which allowed the ingredients yeast, wheat malt and cane sugar were introduced. Back in the Medieval era, many brewers had used many problematic ingredients to preserve beers, including soot and fly agaric mushrooms. When the Reinheitsgebot came into effect, several penalties for not following the law were set, for instance, the confiscation of all questionable barrels is assumed to have occurred quite often. It is also believed that the Reinheitsgebot was introduced for economic reasons. The prevention of price competition with bakers for wheat and rye was intended in order to guarantee affordable bread. The Reinheitsgebot started to spread very slowly across Bavaria and later Germany. Bavaria insisted on its application throughout Germany as a precondition of German unification in 1871, to prevent competition from beers brewed elsewhere with a wider range of ingredients. Many brewers opposed the new law and they claimed that the Reinheitsgebot would lead to the extinction of many brewing traditions and local beer specialties, for instance the North German spiced beer and cherry beer were affected. In 1988 the law changed again and from then on, any ingredient that was allowed in other foods was not allowed in beer as well. However, these changes only applied to imported beers and beer brewed in Germany still has to abide to the law. On this day, many German breweries claim to follow the original Reinheitsgebot, even though this is often false. At yovisto, you may be interested in a video lecture titled ‘The Bitter, Twisted Truth of Hop‘'],\n",
       " [188,\n",
       "  'Encore un Moment – The Life of Madame Du Barry.  Madame Du Barry (1743 – 1793).  On April 22, 1769, Jeanne Bécu, comtesse du Barry, better known as Madame du Barry, was introduced at the French court. Originally being only a seamstress, Madame du Barry should become Maîtresse-en-titre of Louis XV of France and the most powerful woman in France. Madame du Barry was born in Lorraine, France and had to support herself financially at the age of 15 or 16. It is assumed that she had started selling rather cheap jewelry on the streets of Paris and continued her career as a companion to an elderly widow, Madame de la Garde. Madame du Barry, back then still known as Jeanne Bécu, was considered highly attractive and her beauty also drew attention to Jean-Baptiste du Barry around 1763. He owned a casino and made Jeanne his mistress. He supported her career as a courtesan in Paris and made it possible for her to take several aristocratic men as brief lovers or clients. Jeanne became widely known across Paris as Mademoiselle Lange. To her clients belonged numerous aristocratic men and Jean du Barry started to see a huge potential of influencing the politics of Louis XV. In order to become a maîtresse-en-titre, Jeanne had to get married to Comte Guillaume du Barry. Jeanne moved in the King’s quarters and had a hard time fitting in. Many of the nobility would not accept the fact that a woman of the street had the audacity to interact with those above her station. Still, it is assumed that her husband often reminded her to speak of presentation with the king. After Jeanne had finally been presented to the Court at Versailles, she started to make friends and quickly accustomed herself to living in luxury. Madame du Barry became known as a very extravagant woman, who wore diamonds covering her neck and ears combined with extremely costly dresses. She became the king’s maîtresse déclarée and historians assume that she made as many friends as enemies at Court. Duchesse de Grammont should become her most bitter rival, who did not hesitate to develop several plans to remove Jeanne with her brother. Still, Jeanne’s power in Court grew stronger as Choiseul sided with the Spanish against the British for possession of the Falkland Islands. When Jeanne found out about it, she exposed the news to the king, which resulted in the removal of Choiseul and his sister. This period is regarded as Jeanne’s golden age and her family received great benefits from her position. She became well known as a supporter of artists and the king often praised her in front of his acquaintances. Unfortunately for her, she grew increasingly unpopular because of the king’s financial extravagance towards her. For instance, Louis XV requested that Parisian jewellers Boehmer and Bassenge create an elaborate and spectacular jeweled necklace for du Barry in 1772. The necklace was neither completed nor paid for when the king passed away, which triggered a huge scandal. Queen Marie Antoinette was wrongly accused of bribing the Cardinal de Rohan, Archbishop of Strasbourg in the Alsace, to purchase it for her. These accusations would figure prominently in the onset of the French Revolution. This incident became well known as the famous Diamond Necklace. After the death of Louis XV, Jeanne was quickly exiled to the Abbey du Pont-aux-Dames near Meaux-en-Brie. After about one year, she was allowed to visit the surrounding countryside on condition, she returned and slept behind the abbey’s walls at sundown. Jeanne started to slowly recover and even managed to purchase some property. Later on, she fell in love with Henry Seymour while having a liaison with Louis Hercule Timolon de Cossé, Duke of Brissac. Brissac was captured while visiting Paris, and was slaughtered by a mob during the French Revolution and an angry crowd threw his head through her open window. Madame du Barry herself was arrested in 1793 for treason and beheaded by means of the guillotine on 8 December in the same year. Her last words to the executioner were Encore un moment, monsieur le bourreau (One more moment, Mr. Executioner). At yovisto, you may be interested in a video lecture on the French Revolution.'],\n",
       " [189,\n",
       "  'Sir George Stokes and Fluid Dynamics.  Sir George Stokes, 1st Baronet (1819-1903). On February 1, 1903, Irish mathematician, physicist, politician and theologian Sir George Gabriel Stokes, 1st Baronet, passed away. Stokes made seminal contributions to fluid dynamics, optics, and mathematical physics including the first version of what is now known as Stokes’ theorem. George Stokes was the youngest son of eight children of the Reverend Gabriel Stokes, rector of Skreen, County Sligo, Ireland, and Elizabeth Haughton. according to one of his obituary writers and colleagues John William Strutt Rayleigh (Lord Rayleigh), Stokes had been a tempestuous and sometimes violent child.[2] After attending schools in Skreen and Dublin, in 1835, at the age of 16 and after his father‘s death, George Stokes moved to England and entered Bristol College in Bristol. In 1837, he entered Pembroke College in Cambridge, where he graduated after four years as Senior Wrangler (the top First Class degree) in the Mathematical Tripos with tutor William Hopkins and he was the first Smith’s prizeman. Pembroke College immediately gave him a Fellowship.[1] Stokes‘ first published papers, which appeared in 1842 and 1843, were on the steady motion of incompressible fluids and some cases of fluid motion. These were followed in 1845 by one on the friction of fluids in motion and the equilibrium and motion of elastic solids, and in 1850 by another on the effects of the internal friction of fluids on the motion of pendulums. To the theory of sound he made several contributions, including a discussion of the effect of wind on the intensity of sound and an explanation of how the intensity is influenced by the nature of the gas in which the sound is produced. These inquiries together put the science of fluid dynamics on a new footing, and provided a key not only to the explanation of many natural phenomena, such as the suspension of clouds in air, and the subsidence of ripples and waves in water, but also to the solution of practical problems, such as the flow of water in rivers and channels, and the skin resistance of ships. His work on fluid motion and viscosity led to his calculating the terminal velocity for a sphere falling in a viscous medium. This became known as Stokes’ law. After he had deduced the correct equations of motion Stokes discovered that again he was not the first to obtain the equations since Navier, Poisson and Saint-Venant had already considered the problem. In fact this duplication of results was not entirely an accident, but was rather brought about by the lack of knowledge of the work of continental mathematicians at Cambridge at that time. Again Stokes decided that his results were obtained with sufficiently different assumptions to justify publication and he published On the theories of the internal friction of fluids in motion in 1845.[1] In 1849, Stokes was appointed to the Lucasian professorship of mathematics at Cambridge, a position he held until his death in 1903. Also in 1849 he wrote two papers on variable gravitation on the Earth\\x92s surface which is said to have reformed the science of geodesy. While it was known that the force of gravity differed depending on where a person was on Earth Stokes claimed that this was not dependent upon the interior composition of the Earth which had been assumed to be the case up until then. In 1851 he was elected to the Royal Society, awarded the Rumford medal of that Society in 1852, and he was appointed secretary of the Society in 1854. The Lucasian chair paid very poorly so Stokes needed to earn additional money and he did this by accepting an additional position to the Lucasian chair, namely that of Professor of Physics at the Government School of Mines in London.   Stokes wrote various papers commenting on criticising and developing ideas first proposed by French mathematicians such as Lagrange, Laplace, Fourier, Poisson and Cauchy. His interest led him to advocate changes to Cambridge\\x92s Tripos exam system to include more continental mathematics. This focus led some colleagues to label him a mathematician of the French tradition. However it is generally acknowledged the papers Stokes wrote on mathematical topics were deeply related to his physical experiments.[2] In 1854 Stokes theorised an explanation of the Fraunhofer lines in the solar spectrum. He suggested these were caused by atoms in the outer layers of the Sun absorbing certain wavelengths. However when Kirchhoff later published this explanation, Stokes disclaimed any prior discovery. Stokes’ career certainly took a rather different track in 1857 when he moved from his highly active theoretical research period into one where he became more involved with administration and experimental work. As part of his experimental drive Stokes helped to set up the Cavendish laboratory in the mid 1880s. Stokes received the Copley medal from the Royal Society in 1893 and he was given the highest possible honor by his College when he was elected as Master of Pembroke College in 1902at age 83. He did not hold this position for long, for he died at Cambridge the following year. At yovisto you might learn more about the principles behind steam engines and thermodynamics in the lecture videos of Prof. Ranamurti Shankar from Yale on ‘Fundamentals of Physics‘, where he also discusses the laws of thermodynamics.'],\n",
       " [190,\n",
       "  'Gideon Mantell and the Iguanodon.  Gideon Mantell (1790-1852).  .  On February 3, 1790, English obstetrician, geologist and palaeontologist Gideon Algernon Mantell was born. His attempts to reconstruct the structure and life of Iguanodon began the scientific study of dinosaurs. In 1822 he was responsible for the discovery of the first fossil teeth, and later much of the skeleton, of Iguanodon. Moreover, Mantell is also famous for his contributions on the Cretaceous of southern England. Well, the Cretaceous is a geologic period from ca. 145 to 66 million years ago. In the geologic timescale, the Cretaceous follows the Jurassic period and is followed by the Paleogene period of the Cenozoic era. It is the last period of the Mesozoic Era, and, spanning 79 million years, the longest period of the Phanerozoic Eon. But more important – at least for me when I was a kid – the Cretaceous also is famous for its dinosaurs. Mantell was born in Lewes, Sussex, the child of Thomas Mantell, a shoemaker, and Sarah Austen. Raised in a small cottage in St. Mary‘s Lane with his two sisters and four brothers, he showed a particular interest in the field of geology already at young age. The Mantell children could not study at local grammar schools that were reserved for children of Anglican faith, because the elder Mantell was a follower of the Methodist church. Thus, Gideon was educated at a dame school in St. Mary‘s Lane, and learned basic reading and writing from an old woman, and subsequently by John Button, a philosophically radical Whig who shared similar political beliefs with Mantell‘s father. At age 15, Mantell secured an apprenticeship with a local surgeon named James Moore in Lewes for a period of five years, in which he took care of Mantell‘s dining, lodging and medical issues. Mantell delivered Moore’s medicines, kept his accounts, wrote out bills and extracted teeth from his patients.When his father died in 1807, Mantell began to anticipate his medical education and taught himself human anatomy, followed by a formal medical education in London. He received his diploma as a Member of the Royal College of Surgeons in 1811. Mantell returned to Lewes, and immediately formed a partnership with his former master, James Moore. In the wake of the cholera, typhoid and smallpox epidemics, Mantell found himself quite busy attending to more than 50 patients a day and delivering between 200 and 300 babies a year. Although mainly occupied with running his busy country medical practice, he spent his little free time pursuing his passion, geology, often working into the early hours of the morning, identifying fossil specimens he found at the marl pits in Hamsey. In 1813, Mantell was elected as a fellow of the Linnean Society of London. Two years later, he published his first paper, on the characteristics of the fossils found in the Lewes area.   Iguanodon remains found near Maidstone Inspired by Mary Anning‘s sensational discovery of a fossilized animal resembling a huge crocodile at Lyme Regis in Dorset, Mantell became passionately interested in the study of the fossilized animals and plants found in his area. The fossils he had collected from the region, near The Weald in Sussex, were from the chalk downlands covering the county. The chalk is part of the Upper Cretaceous System and the fossils it contains are marine in origin. But by 1819, Mantell had begun acquiring fossils from a quarry, at Whitemans Green, near Cuckfield. He named the new strata the Strata of Tilgate Forest, after an historical wooded area and it was later shown to belong to the Lower Cretaceous. By 1820, he had started to find very large bones at Cuckfield, even larger than those discovered by William Buckland, at Stonesfield in Oxfordshire. Then, in 1822, shortly before finishing his first book The Fossils of South Downs, while Mantell was visiting a patient, his wife Mary Ann took a short stroll as she waited for him, and when Mantell finished his house call, she presented him with a puzzling tooth. In fact, this account can’t be confirmed and there have been several conflicting accounts later. What’s certain is that the tooth was unlike anything Mantell had ever seen. It was typical of an herbivore. Could it belong to a mammal? Mantell was confident that it came from Mesozoic strata, and there were no Mesozoic mammals known to science in the early 1820s. Even today, there are few known Mesozoic mammals of significant size, and Mantell‘s tooth was huge.[2] Mantell showed the teeth to other scientists but they were dismissed as belonging to a fish or mammal and from a more recent rock layer than the other Tilgate Forest fossils. The eminent French anatomist, Georges Cuvier, identified the teeth as those of a rhinoceros. Cuvier‘s dismissal was a blow to Mantell‘s confidence, but ultimately he remained firm: This tooth, along with other remains he found, belonged to a giant herbivorous reptile from the Mesozoic strata. He surmised that the owner of the remains must have been at least 18m in length.   Mantell’s “Iguanodon” restoration based on the Maidstone Mantellodon remains, 1834   Years later, Mantell had acquired enough fossil evidence to show that the dinosaur’s forelimbs were much shorter than its hind legs, therefore proving they were not built like a mammal as claimed by Sir Richard Owen. Mantell went on to demonstrate that fossil vertebrae, which Owen had attributed to a variety of different species, all belonged to Iguanodon. He also named a new genus of dinosaur called Hylaeosaurus and as a result became an authority on prehistoric reptiles. In 1833, Mantell relocated to Brighton but his medical practice suffered. He was almost rendered destitute, but for the town’s council who promptly transformed his house into a museum. The museum in Brighton ultimately failed as a result of Mantell‘s habit of waiving the entrance fee. Finally destitute, Mantell offered to sell the entire collection to the British Museum, in 1838, and moved to Clapham Common in South London, where he continued his work as a doctor. In 1841 Mantell was the victim of a terrible carriage accident and suffered a debilitating spinal injury. Despite being bent, crippled and in constant pain, he continued to work with fossilised reptiles and published a number of scientific books and papers until his death in 1852 from an overdose of opium. At the time of his death Mantell was credited with discovering 4 of the 5 genera of dinosaurs then known. At yovisto you can learn more about the interesting subject of paleontology in the TED talk of Dr. Paul Sereno on ‘What can Fossils Teach Us?‘.'],\n",
       " [191,\n",
       "  'John Lindley and his Love for Plants.  John Lindley (1799-1865).  .  On February 5, 1799, English botanist, gardener and orchidologist John Lindley was born. His attempts to formulate a natural system of plant classification greatly aided the transition from the artificial (considering the characters of single parts) to the natural system (considering all characters of a plant). He made the first definitive orchid classification in 1830. John Lindley was born in Catton, near Norwich, England, as one of four children of George Linley, a nurseryman and pomologist who ran a commercial nursery garden, and his wife Mary. Although he had great horticultural knowledge, the undertaking was not profitable and the family lived in a state of indebtedness. As a boy John would assist in the garden and also collected wild flowers he found growing in the Norfolk countryside. Educated at Norwich School, he would have liked to go to university or to buy a commission in the army but the family could not afford either. Thus, he became Belgian agent for a London seed merchant in 1815. At this time Lindley became acquainted with the botanist William Jackson Hooker who allowed him to use his botanical library and who introduced him to Sir Joseph Banks who offered him employment as an assistant in his herbarium. In 1819 he published his first scientific papers which were acknowledged by the Linnaean Society. Lindley went to work at Banks’ house in London. For his botanical interest he concentrated on the genera “Rosa” and “Digitalis” and published the monograph “A Botanical History of Roses” which distinguished seventy-six species. He became acquainted with Joseph Sabine who grew a large assortment of roses and was the Secretary of the Horticultural Society of London. His employment came to an abrupt end with the death of Banks a few months later. In 1820, at the age of twenty-one, Lindley was elected a fellow of the Linnean Society of London. Next, Lindley was appointed assistant secretary to the Horticultural Society and its new garden at Chiswick in 1822, where he supervised the collection of plants. In 1828 Lindley was elected a fellow of the Royal Society of London and in 1833 was awarded the honorary degree of Doctor of Philosophy from the University of Munich. In 1829 he was appointed to the chair of botany at University College, London, which he retained until 1860. Plate from ‘A sketch of the vegetation of the Swan River Colony’ by John Lindley, 1839 Lindley’s investigation in 1838 of the conditions at the Kew Gardens in London led him to recommend that the gardens be turned over to the nation and used as the botanical headquarters for the United Kingdom. His famous collection of orchids was eventually housed in the Kew herbarium. His Theory and Practice of Horticulture (1842) is considered to be one of the best books ever written on the physiological principles of horticulture.[1] Time-consuming though his official duties and public activities certainly were, Lindley nevertheless managed to prepare the specific characters for the 16,712 species of flowering plants and cryptogams included in John Loudon’s Encyclopaedia of Plants (1829) and to produce a series of well-documented, clearly written, authoritative educational publications As a young man Lindley campaigned vigorously against the artificial “sexual system” of classification of plants introduced by Linnaeus in favor of a more natural system. In 1830 he published Introduction to the Natural System of Botany which was the first work in English to give descriptions of the families on a worldwide basis. It embodied detailed, firsthand observations of their representatives in the garden and herbarium. Uninfluenced by theories of evolution, and hence without thought of phylogeny, Lindley regarded the characters of plants as “the living Hieroglyphics of the Almighty which the skill of man is permitted to interpret. The key to their meaning lies enveloped in the folds of the Natural System.”[2] In 1845, Lindley was part of a scientific commission set up by the Government to investigate potato blight and the Irish famine. The cause of the fungal disease was not known at the time and the weather was thought to be to blame. In 1861, Lindley took charge of organising the exhibits from the British colonies for the International Exhibition at South Kensington. This was exhausting work and seems to have taken a toll on his health. In 1863 he travelled to Vichy, a spa in the south of France, but his health continued to decline. He died at his home at Acton Green, near London, aged 66. At yovisto, you can learn more about botany  in the video lecture on ‘Human Livelihoods Depend on Wild Flowers: Kew’s Millennium Seed Bank explained‘.'],\n",
       " [192,\n",
       "  'John McCarthy and the Raise of Artificial Intelligence.  John McCarthy (1927 – 2011) Image by null0.  On September 4, 1927, American computer scientist and cognitive scientist John McCarthy was born. He was one of the founders of the discipline of artificial intelligence. He coined the term “artificial intelligence” (AI), developed the Lisp programming language family, significantly influenced the design of the ALGOL programming language, popularized timesharing, and was very influential in the early development of AI. John McCarthy graduated from high school two years early and already studied the textbooks of MIT in the field of mathematics. He was accepted at Caltech in 1944, but the first years did not go as smooth as expected. The brilliant student skipped the required P.E courses and was suspended. After serving the US Army , he was again readmitted and even studied under John von Neumann. McCarthy earned his degree at Caltech and finished his PhD in mathematics at Princeton[1]. McCarthy worked at Dartmouth in the 1950s and in this period, he authored a proposal for a two-month, 10-person summer research conference on “artificial intelligence“. It was the first time, the term was used in a publication. In proposing the conference, McCarthy wrote, “The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it“. Marvin Minsky also attended the conference and later on, he became one of the main AI theorists and joined McCarthy at MIT in 1959. McCarthy invented the computer programming language LISP. It is the second oldest programming language after FORTRAN and still in use today in the field of artificial intelligence. He also served on the committee that designed ALGOL, which became a very influential programming language by introducing many new constructs now in common use [1,2]. In the later 1950s, McCarthy began developing a concept for computer time-sharing in order to improve the efficiency of distributed computing and predated the era of cloud computing by decades. In the same period, McCarthy authored a paper titled, “Programs with Common Sense”. He laid out the principles of his programming philosophy and describing “a system which is to evolve intelligence of human order”. The scientist hosted a series of four simultaneous computer chess matches carried out via telegraph against rivals in Russia in 1966. The matches lasted over a couple of months and McCarthy lost two of the matches and drew two. He later pointed out, that board games like chess were essential for the development of artificial intelligence [2]. During his career, McCarthy co-founded the MIT Artificial Intelligence Project and what became the Stanford Artificial Intelligence Lab, serving as director at Stanford from 1965 until 1980. He was named the Charles M. Pigott Professor at the Stanford School of Engineering in 1987, before stepping down in 1994. The Association of Computing Machinery honored McCarthy with the A. M. Turing Award in 1971 and he received the Kyoto Prize in 1988 and the National Medal of Science in 1990, the nation’s highest technical award [2,3]. At yovisto, you may be interested in a talk by John McCarthy on the Philosophy of AI.'],\n",
       " [193,\n",
       "  'E.F. Codd and the Relational Database Model.  E. F. Codd (1923-2003).  On August 23, 1923, English computer scientist Edgar Frank “Ted” Codd was born. His main achievement besides many contributions to computer science was the invention of the relational model for database management, the theoretical basis for relational databases.   When you talk about databases today, usually you are referring to relational databases that store their data within tables, interconnected via so-called keys. Of course there are also modern alternatives such as e.g. graph based databases, but relational databases are widespread and rather common today. And this is also thanks to E.F. Codd and his relational algebra. Edgar Frank Codd was born the youngest of seven children in Portland Bill, in Dorset, England, in 1923. His father was a leather manufacturer, his mother a schoolteacher. After attending Poole Grammar School, he studied mathematics and chemistry at Exeter College, Oxford, before serving as a pilot in the Royal Air Force during the Second World War. In 1948 at age 25, he moved to New York to work for IBM as a mathematical programmer. In 1953, angered by Senator Joseph McCarthy, Codd moved to Ottawa, Canada. While in Canada, he established a computing center for the Canadian guided missile program. A decade later he returned to the U.S. and received his doctorate in computer science from the University of Michigan in Ann Arbor. His thesis was about self-replication in cellular automata, extending on work of von Neumann and showing that a set of eight states was sufficient for universal computation and construction. Two years later he moved to San Jose, California, to work at IBM‘s San Jose Research Laboratory, where he continued to work until the 1980s. There he found existing data management systems “seat-of-the-pants, with no theory at all,” he recalled in one interview. “I began reading documentation,” Codd said, “and I was disgusted.” [2]. Subsequently, Codd worked out his theories of data arrangement, issuing his paper “A Relational Model of Data for Large Shared Data Banks” in 1970, after an internal IBM paper one year earlier. In fact, the 1970 paper became one of the most important research papers in computer history. Codd believed that all the information in a database should be represented as values in the rows and columns of tables, and that no information should be represented by pointers or connections among records.[2] To his frustration, IBM largely ignored his work, as the company was investing heavily at the time in commercializing a different type of database system, the IMS/DB [1]. Then IBM included in its Future Systems project a System R subproject — but put in charge of it developers who were not thoroughly familiar with Codd’s ideas, and isolated the team from Codd. As a result, they did not use Codd’s own Alpha language but created a non-relational one, SEQUEL. Even so, SEQUEL was so superior to pre-relational systems that it was copied, in 1979, based on pre-launch papers presented at conferences, by Larry Ellison, of Relational software Inc, in his Oracle Database, which actually reached market before SQL/DS — because of the then-already proprietary status of the original name, SEQUEL had been renamed SQL. System R was a success, and in 1981 IBM announced its first relational database product, SQL/DS. DB2, initially for large mainframe machines, was announced in 1983 [3]. Codd continued to develop and extend his relational model, sometimes in collaboration with Chris Date. One of the normalized forms, the Boyce–Codd normal form, is named after him. Codd’s theorem, a result proven in his seminal work on the relational model, equates the expressive power of relational algebra and relational calculus (both of which, lacking recursion, are strictly less powerful than first-order logic). As the relational model started to become fashionable in the early 1980s, Codd fought a sometimes bitter campaign to prevent the term being misused by database vendors who had merely added a relational veneer to older technology. As part of this campaign, he published his 12 rules to define what constituted a relational database. This made his position in IBM increasingly difficult, so he left to form his own consulting company with Chris Date and others. Nevertheless, Codd was appointed IBM Fellow in 1976. In 1981, Codd was honoured with the Turing Award, the most prestigious award in computer science similar to the Fields medal in mathematics. During the 1990s, his health deteriorated and he ceased work. Codd died of heart failure at his home in Williams Island, Florida, at the age of 79 on April 18, 2003. At yovisto you can watch a lecture from Dr. Jens-Peter Dittrich from ETH Zürich about ‘Dataspaces‘ where he is talking about Codd’s Relational Model.'],\n",
       " [194,\n",
       "  'Marvin Minsky and Artificial Neural Networks.  Marvin Minsky at OLPCb.  On August 9, 1927, American biochemist and the founder of the MIT Artificial Intelligence Project Marvin Minsky was born. He is also known for his foundational work in the analysis of artificial neural networks. Yes, I did my diploma thesis in computer science on backpropagation networks, a special variant of neural networks. Therefore, Marvin Minsky definitely deserves an entry in this blog, simply because he is one of the fathers of artificial neural networks. Marvin Lee Minsky was born in New York City into a Jewish family in 1927. His father was an eye surgeon and Marvin attended The Fieldston School and the Bronx High School of Science. He later attended Phillips Academy in Andover, Massachusetts. He served in the US Navy from 1944 to 1945. He holds a BA in Mathematics from Harvard (1950) and a PhD in mathematics from Princeton (1954). He taught at Harvard before moving to the Massachusetts Institute of Technology in 1957 as professor of mathematics, a post he occupied until 1962 when he became professor of electrical engineering. In the summer of 1956 Minsky attended a conference on Artificial Intelligence (AI) at Dartmouth, New Hampshire. Here, it was generally agreed that powerful modern computers would soon be able to simulate all aspects of human learning and intelligence. Much of Minsky’s later career has been spent testing this claim. In 1959 Minsky and John McCarthy founded what is now known as the MIT Computer Science and Artificial Intelligence Laboratory. Under Minsky’s direction a number of AI programs have been developed at MIT. One of the earliest, a program to solve problems in calculus, showed that most problems could be solved by a careful application of about 100 rules. The computer actually received a grade A in an MIT calculus exam. Other programs developed such topics as reasoning by analogy, handling information expressed in English, and how to catch a bouncing ball with a robotic arm [2]. Already in 1951 as a student, Minsky built the first randomly wired neural network learning machine, SNARC. SNARC is a randomly connected network of Hebb synapses built in hardware using vacuum tubes, and was possibly the first artificial self-learning machine. In general, artificial neural networks are computational models inspired by an animal’s central nervous systems (i.e. the brain) which is capable of machine learning as well as pattern recognition. They are generally presented as systems of interconnected “neurons” which can compute values from inputs. Like other machine learning methods neural networks have been used to solve a wide variety of tasks that are hard to solve using ordinary rule-based programming, including computer vision and speech recognition. Minsky’s inventions include the first head-mounted graphical display (1963) and the confocal microscope (1957, a predecessor to today’s widely used confocal laser scanning microscope). Together with Seymour Papert he developed the first Logo “turtle”. LOGO is an educational programming language and a “turtle is something like a “robot” used in computer science and mechanical engineering training. Turtles specifically designed for use with Logo systems often come with pen mechanisms allowing the programmer to create a design on a large sheet of paper.   His seminal 1961 paper, “Steps Towards Artificial Intelligence” surveyed and analyzed what had been done before, and outlined many major problems that the infant discipline would later later need to face. The 1963 paper, “Matter, Mind, and Models” addressed the problem of making self-aware machines [1]. In 1969 Minsky wrote the book Perceptrons (with Seymour Papert), which became the foundational work in the analysis of artificial neural networks. This book is the center of a long-standing controversy in the study of artificial intelligence. It is claimed that pessimistic predictions made by the authors were responsible for an erroneous change in the direction of research in AI, concentrating efforts on so-called “symbolic” systems, and contributing to the so-called AI winter, a period of reduced funding and interest in artificial intelligence research. This decision, supposedly, proved to be unfortunate in the 1980s, when new discoveries showed that the prognostics in the book were wrong. Besides neural networks Minsky also founded several other famous AI models. His book “A framework for representing knowledge” created a new paradigm in programming. While his “Perceptrons” is now more a historical than practical book, the theory of frames is still a working concept in knowledge representation. Minsky has also written on the possibility that extraterrestrial life may think like humans, permitting communication. He was an adviser on Stanley Kubrick’s movie 2001: A Space Odyssey and is referred to in the movie as well as in Arthur C. Clarke’s original book. In the early 1970s at the MIT Artificial Intelligence Lab, Minsky and Seymour Papert started developing what came to be called The Society of Mind theory. The theory attempts to explain how what we call intelligence could be a product of the interaction of non-intelligent parts. Minsky says that the biggest source of ideas about the theory came from his work in trying to create a machine that uses a robotic arm, a video camera, and a computer to build with children’s blocks. In 1986, Minsky published The Society of Mind, a comprehensive book on the theory which, unlike most of his previously published work, was written for a general audience. Minsky won the Turing Award in 1969 – the most prestigious award in computer science, and is currently the Toshiba Professor of Media Arts and Sciences, and Professor of electrical engineering and computer science at MIT. The science fiction author Isaac Asimov described Minsky as one of only two people he would admit were more intelligent than he was, the other being Carl Sagan. At yovisto you can listen to Marvin Minsky’s lecture series ‘The Society of the Mind‘ in which he is here referring to the concept of Consciousness.'],\n",
       " [195,\n",
       "  'Dan Bricklin and VisiCalc.  VisiCalc.  On July 16, 1951, computer scientist Dan Bricklin was born. Together with Bob Frankston he created VisiCalc, the first spreadsheet computer program (1979) which created a market beyond hobbyists for the emerging personal computers. Today, everybody knows spreadsheet programs, no matter if you choose a desktop application or a web based application, spreadsheets are everywhere. And sometimes, we don’t have any idea, how we could possibly get along without them. So, what is a Spreadsheet? A spreadsheet is an interactive computer application program for organization and analysis of data in tabular form. Spreadsheets developed as computerized simulations of paper accounting worksheets. The program operates on data represented as cells of an array, organized in rows and columns. The user of the spreadsheet can make changes in any stored value and observe the effects on calculated values, which is rather useful for “what-if” analysis. In addition to the fundamental operations of arithmetic and mathematical functions, modern spreadsheets provide built-in functions for common financial and statistical operations. But, how did it all start? It was Dan Bricklin, born in 1951 into a Jewish family in Philadelphia, USA. He earned a Bachelor of Science in electrical engineering and computer science from the Massachusetts Institute of Technology in 1973. Upon graduating from MIT, Bricklin worked for Digital Equipment Corporation (DEC) until 1976, when he began working for FasFax, a cash register manufacturer. In 1977, he returned to school and he earned a Master of Business Administration from Harvard University in 1979. It was in his last year in Harvard Business School, when Bricklin was watching a presentation that gave him the first idea for VisiCalc. The professor was creating a financial model on a blackboard that was ruled with lines to create a table, and formulas and data were being written into the cells. When the professor found an error or wanted to change a parameter, he had to erase and rewrite a number of sequential entries in the table. Bricklin realized that he could replicate the process on a computer using an “electronic spreadsheet” to view results of underlying formulae. Bricklin was joined by Bob Frankston, and the pair worked on VisiCalc for two months during the winter of 1978–79, forming Software Arts. Visicalc was first published for the Apple II personal computer. The power of the VisiCalc concept was noticed immediately and for the first 12 months it was only available for the Apple II computer, and became that platform’s killer app. VisiCalc is widely credited for fueling the rapid growth of the personal computer industry. Instead of doing financial projections with manually calculated spreadsheets, and having to recalculate with every single cell in the sheet, VisiCalc allowed the user to change any cell, and have the entire sheet automatically recalculated. This turned 20 hours of work into 15 minutes and allowed for more creativity. In its 1980 review, BYTE wrote “The most exciting and influential piece of software that has been written for any microcomputer application is VisiCalc“. VisiCalc sold over 700,000 copies in six years, and as many as 1 million copies over its history. When Lotus 1-2-3 was launched in 1983, taking full advantage of the expanded memory of the PC and added integrated charting, plotting and database capabilities, VisiCalc sales practically ended overnight. Sales imploded so rapidly that the company was soon insolvent. The next milestone for spreadsheets was the Microsoft Excel spreadsheet. Excel was originally written for the 512K Apple Macintosh in 1984-1985 and was one of the first spreadsheets to use a graphical interface with pull down menus and a point and click capability using a mouse pointing device. Spreadsheets have even found there way into popular culture. As for example in Douglas Adams novel “Dirk Gently’s Holistic Detective Agency“ he describes a character named Richard MacDuff, a young software engineer. MacDuff is the programmer of a rather popular application called Anthem, which is designed as a spreadsheet, but also has a unique feature to convert corporate accounts into music. I really would appreciate a feature like that At yovisto you can watch Dan Bricklin himself in a talk he gave at StartupBootcamp telling the story of VisiCalc.'],\n",
       " [196,\n",
       "  'The Antikythera Mechanism – an Ancient Analog Computer.  The Antikythera mechanism.  On May 17, 1902, Greek archaeologist Valerios Stais discovers the Antikythera mechanism, an ancient mechanical analog computer, designed to predict astronomical positions and eclipses. The famous mechanism was discovered in a shipwreck near the Greekisland of Antikythera. In October 1900, a group of sponge divers discovered the wreck and retrieved a great number of artifacts dating back to the end of the second century BC, which included bronze and marble statues, pottery, glassware, jewelry, coins, and of course, the mechanism. All together, they were brought to the National Museum of Archaeology in Athens for research purposes. However, the mechanism itself stayed unnoticed for over two years. The big clot of corroded bronze and wood looked pretty inconspicuous to the museum staff and they decided that other pieces had a higher priority. It took two more years until archaeologist Valerios Stais found out that one of the pieces belonging to the mechanism had some kind of gear wheel embedded in it. The scientist immediately thought of an astronomical clock, but most of the archeologists examining the mechanism from then on believed it to be prochronistic due to its incredible complexity. Unfortunately for Stais, the investigations on the device were dropped. The physicist, historian of science, and information scientist Derek J. de Solla Price increased his interest in the mechanism in 1951. Along with the Greek nuclear physicist Charalampos Karakalos he took X-ray and gamma-ray images and published a very large scientific paper on their findings in the 1970s. It was quickly realized, how important the mechanism was and Cardiff University professor Michael Edmunds, who led a 2006 study of the mechanism, described the device as “more valuable than the Mona Lisa“. Antikythera Machine mechanical model Image: Mogi Vicentini Derek Price concluded that the device was an astronomical computer capable of predicting the positions of the sun and moon in the zodiac on any given date. A new analysis, though, suggests that the device was even more complex than the scientist thought and reinforces the evidence for his theory of an ancient Greek tradition of complex mechanical technology. Today, the device is often called the first analog computer. However, it is also assumed that the mechanism may have had predecessors during the Hellenistic Period that remained undiscovered. One of the things that astonished the experts the most was the high level of miniaturisation and overall complexity that was for example seen in 14th century astronomical clocks. Since research on the device progressed only slowly and needed decent funding, the Antikythera Mechanism Research Project was initiated in 2005. It is an international collaboration of academic researchers, which aims to completely reassess the function and significance of the Antikythera Mechanism. Recent findings of the project suggest that the concept for the mechanism originated in the colonies of Corinth, since some of the astronomical calculations seem to indicate observations that can be made only in Corinth area of ancient Greece. Also, a connection to the school of Archimedes is assumed, since Syracuse was a colony of Corinth and the home of the inventor, mathematician and engineer. But this is not the only theory regarding the device’s origin. Some historians assume that it may have been built in the ancient Greek city of Pergamon. It was found out that the mechanism was operated by turning a small hand crank which was linked via a crown gear to the largest gear. This allowed the setting of the date on the front dial and the calculation of the position of the Sun and Moon and other astronomical information was possible. It is known that the device has at least 30 gears, but on this day it is still argued whether the mechanism had indicators for all five of the planets known to the ancient Greeks. It is assumed that the gears were created from a blank bronze round using hand tools and with the help of X-ray images, the precise number of teeth and size of the gears within the located fragments could be determined and thus, the basic operation of the device was revealed. Another point that was highly discussed was the question whether the mechanism was based on the geocentric or even the heliocentric model. It was then found out that since the device’s purpose was to position astronomical bodies with respect to the celestial sphere, in reference to the observer’s position on the Earth, the device was based on the geocentric model. In 2012, the Woods Hole Oceanographic Institution in the United States received permission from the Greek Government to conduct new dives around the deep shoals of Antikythera. The researchers hope to find other small pieces of the Antikythera mechanism on the sea floor as well as to locating and surveying the wrecks of other ships that foundered near the island. At yovisto, you may be interested in a discussion about ‘The Technology of the Antikythera Mechanism‘ at the Getty Museum.'],\n",
       " [197,\n",
       "  'Rudy Rucker – Infinity and the Mind.  Rudy Rucker, Fall 2004, photo by Georgia Rucker.  On March 22, 1946, American mathematician, computer scientist, science fiction author, and philosopher Rudolph von Bitter Rucker, better known as Rudy Rucker, was born. He is also one of the founders of the cyberpunk literary movement. Rucker was born and raised in Louisville, Kentucky, where his father Embry Cobb Rucker, Sr., a descended from Flemish Huguenots, ran a small furniture-manufacturing company. Later in life, Embry Cobb Rucker, Sr. became an Episcopal minister and worked as parish priest for the rest of his life. His mother, Marianne von Bitter originally was from Berlin and came to study at the Pennsylvania Academy of Fine Arts in Philadelphia in 1937. She was an enthusiastic gardener, amateur artist and potter. Moreover, she also was a descendent of famous German philosopher Georg Wilhelm Friedrich Hegel. Rucker attended St. Xavier High School before earning a B.A. in mathematics from Swarthmore College in 1967 and M.S. (1969) and PhD (1973) degrees in mathematics from Rutgers University with a specialization on mathematical logic. In 1972, Rucker started teaching in the Math. Dept. at the State University College at Geneseo, New York, with a “Higher Geometry” course, which turned into a series of lectures on the fourth dimension. Eventually he wrote the lectures up as Geometry, Relativity and The Fourth Dimension, published by Dover Publications, which should become the foundation of his writing career. Thanks to a grant from the German Alexander von Humboldt Foundation, Rucker taught math at the Ruprecht Karl University of Heidelberg from 1978 to 1980. He then taught at Randolph-Macon Women’s College in Lynchburg, Virginia from 1980 to 1982, before trying his hand as a full-time author. Inspired by an interview with British scientist Stephen Wolfram, Rucker became a computer science professor at San José State University in 1986, from which he retired in 2004. “Computationsare everywhere, once you begin to look at things in a certain way.” (Rudy Rucker) A mathematician with philosophical interests, Rucker published Infinity and the Mind in 1982. The book contains accessible popular expositions on the mathematical theory of infinity, and a number of related topics. These include Gödel’s incompleteness theorems and their relationship to concepts of artificial intelligence and the human mind, as well as the conceivability of some unconventional cosmological models. The material is approached from a variety of viewpoints, some more conventionally mathematical and others being nearly mystical. As his “own alternative to cyberpunk,” Rucker developed a writing style he terms Transrealism. The essence of transrealism, as outlined in his 1983 essay “The Transrealist Manifesto,” is to write about one’s real life in fantastic terms. The Secret of Life, White Light, and The Sex Sphere are examples of his transreal novels. The first recasts a traditional coming of age memoir as a UFO novel, the second is about Rucker’s time as a mystical mathematician at SUNY Geneseo, while the third turns his two years in Germany into a tale of higher dimensions and nuclear terrorism. Rucker is presently working on a 1950s SF novel called The Turing Chronicles, featuring a love affair between computer pioneer Alan Turing and Beat author William Burroughs. Rucker often uses his novels to explore scientific or mathematical ideas; White Light examines the concept of infinity, while the Ware Tetralogy is in part an explanation of the use of natural selection to develop software. His non-fiction book, The Lifebox, the Seashell, and the Soul: What Gnarly Computation Taught Me About Ultimate Reality, the Meaning Of Life, and How To Be Happy summarizes the various philosophies he’s believed over the years and ends with the tentative conclusion that we might profitably view the world as made of computations, with the final remark, “perhaps this universe is perfect.” At yovisto you can watch Rudy Rucker delivering a rather interesting talk at TEDx Brussels 2012 about “Beyond Machines: The Year 3000“.'],\n",
       " [198,\n",
       "  'J.C.R. Licklider and Interactive Computing.  A SAGE operator’s terminal Image: Joi Ito.  On March 11, 1915, American psychologist and computer scientist J.C.R. Licklider, known simply as J.C.R. or “Lick“, was born. He is particularly remembered for being one of the first to foresee modern-style interactive computing and was one of the most distinguished Internet pioneers. Licklider was born in St. Louis, Missouri and his engineering talents became clear pretty early, when he built model airplanes as a child. He enrolled at Washington University in St. Louis, where he received a bachelor of arts degree in 1937. Licklider received his master degree one year later, majoring in physics, psychology, and mathematics. After receiving a PhD in psychoacoustics from the University of Rochester in 1942, Licklider moved to Harvard where he started working at the Psycho-Acoustic Laboratory. J.C.R Licklider Licklider’s interest in information technologies evolved in the late 1940s. His early ideas foretold of graphical computing, point-and-click interfaces, digital libraries, e-commerce, online banking, and software that would exist on a network and migrate wherever it was needed. The scientist moved to MIT, where he was appointed associate professor and served a committee that established a psychology program for engineering students. Also, he worked on the SAGE-Program, a Semi-Automatic Ground Environment creating a computer-aided air defense system. Licklider worked there as a human factors experts, which convinced him of the great potential for computer interfaces. Licklider became a Vice President at Bolt Beranek and Newman, Inc., where he bought the first production PDP-1 computer and conducted the first public demonstration of time-sharing. At DARPA, Licklider continued his career, where he became the head of the Information Processing Techniques Office. Shortly after, he was named Director of Behavioral Science. This version led to the precursor of today’s internet, the ARPAnet. Licklider also did some seminal early work for the Council on Library Resources, imagining what libraries of the future might look like and describing them as “thinking centers.” Licklider became part of the MAC project at MIT, where a large mainframe computer was designed to be shared by up to 30 simultaneous users, each sitting at a so called typewriter terminal. The first computer time-sharing system and one of the first online setups with the development of Multics were established. During his active years in computer science, Licklider managed to conceive, manage, and research the fundamentals that led to modern computers and the Internet as we know it today. His 1960 scientific paper on the Man-Computer Symbiosis was revolutionary and foreshadowed interactive computing. This inspired many other scientists to continue early efforts on time-sharing and application development. One of the scientists funded by Licklider’s efforts was the famous American computer scientist Douglas Engelbart, whose efforts led to the invention of the computer mouse. At yovisto, you may be interested in the 1972 documentary ‘Computer Networks: Heralds of the Resource Sharing‘, which shows some great people (including J.C.R Licklider) who were designing and operating open networks which were eventually developed to what we now know as the Internet.'],\n",
       " [199,\n",
       "  'The Birth of the Internet.  On October 29, 1969, the very first message between two distant computer nodes, from the Network Measurement Center at the UCLA’s School of Engineering and Applied Science and SRI International (SRI) was sent. This is to be considered the birth of the ARPANET, which should become the Internet.  What was the reason for the development of the Internet? Especially in the 1960s, when computers were absolutely not widespread or ubiquitous as today. Moreover, computers in the 1960s did not follow the same or similar hardware and software architecture. This means that for two computers to communicate, a special translation interface must be constructed either way by hardware and by software. On the other hand, we are in the 1960s. In the late 1940s, Thomas Watson, founder of IBM stated “I think there is a world market for maybe five computers.” We know that he was wrong. But, there were only a few computers around concentrating on research laboratories, universities, or working for the military. The founding myth of the internet always refers to the so called “Sputnik Shock” as being the initial event. On October 4, 1957, the Soviet launched the very first satellite into orbit. Thus, proving that they were also able to reach the USA with their ballistic missiles. This first strike capability gave them a significant advantage in the times of Cold War. US president Eisenhower in response founded the ARPA, the Advanced Research Projects Agency, to catch up the Soviet’s military and scientific advantage. One of the many projects being founded by ARPA was also computer network communication. Something exotic, considering the times and the circumstances. But, nevertheless, in times of potential nuclear thread it seemed not to be difficult to come up with an argument to support also the funding of more or less ‘esoterical’ technologies.  For this reason you might read that the internet was developed as response to he Soviet nuclear threat to enable fault tolerant computer network communication that will also work when parts of the communication network might get destroyed by a nuclear blast (or something else). The internet’s fault tolerance really is something extraordinary, compared to the previous switching networks that failed, whenever some relay station went out of service and the network traffic had to be explicitly rerouted. The internet is based on the principle of packet switching. Thus, contrariwise to the way traditional telephone services are working – i.e. a connection between sender and receiver is established and along the switched connection the entire message is transferred, blocking the communication for other parties until the message is received completely – packet switching splits the message in small packets that are sent independently over various routes within the network. This has several advantages: First, a connection is only blocked for the time one small packet needs to travel from sender to receiver. Other users might also send their packets in between the packets from the original sender. Second, if a packet got lost, only the packet has to be retransmitted instead of the entire message. Thus making network communication more efficient. The principle of packet switching was already developed by Paul Baran from RAND Corporation in 1959.  The earliest ideas for a computer network intended to allow general communications among computer users were formulated by J. C. R. Licklider of Bolt, Beranek and Newman (BBN), in April 1963, in memoranda discussing his concept for an “Intergalactic Computer Network“. Those ideas contained almost everything that composes the contemporary Internet. In October 1963, Licklider was appointed head of the Behavioral Sciences and Command and Control programs at the Defense Department‘s Advanced Research Projects Agency — ARPA (the initial ARPANET acronym). He then convinced Ivan Sutherland and Bob Taylor that this computer network concept was very important and merited development, although Licklider left ARPA before any contracts were let that worked on this concept. Ivan Sutherland and Bob Taylor continued their interest in creating such a computer communications network, in part, to allow ARPA-sponsored researchers at various corporate and academic locales to put to use the computers ARPA was providing them, and, in part, to make new software and other computer science results quickly and widely available. In his office, Taylor had three computer terminals, each connected to separate computers, which ARPA was funding: the first, for the System Development Corporation (SDC) Q-32, in Santa Monica  “For each of these three terminals, I had three different sets of user commands. So, if I was talking online with someone at S.D.C., and I wanted to talk to someone I knew at Berkeley, or M.I.T., about this, I had to get up from the S.D.C. terminal, go over and log into the other terminal and get in touch with them. I said, “Oh Man!”, it’s obvious what to do: If you have these three terminals, there ought to be one terminal that goes anywhere you want to go. That idea is the ARPANET“. The problem remains that for connecting a number of computers of various architectures, you need one dedicated interface between each pair of connected computers. Thus, for 4 computers, you will need 6 interfaces, for 5 computers, you will need 10, for 6 computers, you will need 15, for 10 computers you will need 45 and for 100 computers even 4,950 interfaces. The growth of the number of required interfaces would be quadratic. Therefor, Robert Taylor developed the following plan: a network composed of small computers called Interface Message Processors (IMPs: today called routers), that functioned as gateways interconnecting local resources. At each site, the IMPs performed store-and-forward packet switching functions, and were interconnected with modems that were connected to leased lines, initially running at 50kbit per second. The host computers were connected to the IMPs via custom serial communication interfaces. In this way, communication was performed in a subnetway and only for each hardware architecture exactly one interface had to be developed to connect to the subnetway.  The first four computers connected to the now called ARPANET were an SDS Sigma 7 from the University of California, Los Angeles (UCLA), an SDS 940 from the Stanford Research Institute’s Augmentation Research Center, an IBM 360 75 from University of California, Santa Barbara (UCSB), and a DEC PDP-10 from University of Utah‘s Computer Science Department. The first message on the ARPANET was sent by UCLA student programmer Charley Kline, at 10:30 pm on 29 October 1969, from Boelter Hall 3420. Kline transmitted from the university’s SDS Sigma 7 Host computer to the Stanford Research Institute’s SDS 940 Host computer. The message text was the word login  At yovisto you can learn more about the beginnings of the Internet in the historic documentary ‘Computer Networks: Heralds of the Resource Sharing‘, where you will meet some of the early internet pioneers in person, such as J. C. R. Licklider, Larry Roberts or Robert Taylor.'],\n",
       " [200,\n",
       "  'The Last Lecture of Randy Pausch.  Randy Pausch (1960 – 2008).  On October 23, 1960, professor of computer science and human-computer interaction Randy Pausch was born. He is best known for a lecture titled “The Last Lecture: Really Achieving Your Childhood Dreams” he gave after he had learned that he had pancreatic cancer, which became rather popular on youtube. Randy Pausch studied at Brown University and received his Ph.D. in computer science at Carnegie Mellon University in the 1980’s. He fulfilled a childhood’s dream while completing sabbaticals at Walt Disney Imagineering and became Associate Professor of Computer Science, Human-Computer Interaction and Design, at Carnegie Mellon University in 1997. Pausch started teaching a course, in which the students coming from all departments built virtual worlds and presented them at the end of the semester. With this course that lasted for 10 years, Pausch became one of the most appreciated and liked teachers at CMU. During his time at the Carnegie Mellon University, Randy Pausch also started a software project called Alice. The 3D programming environment was designed to enable children to learn how to program Java, C, and C++ in the most enjoyable way possible. The free software allows students to learn fundamental programming concepts in the context of creating animated movies and simple video games and is still available on this day. In August 2007, Randy Pausch was told to expect three to six months of good health living after being diagnosed with pancreatic cancer. On September 18, 2007, Pausch gave his famous last lecture at Carnegie Mellon University called ‘The Last Lecture: Really Achieving Your Childhood Dreams’ and it was dedicated to his three children and wife. Originally, Pausch was invited to give the talk in the series ‘the last lecture‘ independent from his illness, just like several other scientists at CMU. After receiving the terminal diagnose however, Pausch and his family decided this to be a good event for sharing his real last thoughts and inspirations to the world. The auditorium was filled with 450 students, staff members and friends, who greeted the lecturer with a standing ovation. Starting his talk, Pausch explained that he would not talk about his wife, children, his terminal cancer or religion and spirituality at this point. Next, Pausch described his childhood dreams like becoming a Disney Imagineer, being in zero gravity, playing in the NFL or being the author of a World Book Encyclopedia article. As the lecture continued, he explained how he got to achieve his goals, how to overcome “brick walls” and why it is important to fail at things once in a while. In the following, Pausch started talking about the importance of enabling childhood dreams of others and described that becoming a professor was the best decision in order to do so. After the quite emotional ending of the lecture in which Pausch also explained that everyone has to decide whether he or she is “a Tigger or an Eeyore“, Pausch again received a standing ovation and was honored by several former professors and colleagues. The lecture received an incredible media attention and soon, Randy Pausch was nominated ABC‘s “Person of the Week”. He appeared at Oprah Winfrey, joined the Pittsburgh Steelers for one practice day and was even invited to shoot a role in the latest Star Trek movie. Randy Pausch passed away on July 25, 2008 at his family’s home. At yovisto, you may watch the famous last lecture from 2007.'],\n",
       " [201,\n",
       "  'FORTRAN – The First Programming Language for Numeric Calculations.  Cover of The Fortran Automatic Coding System, the first book about FORTRAN.  On October 15, 1956, the Reference Manual for the Programming Language FORTRAN – The IBM Mathematical Formula Translating System – was published. It is considered the very first high-level programming language. FORTRAN was developed at IBM under the guidance of John W. Backus to develop a more practical alternative to assembly language for programming their IBM 704 mainframe computer. FORTRAN became to dominate the area of numerical programming early on and has been in continual use for over half a century in computationally intensive areas such as numerical weather prediction, finite element analysis, computational fluid dynamics, computational physics and computational chemistry. The story of FORTRAN begins in late 1953, when computer scientist John W. Backus submitted a proposal to his superiors at IBM to develop a more practical alternative to assembly language for programming their IBM 704 mainframe computer. If you are not a programmer, you have to know that programming in assembly language means to break an abstract programming problem down into machine instructions. Thus, blowing up simple algorithmic tasks to complex problems, which are rather hard to manage and to maintain. Moreover, assembly language depends always on the computer’s architecture and thus, programs written in assembly language won’t be able to be shared among several different computers. Therefor, soon the idea of a high-level programming language came up, raising the tedious task of programming to a more abstract level, and enabling programs to be generally portable across multiple architectures. To achieve this, higher-level programming languages must be (automatically) translated into machine instructions with the help of a special program called interpreter or compiler. “God is Real, unless declared Integer.” (J. Allan Toogood, FORTRAN programmer) John W. Backus‘ historic FORTRAN team consisted of programmers Richard Goldberg, Sheldon F. Best, Harlan Herrick, Peter Sheridan, Roy Nutt, Robert Nelson, Irving Ziller, Lois Haibt, and David Sayre. One of the most important concepts to be realized included easier entry of equations into a computer, an idea developed by J. Halcombe Laning and demonstrated in his GEORGE compiler of 1952. A draft specification for The IBM Mathematical Formula Translating System was completed by mid-1954. The first manual for FORTRAN then appeared in October 15, 1956, with the first FORTRAN compiler delivered in April 1957. The main problem of early compilers was efficiency, i.e. the translation process from higher-level programming language into machine instructions usually ended up in sub-optimal machine programs, which compared to hand-coded machine programs were much more complex and also slower in the execution. Therefore, the FORTRAN compiler was realized as an optimizing compiler, because customers were reluctant to use a high-level programming language unless its compiler could generate code whose performance was comparable to that of hand-coded assembly language. “The determined Real Programmer can write FORTRAN programs in any language.” (Ed Post, Real Programmers Don’t Use Pascal, 1982) While the community was skeptical that this new method could possibly outperform hand-coding, it reduced the number of programming statements necessary to operate a machine by the incredible factor of 20, and therefore quickly gained acceptance. John Backus said during a 1979 interview with ‘Think, the IBM employee magazine’, “Much of my work has come from being lazy. I didn’t like writing programs, and so, when I was working on the IBM 701, writing programs for computing missile trajectories, I started work on a programming system to make it easier to write programs.“ FORTRAN was widely adopted by scientists for writing numerically intensive programs, which encouraged compiler writers to produce compilers that could generate faster and more efficient code. The inclusion of a complex number data type in the language made Fortran especially suited to technical applications such as electrical engineering. Significantly, the increasing popularity of FORTRAN spurred competing computer manufacturers to provide FORTRAN compilers for their machines, so that by 1963 more than 40 FORTRAN compilers for various computer architectures existed. For these reasons, FORTRAN is considered to be the first widely used programming language supported across a variety of computer architectures. As a short example of FORTRAN programming code, here is FORTRAN version of the ‘hello-world’-program: program helloworld print *, “Hello, world!” end program helloworld Also by today, FORTRAN is still one of the most popular languages in the area of high-performance computing and is the language used for programs that benchmark and rank the world’s fastest supercomputers. At yovisto you can learn more about the origins of the first mathematical high level programming language FORTRAN in the short documentary ‘The Beginnings of FORTRAN‘.'],\n",
       " [202,\n",
       "  'John Atanasoff and the first Electronic Digital Computer.  John Vincent Atanasoff (1903-1995). On October 4, 1903, American physicist and inventor John Vincent Atanasoff was born. He is best known for being considered as one of the inventors of the electronic digital computer. Even computer scientists most probably haven’t heard anything of this computer pioneer. Of course you will have heard about Alan Turing or John von Neumann, who are traditionally referenced as being the fathers of the computer. Maybe, when you are European or even German, then you most probably will have heard of Konrad Zuse, who in near total intellectual isolation constructed the first universal computer Z3, which became operational in May 1941. So why is it, we haven’t heard of John Atanasoff John Atanasoff, of Bulgarian, French and Irish ancestry, was born on October 4, 1903 in Hamilton, New York to Ivan Atanasoff, an electrical engineer and a school teacher, who had immigrated to the United States in 1889. Atanasoff’s mother, Iva Lucena Purdy, was a teacher of mathematics. Atanasoff was raised in Brewster, Florida. Already at the age of nine he learned to use a slide rule and logarithms. In 1925, he received his bachelor of science degree in electrical engineering from the University of Florida and continued at Iowa State College, where he earned his master’s degree in mathematics in 1926. In 1930 by he received a PhD in theoretical physics from the University of Wisconsin–Madison and accepted a professorship at Iowa State College in mathematics and physics. While working at his PhD thesis, Atanasoff became rather frustrated about the available mechanical calculation machines and began to search for faster methods of computation. In 1936 Atanasoff invented an analog calculator for analyzing surface geometry. The fine mechanical tolerance required for good accuracy pushed him to consider digital solutions. According to Atanasoff, several operative principles of his famous invention, the Atanasoff–Berry Computer (ABC), were conceived in a flash of insight during the winter of 1937–1938 after a drive to Rock Island, Illinois. One night in a bar on the Illinois-Iowa border, after another frustrating day performing tedious mathematical calculations in his lab, Atanasoff hit on the idea that the binary number system and electronic switches, combined with an array of capacitors on a moving drum to serve as memory, could yield a computing machine that would make his life as a scientist easier. With a grant of $650 received in September 1939 Atanasoff went back to his office and with the assistance of his graduate student Clifford Berry, he built the machine by November of that year. The prototype really worked. The whole world changed. The key ideas employed in the ABC included binary math and Boolean logic to solve up to 29 simultaneous linear equations. The ABC had no central processing unit (CPU), but was designed as an electronic device using vacuum tubes for digital computation. It also used separate regenerative capacitor memory that operated by a process still used today in DRAM memory. Between 1954 and 1973, Atanasoff was a witness in the legal actions brought by various parties to invalidate electronic computing patents issued to John Mauchly and J. Presper Eckert, who designed ENIAC, the first general purpose electronic digital computer. The patents were owned by computer manufacturer Sperry Rand. But in 1973 a court declared that the patent on the Sperry Rand UNIVAC device was invalid and declared Atanasoff the inventor of the electronic digital computer, opening the intellectual property gates to the computer revolution. In 1980, Dr. John Atanasoff gave a lecture at the Digital Computer Museum in Massachusetts, where he discusses his life, the events that lead to his breakthroughs in computing and the design of the Atanasoff–Berry Computer.'],\n",
       " [203,\n",
       "  'GNU’s not Unix.  On September 27, 1983, American software freedom activist and computer programmer Richard Stallman announced the GNU project. Its aim is to give computer users freedom and control in their use of their computers and computing devices, by collaboratively developing and providing software. You’ve probably never heard of GNU, unless you are a computer scientist or some kind of software developer. But, GNU denotes the starting point of a development that still continues today – the concept of public domain software, with GNU as a Unix-like operating system that started it all leading to other public domain operating systems such as FreeBSD or Linux. The Unix operating system is a multitasking, multi-user computer operating system originally developed in 1969 by a group of AT&T employees at Bell Labs, including among others Ken Thompson, Dennis Ritchie, Brian Kernighan. Unix soon became rather popular because it was written in a high-level programming language(instead of assembly language), it was based on a rather simple file data structure(everything in the file system was treated as simple byte arrays), and it came with lots of rather useful little tools that made the life of a programmer so much easier. But, of course it was proprietary software. This means that a single company took hold of the copyright and decided about future improvements, extensions, and development of the operating system. In the late 1970s and early 1980s, the hacker culture began to fragment. To prevent software from being used on their competitors’ computers, most manufacturers stopped distributing source code and began using copyright and restrictive software licenses to limit or prohibit copying and redistribution.In 1980, Richard Stallman, an employee from the Massachusetts Institute of Technology (MIT) Artificial Intelligence Laboratory together with some other hackers at the AI Lab were refused access to the source code for the software of a newly installed laser printer, the Xerox 9700. Stallman had modified the software for the Lab’s previous laser printer, so it electronically messaged a user when the person’s job was printed, and would message all logged-in users waiting for print jobs if the printer was jammed. Not being able to add these features to the new printer was a major inconvenience, as the printer was on a different floor from most of the users.This experience convinced Stallman of people’s need to be free to modify the software they use. As a reaction to these events, Richard Stallman publicly announced the GNU project on September 27, 1983 on the net.unix-wizards and net.usoft newsgroups, an ambitious effort to create a free software Unix-like system; “free” in that everyone who received a copy would be free to use, study, modify, and redistribute it. Stallman argued that software users should have the freedom to share with their neighbor and to be able to study and make changes to the software that they use. He maintains that attempts by proprietary softwarevendorsto prohibit these acts are antisocial and unethical. “As an operating system developer, I had the right skills for this job. So even though I could not take success for granted, I realized that I was elected to do the job. I chose to make the system compatible with Unix so that it would be portable, and so that Unix users could easily switch to it.” (Richard Stallman on GNU) GNU Software development began on January 5, 1984, when Stallman quit his job at the Massachusetts Institute of Technology so that they could not claim ownership or interfere with distributing GNU as free software. In 1985, Stallman published the GNU Manifesto, which outlined his motivation for creating a free operating system called GNU, which would be compatible with Unix. The name GNU is a recursive acronym for “GNU’s Not Unix.” Soon after, he started a nonprofit corporation called the Free Software Foundation to employ free software programmers and provide a legal infrastructure for the free software movement. Furthermore, he popularized the concept of copyleft, a legal mechanism to protect the modification and redistribution rights for free software. It was first implemented in the GNU Emacs General Public License, and in 1989 the first program-independent GNU General Public License (GPL) was released. In 1991, Linus Torvalds, a Finnish student, used the GNU development tools to produce the Linux kernel. The existing programs from the GNU project were readily ported to run on the resultant platform. Stallman‘s influences on hacker culture also include the famous Emacs editor. On UNIX systems, GNU Emacs‘s popularity rivaled that of another editor vi, spawning an editor war. Stallman‘s take on this was to canonize himself as St. IGNUcius of the Church of Emacs and acknowledge that “vi vi vi is the editor of the beast,” while “using a free version of vi is not a sin; it is a penance“. While on the other side supporters of vi have created an opposing Cult of viand argued by the more hardline Emacs users to be an attempt to “ape their betters“. Richard Stallman has written many essays on software freedom and since the early 1990s has been an outspoken political campaigner for the free software movement, which he has devoted the bulk of his life. At yovisto you can learn more about software freedom activist Richard Stallman in a lecture he gave at the University of Calgary in 2005 on ‘The Danger of Software Patents‘.'],\n",
       " [204,\n",
       "  'Space Invaders!.  Space Invaders Image:  Adlen In early June 1978 – we have not been able to determine the exact date – the famous arcade video game Space Invaders designed by Tomohiro Nishikado was released by the Japanese Taito Corporation. Space Invaders is one of the earliest shooting games and the aim is to defeat waves of attacking aliens with a laser cannon to earn as many points as possible. As the invaders were shot down one by one, their march grew faster and faster, until a lone invader sped across the screen. If you managed to hit them all, a new wave of invaders would take to the sky. But if the aliens were able to hit ground zero, it was game over for you and for the Earth. With the inspiration of Atari’s game Breakout, Tomohiro Nishikado spent one year planning, designing and developing the needed hardware for the game. If you believe it or not, the game was in the sense of its graphics alot more advanced than Breakout. Also the game play was a bit more complex and allowed the player to shoot moving objects instead of static ones. The developer faced the difficulty of creating flying objects after he thought of using a space theme and found that computing humans would be alot easier but immoral in his eyes. The figures in the game were created after Nishikado saw a movie adaptation of H.G Well’s ‘War of the Worlds‘. He had to build his own hardware because the common microcomputers in Japan were not powerful back then for designing a game of such a complexity. For his programming purposes, Nishikado created the arcade board with new microprocessors imported from the U.S., but even those were not quite as powerful as Nishikado wished. However, the game was released in black and white at first, the colored monsters were published a bit later. Soon after the game’s release in Japan, whole new arcades with Space Invader cabinets opened and it became widely popular. Only a few months after the release, more than 100,000 machines were set up. 500,000 plus coin-op machines were sold worldwide in the first year, seventy percent of which remained in Japan. Space Invaders not only depicted the world’s most famous arcade game of its time, but was also seen as the ‘killer app’ for the upcoming game consoles. The high popularity of the games was, as specialists later found, the fact that it depicted one of the most complex shooting games of its time because the enemy targets shot back for the first time. Actually, in Japan demand for the arcade game was so great that it led to a coin shortage and prompted an increase in production of the 100-yen coin. At yovisto, you may enjoy the original Human Space Invader Performance made by Guillaume Reymond in Switzerland.'],\n",
       " [205,\n",
       "  'Vannevar Bush and the Memex.  Vannevar Bush (1890-1974).  On March 11, 1890, American engineer, inventor and science administrator Vannevar Bush was born. He is best known as as head of the U.S. Office of Scientific Research and Development (OSRD) during World War II, through which almost all wartime military research and development was carried out, including initiation of the Manhattan Project. In computer science we know Vannevar Bush as the father of the memex, an adjustable microfilm viewer with a structure analogous to that of the World Wide Web. The origins of the World Wide Web as a distributed hypermedia system date back further than 1990, as you might have guessed. Of course, before hypermedia there was hypertext and already in the late 1960s Ted Nelson presented the idea of Xanadu, an early hypertext system. But did you know that already in the mid 1940s – in the time when the very first computers hit the stage filling up entire rooms and performing less than you average mobile phone today – Vannevar Bush came up with the idea of the memex, the proposal of a hypermedia system based on electromechanics and microfilm, enabling the user to access information at his very ‘fingertips’ Vannevar Bush was born on March 11, 1890, in Everett, Massachusetts, as the third child and only son of Perry Bush, the local pastor, and his wife Emma Linwood. In 1892, the Bush family moved to Chelsea, Massachusetts, where Vannevar Bush graduated from Chelsea High School in 1909. Like his father before him, he attended Tufts College, which allowed students to gain a master’s degree in four years simultaneously with a bachelor’s degree. Thus, Bush graduated in 1913 receiving both bachelor of science and master of science degrees. By this time, Bush had already patented his first engineering invention, a surveying device. Next, Bush went to work for General Electric testing electrical equipment, but he was laid off after a fire broke out in his plant. In 1914, he took a position teaching math at Tufts’ sister college-Clark University, the same year he started to pursue his PhD at MIT where he earned his doctorate in engineering in less than a year ad then returned to Tufts as a assistant professor. In the first World War in which the U.S. entered in 1917, Bush had an idea for a device that would use magnetic fields to detect submarines. He traveled to Washington and convinced the director of the National Research Council to pursue his idea, which tested successful but proved to be virtually useless in real combat. By the 1930’s Bush was working on analog computers, which actually used large gears and other mechanical parts to solve equations. In 1931, he completed the first differential analyzer – a machine that was used to solve differential equations with as many as eighteen independent variables. Thus, Bush was one of the first to construct a machine based on the computer concepts developed in the nineteenth century by computer pioneer Charles Babbage. Bush’s science policy activities also began in the 1930s. From 1938 to 1955 he served as president of the Carnegie Institution in Washington, one of the first privately-financed scientific research organizations in the U.S. During World War II he became director of the OSRD, a presidential appointment which made him responsible for the 6,000 scientists involved in the war effort. Research guided by the OSRD also included the development of radar and the Manhattan Project to develop the atomic bomb. After World War II, Bush played an important role in the Federal government’s financial support of basic research leading to the establishment of the National Science Foundation. As mentioned at the beginning Bush is most famous for his memex, envisioning an automated information management system, which later inspired many of the creators of the Internet. But, in his Atlantic Magazine article Bush also envisioned descriptions of other rarely cited but nevertheless interesting devices, such as e.g., the Cyclops Camera, “worn on forehead, it would photograph anything you see and want to record. Film would be developed at once by dry photography.” or the Vocoder, “a machine which could type when talked to”. During the next decades Bush was appointed chairman or director of many institutions including the Joint Research and Development Board of the War and Navy Departments, the Development Board of National Military Establishment, and also of AT&T. At yovisto you can learn more about the origins of the World Wide Web and its early visionary pioneers including Vannevar Bush in Alex Wrights presentation ‘The Web that Wasn’t‘.'],\n",
       " [206,\n",
       "  'Amusing Ourselves to Death by Neil Postman.  Neil Postman (1931 – 2003).  On March 8, 1931, media theorist, author, and cultural critic Neil Postman was born. He is best known for his works criticizing the increase of the role of technology in every human’s life not seeing the dangerous side effects. Neil Postman spent almost all of his lifetime in New York City and graduated at the State University of New York, receiving a master’s degree in 1955. A few years later, he began teaching at the New York University and founded a graduate program in media ecology. In his further career, Postman became professor and chairman of the Department of Culture and Communication. Neil Postman earned himself an astonishing reputation through the years criticizing new technologies as they could “never substitute for human values“, which he distributed in 18 books and hundreds of newspaper and magazine articles. Amusing Ourselves to Death from 1985 presumably depicts Postman‘s best known work, in which he warns society about the increase of mass communication in order to lose the ability to share and discuss rather serious topics, such as politics, journalism or education adequately. According to Postman, television turns serious and complex issues into superficial topics, aiming to entertain instead of inform society. His work was translated into eight languages and was sold over 200.000 times. In 1990, Postman gave a speech at the German Society for Computer Science stating that the way our society depends on information is critical and has become more of a burden instead of a benefit. Another well known and highly discussed work by Postman depicts his 1992 published book Technopoly. In this work, the technopoly is a culture like the United States, longing for efficiency, preferring technical calculations over human judgement. In order to Postman, this is a problem since more technology produces more information. He later states that all affected humans, preferably students should have access to learn all effects of the increasing role of technology in their future. In his argumentation, Postman often refers to specific situations in the middle ages, just as he did in The Disappearance of Childhood. He argues that since the middle ages, society developed a whole different role of the childhood in a human’s life. Childhood became innocent and independent from adult’s problems, speech and thoughts. Postman also argues that since the spread of television in society, childhood loses this innocence. According to the critic, children are no longer protected from the way adults talk, from issues in society and especially family such as divorce or alcoholism. Further works by Neil Postman are almost as widely known as they are discussed and his reputation survived until this day, wherefore he belongs to one of the most significant media and cultural critics of all times. Neil Postman passed away on October 5, 2003. At yovisto, you may enjoy Neil Postman in an interview on ‘Are we “Amusing Ourselves to Death”‘ from 1985 as part of the Open Mind series.'],\n",
       " [207,\n",
       "  'Nikolaus Wirth and PASCAL.  Niklaus Wirth giving a lecture.  On February 15, 1934, Swiss computer scientist Niklaus Emil Wirth was born. He is best known for designing several programming languages, including Pascal, and for pioneering several classic topics in software engineering. If there is (or better ‘was’) one programming language that I really loved in the same way I hated it, then it was Pascal. On the one hand it was a rather easy to understand beginners programming language, but when trying to build ‘real world’ software projects based on Pascal, most of them in my experience were doomed to fail. The largest project based on Pascal that I was involved with was a 2 mio lines of code near realtime application for the military back in the 1990s. Everybody knew, we better should have chosen Ada or C++, but it was not our decision to use Pascal. Believe me, you wouldn’t like to maintain 2 mio lines of Pascal code. Nevertheless, the concept of the language designed by Niklaus Wirth was a great achievement for computer science! “A good designer must rely on experience, on precise, logic thinking; and on pedantic exactness. No magic will do.” (Niklaus Wirth) Niklaus Wirth was born in Winterthur, Switzerland, in 1934. In 1959 he earned a degree in Electronics Engineering from the Swiss Federal Institute of Technology Zürich (ETH Zürich), an M.SC. from Laval University (1960), and a Ph.D. in electrical engineering and computer science from UC Berkeley (1963). Upon graduation, Wirth became an assistant professor at the newly created computer science department at Stanford University. Then in 1968 he became Professor of Informatics at ETH Zürich, where he stayed until his retirement in 1999. It was at the ETH Zürich, where he developed the programming languages Pascal (1970), Modula-2 (1979), and also Oberon (1988). Pascal was by far the most popular of them and became a widely used programming language in computer-science education. It influenced a generation of students and professional programmers. The basis of the development of Pascal was the programming language Algol-W and the desire to have a language that would satisfy the requirements of system design. The peculiar simplicity and beauty of a Pascal program can easily be demonstrated via ‘Hello World‘: program HelloWorld; begin writeln(‘Hello World’); end. The first Pascal compiler was designed in Zurich for the CDC 6000 computer family, and it became operational in 1970. Already in 1972 Pascal was used in introductory programming courses. Wirth has contributed to both hardware and software aspects of computer design and has written influential books on software engineering and structured programming. He received the ACM Turing Award for the development of these languages and in 1994 he was inducted as a Fellow of the ACM Niklaus Wirth also popularized the so-called Wirth’s law, a computing adage in 1995. It states a simple fact that should give us computer scientists a lot to think about:”Software is getting slower more rapidly than hardware becomes faster.” (Wirth’s Law)'],\n",
       " [208,\n",
       "  'ENIAC – The First Computer Introduced Into Public.  The ENIAC.  On February 13, 1946, J. Presper Eckert and John Mauchly introduced Electronic Numerical Integrator and Computer, or ENIAC, the first general purpose, electronic computer. ENIAC was a giant step forward in computing technology. Actually, the research that lead to the development of ENIAC was sponsored by the US military. The army needed a computer for calculating artillery-firing tables, the settings used for different weapons under varied conditions for target accuracy. The Ballistics Research Laboratory (BRL), the branch of the military responsible for calculating these tables, heard about John Mauchly‘s research at the University of Pennsylvania, who had previously created several calculating machines, some with small electric motors inside. In 1942, Mauchly had begun designing an improved calculating machine based on the work of John Atanasoff that would use vacuum tubes to speed up calculations. Finally, on May 31, 1943, the military commission on the new computer began with 32 year old John Mauchly as chief consultant and 24 year old John Presper Eckert Jr., a genius graduate student from Moore School, as chief engineer. It took the team about one year to design the ENIAC and 18 months and US$ 500,000 to build it. Nevertheless, by the time they had finished construction, the war was over. But, the ENIAC was still put to work by the military doing calculations for, as e.g., the design of hydrogen bombs, weather prediction, cosmic-ray studies, but also wind-tunnel design. The ENIAC combined, for the first time, the high speed of electronics with the ability to be programmed for many complex problems. It could add or subtract 5000 times a second, a thousand times faster than any other machine. It also had modules to multiply, divide, and square root. High speed memory was limited to 20 words (about 80 bytes). Built under the direction of John Mauchly and J. Presper Eckert at the University of Pennsylvania, ENIAC‘s development and construction lasted from 1943 to full operation at the end of 1945. The machine was huge, weighing 30 tons, and contained over 18,000 vacuum tubes. One of the major engineering feats was to minimize tube burnout, which was a common problem at that time. The machine was in almost constant use for the next ten years. ENIAC employed paper card readers obtained from IBM, by the time a long established part of IBM‘s business accounting machines. During operation, the ENIAC was silent but you knew it was on as the 18,000 vacuum tubes each generated waste heat like a light bulb and 174,000 wattsof heat meant that the computer could only be operated in a specially designed room with its own heavy duty air conditioning system. One of the most difficult problems to solve was that ENIAC‘s design would require 18,000 vacuum tubes to all work simultaneously. But, vacuum tubes were notoriously unreliable. The idea that 18,000 tubes could work together was considered so unlikely that the dominant vacuum tube supplier of the day, RCA, first refused to join the project. By the time ENIAC was working, about 2000 of the computer’s vacuum tubes had to be replaced each month by a team of six technicians. ENIAC was definitively a so-called ‘Turing-complete’ device, i.e. it was not restricted to special problems, but could compute any problem – well, of course only if this problem would fit in the considerably small memory. A “program” on the ENIAC, however, was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. Once a program was written, it had to be mechanically set into the machine. Six women did most of the programming of ENIAC. Improvements completed in 1948 made it possible to execute stored programs set in function table memory, which made programming less a “one-off” effort, and more systematic. About 10 percent of the historic computer lives on in the same basement room where it was created. ENIAC‘s 50th anniversary was celebrated in 1996 with a visit by Vice President Al Gore. What was left of the old computer was fired up one last time. Today, ENIAC is generally closed but special arrangement can be made to see it by contacting the University’s electrical engineering school at 33rd and Walnut. Eckert and Mauchley eventually formed their own company, which was later bought by the Rand Corporation.They produced the Universal Automatic Computer (UNIVAC), which was the first commercially available computer, but this is a completely different story… At yovisto, you may enjoy a short documentation on ENIAC.'],\n",
       " [209,\n",
       "  'Donald Knuth and the Art of Programming.  Donald E. Knuth, photo: October 25, 2005 by Jacob Appelbaum.  On January 10, 1938, computer scientist Donald Knuth, developer of the seminal computer science textbooks ‘The Art of Computer Programming’, was born. He is also widely known for his development of the TeX typesetting framework and the Metafont font definition language. Actually, Donald Knuth is one of my personal heroes in computer science. The very day I started to study this subject, his textbooks had already become a sort of ‘holy bible’ when it comes to algorithms and esp. the analysis of algorithms, i.e. the very heart of computer science. About the person behind the book, I almost knew next to nothing… Donald Ervin Knuth was born in Milwaukee, Wisconsin, where his father owned a small printing business and taught bookkeeping at Milwaukee Lutheran High School, where he enrolled, earning achievement awards. He applied his intelligence in unconventional ways, winning a contest when he was in eighth grade by finding over 4,500 words that could be formed from the letters in “Ziegler’s Giant Bar”. However, the judges had only about 2,500 words on their master list. This won him a television set for his school and a candy bar for everyone in his class. At high school Knuth’s interests were more directed towards music than they were to mathematics. His musical interests involved both playing and composing music and he decided at that stage that he would study music after graduating from high school. Knuth played the saxophone, and later the tuba, in his school band. However, in 1956 he graduated from High School with the highest grade point average that anyone had ever achieved at his school.He decided to take physics as his major at Case Institute of Technology (now part of Case Western Reserve University), where he was introduced to the IBM 650 computer, one of the early mainframes. After reading the computer’s manual, he decided to rewrite the assembly and compiler code for the machine used in his school, because he believed he could do it better. In 1958, Knuth constructed a program based on the value of each player that could help his school basketball team win the league. This was so novel a proposition at the time that it got picked up and published by Newsweek and also covered by Walter Cronkite on the CBS Evening News. Knuth was one of the founding editors of the Engineering and Science Review, which won a national award as best technical magazine in 1959.He then switched from physics to mathematics, and in 1960 he received his bachelor of science degree, simultaneously receiving his master of science degree by a special award of the faculty who considered his work outstanding. In the autumn of 1960 Knuth entered the California Institute of Technology and, in June 1963, he was awarded a Ph.D. in mathematics for his thesis ‘Finite semifields and projective planes’. Besides, knowledge of his computing expertise was so well established by 1962 that, although he was still a doctoral student at the time, Addison-Wesley approached him and asked him to write a text on compilers. He began to work at CalTech as associate professor and the commission from Addyson-Wesley turned out into the writing of his seminal multivolume book ‘The Art of Computer Programming’. This work was originally planned to be a single book, and then planned as a six- and then seven-volume series. In 1968, just before he published the first volume, Knuth was appointed as Professor of Computer Science at Stanford University. After producing the third volume of his book series in 1976, he expressed such frustration with the nascent state of the then newly-developed electronic publishing tools (especially those that provided input to phototypesetters) that he took time out to work on typesetting and created the TeX and METAFONT tools. As of 2012, the first three volumes and part one of volume four of his series have been published. At yovisto, you can watch Prof. Donald Knuth himself in his 17th annual Christmas Tree lecture at Stanford University about ‘Bayesian trees and BDDs‘.'],\n",
       " [210,\n",
       "  'Joseph Weizenbaum and his famous Eliza.  Joseph Weizenbaum (1923-2008) photo: Ulrich Hansen.  On January 8, 1923, computer scientist Joseph Weizenbaum, a pioneer in natural language processing and artificial intelligence, who later became one of artificial intelligence’s leading critics, was born. In 1966 he published a simple program named Eliza, which involved its users in a conversation that bore a striking resemblance to one with a psychologist. Joseph Weizenbaum was born in Berlin to Jewish parents on January 8, 1923. He was able to escape Nazi Germany in January 1936, emigrating with his family to the United States, where he started studying mathematics at the Wayne State University in Detroit in 1941. However, his studies were interrupted by the war, during which he served in the military at the meteorological service of the Air Force. In 1946 Weizenbaum returned to earn his M.S. in Mathematics in 1950. Around 1952 he worked on analog computers, and helped create a digital computer for Wayne State University. He joined a General Electric Co. team in 1955 that designed and built the first computer system dedicated to banking operations. In 1956 he worked for General Electric on ERMA, a computer system that introduced the use of the magnetically encoded fonts imprinted on the bottom border of checks, allowing automated check processing via Magnetic Ink Character Recognition (MICR).In 1964 he took a position at MIT as an associate professor and in 1970 he became Full professor of computer science. It was at MIT in 1966, when he published the Eliza program. As a computer scientist you simply have to know Eliza. I stumbled accross this unique piece of software in the late 1980s and – believe it or not – people really talked with this computer program as if it was a real person. However, Joseph Weizenbaum wrote a simple program that was able to pose a few standard questions in the way a psychiatrist does and included some templates and patterns used to reflect the answers of the user in a simple way. Weizenbaum adopted the use of open-ended questions that is used to encourage patients to communicate more effectively with therapists. Thereby, Eliza was able to mock a real conversation and no wonder that its creator named it Eliza after the ingenue in George Bernard Shaw‘s play Pygmalion. Actually, Weizenbaum was shocked, when he realized, how people reacted to Eliza, opening up their deepest inner thoughts to a (stupid) machine. The experience prompted him to think philosophically about the implications of artificial intelligence and, later, to become a critic of it. In his 1976 book “Computer Power and Human Reason: From Judgment to Calculation,” Weizenbaum suggested it could be both dangerous and immoral to assume computers could eventually take over any roll, given enough processing power and the right programming. “No other organism, and certainly no computer, can be made to confront genuine human problems in human terms,” he wrote. According to Weizenbaum, there is a crucial distinction between deciding and choosing. Deciding is a computational activity, something that can ultimately be programmed. Choice, however, is the product of judgment, not calculation. It is the capacity to choose that ultimately makes us human. Comprehensive human judgment is able to include non-mathematical factors, such as emotions. In 1996, Weizenbaum moved back to Berlin and lived in the vicinity of his childhood neighborhood. Besides his work at MIT, he held academic appointments at many schools, including Harvard University, Stanford University and the University of Bremen, among others. Berlin’s Humboldt University awarded him an honorary doctorate on his 80th birthday in 2003. Joseph Weizenbaum passed away on March 5, 2008, at age 85. At yovisto you can learn more about Joseph Weizenbaum in the documentary ‘Joseph Weizenbaum – Rebell at Work‘. References and further reading: David Rising: AI pioneer Joseph Weizenbaum Dies, at MSNNBC Joseph Weizenbaum: “ELIZA – A Computer Program for the Study of Natural Language Communication between Man and Machine,” Communications of the Association for Computing Machinery 9 (1966): 36-45. Joseph Weizenbaum: Computer Power and Human Reason: From Judgment To Calculation, San Francisco: W. H. Freeman, 1976 [in German language]Joseph Weizenbaum: Die Macht der Computer und die Ohnmacht der Vernunft, Suhrkamp, Frankfurt am Main, 1977'],\n",
       " [211,\n",
       "  'Konrad Zuse – The Inventor of the Computer.  Konrad Zuse (1910 – 1995).  On December 18, 1995, German engineer and computer pioneer Konrad Zuse passed away. He is renowned to have constructed the very first functional program-controlled Turing-complete computer, the Z3, which became operational in May 1941. Konrad Zuse developed the ability to build various kinds of machines in his early high school years, and he began his engineering-career at Berlin’s Technical University, where he earned his degree in 1935. Right after graduating, the inventor quit his promising engineering job at a company, responsible for transport machines and aircrafts. When he told his parents, he needed their entire living room to construct a machine that was able to do the moronic work of calculating automatically, he earned much astonishment, but also their complete support. So this is, where one of the greatest inventions of all times started – in an ordinary family’s living room in Berlin-Kreuzberg, just a few years before World War II. Zuse was going to build a binary calculating machine based on mechanical bistable elements continuing the works of the congenial 19th century English mathematician Charles Babbage. Also, the entire machine was supposed to be based on propositional logic, which he developed the famous floating-point execution unit for. Zuse built a memory, as well as a control unit made of punched tape, which he received from the Babelsberg film studios and finished his first mechanical computer, the Z1 in 1938. [1] Because of the limited resources, Konrad Zuse was not quite satisfied with this new very loudly calculating “monstrosity” he had created at his parent’s home. He made a few adjustments, like using telephone-relays and designed the Z2 right after. He refined further details and partly financially supported by the government, Konrad Zuse was able to finish his famous Z3, the first computer world wide that was freely programmable and based on the binary number system as well as a binary circuit technology in 1941. The construction of the Z4 began in 1942, but due to World War II, Zuse could not finish it in Berlin, wherefore he moved it to Neukirchen in Hessen, Germany. You may imagine, that moving a whole computer system (as big as a whole shelf unit and as heavy as a small car) in Germany near the end of the war was definitely not a walk in the park. Because all other machines have been destroyed by the bombs, the Z4 was everything he had left and therefore the move was even more risky. But fortunately, Zuse and his team made it just on time and five years after the war, the machine was completely reconstructed and calculated from then on at the ETH Zurich as the only commercial computing system in Europe. After the Z3 and Z4, Zuse was still motivated to build and sell fully automatic calculating machines, wherefore he founded a company in Neukirchen. Zuse and his wife, who lead the business sold more than 250 computers across Europe. Another problem, regarding the Z3 was Zuse’s recognition as the inventor of the Computer. Howard Aiken presented the Mark 1 in 1944 in the USA, but Zuse’s Z3 was destroyed during World War II and only some sketches remained. However, he could collect numerous evidences for his achievement and during a mathematical conference concerning the fact ‘Who invented the Computer‘, a huge majority spoke for Konrad Zuse. Unfortunately, this was in 1998, three years after Zuse’s passing, but after this, he received the Computer History Museum Fellow Award, to be seen as the USA’s acknowledgement. Also, in 2010, the ‘Zuse Year’ was announced to honor his contributions and to emphasize the importance of his invention to the digital age. At yovisto you can learn more about computer pioneer Konrad Zuse in a talk given by his son, Prof. Horst Zuse, about his father and the invention of the computer (in German language).'],\n",
       " [212,\n",
       "  'George Boole – The Founder of Modern Logics.  George Boole (1815-1864).  On December 8, 1864, British mathematician and logician George Boole passed away. He is best known as the inventor of the prototype of what is now called Boolean logic, which became the basis of the modern digital computer. Thus, Boole also is regarded as one of the founders of the field of computer science. George Boole was born on November 2, 1815 as first of four children to his father John Boole, a London tradesman who was interested in science and in particular the application of mathematics to scientific instruments, and his wife Mary Ann Joyce, a lady’s maid. The family were not well off, partly because John’s love of science and mathematics meant that he did not devote the energy to developing his business in the way he might have done. George Boole had an elementary school education, but little further formal and academic teaching. William Brooke, a bookseller in Lincoln, has introduced him into the Latin language, when George went on to teach himself Greek. By the age of 14 he had become so skilled in Greek that it provoked an argument. He translated a poem by the Greek poet Meleager which his father was so proud of that he had it published. However the talent was such that a local schoolmaster disputed that any 14 year old could have written with such depth. By that time he had entered the school of Thomas Bainbridge, the Bainbridge’s Commercial Academy in Lincoln. This school did not provide the type of education he would have wished but it was all his parents could afford. However he was able to teach himself French and German studying for himself academic subjects that a commercial school did not cover. At age 16 Boole took up a junior teaching position in Doncaster, at Heigham’s School. This was rather forced on him since his father’s business collapsed and he found himself having to support financially his parents and his younger siblings. He maintained his interest in languages, began to study mathematics seriously. In 1833 he moved to a new teaching position in Liverpool but he only remained there for six months before moving to Hall’s Academy in Waddington, four miles from Lincoln. In 1834 he opened his own school in Lincoln although he was only 19 years old. Four years later he took over Hall’s Academy, at Waddington, outside Lincoln, following the death of Robert Hall. In 1840 he moved back to Lincoln, where he ran a boarding school. From 1838 onwards Boole was making contacts with sympathetic British academic mathematicians, and reading more widely. He studied algebra in the form of symbolic methods, as these were understood at the time, and began to publish research papers. Boole’s status as mathematician was recognised by his appointment in 1849 as the first professor of mathematics at Queen’s College, Cork in Ireland. He taught there for the rest of his life, gaining a reputation as an outstanding and dedicated teacher. In 1854 Boole published his most important work ‘An investigation into the Laws of Thought, on Which are founded the Mathematical Theories of Logic and Probabilities‘. Boole approached logic in a new way reducing it to a simple algebra, incorporating logic into mathematics. He pointed out the analogy between algebraic symbols and those that represent logical forms. It began the algebra of logic called Boolean algebra which now finds application in computer construction, switching circuits etc. Many honours were given to Boole as the genius in his work was recognised. He received honorary degrees from the universities of Dublin and Oxford and was elected a Fellow of the Royal Society (1857). However his career, which was started rather late, came to an unfortunately early end when he died at the age of 49 in 1864. Boolean algebra has wide applications in telephone switching and the design of modern computers and his work has to be seen as a fundamental step in today’s computer revolution. At yovisto you might learn more about Boolean Algebra in the lecture of Prof. Jim Pytel from Columbia Gorge Community College. References and further Reading: George Boole at The MacTutor History of Mathematics Archive Des MacHale: George Boole: His Life and Work. Boole Press (1985) George Boole: An investigation into the Laws of Thought, on Which are founded the Mathematical Theories of Logic and Probabilities, Cambridge University Press (2009)'],\n",
       " [213,\n",
       "  'Doug Engelbart and the Computer Mouse.  First Computer Mouse Prototype © SRI International.  On November 17, 1962, Douglas C. Engelbart has been granted a patent on the world’s first computer mouse. Using the computer mouse has become as usual as eating with knife and fork these days. But this has not always been the case, since the first computers had no graphical interface and every command had to be typed in with a keyboard, which made the use of computers quite complicated. It was Douglas Engelbart in 1963, who worked at the Stanford Research Institute on human computer interactions and was looking for a better solution to navigate though the system. His first prototype of a mouse was ready in 1968, Engelbart presented his results at a congress but found no prospective customer due to the unfortunate fact that graphical interfaces were still not in use. During the 1970’s Engelbart was able to focus on his mouse-research at the Palo Alto Research Center, where he developed the very first ball-mouse, which was first used by Xerox. The company was already using graphical interfaces and therefore appreciated Engelbart’s contributions. The development of the mouse gradually encouraged computer scientists to improve the graphical interfaces and to improve the computer’s usability. The company Apple noticed the new trend, but also saw the difficulty that the new mouse was just too expensive (400 USD) for the market. They occupied many engineers to build a mouse that was smarter and could be sold for only 25$. The new improved pointer was first introduced with Apples computer ‘Lisa‘, but due to the high costs of the computer it was not a great success. However, the release of ‘Lisa‘ and the new computer mouse was a breakthrough and was seen as the ultimate intersection between humans and machines. At yovisto you can watch Doug Engelbart himself talking about innovation and entrepreneurship at the UC Berkeley.'],\n",
       " [214,\n",
       "  'Intel 4004 – The World’s First Microprocessor.  The Intel C4004, the very first commercially available microprocessor.  On November 15, 1971, Intel presented the Intel 4004 microprocessor, the world’s very first commercially available 4-bit central processing unit (CPU). It was the first complete CPU on one chip. By the time, this revolutionary microprocessor, the size of a little fingernail, delivered the same computing power as the first electronic computer built in 1946, which filled an entire room. Back in 1969, Nippon Calculating Machine Corporation approached chip maker Intel, which had previously made semiconductor memory chips, to design a number of custom designed chips for its new printing calculator. Intel engineers suggested a family of just four chips, including one that could be programmed for use in a variety of products, setting in motion an engineering feat that dramatically altered the course of electronics.The chief designers of the chip were Federico Faggin and Ted Hoff of Intel, and Masatoshi Shima of Busicom (later Zilog). Intel designed a set of four chips known as the MCS-4, which included a central processing unit (CPU) chip – the famous 4004 – as well as a supporting read-only memory (ROM) chip for the custom applications programs, a random-access memory (RAM) chip for processing data, and a shift-register chip for the input/output (I/O) port. Federico Faggin, the sole chip designer among the development team on the MCS-4 project, was the only one with experience in MOS random logic and circuit design. He created a new random logic design methodology based on silicon gate, and contributed many technology and circuit design inventions that enabled a single chip microprocessor to become a reality for the first time. His methodology set the design style for all the early Intel microprocessors and later for the Zilog’s Z80. Intel immediately saw the potential of their new development, purchased the rights from Nippon Calculating Machine Corporation and launched the Intel®4004 processor and its chipset with an advertisement in the November 15, 1971 issue of Electronic News ”Announcing A New Era In Integrated Electronics”, though unconfirmed reports put the date of first delivery as early as March 1971. That’s when the Intel 4004 became the first general-purpose programmable processor on the market – a “building block” that engineers could purchase and then customize with software to perform different functions in a wide variety of electronic devices. Packaged in a 16-pin ceramic dual in-line package, the Intel 4004 was built of approximately 2,300 transistors. It employed a 10 µm process silicon-gate enhancement load pMOS technology and could execute approximately 92,000 instructions per second A popular myth says that Pioneer 10, the first spacecraft to leave the solar system, applied an Intel 4004 microprocessor on board. According to Dr. Larry Lasher of Ames Research Center, the Pioneer team actually did evaluate the 4004, but decided it was too new at the time to include in any of the Pioneer projects. On October 15, 2010, Faggin, Hoff, and Mazor from the original designer team were awarded the National Medal of Technology and Innovation for their pioneering work on the Intel 4004. At yovisto you can watch a presentation for the 35th anniversary of the Intel 4004 processor.'],\n",
       " [215,\n",
       "  'Charles Babbage – The Father of the Computer who hated Street Music.  Drawing of Charles Babbage‘s famous Difference Engine.  On October 18, 1871, Charles Babbage, mathematician, inventor and early computer scientist passed away. We think, everybody should know about Charles Babbage and his seminal work on the first mechanical universal computer, the Analytical Engine. Although the Analytical Engine never was build during his lifetime, due to the lack of according fine mechanics in the 19th century, Babbage sketched out everything necessary to construct and to program a universal computer. Born in Teignmouth, Devonshire on December 26, 1791 as son of Benjamin Babbage, a fairly wealthy London banker, Charles Babbage suffered from many childhood illnesses, which forced his family to send him to a clergy operated school for special care. During his younger years, he received private tutoring from elite school teachers due to the wealth of his father. When he went to Trinity College, Cambridge, in October 1810, he was turned off by the sort of math that was taught, so together with his friend John Herschel, the later famous astronomer, he decided to form his own math group known as the Analytical Society who would apply scientific logic and thought to test mathematical ideas of the time. When, in 1812, Babbage transferred to Peterhouse, Cambridge, he was the best mathematician In the times of Babbage there was a really high error rate in the calculation of math tables, when Babbage planned to find a new method that could be use to make it mechanically, removing the human error factor. This idea started to tickle his brain very early, in 1812. Three different elements influenced him in this decision: he disliked untidiness and unprecision; he was very able with logarithmical tables; he was inspired from an existing work on calculating machines produced by Schickard, Pascal, and Leibniz. He discussed the main principles of a calculating engine in a letter he wrote to Sir Humphrey Davy in the early 1822. By that time Babbage began developing his Difference Engine, a mechanical device that could calculate and tabulate polynomial functions, but he was unable to complete it because of a lack of funding. The name ‘Difference Engine‘ derives from the method of divided differences, a way to interpolate or tabulate functions by using a small set of polynomial coefficients. Both logarithmic and trigonometric functions, can be approximated by polynomials, so a difference engine can compute many useful sets of numbers for navigators and scientists. In the 1830s Babbage began developing his Analytical Engine, which was designed to carry calculations guided by a programming logic, but this device was never built. Babbage’s book Economy of Machines and Manufactures (1832) initiated the field of study known today as operational research. Unfortunately, little remains of Babbage’s prototype computing machines. Critical tolerances required by his machines exceeded the level of technology available at the time. And, though Babbage’s work was formally recognized by respected scientific institutions, the British government suspended funding for his Difference Engine in 1832. One year later Ada Augusta King, Countess of Lovelace, the only legitimate child of the famous poet Lord Byron, met Babbage and was fascinated with both him and his computers. She became a competent student of mathematics, which was most unusual for a woman at the time. It is often suggested that Ada was the world’s first programmer. Unfortunately, Babbage was never able to complete his Analytical Engine, and the concept was shelved and forgotten until 1937 when many of his unpublished notebooks were discovered. Finally, in 1991, British scientists got around to constructing a machine called Difference Engine No. 2 (accurate to 31 digits) built according to Babbage’s detailed specifications. According to the account of Lady Lovelace Babbage hated music. He tolerated its more exquisite forms, but abhorred it as practiced on the street. “Those whose minds are entirely unoccupied”, he wrote with some seriousness in 1864, “receive [street music] with satisfaction, as filling up the vacuum of time”. He calculated that 25% of his working power had been destroyed by street nuisances, many of them intentional. Letters to the Times and the eventual enforcement of “Babbage’s Act”, which would squelch street nuisances, made him the target of ridicule. Babbage also worked in the fields of philosophy and code-breaking, as well as campaigning for reform in British science. He died at his home in London on 18 October 1871. Learn more about Charles Babbage and his work in the lecture of Prof. Doron Swade from Neukom Institute at Dartmouth College about ‘Constructing Charles Babagge’s Analytical Engine‘.'],\n",
       " [216,\n",
       "  'Dennis Ritchie – Designer of UNIX and C.  Dennis Ritchie (1941-2011) CC-BY-2.0 photo by Denise Panyik-Dale.  On October 12, 2011, computer scientist Dennis Ritchie, who designed the UNIX operating system as well as the C programming language, passed away. Thanks to his contributions, computing made a huge leap forward and enabled real-time processing and multi-threading. Dennis Ritchie was born on September 9, 1941, in Bronxville, New York as son of Alistair E. Ritchie, a longtime Bell Labs scientist working on switching circuit theory. Dennis Ritchie graduated from Harvard University with degrees in physics and applied mathematics, and in 1967, he began working at the Bell Labs Computing Sciences Research Center following his father. In 1968, he received a PhD from Harvard with a thesis on the subject of subrecursive hierarchies of functions. About himself, we wrote: ‘My undergraduate experience convinced me that I was not smart enough to be a physicist, and that computers were quite neat. My graduate school experience convinced me that I was not smart enough to be an expert in the theory of algorithms and also that I liked procedural languages better than functional ones.’ [1] Ritchie came in contact with operation systems design at Bell Labs, while contributing compilers for the BCPL and ALTRAN programming language to the Multics (Multiplexed Information and Computing Service) project, then a joint effort of Bell Labs, MIT, and General Electric, an influential early time-sharing operating system. Subsequently, he aided Ken Thompson in creating the Unix operating system. With his first porting of the Unix OS to the Interdata 8/32 computer, Ritchie demonstrated its portability, and laid the groundwork for the widespread growth of Unix: the Seventh Edition version from the Bell Labs research group was the basis for commercial Unix System V and also for the Unix BSD distributions from the University of California at Berkeley. Early in the development of Unix, Ritchie added data types and new syntax to Thompson’s B language, thus producing the new programming language C. C was the foundation for the portability of Unix, but it has become widely used in other contexts as well, much application and system development for computers of all sizes, from hand-held to supercomputer, uses it. In 1983, Ritchie and Thompson received the Turing Award for their development of generic operating systems theory and specifically for the implementation of Unix. In 1990, both Ritchie and Thompson also received the IEEE Richard W. Hamming Medal from the Institute of Electrical and Electronics Engineers (IEEE), and in 1997, both were made Fellows of the Computer History Museum. On April 21, 1999, Thompson and Ritchie jointly received the National Medal of Technology of 1998 from President Bill Clinton. On October 12, 2011, Ritchie was found dead in his apartment in Berkeley Heights, New Jersey. His contribution to computer science must be highly valued, because with Unix and C he formed the shape of the modern information society enabling such things as search engines or even smart phones [2]. Learn more about the history of the world’s most famous operating system UNIX in the ATT Tech channel documentation produced by Bell Labs in 1982, a decade after its first implementation. References and further Reading: [1] Dennis M. Ritchie, short biography at Bell Labs [2] Lohr, Steve: “Dennis Ritchie, Programming Trailblazer, Dies at 70“, The New York Times, (October 12, 2011) [3] Brian W. Kernigham, Dennis M. Ritchie: The C Programming Language, Prentice Hall, 1978. [4] Ken Thompson, Dennis M. Ritchie: The UNIX Reference Manual, 1971.'],\n",
       " [217,\n",
       "  '“Don’t be evil” – Google celebrates its 14th Birthday.  Google Logo from 1998.  On September 27, 1998, Larry Page and Sergey Brin founded Google and began their work in the garage of businesswoman Susan Wojcicki. Up to this day, the company has become one of the most powerful in the field of search, cloud computing, productivity software, and advertising, running more than one million servers world wide. Larry Page and Sergey Brin, who met at Stanford University began working together on BackRub, a search engine that was not suitable to the University, because of it taking up too much bandwidth. They soon decided to found a new company and came up with the name Google, originating in the word ‘googol’, a mathematical term. It reflected their aim to organize an infinite amount of information on the web. With the financial support by Andy Bechtolsheim and the working space in Susan Wojcicki‘s garage, they could hire their first employee and immediately began growing tremendously, building up a great reputation in Silicon Valley and beyond. PageRank was one of the first technologies, developed at Google. It was the first technology ranking websites based on the relationships to each other instead of counting how many times the search terms appeared on the page, which most search engines did back then. Google soon succeeded with their technology, allowing them to offer further services like mail, cloud computing, social media platforms or advertising. However, Google‘s search engine stays the companies oldest and probably most successful features, dominating the market in search engines and ranked as the most visited website in history. A Noogler’s propeller beanie Like many other multinational companies, Google also had to face numerous skeptics and critics, mainly concerning data privacy. But besides the many opponents, Google has accumulated through the years, they are still able to fascinate and entertain the users in many ways. Google is known for its many creative Doodles or the yearly April Fool Jokes like the announcement of the Internet service TiSP (Toilet Internet Service Provider). Also the company is known for its special methods to motivating their employees. For instance, every new employee is called ‘Noogler’ and has to wear a propeller beanie cap in Google colors on their first Friday. Also the employees are able to use the company’s gym, play billiards or enjoy Google‘s health care plan. Presumably this is why the company is in the list of ideal employers, published by Universum in 2011. At yovisto you can learn more about Google and watch Larry Page himself presenting at TED talks about ‘Inside the Google Engine‘.'],\n",
       " [218,\n",
       "  'Happy Birthday Linux!.  Penguin Tux, the Linux Mascot © wikipedia.  On September 17, 1991, the Finnish student of computer science Linus Torvalds, uploaded Linux kernel version 0.01 to the ftp server ftp.funet.fi. This might be considered as the date of birth of the famous free operating system Linux, although Torvalds announced the new OS a few weeks earlier on usenet already. Nevertheless, Linux has become one of the most popular operating systems today, and this of course with a god reason…. Linus Torvalds was born in 1969 in Helsinki, Finnland. His interest in computers started early with the Commodore VIC-20 and the Sinclair QL, for which he is known to have programmed a clone of the famous PacMan game. Later as a student of computer science, he purchased an IBM PC before receiving his copy of the MINIX operating system, which in turn enabled him to begin work on Linux. MINIX is an inexpensive minimal Unix-like operating system, designed for education in computer science, written by Andrew S. Tanenbaum. During his computer science studies Torvalds became curious about operating systems in general. But, he soon got frustrated by the licensing of MINIX, which limited it to educational use only. Therefore, he decided to begin to work on his own operating system which eventually became the Linux kernel. As Torvalds wrote in his book “Just for Fun“, he eventually realized that he had written an operating system kernel. Torvalds started the development of the Linux kernel on MINIX, and applications written for MINIX were also used on Linux. Later on, when Linux matured, further Linux development took place on native Linux systems replacing all MINIX components by GNU applications, because it was advantageous to use the freely available code from the GNU project with the fledgling operating system. Programm code licensed under the GNU General Public License (GNU GPL) can be reused in other projects as long as they also are released under the same or a compatible license. Torvalds initiated a switch from his original license, which prohibited commercial redistribution, to the GNU GPL. Developers worked to integrate GNU components with Linux to make a fully functional and free operating system. Today, Linux systems are used in every domain, from embedded systems to supercomputers. The Use of Linux distributions in home and enterprise desktops has been constantly growing and Linux has also gained popularity with various local and national governments, such as e.g., Brazil, Russia, Spain, or in India or China, because of its independency from a special supplier. At yovisto you can listen to Linus Torvalds himself sharing his thoughts on <a href=”http://www.yovisto.com/play/20275″>git, the source control management system</a> he created two years ago. References and further reading: The History of Linux in the wikipedia Oliver Diedrich: The History of Linux Linus Torvalds: Just for Fun or The Story of an Accidental Revolutionary, Harper Business, 4th ed. (2002)'],\n",
       " [219,\n",
       "  'The Bug that wasn’t really a Bug – Computer Pioneer Grace Murray Hopper.  The first documented computer bug in a 1947 log file © Naval Surface Warfare Center, Dahlgren, VA Most of you might think that computers is one of these men’s business things. Far from it! Not even that it was a girl who was the very first programmer in history – Ada Augusta King Countess of Lovelace – it was also a woman in the early days of computers, who developed the very first compiler to translate high level language computer programs into low level machine commands. But besides her merits in computer science, we also owe the term ‘debugging’ to Grace Hopper, and the story goes like this…. It was on September 9 in 1947, when Grace Hopper was working on a Mark II Computer at Harvard University, which was known for its high-speed electromagnetic relays. However, a moth was stuck in between the relays and after removing it, Hopper taped the moth into the log book, noting that the “First actual case of bug being found.” The story of Hopper’s ‘debugging‘ soon spread widely and caused that the term was from then on used for computer problems. However, the term ‘bugs’ for causing mechanical or electronic issues has a longer history and is to be attributed to the famous inventor Thomas Edison. In 1878, he wrote a letter to the inventor of the telephone exchange, Tivadar Puskás, mentioning ‘bugs’ as being responsible for his technical difficulties: “The first step [in all of my inventions] is an intuition, and comes with a burst, then difficulties arise – this thing gives out and [it is] then that ‘Bugs’ – as such little faults and difficulties are called – show themselves” Even though Grace Hopper was not the ‘inventor’ of the term, she did a great job distributing it widely considering computer errors, but it must be said that this was not her only achievement during her long career as a computer scientist and US-Navy officer. Grace Hopper has always been one of the curious kids, taking alarm clocks apart when she was seven and building toy vehicles she had designed by herself. After receiving her Ph.D from Yale University in 1934, she started teaching mathematics and joined the US-Navy at the age of 37. Soon she was assigned to a Computation Project at Harvard University as lieutenant, working on the Mark I computer, which was a special computer due to its Turing completeness (meaning that it was universally programmable). Some years later, she was developing the UNIVAC I and could make major contributions in designing the computer language COBOL, special due to its high dependence on the natural human language. Grace Hopper depicts a pioneer in computer science and was honored numerous times, for instance she ironically won the ‘computer sciences man of the year’ award in 1969. She also received the National Medal of Technology in 1991. At yovisto you can watch a lecture of author Kurt W. Beyer presenting his biography ‘Grace Hopper and the Invention of the Information Age‘.'],\n",
       " [220,\n",
       "  'It\\'s Computable - thanks to Alonzo Church.  You know, the fact that you can read your email on a cell phone as well as on your desktop computer or almost any other computer connected to the internet, in principle is possible thanks to mathematician Alonzo Church, who gave the proof (together with Alan Turing) that everything that is computable on the simple model of a Turing Machine, also is computable with any other \\'computer model\\'.  In mathematics and computer science, the \\'Entscheidungsproblem\\' is one of the challenges posed by mathematician David Hilbert in 1928. The Entscheidungsproblem asks for an algorithm that takes as input a statement of a first-order logic and answers \"Yes\" or \"No\" according to whether the statement is universally valid, i.e., valid in every structure satisfying the underlying axioms.  Actually, the origin of the Entscheidungsproblem goes back to Gottfried Wilhelm Leibniz, who in the 17th century, after having constructed a successful mechanical calculating machine, dreamt of building a machine that could manipulate symbols in order to determine the truth values of mathematical statements. Leibniz realized that the first step would have to be a clean formal language, and much of his subsequent work was directed towards that goal.  By the completeness theorem of first-order logic, a statement is universally valid if and only if it can be deduced from the axioms, so the Entscheidungsproblem can also be viewed as asking for an algorithm to decide whether a given statement is provable from the axioms using the rules of logic. In 1936 and 1937, Alonzo Church and Alan Turing, respectively, published independent papers showing that a general solution to the Entscheidungsproblem is impossible. To achieve this, Alonzo Church applied the concept of \"effective calculability\" based on his λ calculus, while Alan Turing based his proof on  his concept of Turing machines. It was recognized immediately by Turing that these two concepts are equivalent models of computation. Both authors were heavily influenced by Kurt Gödel\\'s earlier work on his incompleteness theorem, especially by the method of assigning numbers (a so-called Gödel numbering) to logical formulas in order to reduce logic to arithmetic.   Alonzo Church died on August 11, 1995, aged 92.  At yovisto you can learn more about Alonzo Church in the lecture \\'At odds with the Zeitgeist: Kurt Gödel\\' by Prof. John W. Dawson from the Institute of Advanced Studies in Princeton.'],\n",
       " [221,\n",
       "  'Let Us Calculate – the Last Universal Academic Gottfried Wilhelm Leibniz.  Gottfried Wilhelm Leibniz (1646 – 1716).  On July 1, 1646, one of the last universally interdisciplinary academics, active in the fields of mathematics, physics, history, politics, philosophy, and librarianship was born. Gottfried Wilhelm Leibniz counts as one of the most influential scientists of the late 17th and early 18th century and impersonates a meaningful representative of the Age of Enlightenment. Leibniz made up his interests concerning philosophy and law studies in his early years, following his father’s footsteps. He even decided to acquire Latin auto-didactically at the age of eight, which is impossible to imagine for today’s Latin students, who experience this language more as a constant torture. But Leibniz sticked to it and was therefore able to attend the famous Thomasschule in Leipzig. His later years at the University of Leipzig and the University of Jena were filled with studies in philosophy, law, mathematics, physics, and astronomy. Because of his widely spread field of education he is now titled as the ‘last universal academic’. He was able to establish a great reputation, working for archbishop Johann Phillip von Schönborn in the 1670‘s. During his time in Mainz he published his first work of great reception ‘Nova methodus discendae docendaeque jurisprudentiae’, a new method to teach and study jurisprudence. He also became a member of the British Royal Society due to his achievement of creating a calculating machine with a stepped reckoner. Another contribution to the field of mathematics was his (and Newton’s) development of infinitesimal calculus, revolutionary then and a basis of many calculations in mathematical, physical, stochastic and economical problems today. In philosophy, Leibniz got famous with the phrase of the ‘best of all possible worlds’. It pictures the correlation between the good and the evil, meaning that the world has a huge potential of development and that even God cannot realize the good things on earth without a certain amount of the evil. Also for computer scientists, Leibniz anticipated the use of formal logic for automated reasoning and decision making. Besides inventing the binary system, which is the basis of nowadays computers, Leibniz argued that if we would be able to find a formal (logic) language to express problems instead of our ambiguous natural language, we should be able to solve arguments simply performing a calculation. Let us calculate! (in Latin: Calculemus!) he requested, to solve every argument or dispute. Another highlight in Leibniz‘ career probably was becoming the first president of the Prussian Academy of Sciences in Berlin. His achievements and contributions to the world’s development are numerous and therefore he was honored several times during his lifetime and has not been forgotten today. Since a big part of his scientific work is documented in letters, the collection of these papers have been inscribed on UNESCO‘s Memory of the World Register in 2007. At yovisto, you may learn about the Highlights of Calculus, a lecture by Professor Strang, who shows how calculus applies to ordinary life situations, such as: driving a car or climbing a mountain.'],\n",
       " [222,\n",
       "  'Churchill’s Best Horse in the Barn – Alan Turing, Codebreaker and AI Pioneer.  Alan Turing (1912-1954). © National Portrait Gallery, London (UK) Outside the world of computer science or mathematics the name of probably the most influential figure and in some sense the father of all computing technology Alan Mathison Turing is hardly known. But it was him, who laid the foundations of the theory of computing. Already in the 1930s, when no digital electronic computer had ever been built, he has shown the limits of computation and thus, anticipated all that was to come in the so-called digital revolution. He also laid the foundations to artificial intelligence. And even more, he was a hero of World War II. Without him, maybe it would have been impossible to decode Nazi Germany’s encrypted radio messages. This makes him to one of the most distinguished figures of the war and we have to thank him for the victory of the Allied forces. And how was he thanked by his contemporaries… [1] Alan Turing’s father was member of the Indian Civil Service, who returned to England to raise his son in his home country. Young Alan learned the ABC by himself and with the age of 16 he was already reading the writings of Albert Einstein. He studied mathematics in Cambridge, where his fellow students considered him to be eccentric. His talking often was stammering with brusquely silence. But he loved sports. In 1937 he published his famous paper ‘On computable numbers’, where he introduced the ‘Turing Machine‘, a simple model of a computer that is able to solve all kind of problems that might be expressed as an algorithm. With his machine he laid the foundation for theoretical computer science and showed the limits of computation at a time, when no computer existed. In summer 1938 he studied cryptology to become the leader of a small group of mathematicians at Bletchley Park, an extensive cryptoanalytic facility that had the task to decipher the codes of the German navy. The Germans were using the famous Enigma for encrypting their messages. Turing had something of a reputation for eccentricity at Bletchley Park. He was known to his colleagues as ‘Prof’ and sometimes came to work with his pyjamas under his jacket or he was wearing a service gas mask at the pollen season in springtime for cycling. But it was his cryptoanalytic effort that made the decryption of the German radio messages possible and thus it also was him to be responsible for the allied victory of the war. Immediately after the war Churchill closed down Bletchley Park. In recognition of Turing’s service he was promoted Officer of the Order of the British Empire. Actually, he stored the medal in his toolbox, considering it to be merely a piece of metal. In 1950 Turing addressed the problem of artificial intelligence, and proposed an experiment which became known as the Turing Test, an attempt to define a standard for a machine to be called “intelligent“. The idea was that a computer could be said to “think” if a human interrogator could not tell it apart, through conversation, from a human being. But in 1952 the tragedy started. During the investigation of a burglary in Turing’s home, he acknowledged a sexual relationship with an accomplice of the suspected burglar. Homosexual acts were illegal in the UK at that time, and so Turing was charged with gross indecency under Section 11 of the Criminal Law Amendment Act 1885. The judge offered him the choice between imprisonment or probation conditional on his agreement to undergo hormonal treatment designed to reduce libido. He accepted chemical castration via injections of stilboestrol, a synthetic oestrogen hormone. On June 8th, 1954 Turing was found dead at his house in Wilmslow near Manchester. Next to him on his bedside table laid a half eaten apple with the soft scent of bitter almond. It is generaly believed that Turing had committed suicide with cyanide (actually BBC is reporting about doubts concerning the results of the former investigation [1]). In the times while working at Bletchley Park, he was sometimes reciting whimsical verses such as the one from the Disney movie “Snow White and the Seven Dwarves”: “Dip the apple in the brew, let the sleeping death seep through” At yovisto you might learn more about the life and works of Alan Turing with the fabulous lecture of Prof. Jack Copeland from MIT on ‘Alan Turing: Codebreaker and AI pioneer‘.   [1] Alan Turing: Inquest’s suicide verdict ‘not supportable’, by Roland Pease BBC Radio Science Unit, June 23, 2011, via http://www.bbc.co.uk/news/science-environment-18561092'],\n",
       " [223,\n",
       "  'Well, I Didn’t Know it was Hard – Happy Birthday Ivan Sutherland.  Ivan Sutherland’s Sketchpad (1963) Happy Birthday 74th Ivan Sutherland! The American computer scientist and Internet pioneer has received the Turing Award from the Association for Computing Machinery in 1988 for his invention of Sketchpad, an early predecessor to the sort of graphical user interface that has become ubiquitous in personal computers today. Sketchpad could accept constraints and specified relationships among segments and arcs, including the diameter of arcs. It could draw both horizontal and vertical lines and combine them into figures and shapes. Figures could be copied, moved, rotated, or resized, retaining their basic properties. Sketchpad also had the first window-drawing program and clipping algorithm, which allowed zooming. When asked, “How could you possibly have done the first interactive graphics program, the first non-procedural programming language, the first object oriented software system, all in one year?” Ivan replied: “Well, I didn’t know it was hard.” (Alan Kay, Doing with Images Makes Symbols, 1987) In 1968 he co-founded Evans and Sutherland with his friend and colleague David C. Evans. The company has done pioneering work in the field of real-time hardware, accelerated 3D computer graphics, and printer languages. At yovisto, you might watch Ivan Sutherland together with his brother Bert reminiscing about their collective 100 plus years with computers and electronics in an interview from 2004.'],\n",
       " [224,\n",
       "  'Do You Speak Polish… Or Maybe Reverse Polish?.  HP 35s Calculator (1972) I guess almost nobody except a few mathematicians and computer scientists have ever heard of the Australian computer scientist Charles Leonard Hamblin, who passed away on May 14, 1985. And also most of my fellow computer scientists might not have heard of him. But, one of his major contributions to computer science was the introduction of the so-called Reverse Polish Notation. Does that ring a bell Back in the 1950s Hamblin became aware of the problem of computing mathematical formulae containing brackets results in memory overhead, which was rather critical at these times, because memory was rather small and expensive. One solution to the problem has already been prepared by the famous Polish mathematician Jan Lukasiewicz’s, inventor of the original Polish notation, which enables a writer of mathematical notation to instruct a reader the order in which to execute the operations (e.g. addition, multiplication, etc) without using brackets. Polish notation achieves this by having an operator (+, *, etc) precede the operands to which it applies, e.g., +ab, instead of the usual, a+b. Hamblin, with his training in formal logic, knew of Lukasiewicz’s work. Hamblin improved this principle to save additional storage by putting the operator behind the operands and thus, enabling the computer to make use of a storage, which did not require an address. This might sound rather weird to you, but 20 years ago using one of those sophisticated HP calculators (that forced you to use/think RPN) made you the undisputed number one among all the other geeks. You might learn more about Reverse Polish Notation at yovisto by watching ‘The Joys of RPN‘ –>'],\n",
       " [225,\n",
       "  'Claude Shannon – Father of Information Theory.  Claude E. Shannon (1916-2001). Today 96 years ago, Claude E. Shannon was born, the “father of information theory“, whose groundbreaking work ushered in the Digital Revolution. Of course Shannon is famous for having founded information theory with one landmark paper published in 1948. But he is also credited with founding both digital computer and digital circuit design theory in 1937, when, as a 21-year-old master’s student at MIT, he wrote a thesis demonstrating that electrical application of Boolean algebra could construct and resolve any logical, numerical relationship. Believe it or not, it has been claimed that this was the most important master’s thesis of all time. Shannon contributed to the field of cryptanalysis during World War II and afterwards, including basic work on code breaking. At yovisto, there are many references to the work of Shannon. Obviously, because he has laid some of the foundations of computer science (and information theory), and on the other hand there are many basic lectures referring to these topics. But, there is also a very nice documentary about Claude Shannon exploring his life and the major influence his work had on today`s digital world through interviews with his friends and colleagues. Further Reading: Claude Shannon, Warren Weaver:  Mathematical Theory of Communication, University of Illinois Press (1949)'],\n",
       " [226,\n",
       "  'Nicolas Steno and the Principles of Modern Geology.  Niels Stensen (1638 – 1686) In January, 1638, Danish Catholic bishop and scientist Nicolas Steno was born. He was both a pioneer in both anatomy and geology, and seriously questioned accepted knowledge of the natural world. Importantly he questioned explanations for tear production, the idea that fossils grew in the ground and explanations of rock formation. By some he is considered the founder of modern stratigraphy and modern geology. Nicolas Steno was born as Niels Stensen, but is better known by the Latinized form Nicholas Steno. He was a native of Copenhagen, but left Denmark around 1660 intending to study medicine at the University of Leiden. His studies of anatomy, which he continued in Paris, Montpelier, and Florence attracted the attention of the Grand Duke of Tuscany, Ferdinand II, who appointed appointed Steno to a hospital post that left him time for his research. [1,2] At first, Nicolas Steno’s studies were focused on the muscular system as well as the nature of muscle contraction. When around 1666, fishermen caught a shark near Livorno, Duke Ferdinand ordered his head to be sent to Steno, who dissected it and published the findings one year later. He noticed the resemblance of the shark’s teeth to certain stony objects found in rocks. As most contemporary scientists argued differently, Steno believed that these ‘stony objects’ looked so much like shark teeth because they actually were shark teeth. Well, Steno was not the first who linked these so called ‘tongue stones’ with shark teeth. For instance, already Robert Hooke and John Ray argued that fossils were the remains of living organisms. Important is however, that Nicolas Steno came to realize that it was not clear yet how how any solid object could come to be found inside another solid object like a rock. In 1669, he published a paper on the topic with the title ‘De solido intra solidum naturaliter contento dissertationis prodromus’. [1,2] Nicolas Steno stated that a solid object will cause any solids that form around it later to conform to its own shape. Thus, the famous ‘tongue stone’ must have been buried in soft sediments which hardened later while crystals must have formed after the surrounding rock was a solid, because they often showed irregularities of form caused by having to conform to the surrounding solid rock. His further conclusions are now referred to as Steno’s law of superposition. It means that layers of rock are arranged in a time sequence, with the oldest on the bottom and the youngest on the top, unless later processes disturb this arrangement. Steno also mentioned that rocks may be uplifted by subterranean forces. Steno also made efforts to distiguish different time periods in the Earth’s history, which would develop more accurately in the work of later scientists. [2,3] Nicolas Steno was ordained as a priest in 1675 and essentially abandoned science. He became a bishop a few years later and spent the rest of his life ministering to the minority Roman Catholic populations in northern Germany, Denmark, and Norway. [3] At yovisto, you may learn more about ‘What can Fossils teach us‘ in a video lecture by Paul Sereno.'],\n",
       " [227,\n",
       "  'Alfred Tarski and the Undefinability of Truth.  Alfred Tarski (1901-1983). On January 14, 1902, Polish-American mathematician and logician Alfred Tarski was born. A prolific author he is best known for his work on model theory, metamathematics, and algebraic logic, he also contributed to abstract algebra, topology, geometry, measure theory, mathematical logic, set theory, and analytic philosophy. For my annual Semantic Web Technologies lecture series I always introduce my students to model-theoretic semantics as a means to enable a formal representation of meaning for languages. I guess, they don’t like the mathematical overhead. But nevertheless, you will need it to make sense of any logical expression. But, let’s get back to Alfred Tarski. Born as Alfred Teitelbaum into a family of Polish Jews of comfortable circumstances, Tarski first manifested his mathematical abilities while in secondary school, at Warsaw’s Szkoła Mazowiecka. Nevertheless, he entered the University of Warsaw in 1918 intending to study biology. After Poland regained independence in 1918, Warsaw University quickly became a world-leading research institution in logic, foundational mathematics, and the philosophy of mathematics. Famous Mathematician Stanisław Leśniewski recognized Tarski’s potential as a mathematician and encouraged him to abandon biology. Henceforth Tarski attended courses taught by Jan Łukasiewicz, Wacław Sierpiński, and became the only person ever to complete a doctorate under Leśniewski’s supervision. In 1923, Alfred Teitelbaum and his brother Wacław changed their surname to Tarski and also converted to Roman Catholicism, Poland’s dominant religion, even though Tarski was an avowed atheist. After becoming the youngest person ever to complete a doctorate at Warsaw University, Tarski served as Łukasiewicz’s assistant. Between 1923 and his departure for the United States in 1939, Tarski not only wrote several textbooks and many papers, a number of them ground-breaking, but also did so while supporting himself primarily by teaching high-school mathematics at Warsaw secondary school, because of the small salary at Warsaw University. In 1930, Tarski visited the University of Vienna, lectured to Karl Menger’s colloquium, and met Kurt Gödel. Due to an invitation from Harvard University, Tarski was able to leave Poland in August 1939, on the last ship to sail from Poland for the United States before the German and Soviet invasion of Poland and the outbreak of World War II. Tarski left reluctantly, because Leśniewski had died a few months before, creating a vacancy which Tarski hoped to fill. Oblivious to the Nazi threat, he left his wife and children in Warsaw. He did not see them again until 1946. During the war, nearly all his extended family died at the hands of the German occupying authorities. Thanks to a Guggenheim Fellowship, Tarski visited the Institute for Advanced Study in Princeton in 1942, where he again met Gödel, who also had fled from Nazi Germany. Subsequently, he joined the Mathematics Department at the University of California, Berkeley, where he spent the rest of his career until he became emeritus in 1968. Tarski was a charismatic teacher who charmed his students, but he demanded perfection and could be devastatingly abusive to those who failed to measure up.[3] He is recognised as one of the four greatest logicians of all time, the other three being Aristotle, Frege, and Gödel. Of these Tarski was the most prolific as a logician and his collected works, excluding his books, runs to 2500 pages. Tarski made important contributions in many areas of mathematics: set theory, measure theory, topology, geometry, classical and universal algebra, algebraic logic, various branches of formal logic and metamathematics. He produced axioms for ‘logical consequence‘, worked on deductive systems, the algebra of logic and the theory of definability. He can be considered a mathematical logician with exceptionally broad mathematical interests.[1] One example of his achievements is a decision procedure for sentences written in the language of the arithmetic of real numbers. These are sentences that can be written using variables ranging over the real numbers, using symbols for the operations of addition and multiplication and for the relations of equality and order (.[3] Another great achievement was his assault on the notion of truth. Tarski was able, under suitable conditions, to give a mathematically precise definition of what it means to say that a given sentence of a language is true. One of these conditions was that the syntax of the language in question be formally well-defined, i.e. one could say precisely just which expressions are legitimate sentences and which not. Moreover, a sentence had to have a well-defined semantics, i.e. the meaning of the individual components of the sentence had to be (formally) given. Now, the “metalanguage” in which this truth definition is developed is, in general, separate from the language whose true sentences are being identified. As Kurt Gödel previously had shown, it is possible for a language to function as its own metalanguage. But for this case, Tarski was able to prove his famous “undefinability theorem“: Under very general conditions, the notion of “truth” of the sentences of a language cannot be defined in that same language.[3] Thus, Tarski radically transformed Hilbert’s proof-theoretic metamathematics. He destroyed the borderline between metamathematics and mathematics by his objection to restricting the role of metamathematics to the foundations of mathematics At yovisto, you can learn more about the history of mathematical logics in the lecture of Prof Christos H. Papadimitriou on the Graphic Novel ‘Logicomix: An Epic Search for Truth‘.'],\n",
       " [228,\n",
       "  'Friedrich Schiller ‘The Robbers’.  The Robbers (Die Räuber), 1781 by Friedrich Schiller  .  On January 13, 1782, Friedrich Schiller’s play ‘The Robbers‘ (Die Räuber) was premiered at the national theatre in Mannheim. The “Sturm und Drang” play astounded its Mannheim audience and made Schiller an overnight sensation. It is believed that Schiller began working on The Robbers more intensively in 1777, but, in secret. Around 1780, he read some passages at first so some friends to see their impact. He was at first unlucky in finding the right publisher and had to come up with the money himself. The very first volume was published annonymously with only 800 copies. The people were shocked by this work, but also the theatre gained interest in the story. Freiherr von Dalberg was back then responsible for the theater in Mannheim and asked Schiller for a theater-version, which he finished by 1781. On January 13, 1782, the scandalous play was premiered in Mannheim. The plot of ‘The Robbers‘ revolves around the two aristocratic brothers, Karl and Franz Moor. Karl is more rebellious and very charismatic while the younger brother, Franz, appears more as a cold hearted villain who plots against Karl to wrest away his inheritance. As the conflict continues thoughout the plot, Franz’s motives as well as Karl’s seemingly innocent characteristics evolve to be more complex. The play is represented in a traditional five-act structure and in the altering scenes, the brother’s conflicts are depicted, showing the one questing for money and power while the other seeks to create a revolutionary anarchy in the Bohemian Forest. Many controversial topics were subject of the play including the dividing lines between personal liberty and law as well as the topic of power in general. Schiller also made the differences between good and evil and masculinity as subject of the famous play. Notable for ‘The Robbers‘ is especially the fact that Schiller intentionally broke the rules of traditional plays. For example, the drama plays at various different locations. Also, Schiller violates the rule to not mix different levels in society, which he also did in his famous work ‘Intrigue and Love‘. When Karl Moor decides to develop his close connection with his robbers and becomes a criminal, he decides to turn away from his family, leaving his priviliges in society. At yovisto, you may learn more about Friedrich Schiller and the Renaissance.'],\n",
       " [229,\n",
       "  'Johannes Schöner and his Globes.  Johannes Schöner, aka Joan Schoenerus (1477-1547). On January 16, 1477, German polymath Johannes Schöner was born. He was a priest, astronomer, astrologer, geographer, cosmographer, cartographer, mathematician, globe and scientific instrument maker and editor and publisher of scientific tests. He is well known for making and printing geographical globes, notably his 1515 globe which is one of the earliest surviving globes produced following the discovery of new lands by Christopher Columbus. Schöner was born in Karlstadt am Main in Lower Franconia. As with most other Renaissance scholars nothing is known about his parents or his early life. Quite detailed information for Schöner’s adult life, at least up to 1506, has been preserved in his own marginalia in his copy of Regiomontanus‘ printed Ephemerides, which he used as a diary. He matriculated at the University of Erfurt in 1494 and graduated Baccalaureus on 21 March 1498. He was appointed to a position in the school in Gemünden in 1499 and ordained as a Catholic priest in the Bishopric of Bamberg. His next appointment was as vicar in his hometown Karlstadt from 4 June 1504. He was a pupil of the famous cartographer Martin Waldseemüller, who is credited with the first recorded usage of the word America, on the 1507 map Universalis Cosmographia in honour of the Florentine explorer Amerigo Vespucci. No diary exists after 1506, and up to 1515 there are only indirect traces of Schöner’s existence. Because he neglected his offices as a priest and his concubinage with Kunigunde Holocher in 1499, with whom he had three children, he was sent to Kirchehrenbach in Franconian Switzerland for disciplinary reasons, where he remained at least until 1525.[2] 1526, he was called to Nürnberg as the first professor of mathematics at the newly founded gymnasium Aegidianum, a post he held till one year prior to his death in 1747. At the same time, he also converted to Protestantism and married his longterm relationship. Already in Bamberg, he owned his own printing company and published astronomical writings, maps and globes. The very first printed globe of the sky was made in his workshop in 1515. He made another globe in 1520 and in 1533. On his globes, Brasilia inferior is depicted seperated by a waterway from South America, i.e. before the “official” discovery by Portuguese explorer Ferdinand Magellan in November 1520. His depiction corresponded to the map created by the Osman Admiral Piri Reis in 1513. Schöner’s first scientific publication also was published in 1515 in Bamberg, entiteled Horari cylindri canones (Instructions on how to draw sundials on cylinders). Also in Bamberg, he published a treaty on Computus Ecclesiasticus, where he emphasized the necessity of a reformation of the old Julian calendar. Western hemisphere of the Schöner globe from 1520 In 1538, Georg Joachim Rheticus, a young professor of mathematics at Wittenberg, stayed for some time with Schöner to be adviced by his profound knowledge in astronomy as well as astrology. Schöner convinced young Rheticus to visit Nicolaus Copernicus in Frauenburg, to win Copernicus‘ books for publication in Nuremberg. In 1540, Rheticus dedicated the first published report of Copernicus work, the Narratio prima, to Schöner. As this was well received, Copernicus finally agreed to publish his main work, and Rheticus prepared Copernicus‘ manuscript for printing.   Schöner also published numerous calendars and prophecies, which reached high circulation. In his later years, he focussed more on astrology and published a beginner’s textbook Opusculum Astrologicum (1539) as well as the monograph De iudiciis nativitatum Libri Tres (1545). In Nürnberg, Schöner published in 1544 the astronomical observations in the rebate of Regiomontanus and Bernhard Walther. Schöner edited several publications of Regiomontanus – especially his De Triangulis omnimodus (On Triangles), one of the first textbooks presenting the current state of trigonometry. From 1539 to 1541, Schöner improved the map of the Nuremberg region, previously produced by Erhart Etzlaub. At yovisto, you can learn more about the scientific, social and religious impact of the Copernican Revolution with the lecture ‘Mathematics, Motion, and Truth: The Earth goes round the Sun‘ by Jeremy Gray of Gresham University.'],\n",
       " [230,\n",
       "  'Lewis Terman and the Intelligence Quotient.  Lewis Madison Terman (1877 – 1956).  On January 15, 1877, American psychologist Lewis Madison Terman was born. He is best known for his pioneering work in individual intelligence tests as well as for his revision of the Stanford-Binet IQ test, with which he introduced the IQ (Intelligence Quotient), being a ratio of chronological age to mental age times 100. Lewis Terman was raised on a farm became a school teacher as well as high school principal in his early career. Terman received his doctorate in psychology from Clark University in 1905. He joined the education faculty in psychology at Stanford University five years later and became the head of Stanford’s Psychology Department in the 1920s. In his research, Terman focused on mental testing while revising Alfred Binet’s scale of intelligence. It was published in 1916 as the famous ‘Stanford-Binet’ scale of intelligence. One of the main innovations of the test was the inclusion of the Intelligence Quotient, which had not been used in mental tests before. The scale became the most widely used individually administered intelligence scale. When the government intended to develop intelligence tests for the army, Terman played a keyrole and the Stanford-Binet scale was considered the foundation for these tests. Also, Terman helped to develop ‘National Intelligence Tests’ for children aged three to eight. The tests were ready for use in the 1920s, and Terman then helped to establish intelligence tests in schools so that students could be classified into homogeneous ability groups, in what became termed a tracking system. Further, Terman became a leader in the development of group achievement tests, which assessed school learning. At yovisto, you may be interested in a video on Intelligence as part of the lecture series ‘Introduction to Psychology’ by Professor William Knapp.'],\n",
       " [231,\n",
       "  'Thomas Augustus Watson – Recipient of the Very First Phone Call.  Thomas Augustus Watson (1854-1934).  .  On January 18, 1854, American telephone pioneer and shipbuilder Thomas Augustus Watson was born. He is best known because, as the recipient of the first telephone call being the assistant of Alexander Graham Bell. He was one of the original organizers of the Bell Telephone Company and later turned to shipbuilding and constructed a number of vessels for the United States government. Born in Salem, Massachusetts, as the son of a livery stable, Watson dropped out of school at 14 and became a bookkeeper and a carpenter before he found a job more to his liking in the Charles Williams machine shop in Boston. There he helped build some rudimentary machines per the design of Alexander Graham Bell, at that time was a teacher of deaf mutes in Boston, trying to make a “harmonic telegraph” that could send several dot-and-dash messages at once over the same telegraph wire. Bell liked Watson and hired him as his assistant, and the two men jointly discovered that tones from a vibrating transmitter reed could be carried electrically by wire and audibly recreated. On March 10, 1876 they laid wire between two rooms on different floors of a boarding house, and Watson was adjusting the machinery in the lower room when he unexpectedly heard Bell’s voice transmitted metallically “Mr. Watson, come here, I want you.” Even though the machine had produced sound before, this was the first time it carried words that were heard distinctly. According to the story often told by Watson in his later years, Bell had accidentally spilled acid on his clothes and called out in frustration, but both men were surprised that Watson had heard him through the wires.[3] On Oct. 9, 1876, they had so perfected the telephone that they held a conversation between Boston and Cambridge over a two-mile wire.[4] Thomas A. Watson has been largely forgotten by history, but he, of course, had constructed and installed both machines for that historic conversation, and early accounts of the telephone’s invention routinely noted that it was the collaborative work of Bell and Watson, with Watson credited as “manufacturer of the first telephone“.[3] Yet Watson was a capable performer when it came to it: during the demonstrations of the telephone, he gamely belted hymns and popular airs into the receiver, despite his vague ability to hold a tune.[2] Between 1877 and 1881, Watson filed applications that resulted in about 40 U.S. patents. Like Bell, Watson had no desire to work in the telephone business once the device was a reality. Watson resigned from the Bell Telephone Company in 1881 at the age of 27. The first order of business was a long vacation in Europe, then marriage.[2] Using money from his royalties from his participation in the invention of the telephone, Watson first tried his hand at farming and then set up his own machine shop. In 1883 Watson founded the Fore River Ship and Engine Building Company. He soon began taking bids for building naval destroyers and by 1901 the Fore River Ship and Engine Company was one of the largest shipyards in America. It would later become one of the major shipyards during World War II, after being purchased by Bethlehem Steel Corporation in 1913. Watson had taken a three-year course in geology and paleontology with his wife while running his shipbuilding outfit, and so was able to recover by teaming up with a geology professor from MIT to evaluate ore deposits. Though he never found anything promising in the way of mines, Watson proved to be capable enough to have a genus of fossil gastropod named after him.[2] Watson continued to expand his interests, even in his later years. He joined a company of touring Shakespearean players after taking theater classes at London University. He also gave public readings of the Bible, Greek drama, Browning and various American authors. In 1919, he received a master of arts degree from Union College and in 1921, a doctor of engineering degree from Stevens Institute of Technology.[5]   On January 25, 1915, Watson was at 333 Grant Avenue in San Francisco to receive the first transcontinental telephone call, placed by Bell from the Telephone Building at 15 Dey Street in New York City. By then more than 13,000,000 telephones were in use worldwide.[3] In 1920, Watson visioned telephone conversations across the Atlantic Ocean as “only the beginning of modern development in this method of communication.” [4] Watson died of heart disease on December 13, 1934.   At yovisto you can learn more about the history of telecommunication in a video from the ATT archives on ‘To communicate is just the beginning‘.'],\n",
       " [232,\n",
       "  'Gaspard Bauhin and the Classification of Plants.  Gaspard Bauhin (1550 – 1624).  On January 17, 1560, Swiss botanist Gaspard Bauhin was born. He is best known for his contributions to the field of botany, and especially for his classification of plants. He was a disciple of the famous Italian physician Girolamo Mercuriale and he also worked on human anatomical nomenclature. Gaspard Bauhin was probably born in Basel and he was the son of the French physician Jean Bauhin. Also the young Gaspard devoted his life to medicine and studied in Padua, Montpellier and in several schools in Germany. He was admitted to the degree of a doctor in 1580 and gave private lectures in anatomy and botany when he returned to Basel. The young doctor was appointed to the  professorship at the local university and became the professor of the chair of anatomy and botany in 1588.   Bauhin was appointed city physician, professor of the practice of medicine, rector of the university, and dean of his faculty. During his career, the scientist published several works in the field of botany. The most important and most influential work is presumably his ‘Pinax Theatri Botanici, seu Index in Theophrasti, Dioscoridis, Plinii, et botanicorum qui a seculo scripserunt opera‘, published in 1596. The work is considered an early and widely celebrated attempt to name and catalog all known kinds of plants. The scientist managed to lit and describe about 6,000 species, while introducing the practice of naming plants by their genus and species (binomial nomenclature), a system that found wide application by the botanists John Ray and Linnaeus. Bauhin also planned a ‘Theatrum Botanicum‘ and it was meant to be comprised in twelve parts folio, of which he finished three. However, only one was published in 1658. In the field of anatomy, Bauhin’s most notable work is considered ‘Theatrum Anatomicum infinitis locis auctum‘, published in 1592. His son, Jean Gaspard Bauhin was professor of botany at Basel for thirty years. Gaspard Bauhin passed away in 1624. At yovisto, you can learn more about botany in the video lecture on ‘Human Livelihoods Depend on Wild Flowers: Kew’s Millennium Seed Bank explained‘.'],\n",
       " [233,\n",
       "  'The Steel of Sir Henry Bessemer.  Sir Henry Bessemer (1813 – 1898)  .  On January 19, 1813, English engineer, inventor, and businessman Sir Henry Bessemer was born. Bessemer’s name is chiefly known in connection with the Bessemer process, the first process for manufacturing steel inexpensively (1856), leading to the development of the Bessemer converter. Henry Bessemer was born on January 19, 1813 in Charlton, Hertfordshire, England. He was the son of an engineer and typefounder and he showed a great interest in making own inventions at early age. Bessemer proved to be mechanically skilled and had his first success selling ‘gold’ powder made from brass as a paint additive. Henry Bessemer also patented a method for making a continuous ribbon of plate glass in 1848, but it was not really commercially successful. Through the years, Henry Bessemer thought of more and more inventions and he began working on the problem of manufacturing cheap steel for ordnance production from 1850 to 1855 when he patented his method. He first described the process to a meeting of the British Association in Cheltenham which he titled “The Manufacture of Iron Without Fuel.” The famous Bessemer process involved the procedure of oxygen blown in the air through molten pig iron to burn off the impurities and thus create steel. It is known that James Nasmyth had been working on a similar idea for some time prior to this. However, after hearing Bessemer talk about his invention, Nasmyth turned his project down as he was about to retire anyway. The general lack of steel was hard for all industries back then and they had to rely on cast iron as well as wrought iron. There were several accidents when cast iron beams collapsed suddenly, such as the Dee bridge disaster of May 1847, the Wooton bridge collapse and the Bull bridge accident of 1860. The failures continued until all cast iron under-bridges were replaced by steel structures. As the cost of production steel decreased, the material was starting to be widely substituted for cast iron. When Bessemer licensed the patent for his process to several ironmasters, the companies had great difficulties producing steel of an acceptable quality. The Swedish ironmaster Göran Fredrik then tried using purer charcoal pig iron and made good steel by the process after numerous attempts. Also, it had been shown that the quantity of carbon could be controlled by removing almost all of it from the iron and then adding an exact amount of carbon and manganese. The process highly improved the quality of the material and was first introduced by Robert Forester Mushet. The inventor and businessman erected steelworks in Sheffield in a business partnership with others and began to manufacture steel. When Mushet’s daughter, Mary, decided to travel to London in order to confront Bessemer at his offices, arguing that his success was based on the results of her father’s work. Bessemer decided to pay Mushet an annual pension of £300, a very considerable sum, which he is assumed to have paid for over 20 years, possibly with the purpose to keeping the Mushets from legal action.   At yovisto you may learn more about the topic in the video lecture ‘From the European Coal and Steel Community to the Common Market’ by Prof. Dr. Vernon Bogdanor at Gresham College.'],\n",
       " [234,\n",
       "  'Simon Marius and his Astronomical Discoveries.  Simon Marius (1573-1625).  .  On January 20 (or January 10 according to the old Julian calendar), 1573, German astronomer Simon Marius was born. Marius was pupil of Tycho Brahe, one of the earliest users of the telescope and the first in print to make mention the Andromeda nebula. He studied and named the four largest moons of Jupiter that he claimed to have them discovered independently and even before Galileo. Simon Marius was born in Gunzenhausen, near Nuremberg in Bavaria, to Reinhard Marius, the Mayor of Gunzenhausen and his wife Elisabetha. Elementary for his education was the fact that, by chance, Margrave Georg Friedrich overheard him singing. Allegedly, the regent took a liking to him and arranged for him to be enrolled in the Fürstenschule at Heilsbronn, a Protestant school for princes in the Heilsbronn monastery, which Marius attended until 1601 becoming its most famous ex-pupil. During this period he became interested in astronomy, and his astronomical and meteorological observations began in 1594.[2] His plan to study at Königsberg couldn’t be realized, however he managed to visit famous astronomer Tycho Brahe at Prague in 1601.[1] There, he learned Tycho Brahe‘s observational techniques and instruments. Brahe died that year, and Marius’s stay in Prague lasted only four months. But he did meet David Fabricius there. Being a versatile observer even at the time before the invention of the telescope, Marius published his observation of the comet of 1596 and precisely established the position of the 1604 supernova in the constellation Ophiuchus. In 1599 Marius published a set of astronomical tables. These efforts resulted in his appointment as mathematician of the Markgrafschaft of Ansbach, in 1601.[2] Having heard that a telescope was being sold at the Frankfurt Fair in 1608, Marius constructed his own. It took him about a year before he had one of sufficient quality to make astronomical observations.[3] In the same year he published the first German translation (from the Greek) of the first six books of Euclid‘s Elements. Marius’s most memorable (and controversial) research involved the telescope:[2] in a letter written in summer 1611 he mentions his observations of Venus, and since August 1611 he had been observing sun spots, and in November of the same year he noticed that the movement of the sunspots and therefore the equatorial plane of the sun is tilted relative to the ecliptic.[1] Simon Marius also observed the Andromeda “nebula”, which had also been known to Arab astronomers of the Middle Ages. Of course he had no notion that he was observing a distant system of stars, because his telescope did not achieve the required resolution. In 1612 Marius measured the diameter of the Andromeda nebula and discerned it as having a dull, pale light which increased in brightness toward its center, like “a candle shining through horn“.   Mundus Iovialis anno MDCIX Detectus Ope Perspicilli Belgici (The World of Jupiter, 1609, detected with a Flemish telescope)   In 1614 Marius published his work Mundus Iovialis describing the planet Jupiter and its moons. Here he claimed to have discovered the planet’s four major moons some days before Galileo Galilei. This led to a dispute with Galileo, who showed that Marius provided only one observation as early as Galileo‘s, and it matched Galileo‘s diagram for the same date, as published in 1610. It is considered possible that Marius discovered the moons independently, but at least some days later than Galileo. Regardless of priority, the mythological names by which these satellites are known today (Io, Europa, Ganymede and Callisto) are those given them by Marius. He also concluded from his observations of the Jovian moons that they must orbit Jupiter while Jupiter orbits the Sun. From Marius‘ observations of the Jovian moons he derived better periods of revolution and other orbital elements for them than did Galileo. From his observations of the Jovian planetary system, Marius wrongly concluded that the geocentric Tychonic system, in which the planets circle the Sun while the Sun circles the Earth, must be the correct world system. He also observed the location of Tycho Brahe‘s supernova of 1572 and found a star there which he estimated to be “somewhat dimmer than Jupiter’s third moon.” Marius drew conclusions about the structure of the universe from his observations of the Jovian moons and the stellar disks. The stellar disks he observed were spurious (likely the Airy disk caused by diffraction, as stars are too distant for their physical disks to be detected telescopically), but Marius interpreted them to be physical disks, like the planetary disks visible through a telescope. He concluded that since he could see stellar disks, the stars could not be as distant as was required in the Copernican world system, and he said that the appearance of the stars as seen through a telescope actually argued against Copernicus. Simon Marius died in Ansbach after a brief illness in 1624. At yovisto, you can learn more about the power of scientific ideas, as well about their failure. Science is a perpetual search for new ideas, but this says nothing of how correct it is. Gresham College Prof Ian Angell introduces you to ‘Science’s First Mistake‘.'],\n",
       " [235,\n",
       "  'Pierre Gassendi and his Trials to reconcile Epicurean atomism with Christianity.  Pierre Gassendi (1592-1655). You have read the title? I guess, you might be scared now, but Pierre Gassendi was a decent fellow… On January 22, 1592, French philosopher, priest, scientist, astronomer, and mathematician. Pierre Gassendi was born. Gassendi revived Epicureanism as a substitute for Aristotelianism, attempting in the process to reconcile Atomism‘s mechanistic explanation of nature with Christian belief in immortality, free will, an infinite God, and creation.He clashed with his contemporary Descartes on the possibility of certain knowledge. He was also an active observational scientist, publishing the first data on the transit of Mercury in 1631. Pierre Gassendi was born at Champtercier, near Digne, in France to Antoine Gassend and Françoise Fabry, a family of commoners. Already at a very early age he showed academic potential and attended the college at Digne, where he displayed a particular aptitude for languages and mathematics. At age 16, he entered the University of Aix-en-Provence, to study philosophy. In 1612 the college of Digne called him to lecture on theology. Four years later he received the degree of Doctor of Theology at Avignon, and in 1617 he took holy orders. In the same year he answered a call to the chair of philosophy at Aix-en-Provence University, and seems gradually to have withdrawn from theology. Pierre Gassendi‘s career as a priest is a crucial facet of his intellectual constitution: his writings reflect an unbending allegiance to Holy Scripture and Church teachings, though not necessarily in orthodox doctrinal lights. He was ordained at the age of 24 or 25 and, while there is no question of the strength of his faith, one motivation for his career in the Church appears to be its provision of a sinecure. [1] He lectured principally on the Aristotelian philosophy, conforming as far as possible to the traditional methods while he also followed with interest the discoveries of Galileo and Kepler. He came into contact with the astronomer Joseph Gaultier de la Vallette (1564–1647). In 1623 the Society of Jesus took over the University of Aix. They filled all positions with Jesuits, who disapproved of Gassendi’s anti-Aristotelianism, and compelled him to leave. He left, returning to Digne, and then travelled for the chapter to Grenoble. In 1624 he printed the first part of his Exercitationes paradoxicae adversus Aristoteleos (Paradoxical Exercises Against the Aristotelians). Pierre Gassendi thereafter engaged in many scientific studies with his patron, Nicolas-Claude Fabri de Peiresc, until the latter’s death in 1637, which seemed to afflict him deeply. Gassendi travelled in Flanders and in Holland, and returned to France in 1631, and two years later became provost of Digne Cathedral. During this time he wrote some works, at the insistence of theologian and mathematician Marin Mersenne. They included his examination of the mystical philosophy of Robert Fludd, an essay on parhelia, and some observations on the transit of Mercury. In 1641, he met Thomas Hobbes in Paris, where Gassendi also gave some informal philosophy classes, which according to the biographer Grimarest included Molière and Cyrano de Bergerac . In 1642 Mersenne engaged Gassendi and other eminent thinkers in controversy with René Descartes to contribute a commentary on the manuscript of René Descartes’s Meditations. This led to Gassendi’s objections to the fundamental propositions of Descartes published as the Fifth Set of Objections in the works of Descartes. In 1645 Gassendi was appointed professor of mathematics at the Collège Royal in Paris, and lectured for several years with great success. In addition to controversial writings on physical questions, there appeared during this period the first of the works for which historians of philosophy remember him. Gassendi attempted to find what he called a middle way between skepticism and dogmatism. He argued that, while metaphysical knowledge of the “essences” (inner natures) of things is impossible, by relying on induction and the information provided by “appearances” one can acquire probable knowledge of the natural world that is sufficient to explain and predict experience. The best theory of such a world, in Gassendi’s opinion, is the ancient atomism according to Epicurus. There, atoms are eternal, differently shaped, and moving at different speeds. Gassendi argued that such atoms must have some of the physical features of the visible objects they constitute, such as extension, size, shape, weight, and solidity. The atoms collide and agglomerate, resulting in events in the perceptible world.[2] In 1647 he published the well-received treatise De vita, moribus, et doctrina Epicuri libri octo followed by further publications on Diogenes Laërtius and another commentary on Epicurus. Gassendi believed that there was no conflict between his mechanistic atomism and the doctrines of Roman Catholicism; indeed, he took pains to emphasize their compatibility. In 1648 ill-health compelled him to give up his lectures at the Collège Royal. He travelled in the south of France and spent nearly two years at Toulon, where the climate suited him. In 1653 he returned to Paris and resumed his literary work publishing lives of Copernicus and of Tycho Brahe. He died at Paris in 1655 from a lung disease. At yovisto, you may enjoy a video lecture by Dr. Richard Brown on Rene Descartes‘ Method of Doubt.'],\n",
       " [236,\n",
       "  'John Fitch and the Steam Boat.  Steamboat of April 1790 used for passenger service.  On January 21, 1743, American inventor, clockmaker, entrepreneur and engineer John Fitch was born. He was most famous for operating the first steamboat service in the United States even before Robert Fulton. John Fitch grew up with his father and it is believed that he did not enjoy his childhood too much. He was pulled from school at the age of eight and had to work at the family farm. Eventually, he fled and took up silversmithing before exploring the Ohio River basin. Some years later, Fitch left again for Pennsylvania, where he set out to make a steam-powered boat to navigate the western rivers. His competitor, Rumsey, also looked forward to making money with steamboats and he gained support from the U.S. government in the 1780s. However, Fitch found support by a private investor and began reinventing a sort of Watt engine, constructing what is believed to be America’s first successful steamboat, ahead of Rumsey. [1,2] Pennsylvania, New York, Delaware, and Virginia issued patents for his steamboat and he obtained financial backings for a total of three boats. Fitch was able to use his odd machines, which (in the first plans they were propelled by a set of Indian canoe paddles), in a passenger line between Trenton and Philadelphia. Unfortunately, his attempt failed commercially. It is widely believed that the people did not take his idea seriously and also, he apparently had difficulities in finding new investors. [1,2] John Fitch was known to be a complex personality – intelligent, ambitious, stubborn, and probably paranoid. He was a self-taught scientist and mechanic, and he wanted to solve practical problems. Unfortunately, his setbacks hit him hard and Fitch felt highly betrayed after Robert Fulton, about a decade later, claimed that he was inventor of the steamboat. Fitch retired and it is believed that he committed suicide. [1] At yovisto you might learn more about the principles behind steam engines and thermodynamics in the lecture videos of Prof. Ranamurti Shankar from Yale on ‘Fundamentals of Physics‘, where he also discusses the laws of thermodynamics.'],\n",
       " [237,\n",
       "  'Andrija Mohorovičić and the Mohorovičić Discontinuity.  Andrija Mohorovicic (1857 – 1936).  On January 23, 1857, Croatian meteorologist and seismologist Andrija Mohorovičić was born. He is best known for the eponymous Mohorovičić discontinuity, i.e. he boundary between the Earth’s crust and mantle discovered by him – and is considered a founder of modern seismology. Andrija Mohorovičić proved to be a talented student from early age. By the age of 15, he spoke English, French and Italian and learned German, Czech, Latin and Ancient Greek as well. He enrolled at the Faculty of Philosophy of the University of Prague and studies with prominent professors, such as Ernst Mach. Afterwards, he was occupied as a teacher at the grammar school in Zagreb and in Osijek. At a nautical school in Bakar near Rijeka, he was able to teach mathematics, physics and meteorology. Mohorovičić established a meteorological station and he maintained continuous meteorological observations. In his observations, he also included the movement of air and the cloud using the nephoscope, which he constructed. Mohorovičić defended his dissertation “On the Observation of Clouds, and the Daily and Annual Cloud Period in Bakar” in 1893 and taught courses in geophysics and astronomy at the Faculty of Philosophy in Zagreb. The scientist and teacher also became a member of the Yugoslav Academy of Sciences and Arts in Zagreb. [1] To one of Mohorovičić’s biggest contributions to science belogs the famous Mohorovičić Discontinuity, which was discovered around 1910 and it can be described as the boundary between the Earth’s crust and the mantle. Mohorovičić realized that the velocity of a seismic wave is related to the density of the material that it is moving through and interpreted the acceleration of seismic waves within Earth’s outer shell as a compositional change within the Earth. Therefore, he concluded, must the acceleration be caused by a higher density material being present at depth. Mohorovičić determined that the basaltic oceanic crust and the granitic continental crust are underlain by a material which has a density similar to an olivine-rich rock such as peridotite. [2] At yovisto, you may more about the Science of Natural Disasters in a video lecture by Dr. David Percovici at Yale University.'],\n",
       " [238,\n",
       "  'Oskar Morgenstern and the Game Theory.  Oskar Morgenstern (1902-1977).  .  On January 24, 1902, German-American economist and mathematician Carl Friedrich Alfred Oskar Morgenstern was born. Morgenstern popularized “game theory” which mathematically analyzes behaviour of man or animals in terms of strategies to maximize gains and minimize losses. He coauthored Theory of Games and Economic Behavior (1944), with John von Neumann, which extended Neumann‘s 1928 theory of games of strategy to competitive business situations. “As far as the use of mathematics in economics is concerned, there is an abundance of formulas where such are not needed. They are frequently introduced, one fears, in order to show off. The more difficult the mathematical theorem, the more esoteric the name of the mathematician quoted, the better.” –Oskar Morgenstern, from Limits of the Use of Mathematics in Economics Oskar Morgenstern was born in Görlitz, Silesia, Germany. His mother was said to be an illegitimate daughter of Emperor Frederick III of Germany. Morgenstern grew up in Vienna, Austria, where he also went to university. In 1925 he graduated from the University of Vienna and got his PhD in political science. From 1925 until 1928 he went on a three year fellowship financed by the Rockefeller Foundation, at the end of which he published Economic Forecasting (1928). After his return in 1928 he became a professor in economics at his alma mater the University of Vienna until his visit to Princeton University in 1938. At Vienna, he published his Frontiers of Economic Policy in 1934. In 1935 Oskar Morgenstern published the article Perfect Foresight and Economic Equilibrium, after which his colleague, Eduard Čech, pointed him to an article of John von Neumann, Zur Theorie der Gesellschaftsspiele (1928). During Morgenstern‘s visit to Princeton University in 1938, Austria was incorporated into Nazi Germany and Morgenstern decided to remain in the United States. He would even remain in the country for the rest of his life, becoming a naturalized citizen in 1944. Morgenstern soon received a promotion to full professor at Princeton but gravitated toward the Institute for Advanced Study. There, he met the John von Neumann and they collaborated to write their famous Theory of Games and Economic Behavior, published in 1944, which is recognized as the first book on game theory. Game Theory is a mathematical framework for the study of strategic structures which govern rational decision-making in certain economic, political and military situations. This book applied John von Neumann‘s theory of games of strategy to competitive business situations. The collaboration between economist Morgenstern and mathematician von Neumann led to the birth of entirely new areas investigation in both mathematics and economics. These have attracted widespread academic and practical interest since that time. Morgenstern wrote many other articles and books, including On the Accuracy of Economic Observations (1950), and Predictability of Stock Market Prices (1970) with subsequent Nobel laureate Clive Granger. After retiring from Princeton in 1970, Morgenstern accepted a professorship in economics at New York University, where he would remain until his death in 1977. At yovisto, you can learn more about Game Theory in the lecture of Tim Roughgarden from Stanford University on Algorithmic Game Theory.'],\n",
       " [239,\n",
       "  'Fabian von Bellingshausen and the Discovery of Antarctica.  Fabian Gottlieb von Bellingshausen (1778 – 1852).  On January 25, 1852, Baltic German officer in the Imperial Russian Navy, cartographer and explorer Fabian Gottlieb von Bellingshausen passed away. He was a notable participant of the first Russian circumnavigation and subsequently a leader of another circumnavigation expedition, which discovered the continent of Antarctica. He is remembered in Russia as one if its greatest admirals and explorers, and multiple geographical features and locations in the Antarctic, named in honor of Bellingshausen, remind of his role in exploration of the southern polar region. It is believed that Fabian von Bellingshausen was born on September 20, 1778 in Estonia and that he enrolled at the Russian navy at the age of only 10. He took part in the first Russian circumnavigation from 1803 to 1806 and was made captain in 1816. It is assumed that Bellingshausen was appointed commander of the southern polar expedition which left the Russian naval base of Kronstadt in the Gulf of Finland in July 1819. Bellingshausen was in charge of two ships, the Vostok and the Mirny. The crew’s objective was to explore as far south as possible and to engage in scientific work. Approximately in January 1820, Fabian von Bellingshausen sighted the coast of Antarctica and sailed towards Port Jackson, which they reached on April 11. [1] Bellingshausen and his crew sailed continued exploring the area. They sailed to the Tuamotu archipelago, making several discoveries and headed south again, probably around November. The expedition discovered Peter I Island and Alexander Island and they explored and mapped Macquarie Island. Fabian von Bellingshausen and his crew then completet the circumnavigation of the Antarctic and returned to Kronstadt in 1821. [1,2] During the journey, three men had been lost. Also, it took ten years to publish the discovery Bellingshausen and his crew accomplished. It is believed that Russia was quite unimpressed with his circumnavigation of the continent and thus all interest in Terra Australis was abandoned until whaling fleets were sent to the south in 1946. The first Russian scientific base was established on the mainland during the International Geophysical Year, 1957-58. [2] At yovisto, you may learn more about the Heroic Age of Antarctic Exploration by Edward Larson.'],\n",
       " [240,\n",
       "  'Henry Briggs and the Popularization on Logarithms.  Plot of logarithms with bases 2, e, and 10.  On January 26, 1630, English mathematician and committed puritan Henry Briggs passed away. He is notable for changing the original logarithms invented by John Napier into common (base 10) logarithms, which are sometimes known as Briggsian logarithms in his honour. Henry Briggs was born in Halifax, however, his exact date of birth remains unknown. His early family life is also not too well known, but it is believed that he became very proficient at Greek and Latin during his education at a grammarschool near Warley Wood. Briggs received his M.A. around 1585 and was elected a fellow of St John’s College. Henry Briggs’ lectureship was in the field of medicine, but he was also appointed as an examiner and lecturer in mathematics at Cambridge around 1592. Just a few years later, he became the very first professor of geometry at Gresham College. The institute had just been founded and it was famed as the birthplace of the Royal Society of London about 25 years after Briggs left. In his active period at Gresham, it has been found that Briggs was quite enthusiastic about astronomy and was corresponding with James Ussher at Trinity College, Dublin. Briggs’ interest revolved around eclipses in particular. It is believed that he read Napier’s work on logarithms in order to help his astronomical calculations. Back then, Briggs was already involved in producing tables to help complex calculations and he already published two tables before even finding out about Napier’s logarithms. When Briggs read Napier’s work on logarithms, he wrote to James Ussher: Napper, lord of Markinston, hath set my head and hands a work with his new and admirable logarithms. I hope to see him this summer, if it please God, for I never saw a book which pleased me better or made me more wonder. [1] However, Briggs noticed a few problems with Napier’s calculations. He discussed that it causes major difficulties that Napier log 1 does not equal 0. Interesting is however, that even though Briggs is widely made responsible for the change to logarithms with log 1 = 0, the scientist himself gives the credit for the idea to Napier. It is believed that the idea avolved in discussions between Napier and Briggs. Briggs visited Napier several times, first in 1615 and his first work on logarithms, titled as ‘Logarithmorum Chilias Prima‘ was published in 1617 and John Napier died in the same year. [1,2] Henry Briggs’ mathematical treatise Arithmetica Logarithmica was published in 1624 and the author gave logarithms of the natural numbers from 1 to 20,000 and 90,000 to 100,000 computed to 14 decimal places. Further, the work introduced tables of natural sine functions, tan, and sec functions. [1] At yovisto, you may learn more about Henry Briggs in the “400 years of Geometry at Gresham College” lecture by Professor Robin Wilson.'],\n",
       " [241,\n",
       "  'Thomas Willis and the Royal Society.  Thomas Willis (1621-1675). On January 27, 1620, English physician and founding member of the Royal Society Thomas Willis who played an important part in the history of anatomy, neurology and psychiatry. A club of scientists including Robert Boyle, Christopher Wren and John Wilkins met in his rooms in Oxford, which later should become founding members of the Royal Society. Thomas Willis was born the eldest of three sons on his parents‘ small farm in Great Bedwyn, Wiltshire, where his father (also) Thomas Willis held the stewardship of the Manor. He was a kinsman of the Willys baronets of Fen Ditton, Cambridgeshire and a staunch Royalist, and both Willis and his father would later serve in the Civil War, though Willis’ father would not survive.[4] Willis went to Oxford as a servitor and graduated M.A. from Christ Church, Oxford in 1642. In the Civil War years he was a royalist, dispossessed of the family farm at North Hinksey by Parliamentary forces. Willis started in Oxford intending to follow a career in the church. When the Civil War made that appear chancy, he turned to medicine. Meanwhile, Willis served King Charles I in the ongoing Civil War in the auxiliary regiment of the Earl of Dover. In the 1640s Willis was one of the royal physicians to Charles I of England. While it is unclear whether or not he actually participated in any battles, Willis’ loyalty and service to the King was rewarded by the early conferral of his medical degree, despite the fact he was seven years away from graduating from the fourteen year program.[4] Less grandly, once qualified B. Med. in 1646, he began as an active physician by regularly attending the market at Abingdon. Willis’ breakthrough as a physician came about with the revival of Anne Green on December 14, 1650. Green, a 22 year old servant, was a prisoner of the state who was convicted of the infanticide of her newborn child, and was sentenced to be hanged. At the time, obtaining corpses for anatomical dissection was difficult, so the bodies of executed individuals were typically donated to universities. After being hanged in Oxford’s Cattle Yard, Green’s body was donated for scientific study to Oxford. Thus, Green was delivered to the home of William Petty, a colleague of Willis’ and a lecturer in anatomy at Oxford. When the coffin was opened, an audible gagging was heard and Green started to breath. Together Petty and Willis resuscitated the ‘corpse’, using unorthodox but ultimately successful techniques.[4] While in Oxford, Willis made his chambers available for Anglican services during the Puritan interregnum.[3] One of several Oxford cliques of those interested in science grew up around Willis and Christ Church. Besides Robert Hooke, who would become Willis’s leading rival, and who both politically and medically held some incompatible views, others in the group were Nathaniel Hodges, John Locke, Richard Lower, Henry Stubbe and John Ward. In the broader Oxford scene, he was a colleague in the “Oxford club” of experimentalists with Ralph Bathurst, Robert Boyle, William Petty, John Wilkins and Christopher Wren.   Frontispiece to Thomas Willis’ 1663 book “Diatribae duae medico-philosophicae – quarum prior agit de fermentatione”   In 1656 and 1659 Willis published two significant medical works, De Fermentatione and De Febribus. These were followed by the 1664 volume on the brain, Cerebri Anatome, cui accessit Nervorum descriptio et usus )Anatomy of the Brain, with a Description of the Nerves and Their Function), which was a record of collaborative experimental work closely with Christopher Wren and Richard Lower, who contributed drawings and assisted with dissections. Cerebri Anatome is considered the most complete and accurate account of the nervous system to that time. Willis is credited with coining the term neurology, which first appears in Cerebri Anatome. Willis was the first to number the cranial nerves in the order in which they are now usually enumerated by anatomists. The Cerebri Anatome was the main reason why the arterial circle found at the base of the human brain is now called the Circle of Willis. Though he was not the first one who discovered and described it, he was the only one who was able to discuss it in great detail, describing each part and vascular pattern in depth. Willis therefore is regarded by modern physicians and anatomists as the founder of clinical neuroscience, neurology, comparative anatomy, and neuroanatomy. In addition, he made significant original contributions to cardiology, endocrinology, and gastroenterology. Willis coined the term mellitus in diabetes mellitus. An old name for the condition is “Willis’s disease“. He observed what had been known for many centuries elsewhere, that the urine is sweet in patients. His observations on diabetes formed a chapter of Pharmaceutice rationalis (1674). Further research came from Johann Conrad Brunner, who had met Willis in London. From 1660 until his death, he was Sedleian Professor of Natural Philosophy at Oxford. At the time of the formation of the Royal Society of London, he was on the 1660 list of priority candidates, and became a Fellow in 1661. Henry Stubbe became a polemical opponent of the Society, and used his knowledge of Willis’s earlier work before 1660 to belittle some of the claims made by its proponents. Willis later worked as a physician in Westminster, London, this coming about after he treated Gilbert Sheldon in 1666. Thomas Willis died on St. Martin‘s Day, 11 November 1675, in London.   At yovisto, you may enjoy a more detailed explanation on the founding of the Royal Society by Professor Michael Hunter at Gresham College.'],\n",
       " [242,\n",
       "  'Ernst Kummer and his Achievements in Mathematics.  Ernst Eduard Kummer (1810-1893). On January 29, 1810, German mathematician Ernst Eduard Kummer was born. One of his major contributions is the introduction of ideal numbers, which are defined as a special subgroup of a ring, extended the fundamental theorem of arithmetic to complex number fields.He also discovered the fourth order surface based on the singular surface of the quadratic line complex. This Kummer surface has 16 isolated conical double points and 16 singular tangent planes. Ernst Kummer was born in Sorau, Brandenburg (then part of Prussia)to his father Carl Gotthelf Kummer, a physician. However his father died when Ernst was only three years old and Ernst and his elder brother Karl were brought up by their mother. Ernst received private coaching before entering the Gymnasium in Sorau when he was nine years old. In 1828 Kummer entered the University of Halle to study Protestant theology. But fortunately for the good of mathematics, Kummer received mathematics teaching as part of his degree to provide a proper foundation to the study of philosophy. Soon the study of mathematics should become his main subject, although at this stage he still saw it as leading to a later study of philosophy.[1] In 1831 Kummer was awarded a prize for a mathematical essay and in the same year he was awarded his certificate to enable him to teach in schools. Moreover, on the strength of his prize winning essay, he was awarded a doctorate. After a probationary year at the Gymnasium in Sorau where he had been educated, he was appointed to a teaching post at the Gymnasium in Liegnitz, now Legnica in Poland that he held for the next 10 years. Some of his pupils there had great ability, most prominent among them Leopold Kronecker, and conversely they were extremely fortunate to find a school teacher of Kummer‘s quality and ability to inspire. During Kummer‘s first period of mathematics he worked on function theory. He extended Gauss‘s work on hypergeometric series, giving developments that are useful in the theory of differential equations. He was the first to compute the monodromy groups of these series. In 1839, although still a school teacher, Kummer was elected to the Berlin Academy on Dirichlet‘s recommendation. In 1842, Kummer became professor of mathematics at the University of Breslau (now Wrocław, Poland). In 1855 he succeeded Peter Gustav Lejeune Dirichlet as professor of mathematics at the University of Berlin, at the same time also becoming a professor at the Berlin War College. In 1843, Kummer showed Dirichlet an attempted proof of Fermat’s last theorem. But, Dirichlet found an error, and Kummer continued his search and developed the concept of so-called ideal numbers. In number theory an ideal number is an algebraic integer which represents an ideal in the ring of integers of a number field. An ideal is a special subset of an algebraic ring. Ideals generalize certain subsets of the integers, such as the even numbers or the multiples of 3. Addition and subtraction of even numbers preserves evenness, and multiplying an even number by any other integer results in another even number. Using the concept of ideal numbers, Kummer proved the insolubility of the Fermat relation for all but a small group of primes, and he thus laid the foundation for an eventual complete proof of Fermat’s last theorem. For his great advance, the French Academy of Sciences awarded him its Grand Prize in 1857. The ideal numbers have made possible new developments in the arithmetic of algebraic numbers. In 1861, Germany’s first seminar in pure mathematics was established at Berlin on the recommendation of Kummer and Karl Weierstrass. It soon attracted gifted young mathematicians form throughout the world, including many graduate students.[3] Kummer’s Berlin lectures, always carefully prepared, covered analytic geometry, mechanics, the theory of surfaces, and number theory. For the rest of his life, Kummer was devoted to geometry. He applied himself with unbroken productivity to ray systems and also considered ballistic problems. By that time, also discovered the fourth order surface, now named after him, based on the singular surface of the quadratic line complex. The Kummer surface has 16 isolated conical double points and 16 singular tangent planes and was published in 1864. He retired at his own request in 1883 to spent the last years of his life in quiet retirement until his death in 1893. At yovisto, you can learn more about number theoryin a lecture on Gauss’ Law.'],\n",
       " [243,\n",
       "  'Johannes Hevelius and his Selenographia.  Map of the Moon engraved by astronomer Johannes Hevelius.  On January 28, 1611, German astronomer Johannes Hevelius was born. From four years’ telescopic study of the Moon, using telescopes of long focal power, Hevelius compiled Selenographia (“Pictures of the Moon”, 1647), an atlas of the Moon with some of the earliest detailed maps. Johannes Hevelius‘ father was a succesful merchant and pushed Johannes to follow his footsteps rather than pursue a scientific career. Hevelius was sent to Poland in order to study Polish. At the age of about 16, Hevelius begged his father to be able to continue a formal education and after he finally gave in, Hevelius fell in love with mathematics and astronomy. The young man also learned Latin and began drawing, engraving , and building instruments of wood and metal. His mentor was Peter Crüger, a reknowned mathematician, astronomer, and polymath, who encouraged Johannes Hevelius to take an active part in his observations. [1] Hevelius and his wife Elisabetha making observations, 1673 However, Hevelius realized that he had to follow his father’s wishes and start taking care of his family, as he was the only son. He undertook the necessary studies of the customs and laws of the city and settled down to pursue a career as a businessman. The turning point came around 1639, when Johannes Hevelius visited his old mentor Crüger, who deeply advised his best student not to give up astronomy. Also, Hevelius was again motivated to study his beloved astronomy after he observed an eclipse of the sun which occurred on 1 June 1639. The now married man Hevelius spent every second of his leisure time with astronomy while his wife, Katharina, agreed to take over much of the administrative work associated with the family’s brewery. He started again to grind lenses for telescopes and making mounts for quadrants and sextants. Hevelius also corresponded much with the European leaders of astronomy. [2] Hevelius’ famous text Selenographia was published in 1647 and included 60 drawings of the moon’s surface. For his accomplishment, Hevelius was praised all over Europe, and his maps were considered the best for over a century. Once, English traveler Mundy is believed to have written in his diary: Of the Moone he hath Made above 30 large mappes, prints, or Copper peeces of the Manner of every daies encrease and decrease, deciphering in her land and sea, Mountaines, valleies, Ilands, lakes, etts., making in another little world, giving Names to every part, as wee in a mappe of our world. After the tragic death of his wife, Johannes Hevelius married Catherina Elisabetha Koopman, who was deeply interested in astronomy and contributed to Hevelius’ studies with mathematical calculations and observations. He was elected to the Royal Society of London in 1664. In 1679, Hevelius faced another tragedy. During a fire, his observatory, as well as his instruments and books were completely destroyed. However, the old man apparently did not even think of giving up, but promptly began to repair the damage, being able to observe the Great Comet of 1680. Johannes Hevelius passed away on January 28, 1687. [2,3] At yovisto, you may be interested in a video lecture by Ross Beyer, who talks about “Making maps to explore the Earth, Moon, and Mars“.'],\n",
       " [244,\n",
       "  'Euclid – the Father of Geometry.  Euclid of Alexandria, fl. 300 BC At about 330 BC, Euclid of Alexandria was born, who often is referred to as the Father of Geometry. His Elements is one of the most influential works in the history of mathematics, serving as the main textbook for teaching mathematics (especially geometry) from the time of its publication until the late 19th or early 20th century. In the Elements, Euclid deduced the principles of what is now called Euclidean geometry from a small set of axioms. Very few original references to Euclid survive, so little is known about his life. The date, place and circumstances of both his birth and death are unknown and may only be estimated roughly relative to other figures mentioned alongside him. The few historical references to Euclid were written long after he lived, by Proclus c. 450 AD and Pappus of Alexandria c. 320 AD. Proclus introduces Euclid only briefly in his Commentary on the Elements. According to Proclus, Euclid belonged to Plato‘s “persuasion” and brought together the Elements, drawing on prior work by several pupils of Plato. Proclus believes that Euclid must have lived during the time of Ptolemy I because he was mentioned by Archimedes, who refers to him as the author of the Elements. Proclus later retells a story that, when Ptolemy I asked if there was a shorter path to learning geometry than Euclid’s Elements, “Euclid replied there is no royal road to geometry.” This anecdote is questionable since it is similar to a story told about Menaechmus and Alexander the Great. Arabian authors state that Euclid was the son of Naucrates and that he was born in Tyre. It is believed by historians of mathematics that this is entirely fictitious and was merely invented by the authors. Because the lack of biographical information is unusual for the period, some researchers have proposed that Euclid was not, in fact, a historical character and that his works were written by a team of mathematicians who took the name Euclid from a historical figure. They think, Euclid might be similar to Bourbaki, the collective pseudonym under which a group of 20th-century mathematicians published with the aim of reformulating mathematics. However, this hypothesis is not well accepted by scholars and there is little evidence in its favor. One of the oldest surviving fragments of Euclid’s Elements, found at Oxyrhynchus and dated to circa AD 100   Euclid‘s most famous work is his treatise on mathematics The Elements. The book was a compilation of knowledge that became the centre of mathematical teaching for 2000 years. Probably no results in The Elements were first proved by Euclid but the organisation of the material and its exposition are certainly due to him.[1] One of Euclid‘s accomplishments was to present the material in a single, logically coherent framework, making it easy to use and easy to reference, including a system of rigorous mathematical proofs that remains the basis of mathematics 23 centuries later. There is no mention of Euclid in the earliest remaining copies of the Elements, and most of the copies say they are “from the edition of Theon” or the “lectures of Theon“. The only reference that historians rely on of Euclid having written the Elements actually was from Proclus, who briefly in his Commentary on the Elements ascribes Euclid as its author. In his Elements, Euclic put the mathematical knowledge of his age on a solid foundation. He began in Book I with 23 definitions, such as “a point is that which has no part” and “a line is a length without breadth”, followed by five unproved assumptions that he called postulates (now known as axioms).[3] Euclid stated that axioms were statements that were just believed to be true, but he realized that by blindly following statements, there would be no point in devising mathematical theories and formulae. He realized that even axioms had to be backed with solid proofs.[2] The Elements is divided into 13 books. Books one to six deal with plane geometry. In particular books one and two set out basic properties of triangles, parallels, parallelograms, rectangles and squares. Book three studies properties of the circle while book four deals with problems about circles and is thought largely to set out work of the followers of Pythagoras. Book five lays out the work of Eudoxus on proportion applied to commensurable and incommensurable magnitudes. Book six looks at applications of the results of book five to plane geometry. Although best known for its geometric results, the Elements also includes number theory, which he presented in book seven to nine. It considers the connection between perfect numbers and Mersenne primes (known as the Euclid–Euler theorem), the infinitude of prime numbers, Euclid‘s lemma on factorization (which leads to the fundamental theorem of arithmetic on uniqueness of prime factorizations), and the Euclidean algorithm for finding the greatest common divisor of two numbers. The geometrical system described in the Elements was long known simply as geometry, and was considered to be the only geometry possible. Today, however, that system is often referred to as Euclidean geometry to distinguish it from other so-called non-Euclidean geometries that mathematicians discovered in the 19th century. Book ten deals with the theory of irrational numbers and is mainly the work of Theaetetus. Books eleven to thirteen deal with three-dimensional geometry, in Greek stereometria. The immense impact of the Elements on Islamic mathematics is visible through the many translations into Arabic from the 9th century forward. Euclid first became known in Europe through Latin translations of these versions. The first extant Latin translation of the Elements was made about 1120 by Adelard of Bath, who obtained a copy of an Arabic version in Spain, where he traveled while disguised as a Muslim student. More than one thousand editions of The Elements have been published since it was first printed in 1482. The impact of this activity on European mathematics cannot be overestimated. The ideas and methods of Johannes Kepler, Pierre de Fermat, René Descartes, and Isaac Newton were deeply rooted in, and inconceivable without, Euclid’s Elements.[1,3] At yovisto, you can learn more about Non-Euclidian geometry in the History of Mathematics lecture of Professor N. J. Wildberger “MathHist12 – Non-Euclidian Geometry“.'],\n",
       " [245,\n",
       "  'Charles Green and his Record Balloon Flight.  Charles Green (1785 – 1870).  On January 31, 1785, Charles Green was born, who was United Kingdom’s most famous balloonist of the 19th century. He experimented with coal gas as a cheaper and more readily available alternative to hydrogen for lifting power. In 1836, Green set a major long distance record in the balloon “Royal Vauxhall”, flying overnight from Vauxhall Gardens in London to Weilburg, Duchy of Nassau (Germany) a distance of 770 km. This record was not broken until 1907. Charles Green joined his father’s business after school. His very first ascent in a balloon possibly took place in London around 1821 at the coronation of George IV. It is believed that several hundred ascents followed this event and that he ascended in August 1828 at Beckham in Kent. Green designed and constructed the Great Nassau balloon in the mid-1830s and made the first ascent from Vauxhall Gardens. It is assumed that he was accompanied by eight people and remained in the air for one hour before descendingnear Gravesend. The famous flight from Vauxhall Gardens to Nassau, Germany took place in 1836 as well. They took off at 1:30pm and crossed the channel from Dover just a few hours later. Green and his passengers descended again at the bext day around 7am in Germany. They traveled a distance of 500 miles in a total time period of 18 hours. This record remained unbeaten until 1907 and Green was accompanied by Monck Mason and Robert Hollond, who financed the adventure. More than 10 years earlier, Green introduced coal gas as a cheaper substitute for hydrogen, which was put in practice by many following balloonists. It is believed that Charles Green planned an Atlantic crossing in a balloon, but he never attempted it. Around 1840, Green incorporated presumably the first mechanically driven propeller ever to power an aircraft. At yovisto, you may learn more about the ‘History of Ballooning’.'],\n",
       " [246,\n",
       "  'Dmitri Mendeleev and the Periodic Table of Elements.  Dmitri Mendeleev (1834 – 1907).  On February 2, 1907, Russian chemist and inventor Dmitri Ivanovich Mendeleev passed away. He is probably best known for his version of the periodic table of chemical elements. Furthermore, he used it to correct the properties of some already discovered elements and also to predict the properties of eight elements yet to be discovered. Dmitri Mendeleev was born in Tobolsk, Siberia and moved to Saint Petersburg where he was able to enroll at the same institution his father attended, the Main Pedalogical Institute. Mendeleev trained to become a teacher while publishing several research papers. Even though it is believed that Mendeleev was due to his temper quite unpopular, he graduated as one of the best students of his class. He was awarded the Master’s degree in Chemistry around 1856. [1] Mendeleev won an award to pursue chemical research in Europe and spent some time at the University of Heidelberg, where he worked with Robert Bunsen. in 1860, Bunsen and Gustav Kirchhoff discovered cesium using chemical spectroscopy, which they introduced to Mendeleev as well. In the same year, Dmitri Mendeleev attended the first known international chemistry conference at Karlsruhe, which was used to discuss standadization methods in chemistry and therefore great use for Mendeleev’s future worok on the periodic table. Back in Russia, Mendeleev saw the need to improve Russian language chemistry textbooks and it has been handed down, that the scientist wrote a 500page textbook in just 60 days called ‘Organic Chemistry’. The work not only improved the education of chemistry in Russia but also increased Mendeleev’s reputation dramatically. He became the Chair of General Chemistry at the University of Saint Petersburg at the age of 33. Another major work by Mendeleev in this period, published in 1869, was The ‘Principles of Chemistry’ which was translated into English, French, and German. [1,2] Even though other scientists including John Newlands, Alexandre Béguyer de Chancourtois, and Julius Lothar Meyer made important contributions to the Periodic Table, the main credit goes to Dmitri Mendeleev. According to the Royal Society of Chemistry, there were two problems regarding the establishment of a pattern for the elements. Back then, only 60 elements were discovered and as we know today, parts of their information was wrong. At first, the scientist wrote the elements’ properties on cards and he realized that when arranging the elements in order of increasing atomic weight, certain element types occurred regularly. Mendeleev’s‘s ideas were presented to the Russian Physico-chemical Society and published in the main German chemistry periodical of the time, Zeitschrift für Chemie. From the arrangement in the table, Mendeleev noticed that sometimes the atomic weights must be wrong, because the elements appeared at the wrong places. Today, we know that it is the atomic number, not relative atomic mass that decides an element’s position in the Periodic Table. However, in most cases they result in the same order.[3] At yovisto you may learn more about ‘Dmitri Mendeleev & Lothar Meyer – The Periodic Table’.'],\n",
       " [247,\n",
       "  'Charles Lindbergh and his Spirit of St. Louis.  Charles Lindbergh.  On February 4, 1902, American aviator, author, inventor, explorer, and social activist Charles Lindbergh was born. As a 25-year-old U.S. Air Mail pilot, Lindbergh emerged suddenly from virtual obscurity to instantaneous world fame as the result of his Orteig Prize-winning solo nonstop flight from New York to Paris, France in the single-seat, single-engine purpose-built Ryan monoplane Spirit of St. Louis. Charles Lindbergh was born in Detroit to a lawyer and a chemistry teacher. It is believed that Lindbergh was fascinated by aviation from early age and his enthusiasm increased during his engineering studies at the University of Wisconsin in Madison, where he started in 1920. Lindbergh entered a Lincoln, Nebraska flying school in 1922 and first served as a mechanic, wingwalker, and parachute jumper. It is believed that his first solo flight was accomplished about one year later. Charles Lindbergh managed to graduate first in his class at the U.S. Army flying school, San Antonio and became the first air mail pilot between Chicago and St. Louis. Already in 1919, the New York hotel businessman Raymond Orteig offered $25.000 for the first non-stop flight between New York and Paris, and Lindbergh decided to challenge a group of businessmen in St. Louis to back him in an attempt to win the prize. The plane was named Spirit of St. Louis and was designed and constructed with Lindbergh’s help by Ryan Airlines of San Diego. In May 1927, Charles Lindbergh took off from New York City to France’s capital city. It is believed that he packed only a few sandwiches, water and most importantly maps and charts. Lindbergh refused to take a parachute and radio with him in order to save fuel. The Spirit of St. Louis was a single-engine monoplane and most people believed it not to be capable of crossing the  Atlantic Ocean, as most long distance pilots favored multi-engine planes. However, after 33.5 hours and 3600 miles, Charles Lindbergh set his plane down at Le Bourget Field near Paris. The pilot’s fame came almost instantly. He received the Congressional Medal of Honor, was congratulated by many countries, and made a U.S. tour in the Spirit of St. Louis to promote the commercialization of aviation after his heroic flight. He also made several trips to Latin American countries to promote aviation and met his future wife Anne Morrow, the daughter of the American ambassador. Of course, he taught his wife how to fly and she became the first known American woman to earn the glider pilot’s license. She became not only Lindbergh’s partner in life but also his co-pilot, radio operator and navigator. It is further assumed that Lindbergh was responsible for inspecting the status of aviation in European countries and he convinced the U.S. government to strengthen their air capability due to Germany’s increasing air power. However, he did not support the entry of the U.S. into the European war. After the attack on Pearl Harbor, Lindbergh served as a technical advisor as well as test pilot for United Aircraft. During his active years in aviation, Lindbergh also chaired the National Advisory Committee for Aeronautics and authored several books, which are also considered successful. The Spirit of St. Louis was probably his most successful work. The autobiographical by Charles Lindbergh focused on the events leading up to and including his 1927 solo trans-Atlantic flight in the Spirit of St. Louis. It was published in 1953, and won a Pulitzer Prize one year later. At yovisto you may learn more about Lindbergh’s Flight and Return.'],\n",
       " [248,\n",
       "  'Joseph Priestley and the Discovery of Oxygen.  Equipment used by Joseph Priestley in his experiments on gases.  On February 6, 1804, English theologian, Dissenting clergyman, natural philosopher, chemist, educator, and Liberal political theorist Joseph Priestley passed away. Being a rather prolific author with more than 150 works published, he is usually credited with the discovery of oxygen, having isolated it in its gaseous state, although Carl Wilhelm Scheele and Antoine Lavoisier also have a claim to the discovery. Joseph Priestley attended local schools and learned Greek, Latin, and Hebrew because he was intended for the ministry. Later on, Priestley also studied languages including French, Italian, and German as well as Aramic and Arabic. Also, he was introduced to mathematics, natural philosophy, logic, and metaphysics through the works of Isaac Watts, Willem’s  Gravesande, and John Locke. Priestley was educated at Daventry, a Dissenting academy and spent most of his life employed as a preacher or teacher. However, he gradually came to question the divinity of Jesus, while accepting much else of Christianity—in the process becoming an early Unitarian. [1] ‘The History of Electricity‘ was Priestley’s first known scientific work and for this achievement, he was made Fellow of the Royal Society. It is believed that he had been inspired by Benjamin Franklin, whom he met in London. Priestley began performing experiments in order to reproduce those reported in scientific works, and later on he started answering some questions on his own. Priestley became interested in the research of nature and gases. Since he was living next to a brewery, Priestley was able to obtain a great supply of carbon dioxide. In his first known publication on the topic, Joseph Priestley described how to carbonate water, in imitation of some naturally occurring bubbly mineral waters. Probably inspired by the works of Stephen Hales. Priestley started examining the ‘airs’ that may be released from different substances. He managed to isolate and characterize about eight gases including oxygen. Priestley is also credited with important contributions to the understanding of photosynthesis.[1] He proved that plants somehow change the composition of the air. In one of his famous experiments, Priestley kept a mouse in a jar of air until it collapsed and he found out that a mouse that was kept with a plant would survive. He developed the hypothesis that plants restore to the air whatever breathing animals and burning candles remove. [2, 3] One of Priestley’s most famous experiment was performed in 1774. He used a 12-inch-wide glass “burning lens” and focused sunlight on a lump of reddish mercuric oxide in an inverted glass container placed in a pool of mercury. As a result, the gas emitted and he found it “five or six times as good as common air”. After further tests, Priestley called his discovery “dephlogisticated air“. He explained that it supported combustion so well because it had no phlogiston in it, and hence could absorb the maximum amount during burning. However, the Swedish apothecary Carl Wilhelm Scheele isolated the same gas and observed a similar reaction. Scheele called his material “fire air” but he did not publish his findings until 1777. [2] At yovisto, you may enjoy a video lecture by Professor McBride called “Oxygen and the Chemical Revolution” at Yale University in 2008.'],\n",
       " [249,\n",
       "  'Alfred Adler and the Individual Psychology.  Alfred Adler (1870-1937).  .  On February 7, 1870, Austrian psychiatrist and ophthalmologist Alfred W. Adler was born. He is best known for being the founder of the school of individual psychology. Alfred Adler considered human beings as an individual whole, therefore he called his psychology “Individual Psychology“. Moreover, Adler also was the first to emphasize the importance of the social element in the re-adjustment process of the individual and who carried psychiatry into the community. Alfred Adler was born in Rudolfsheim, in the suburbs of Vienna, as third of the seven children of a Hungarian-born, Jewish grain merchant and his wife. At the age of four, Alfred developed pneumonia and heard a doctor say to his father, “Your boy is lost”. At that point, he decided to become a physician. He was very interested in the subjects of psychology, sociology as well as philosophy. After studying at University of Vienna, he recieived a medical degree in 1895. First he specialized as an eye doctor, and later in neurology and psychiatry. He established his office across from the Prater, the famous e amusement park and circus in the lower class part of Vienna. Most his clients were circus performers. He studied their unusual strengths and weaknesses, and this gave him insights on his organ inferiority theory. In 1902 Adler received an invitation from Sigmund Freud to join an informal discussion group, the “Wednesday Society” (Mittwochsgesellschaft), which met regularly on Wednesday evenings at Freud’s home and was the beginning of the psychoanalytic movement. A long-serving member of the group, in 1910 Adler became president of the Vienna Psychoanalytic Society. He remained a member of the Society until 1911, when he and a group of his supporters formally disengaged from Freud’s circle, the first of the great dissenters from orthodox psychoanalysis, preceding Carl Jung’s split in 1914. This departure suited both Freud and Adler, since they had grown to dislike each other. While Adler is often referred to as a “a pupil of Freud’s“, in fact this was never true; they were colleagues. Adler founded the Society for Individual Psychology in 1912 after his break from the psychoanalytic movement. Their enmity aside, Adler retained a lifelong admiration for Freud’s ideas on dreams and credited him with creating a scientific approach to their clinical utilization. Nevertheless, even regarding dream interpretation, Adler had his own theoretical and clinical approach. The primary differences between Adler and Freud centered on Adler’s contention that the social realm (exteriority) is as important to psychology as is the internal realm (interiority). The dynamics of power and compensation extend beyond sexuality, and gender and politics can be as important as libido. Freud also did not share Adler’s socialist beliefs. Adler enjoyed considerable success and celebrity in building an independent school of psychotherapy and a unique personality theory. He traveled and lectured for a period of 25 years promoting his socially oriented approach. His intent was to build a movement that would rival, even supplant, others in psychology by arguing for the holistic integrity of psychological well-being with that of social equality. Adler’s efforts were halted by World War I, during which he served as a doctor with the Austrian Army. From 1921 onwards, Adler was a frequent lecturer in Europe and the United States, becoming a visiting professor at Columbia University in 1927.   Adler was concerned with the overcoming of the superiority/inferiority dynamic and was one of the first psychotherapists to discard the analytic couch in favor of two chairs. This allows the clinician and patient to sit together more or less as equals. Adler argued for holism, viewing the individual holistically rather than reductively, the latter being the dominant lens for viewing human psychology. Adler was also among the first in psychology to argue in favor of feminism, and the female analyst, making the case that power dynamics between men and women are crucial to understanding human psychology. In the early 1930s, after most of Adler’s Austrian clinics had been closed due to his Jewish heritage, Adler left Austria for a professorship at the Long Island College of Medicine in the USA. In 1937, Adler went on a lecture tour and suffered a fatal heart attack in Aberdeen, Scotland.   Around the world there are various organizations promoting Adler’s orientation towards mental and social well-being. These include the International Committee of Adlerian Summer Schools and Institutes (ICASSI), the North American Society for Adlerian Psychology (NASAP) and the International Association for Individual Psychology. Teaching institutes and programs exist in Austria, Canada, England, Germany, Greece, Israel, Italy, Japan, Latvia, Switzerland, the United States, Jamaica, Peru, and Wales. Adler left behind many theories and practices that very much influenced the world of psychiatry. Today these concepts are known as Adlerian psychology. At yovisto, Dr. Paul Bloom of Yale University in his 2007 course on ‘Introduction to Psychology’ introduces the students to the theories of Sigmund Freud, including a brief biographical description and his contributions to the field of psychology. The limitations of his theories of psychoanalysis are covered in detail, as well as the ways in which his conception of the unconscious mind still operate in mainstream psychology today.'],\n",
       " [250,\n",
       "  'Erich von Drygalski’s Antarctic Expeditions.  Erich von Drygalski (1865-1949).  .  On February 9, 1865, German geographer, geophysicist and polar scientist Erich Dagobert von Drygalski was born. Drygalski discovered a volcano, free of ice, on the Antarctic continent. He named it Gaussberg, after the name of his research ship Gauss in which he led the German South Polar Expedition (1901-03). Erich von Drygalski was born in Köningsberg, East Prussia. At age 17, Drygalski began to study mathematics and natural science at the University of Königsberg, but soon went to Bonn in order to attend the lectures of Ferdinand von Richthofen, whom he followed in 1883 to Leipzig and in 1886 to Berlin. He graduated with a doctorate thesis about ice shields in Nordic areas. Between 1888 and 1891, he was an assistant at the Geodetic Institute and the Central Office of International Geodetics in Berlin. He habilitated 1889 for geography and geophysics with the collected scientific evidence. In 1898, Drygalski became associate professor and 1899 extraordinary professor for geography and geophysics in Berlin. Near the end of the nineteenth century ‘Antarctic fever’ broke out in western Europe and the summer of 1891 and in 1892–1893 Drygalsky led the preliminary and main expeditions of the Berlin Geographical Society to western Greenland. One expedition wintered during the winter between 1892 and 1893 in Western Greenland. This expedition established Drygalski’s international reputation. In 1898 the German South Polar Commission suggested a national expedition to Antarctica, which was tirelessly advocated and supported by Georg von Neumayer. As Professor of Geography and Geophysics at the University of Berlin, Drygalski was subsequently chosen to be the leader of the expedition. Financing was not an issue but the Commission felt one ship would be all that was necessary so Drygalski asked for and received permission to build a new vessel – The Gauss – rather than modify an existing ship.   The Gauss enclosed in the ice. Photo taken from a balloon, the first aerial photography in Antarctica   On August 11, 1901, the Gauss left Kiel for the south with a crew of 32 men, among them also 5 scientists including Drygalsky. Its goal was to explore the unknown area of Antarctica lying south of the Kerguelen Islands. A small party of the expedition was also stationed on the Kerguelen Islands, where they arrived in early January 1902, while the main party proceeded further south. Gauss was carrying a balloon which allowed Drygalski to become the first man to fly over the Antarctic. Drygalski also paid a brief call to Heard Island and provided the first comprehensive scientific information on the island’s geology, flora and fauna. Despite being trapped by ice at latitude 66° 5′ for nearly fourteen months until February 1903, the expedition discovered new territory in Antarctica, the Kaiser Wilhelm II Land with the Gaussberg. After returning Cape Town, South Africa, on June 9, 1903, Drygalski asked for a new expedition to the German Government, but it was denied, so the crew put heading to Germany. Emperor Wilhelm II complained that the Gauss had only reached 66° 5′, while a British expedition already proceeded up to 82° 17′. Upon arrival to Kiel on 23 November, Drygalski was found with frustration that his expedition not was sufficiently valued, although he would still feel really satisfied.[2] After his return, Drygalsky refused to take part in the “Race to the South Pole” and concentrated of his scientific publications. Although the expedition’s report appeared soon after its return (Zum Kontinent des Eisigen Südens, 1904[4]), the scientific conclusions were fully developed only after almost thirty years of indefatigable labor by Drygalski and his co-workers. Between 1905 and 1931, he published twenty volumes and two atlases documenting the expedition. In 1906 he accepted a call to the newly established chair of geography at the University of Munich, which he made highly regarded and held until his retirement in 1935.[1] He also presided the Geographic Institute, founded by him, until his death. In 1910, he also took part in Count Ferdinand von Zeppelin’s expedition to Spitsbergen and participated in other expeditions to North America and northeastern Asia. In 1933, The Royal Geographical Society awarded Drygalsky with the Patron’s medal. Erich von Drygalsky died 1949 in Munich. At yovisto, you may learn more about the Heroic Age of Antarctic Exploration by Edward Larson.'],\n",
       " [251,\n",
       "  'Leo Szilard and the Atomic Bomb.  Leó Szilárd (1898–1964)  .  On February 11, 1898, Hungarian-American physicist and inventor Leo Szilárd was born. He conceived the nuclear chain reaction in 1933, patented the idea of a nuclear reactor with Enrico Fermi, and in late 1939 together with Albert Einstein wrote the letter that resulted in the Manhattan Project that built the atomic bomb. He also conceived the electron microscope, the linear accelerator, and also the cyclotron. Szilárd was born in Budapest, Hungary, as son of Louis Spitz, a Jewish civil engineer, and Thekla Vidor [1]. Already while attending high school, Leo showed an early interest in physics and a proficiency in mathematics. In 1916, he enrolled as an engineering student at Budapest Technical University. The following year he was drafted, but before his regiment was sent to the front lines, Szilárd fell ill with Spanish Influenza and he was returned home for hospitalization. In 1919 he resumed engineering studies at Budapest Technical University but soon decided to leave Hungary due to the chaotic political situation and continued engineering studies at Technische Hochschule (Institute of Technology) in Berlin-Charlottenburg. He soon changed to physics there and took physics classes from Albert Einstein, Max Planck, and Max von Laue. With his dissertation on thermodynamics Über die thermodynamischen Schwankungserscheinungen (On The Manifestation of Thermodynamic Fluctuations), praised by Einstein, he was awarded a doctorate in physics from Humboldt University of Berlin in 1922 [4]. He was appointed as assistant to Max von Laue at the University of Berlin’s Institute for Theoretical Physics in 1924 , where he finished his habilitation in 1927 to become a Privatdozent (private lecturer) in physics. Throughout his time in Berlin he worked on numerous technical inventions. In 1928 he submitted a patent application for the linear accelerator and, in 1929, he applied for a patent for the cyclotron. Szilárd’s 1929 paper, “Über die Entropieverminderung in einem thermodynamischen System bei Eingriffen intelligenter Wesen” (On the reduction of entropy in a thermodynamic system by the intervention of intelligent beings), introduced the thought experiment now called Szilárd’s engine and became important in the history of attempts to understand Maxwell’s demon. This work also is the first equation of negative entropy and information. Szilárd went to London in 1933 where he read an article where Ernest Rutherford rejected the feasibility of using atomic energy for practical purposes. Rutherford remarked specifically on the recent 1932 work of his students, John Cockcroft and Ernest Walton, in “splitting” lithium into alpha particles, by bombardment with protons from a particle accelerator they had constructed. Although the atom had been split and energy released, nuclear fission had not yet been discovered. Szilárd was reportedly so annoyed at Rutherford’s dismissal that he conceived of the idea of nuclear chain reaction (analogous to a chemical chain reaction), using recently discovered neutrons. The idea did not use the mechanism of nuclear fission, which was not then known, but Szilárd realized that if neutrons could initiate any sort of energy-producing nuclear reaction, such as the one that had occurred in lithium, and could be produced themselves by the same reaction, energy might be obtained with little input, since the reaction would be self-sustaining. The following year he filed for a patent on the concept of the neutron-induced nuclear chain reaction. In 1938 Szilárd accepted an offer to conduct research at Columbia University in Manhattan, and moved to New York. After learning about the successful nuclear fission experiment conducted in 1939 in Germany by Otto Hahn, Fritz Strassmann and Lise Meitner, Leo Szilárd and Enrico Fermi concluded that uranium would be the element capable of sustaining a chain reaction. Szilárd and Fermi conducted a simple experiment at Columbia and discovered significant neutron multiplication in uranium, proving that the chain reaction was possible and enabling nuclear weapons. At around that time the Germans and others were in a race to produce a nuclear chain reaction. German attempts to control the chain reaction sought to do so using graphite, but these attempts proved unsuccessful. Szilárd realized graphite was indeed perfect for controlling chain reactions, and fostered by his attempts, the first human-controlled chain reaction occurred on December 2, 1942. Szilárd was directly responsible for the creation of the Manhattan Project. In August 1939, together with his old friend Albert Einstein he drafted a confidential letter to Franklin D. Roosevelt explaining the possibility of nuclear weapons, warning of Nazi work on such weapons and encouraging the development of a program which could result in their creation [5]. The Einstein–Szilárd letter resulted in the creation of the Manhattan Project. Szilárd relocated to the University of Chicago to continue work on the project. As the war continued, Szilárd became increasingly dismayed that scientists were losing control of their research to the military. His resentment towards the U.S. government was exacerbated by his failure to prevent the destructive use of the atomic bomb through having a test explosion that could be witnessed by Japanese observers who would then have the opportunity to surrender and spare lives. However, the new U.S. President Harry Truman agreed with advisers and chose to use atomic bombs against Hiroshima and Nagasaki over the protestations of Szilárd and other scientists. In 1947, Szilárd switched his field of study from physics to molecular biology. There, he gave essential advice to Theodore Puck and Philip I. Marcus for their first cloning of a human cell in 1955. In February 1950 Szilárd publicly warned of the possibility of a so-called cobalt bomb, a new kind of nuclear weapon using cobalt as a tamper, designed to produce enhanced amounts of radioactive fallout to contaminate a large area with radioactive material. Szilárd suggested that an arsenal of cobalt bombs would be capable of destroying all human life on Earth [6]. In 1961 Szilárd published a book of short stories, The Voice of the Dolphins, in which he dealt with the moral and ethical issues raised by the Cold War and his own role in the development of atomic weapons. In 1960, Szilárd was diagnosed with bladder cancer. He spent his last years as a fellow of the Salk Institute in San Diego until his death in May 1964. At yovisto, you may enjoy a short video lecture by Tyler DeWitt on the ‘Atomic Structure: Discovery of the Neutron‘   Acknowledgment: We would like to express our heartly thanks to Gene Dannen, who spent decades dedicated to the research of Leo Szilárd’s life. With his support we were able to correct previous errors in this article and provided us with helpful bibliographic references.'],\n",
       " [252,\n",
       "  'Lejeune Dirichlet and the Mathematical Function.  Peter Gustav Lejeune Dirichlet (1805-1859). On February 13, 1805, German mathematician Johann Peter Gustav Lejeune Dirichlet was born. Dirichlet is best known for his papers on conditions for the convergence of trigonometric series and the use of the series to represent arbitrary functions. He also proposed in 1837 the modern definition of a mathematical function.   Gustav Lejeune Dirichlet was born in Düren, halfway between Aachen and Cologne in Germany, a town on the left bank of the Rhine which at the time was part of Napoleon Bonaparte’s French Empire. His father Johann Arnold Lejeune Dirichlet was the postmaster, merchant, and city councilor, whose family came from Richelet, a small town in Belgium. This explains the origin of his name which comes from “Le jeune de Richelet” meaning “Young from Richelet”. The youngest of seven children, his parents enrolled him in an elementary school and then private school to become a merchant. But, young Dirichlet showed a strong interest in mathematics and convinced his parents to allow him to continue his studies. In 1817 he was sent to the Gymnasium in Bonn and in 1820, Dirichlet moved to the Jesuit Gymnasium in Cologne, where his lessons with Georg Simon Ohm widened his knowledge in mathematics. By the age of 16 Dirichlet had completed his school qualifications and was ready to enter university. However, the standards in German universities were not high at this time so Dirichlet decided to study in Paris.[1] In 1822, Dirichlet contracted smallpox, but it did not keep him away from his lectures in the Collège de France for long. In 1823 he was recommended to General Foy, who hired him as a private tutor to teach his children German, the wage finally allowing Dirichlet to become independent from his parents’ financial support. Dirichlet’s first original research brought him immediate fame, since it was on Fermat’s Last Theorem. The theorem claimed that for n > 2 there are no non-zero integers x, y, z such that xn + yn = zn. The cases n = 3 and n = 4 had been proven by Leonard Euler and Fermat, and Dirichlet attacked the theorem for n = 5. Adrien-Marie Legendre, one of the referees, soon completed the proof for this case, while Dirichlet completed his own proof a short time after Legendre, and a few years later produced a full proof for the case n=14. In 1825, encouraged by Alexander von Humboldt, Dirichlet decided to return to Germany. In order to teach in a German university Dirichlet would have needed an habilitation. Although Dirichlet could easily submit an habilitation thesis, this was not allowed since he did not hold a doctorate, nor could he speak Latin, as it was required by that time. The problem was nicely solved by the University of Cologne giving Dirichlet an honorary doctorate, thus allowing him to submit his habilitation thesis to the University of Breslau [1]. With Alexander von Humboldt’s help Dirichlet then moved to Berlin in 1828, where he was appointed at the Military College and would be able to teach at the University of Berlin. Soon after this he was appointed a professor at the University of Berlin where he remained from 1828 to 1855. In 1829, during a trip, he met Carl Gustav Jacob Jacobi, at the time professor of mathematics at Königsberg University. Over the years they kept meeting and corresponding on research matters, in time becoming close friends. Dirichlet was appointed to the Berlin Academy in 1831 and an improving salary from the university put him in a position to marry, and he married Rebecca Mendelssohn, one of the composer Felix Mendelssohn’s two sisters. In 1837 Dirichlet proposed the modern concept of a function y = f (x) in which for every x, there is associated with it a unique y. This work was inspired by significant contributions he had made to the understanding on Fourier Series, particularly with respect to conditions of convergence.[4] In mechanics he investigated the equilibrium of systems and potential theory, which led him to the Dirichlet problem concerning harmonic functions with prescribed boundary values.[3] Dirichlet had a high teaching load at the University of Berlin, being also required to teach in the Military College and in 1853 he complained in a letter to his pupil Leopold Kronecker that he had thirteen lectures a week to give in addition to many other duties. It was therefore something of a relief when, on Carl Friedrich Gauss’s death in 1855, he was offered his chair at Göttingen.[1] Ernst Eduard Kummer was called to assume his position as a professor of mathematics in Berlin. The quieter life in Göttingen seemed to suit Dirichlet. He had more time for research and some outstanding research students. However, sadly he was not to enjoy the new life for long. Dirichlet died on 5 May 1859, in Göttingen. At yovisto, you can learn more about number theoryin a lecture on Gauss’ Law.'],\n",
       " [253,\n",
       "  'Fritz Zwicky and the Dark Matter.  Fritz Zwicky (1898 – 1974)On February 14, 1898, Swiss astronomer Fritz Zwicky was born. He is best known for his proposal of he existence of dark matter and counts as one of the most important astronomers of the 20th century. Fritz Zwicky attended a grammar school in Zurich, Switzerland and enrolled at the ETH Zurich in order to study physics and mathematics afterwards. Zwicky became a research assistant around 1922 and worked at the California Institute of Technology in Pasadena starting from 1925. He received a scholarship by the Rockefeller Foundation. In California, he worked as a theoretical physicist and later astrophysicist at the observatories of Mt.Wilson and Palomar. [1] He gained attention around 1933 when he coined the term ‘supernova‘ and theorized that they were most likely the transition of normal stars into neutron stars. In order to prove his hypthesis, Fritz Zwicky began hunting for supernovae. By the later 1930s, he is believed to have discovered more than a dozen of them. In his whole life, it is assumed that Zwicky discovered more than 120 supernovae. During World War II, Fritz Zwicky began to get active in Pasadena in rocket engineering. Also, he was known to establish a program for academic libraries that suffered from the war. In the later 1940s, Zwicky became the scientific director of the company Aerojet and worked on the improvement of engines, which resulted in several patents. [1] Fritz Zwicky is by many remembered as the father of Dark Matter  even though this has been a topic of discussion. Zwicky first recognized that in rich clusters of galaxies, a large portion of the matter is not visible. In 1933, he published a scientific work, estimating that “the total mass of the COMA cluster of galaxies from the motions of the galaxies within that cluster. Using the virial theorem he came to the conclusion that the galaxies were on average moving too fast for the COMA cluster to be held together only by the mass of the visible matter”: “In order to receive an average Doppler effect of 1000 km/s or more, which is what we have observed, the average density in the COMA system would have to be at least 400 times greater than that of visible matter. If this can be shown to be the case, then it would have the surprising result that dark matter is present in the Universe in far greater density than visible matter.” It has been argued that Fritz Zwicky’s analysis was deduced from limited statistics, but still, his estimation results were considered reasonable. The same calculation done today shows a smaller factor than the one Zwicky proposed back in the 1930s, based on greater values for the mass of luminous material. However, it is still clear that the great majority of matter appears to be dark. [2] During his lifetime, Fritz Zwicky was known to be a great speaker and was invited for talks numerous times. He also published a trmendous amount of scientific works. More than 500 publications were made by Zwicky including his ‘Morphological Astronomy’ from 1957 and he was honored for his contributions to astronomy around the globe. In 1972, Fritz Zwicky received the gold medal by the Royal Astronomical Society in London.[1,2] At yovisto you may learn more about ‘The Fifth Element: Astronomical Evidence for Black Holes, Dark Matter, and Dark Energy‘ in a lecture by Professor Scott Tremaine.'],\n",
       " [254,\n",
       "  'Henry Steinway and the Grand Pianos.  Heinrich Engelhard Steinweg (1797-1871). On February 15, 1797, German-born American inventor and entrepreneur Henry Engelhard Steinway was born. He invented the overstrung iron-frame grand piano (1859) and is founder of the piano company Steinway & Sons. Steinway was born Heinrich Engelhard Steinweg in Wolfshagen im Harz, Duchy of Brunswick in the Holy Roman Empire of the German Nation (modern Germany). His childhood was marked by many tragedies and twists of fate. He attended the common schools of his home town. Several brothers were killed during the Napoleonic War and Steinway lost his father and remaining brother at age 15. As an orphan he was now thrown upon his own resources. In 1814 he joined the Schwarze Schar, the volunteer corps of Frederick William, Duke of Brunswick-Wolfenbüttel in the war against Napoleon’s occupation of parts of Germany but remained in the garrison throughout the Napoleonic War campaign of the Hundred Days in 1815. He left service on 23 June 1822 and began to work as a carpenter, and later he became an apprentice to an organ builder in the town of Goslar. Although he had no musical training, he displayed a talent in building musical instruments. The first instrument he built was a zither.[1] He soon discovered his love for music and learned how to play the organ, and became a church organist. He started building instruments, though hidden in the kitchen of his house because of the strong rules of the guild. In Braunschweig, he started by building guitars and zithers, and then graduated to pianos, of small proportions initially and gradually increasing in size. Then, in 1835 he made the first square piano, which he presented to his bride Juliane as a wedding gift. They later had seven children. In 1836 he built his first grand piano in his kitchen in the town of Seesen. This piano was later named the “kitchen piano“. Because of the unstable political climate following the revolutions of 1848 in the German states, Steinweg decided to leave his hometown Braunschweig to emigrate to New York City in 1850 with five of his sons. There, he anglicized his name to Henry E. Steinway upon advice from friends, who concluded that the German surname Steinweg would be disadvantageous for doing business. Steinway and his sons worked for other piano companies until they could establish their own production under the name of Steinway & Sons in 1853. The first factory was located at 81 Walker Street, in Manhattan. A new factory was founded in 1859 at Park Avenue and 53rd Street, the present site of the Seagrams Building, where it covered a whole block. All the children, with the exception of Christian Friedrich Theodor, who had remained in Germany, worked in the business.[1] The overstrung scale in a square piano earned the Steinway Piano first prize at the New York Industrial Fair of 1855. According to Franz Liszt, Anton Rubinstein, and other high authorities, the Steinways have done more to advance the durability, action, and tone-quality of their instruments than any other makers of Europe or America. Important among Steinway’s innovations were the overstrung scale, a design in which the bass strings cross over the higher ones, permitting longer bass strings and improved tone. Moreover, Steinway used an improved cast-iron frame that bore the tension of the strings without twisting as wooden frames tend to do.[2] The Steinways’ further improvements in piano design included methods for improving the action, or key mechanism; redesigning the iron frame and case to allow increased string tension; and strengthening the soundboard. In 1866 Steinway & Sons opened the first Steinway Hall on 14th Street in Manhattan. With a main auditorium of 2,000 seats, it became New York City’s artistic and cultural center, housing the New York Philharmonic until Carnegie Hall opened in 1891. At yovisto, you can learn more about the history of the piano in the lecture of Prof. Craig Wright from Yale University. This lecture addresses the history of the modern piano and its music.'],\n",
       " [255,\n",
       "  'Georg Joachim Rheticus’ Achievements for Astronomy.  Frontpage of Rheticus’s book Canon Doctrinae Triangulorum (1551).  On February 16, 1514, mathematician, cartographer, navigational-instrument maker, medical practitioner, and teacher Georg Joachim Rheticus was born. He is perhaps best known for his trigonometric tables and as Nicolaus Copernicus’s sole pupil, who facilitated the publication of his master’s famous work De revolutionibus orbium coelestium (On the Revolutions of the Heavenly Spheres). Georg Joachim Rheticus was the son of a doctor and government official. He was taught by his father in his early life, but when the young Rheticus was only 14 years old, his father was charged for sorcery and was behaeded. The boy was then highly supported by Achilles Gasser, who took over his father’s medical practice. He helped Rheticus to begin his studies at the Latin school in Feldkirch, continuing his education in Zurich. Georg Joachim Rheticus entered the University of Wittenberg aroung 1533 and received his M.A. three years later. [1] Rheticus was then appointed teacher of mathematics and astronomy at the University of Wittenberg after he received his degree. He was back then supported by Philipp Melanchthon, who also helped Rheticus to study with the leading astronomers at the time. In 1538, Rheticus traveled to Nuremberg where he met Johann Schöner and the printer Petreius. In Ingolstadt, Rheticus visited Peter Apianus and went on to Tübingen in order to meet Joachim Camerarius. In the Spring of 1539, Rheticus arrived at Frauenburg in Ermland where he studied for two years with Copernicus. And experience he remembered as following: I heard of the fame of Master Nicolaus Copernicus in the northern lands, and although the University of Wittenberg had made me a Public Professor in those arts, nonetheless, I did not think that I should be content until I had learned something more through the instruction of that man. And I also say that I regret neither the financial expenses nor the long journey nor the remaining hardships. Yet, it seems to me that there came a great reward for these troubles, namely. that I, a rather daring young man compelled this venerable man to share his ideas sooner in this discipline with the whole world. [2] In 1539, the Narratio Prima was published. It is believed that to this day, the work remains the best introduction to Copernicus’s work. Rheticus managed to put himself in favor with the Duke Albert of Prussia and asked successfully for the permission to publish Copernicus’s De Revolutionibus. In 1541, Rheticus returned to the University of Wittenberg, where he was elected dean of the Faculty of Arts. In the same year, he published the trigonometrical sections of Copernicus’s De Revolutionibus, adding tables of sines and cosines, hoewever, not naming them this way. [1,2] One year later, Rheticus left Wittenberg for Nuremberg, where he supervised the printing of De Revolutionibus, but continued his journey to Leipzig before the work was finished. He began his teaching position in Leipzig as the professor of higher mathematics. Rheticus managed to publish a calendar and ephemeris of 1550 and also an ephemeris and calendar of 1551. In 1551 however, the scientist was forced to leave Leipzig because he was suspected of having a homosexual affair with a student. Now even Melanchton turned away from Rheticus and he was sentenced to 101 years in exile. Rheticus then managed to study medicine in Prague and moved to Kraków where he became a practicing doctor, but he continued with his famous trigonometric tables and made instruments which he used for observations and experiments. His following important work Opus Palatinum de triangulis used all six trigonometric functions. [2,3] At yovisto, you can learn more about the scientific, social and religious impact of the Copernican Revolution with the lecture ‘Mathematics, Motion, and Truth: The Earth goes round the Sun‘ by Jeremy Gray of Gresham University.'],\n",
       " [256,\n",
       "  'Frederick Eugene Ives and the Halftone Printing Process.  Frederic Eugene Ives (1856–1937)  .  On February 17, 1856, American photographer and inventor Frederic Eugene Ives was born. He is probably best known for his invention of the halftone process, a method of reproducing photographs on a printing press. In 1881, he was the first to make a three-colour print from halftone blocks. Further inventions in photography and color printing yielded 70 patents. Born near Litchfield, Connecticut, Ives after receiving a public school education apprenticed as a young man at the Litchfield Enquirer newspaper, where he became interested in photography and soon after opened a photographic studio in Ithaca, New York. Already at age 18, Ives became the head of the Cornell University photographic laboratory in 1875. There, Ives began to study and experiment in the field of photographic reproduction. Newspapers and other print media at the time had not yet been able to harness the potential of photography. The reason for this was in the printing process itself. Printing involved pressing an engraved plate coated with ink onto paper. The challenge now was to find a way to translate finely-shaded pictures such as photographs onto plates. Turning his attentions exclusively to photographic experimentation in 1878, Ives studied the process of photoengraving, through which designs are projected onto plates treated with light-sensitive substances, to create engravings. At Cornell, he developed the swelled gelatin process, which refined the sensitivity of the photoengraving process using a gelatin-based coating. However, the new process still could only reproduce black lines on white. To translate the gradations of shading in photographs, Ives hit upon the idea of breaking down photographs into dots of various sizes to convey shades, or so-called “halftones,” which gave the name to the process that should revolutionize printed illustrations.[2] Prior to such processes, images were printed in books and periodicals by means of hand-engraved metal plates or wood blocks, or from drawings made on lithographic stones. Half-tone effects were obtained by engraving closely spaced parallel or hatched lines, by stippling, or by exploiting the granular texture inherent in the stone lithography process. Ives was not the first to experiment with halftone processes in printing. But, his objective was more or less to automatically convert the intermediate tones of a photographic image into small lines or dots of stark black and white. As well, is process should perform better, or at least more efficiently, than was possible with existing processes. Furthermore, it was his goal to create a printing block that could be combined with blocks of text in an ordinary printing press. The lines or dots, of varying widths or sizes respectively, had to be small enough to adequately blend together in the eye at a normal viewing distance, producing the illusion of various shades of gray, yet the printing plates had to be durable enough to last through a typical press run without excessive degradation. Above all, the process had to be economical enough to make its widespread commercial use practical. Ives patented his first “Ives’ process” in 1881, which required the creation of a photographic relief image, made by a variety of the carbon process, from which a plaster cast was made. The highest areas on the surface of the plaster corresponded with the darkest areas of the original photograph. The cast was pressed into contact with an inked rubber grid consisting of an array of tiny pyramidal elements, which caused a regular array of ink dots to be deposited on the plaster, their sizes varying according to the heights of the surface. The dot pattern was then photographed onto a metal plate coated with photoresist, which was developed and chemically etched, a process known as photoengraving and already in use for making printing plates from line drawings, handwriting and other purely black and white subject matter. Although complex, this process was simpler and more efficient than other processes, and put in commercial operation in 1884. A few years later, Ives replaced this process with the much simpler one, where an ordinary photograph was rephotographed directly onto the sensitized metal plate. During the 1890s, this “Ives process” largely replaced the use of hand-engraved wood block and steel plate illustrations and remained the standard process for photographically illustrating books, magazines and newspapers during the next eight decades.   An Ives Kromogram issued in 1897   But, Ives also was a pioneer in the field of color photography. He first demonstrated a system of natural color photography in 1885. His fully developed Kromskop color photography system was commercially available already by late 1897. Three separate black-and-white photographs of the subject were taken through carefully adjusted red, green and blue filters. Then, transparent positives of the three images were viewed in Ives’ Kromskop with red, green and blue filters and transparent reflectors to visually combine them into one full-color image. The quality of the color was highly praised but the system was not a commercial success. It was discontinued shortly after the 1907 introduction of the Autochrome process, which was simple to use and required no special equipment. In 1903 Ives patented the parallax stereogram, the first “no glasses” autostereoscopic 3-D display technology. The device was able to present the illusion of a three-dimensional image. However, to achieve this effect, the image had to be viewed from a specific vantage point or the image’s 3-D qualities would be lost. Ives received several medals and recognitions for his photographic inventions, which included the prestigious Progress Medal of London’s Royal Photographic Society for his contributions to color photography.[3] Frederic Ives died in Philadelphia on May 27, 1937.   At yovisto you can learn more about the history of photography in the presentation of Nancy Crandall about the origins and beginnings of photography.'],\n",
       " [257,\n",
       "  'Octave Chanute – One of the Fathers of Aviation.  Octave A. Chanute (1832-1910).  .  On February 18, 1832, French-born American railway engineer and aviation pioneer Octave Chanute was born. He provided many budding enthusiasts, including the Wright brothers with help and advice, and helped to publicize their flying experiments. At his death he was hailed as the father of aviation and the heavier-than-air flying machine. Immigrating to the United States with his father in 1838, Chanute attended private schools in New York City. His first job was as a member of a surveying crew with the Hudson River Railroad. He then worked his way up through a series of increasingly responsible engineering positions on western railroads. In addition, he served as chief engineer on a variety of important projects, notably the construction of the first bridge across the Missouri River.[1] Chanute was widely considered brilliant and innovative in the engineering profession. During his career he designed and constructed the United States‘\\u200b two biggest stock yards, Chicago Stock Yards (1865) and Kansas City Stockyards (1871). He designed and built the Hannibal Bridge which was the first bridge to cross the Missouri River in Kansas City, Missouri, in 1869 and established Kansas City as the dominant city in the region. He designed many other bridges during his railroad career. Chanute also established a procedure for pressure-treating wooden railroad ties with an antiseptic that increased the wood’s lifespan in the tracks. In 1883, Chanute retired from the Erie Railway to become an independent engineering consultant. Already in 1875, he had visited Europe and learned of the extensive efforts being made there, particularly by F.H. Wenham in England, to develop mechanical flight. Not until he retired from his engineering business in 1889 did Chanute have opportunity for personal study and experiment in aeronautics. With the same analytical persistence that had made him a successful engineer he undertook to learn what had gone before. Chanute collected all available data from flight experimenters around the world and combined it with the knowledge gathered as a civil engineer in the past. He published his findings in the influential book Progress in Flying Machines in 1894. This was the most systematic global survey of fixed-wing heavier-than-air aviation research published up to that time.[2]   A twelve-winged glider of Chanute’s design, prepared for launch from the dunes of Miller Beach in 1896.   Chanute was too old to fly himself, so he partnered with younger experimenters, including Augustus M. Herring and William Avery. In 1896 Chanute, Herring, and Avery tested a design based on the work of German aviation pioneer Otto Lilienthal, as well as hang gliders of their own design in the dunes along the shore of Lake Michigan near the town of Miller Beach, Indiana, just east of what became the city of Gary. Chanute also sponsored the work of others, including the Albatross by Bustov and a paper tube glider that was ruined by a rainstorm before it could be tested. These experiments convinced Chanute that the best way to achieve extra lift without a prohibitive increase in weight was to stack several wings one above the other, an idea proposed by the British engineer Francis Wenham in 1866 and realized in flight by Otto Lilienthal in the 1890s. Chanute introduced the “strut-wire” braced wing structure that would be used in powered biplanes of the future, not seriously challenged until the pioneering efforts of Hugo Junkers to develop all-metal cantilever airframe technology without external bracing from 1915 onwards. The Wright brothers based their glider designs on the Chanute “double-decker,” as they called it. A new design of a biplane glider was developed and flown in 1897. Chanute corresponded with many aviation pioneers, including Otto Lilienthal, Gabriel Voisin, Louis Blériot, and Alberto Santos Dumont. Chanute freely shared his knowledge about aviation with anyone who was interested and expected others to do the same, although he did encourage colleagues to patent their inventions. His open approach led to friction with the Wright brothers, with whom he had exchanged more than 100 letters between 1900 and 1910. Nevertheess, Chanute helped to publicize the Wright brothers’\\u200b work, and provided consistent encouragement. He also witnessed many of the early Wright flights, including the 1902 glider and 1904 and 1905 powered flyer. Chanute died on November 23, 1910, in Chicago, Illinois.   At yovisto you can learn more about the future of aviation and space flight in the presentation from Marc Millis on ‘Space Flight Predictions: After AI & Transhumanism‘'],\n",
       " [258,\n",
       "  'Robert E. Peary’s Arctic Expedition.  Robert Edwin Peary (1856-1920). On February 20, 1920, American polar explorer Robert Edwin Peary passed away. Peary made the first successful expedition to the North Pole arriving 6 Apr 1909 with his assistant Matthew Henson and four Inuit eskimo companions. Peary’s claim was widely credited for most of the 20th century, rather than the competing claim by Frederick Cook, who said he got there a year earlier. Both claims were widely debated in newspapers until 1913. Robert Edwin Peary was born in Cresson, Pennsylvania on May 6, 1856, to Charles N. and Mary P. Peary. Peary attended Bowdoin College, north of Portland, Maine, where his mother has moved after the death of Peary’s father in 1859. Peary graduated in 1877 with a civil engineering degree and then worked as a draftsman making technical drawings in Washington, DC, at the US Coast and Geodetic Survey office. He joined the United States Navy in 1881 as a civil engineer with the relative rank of lieutenant. Three years later, he began his career in exploration as chief assistant on a surveying expedition to Nicaragua. Although he was initially assigned to duty in the tropics, he resolved to become the first man to reach the North Pole.   In April 1886 he wrote a paper for the National Academy of Sciences proposing two methods for crossing Greenland’s ice cap. Between 1886 and 1897, Robert Peary led five expeditions to Greenland and Arctic Canada. In his 1891 expedition, Peary returned to Greenland with seven companions, including Frederick A. Cook, who in 1909 would claim to have reached the North Pole before Peary. On this expedition Peary sledged 2,100km to northeastern Greenland, discovered Independence Fjord, and found evidence of Greenland’s being an island. He also studied the “Arctic Highlanders,” an isolated Eskimo tribe who helped him greatly on later expeditions.[2] Peary was promoted to the rank of lieutenant commander on January 5, 1901, and to commander on April 6, 1902. Between 1898 and 1902 Peary explore routes to the pole from Etah, in Inglefield Land, northwestern Greenland, and from Fort Conger, Ellesmere Island, in the Canadian Northwest Territories. He departed New York Harbor for the Arctic in July 1898. By August, his ship was icebound after crossing Smith Sound, nearly 1,100km from the pole. While establishing and supplying a base on the edge of the Polar Sea, Peary had both feet badly frozen and suffered the amputation of eight toes. He stayed in the Arctic until the fall of 1902 carrying out an extensive exploration of the region and in the spring of 1902 made the nearest approach yet to the pole in the American Arctic, 84°17′ north.[3] In September 1903, supported by president Theodore Roosevelt, Peary was given three years leave to pursue another attempt on the pole. A problem in the previous attempt was the lack of a ship capable of forcing a passage through the ice to a high enough latitude for a cross-polar dash. Peary’s Arctic Club raised $100,000 for the expedition and built such a ship, the Roosevelt. This time the explorers would use Eskimo methods and clothing, and travel in individual dog sledges. In July 1905 the Roosevelt sailed north from New York and reached the north coast of Grant Land by September. Peary struck out for the pole from Cape Hecla in March 1906. However, after two weeks of travel across broken ice fields, and open leads, the conditions of his dogs and his declining food supply forced him and his associates to turn back. Nevertheless, he reached latitude 87° 6’ north, 280km from the pole and the farthest north anyone had ever reached.[3]   Admiral Peary’s diary entry for arrival at the North Pole   For his final expedition to reach the Pole, Peary and 23 men set off from New York City on July 6, 1908 aboard the Roosevelt. They wintered near Cape Sheridan on Ellesmere Island, and from Ellesmere departed for the pole on February 28 – March 1, 1909. The last support party was turned back from “Bartlett Camp” on April 1, 1909, in latitude no greater than 87°45′ north. On the final stage of the journey toward the North Pole, Peary continued with five assistants, none capable of making navigation observations. On April 6, 1909, he established “Camp Jesup” allegedly within 8 km of the pole. Peary returned to civilization only to discover that his former colleague, Cook, who had been a surgeon on the 1891–1892 Peary expedition, was claiming to have reached the North Pole independently in April 1908. Cook’s claim, though subsequently discredited, marred Peary’s enjoyment of his triumph. In 1911 Peary retired from the navy with the rank of rear admiral. Peary’s claim to have reached the North Pole was almost universally accepted, but in the 1980s the examination of his 1908–09 expedition diary and other newly released documents cast doubt on whether he had actually reached the pole.[3]   At yovisto, you can watch a movie by Admiral Peary’s adversary Dr. Frederick Cook in 1912, produced to substantiate his claim as discoverer of the North Pole.'],\n",
       " [259,\n",
       "  'John Mercer and the Cotton Mercerisation.  John Mercer (1791 – 1866).  On February 21, 1791, English dye and fabric chemist John Mercer was born. He invented the mercerisation process for treating cotton which is still in use today and was a pioneer in colour photography. John Mercer grew up in Lancashire, England. He entered the textile industry as a bobbin-winder when he was still a boy. The art of dyeing came to Mercer’s interest approximately at the age of 16. He set up a dye laboratory at his home and experimented with mixing colors and soon began a partnership with an investor. They opened a small dyeing shop, which was considered quite successful. [1,2] After several years of experience as a simple weaver, Mercer returned to the profession of a dyer and increased his enthusiasm in chemistry. Mercer managed to produce a new orange dye, which was found good for calico-printing. In the late 1810s, Mercer was employed by the Fort brothers, a textile printing company. Mercer was employed as a color chemist and after making progress with further colors including indigo, yellow, and orange, the chemist was made the company’s partner in 1825. [1] Despite the profitable partnership with the Fort brothers, Mercer had no more chance to develop new chemicals for textile processing in his laboratory. He dissolved the partnership in 1848 and devoted all of his time and resources to pursue his own research. It is believed that Mercer had wondered about the effect upon cotton fabric of sodas, acids, and chlorides. He came to realize that the material became thicker and shorter when treated with these chemicals. These early experiments turned out to be Mercer’s most important. The process made the cotton stronger and more easily dyed. John Mercer called this process mercerization. It was patented in 1850. It became clear that mercerization could be easily applied to many other materials. To this day, mercerization is an important part of the cotton finishing process. John Mercer was made a Fellow of the Royal Society in 1850 and he was acknowledged the ‘father of textile chemistry’. [1,2] Mercer was also interested in photography and especially photochemistry. He managed to develop processes for photographic printing on fabric . [2] At yovisto you may learn more about the Industrial Revolution in a lecture by John Merriman at Yale University.'],\n",
       " [260,\n",
       "  'Frank P. Ramsey and the Ramsey Theory.  Frank P. Ramsey (1903-1930). On February 22, 1903, precocious British philosopher, mathematician and economist Frank Plumpton Ramsey was born. Although he died already at age 26, he had made significant contributions to logic, philosophy of mathematics, philosophy of language and decision theory. He remains noted for his Ramsey Theory, a mathematical study of combinatorial objects in which a certain degree of order must occur as the scale of the object becomes large. Frank P. Ramsey was born as the eldest of four siblings in Cambridge where his father Arthur Stanley Ramsey, also a mathematician, was President of Magdalene College. His brother Michael Ramsey later should become Archbishop of Canterbury. Ramsey entered Winchester College in 1915 and later returned to Cambridge to study mathematics at Trinity College. At Trinity College, Ramsey became a student to John Maynard Keynes. He became a senior scholar in 1921 and graduated as a Wrangler in the Mathematical Tripos of 1923. Then, Ramsey went to Vienna for a short while, returning to Cambridge where he was elected a fellow of King’s College Cambridge in 1924, which was rather unsusual, because in fact Ramsey was only the second person ever to be elected to a fellowship at King’s College, not having previously studied at King’s.[1] In 1926 he was appointed as a university lecturer in mathematics and he later became a Director of Studies in Mathematics at King’s College. It was a short career, for sadly Ramsey died at the beginning of 1930. Suffering from chronic liver problems, Ramsey developed jaundice after an abdominal operation and died on 19 January 1930 at Guy’s Hospital in London at the age of 26. However, in the short time during which he lectured at Cambridge he had already established himself as an outstanding lecturer. He published his first major work The Foundations of Mathematics in 1925, in which he accepted the claim by Russell and Whitehead made in the Principia Mathematica that mathematics is a part of logic. Already at the age of 19, Ramsey was able to make the first draft of the translation of the German text of Ludwig Wittgenstein’s Tractatus Logico Philosophicus, Wittgenstein’s seminal work that aimed to identify the relationship between language and reality and to define the limits of science. Ramsey was very impressed by Wittgenstein’s work and after graduating in 1923 he made a journey to Austria to visit Wittgenstein. For two weeks Ramsey discussed the difficulties he was facing in understanding the Tractatus. Wittgenstein made some corrections to the English translation in Ramsey’s copy and some annotations and changes to the German text that subsequently appeared in the second edition in 1933. In his second paper on mathematics On a problem of formal logic, which was published in the Proceedings of the London Mathematical Society in 1930, he examined methods for determining the consistency of a logical formula and included some theorems on combinatorics which have led to the study of a whole new area of mathematics called Ramsey theory. The combinatorics was introduced by Ramsey to solve a special case of the decision problem for the first-order predicate calculus. Ramsey theory studies the conditions under which order must appear. Problems in Ramsey theory typically ask a question of the form: “how many elements of some structure must there be to guarantee that a particular property will hold?” Ramsey made a systematic attempt to base the mathematical theory of probability on the notion of partial belief. This work on probability, and also important work on economics, came about mainly because Ramsey was a close friend of John Meynard Keynes. Being a friend of Keynes did not stop Ramsey attacking Keynes’ work, however, and in Truth and probability (1926) he argues against Keynes’ ideas of an a priori inductive logic. Ramsey’s arguments convinced Keynes who then abandoned his own ideas. In economics, Ramsey wrote two papers A contribution to the theory of taxation and A mathematical theory of saving. These would lead to important new areas in the subject. In A mathematical theory of saving, published in The Economic Journal in late 1928, Ramsey aimed to determine the optimal amount an economy should invest (save) rather than consume so as to maximize future utility, or in Ramsey’s words “how much of its income should a nation save?” Keynes described the article as “one of the most remarkable contributions to mathematical economics ever made. The Ramsey model is today acknowledged as the starting point for optimal accumulation theory although its importance was not recognized until many years after its first publication. At yovisto, you can learn more about the work of Frank P. Ramsey in the lecture “A Dictator Theorem of Belief Revision Derived from Arrow’s Theorem” at LMU Munich, where Hannes Leitgeb discusses the Ramsey test for conditionals.'],\n",
       " [261,\n",
       "  'Andrea Cesalpino and the Classification of Plants.  Andrea Cesalpino.  On February 23, 1603, Italian physician, philosopher and botanist Andrea Cesalpino passed away. He classified plants according to their fruits and seeds, rather than alphabetically or by medicinal properties. He helped establish botany as an independent science and also made contributions to medical science and physiology. Andrea Cesalpino was probably born on June 5, 1525. However, some sources suggest also 1519 as his actual year of birth. It is believed that his father was a simple mason, but also here, some doubt that because he was able to send his son to the university. Cesalpino studied philosophy and medicine at Pisa, where he received his doctorate in 1551. He studied under Vesalius and Guido Guidi, and Luca Ghini. Starting from 1592, he was called to Rome as a physician to Pope Clement VIII while simultaneously working as a professor at Sapienza. [1,2] Cesalpino’s research of the anatomy and physiology of the movement of the blood presumably count as his most important medical studies. He published several works on practical medicine including diseases of the heart and chest, as well as syphilis. Even though Cesalpino did not discover the major blood circulation, he found out that the heart is the center of the circulation of the blood. [1] His most important contributions to science lies in the field of botany. De plantis libri XVI, published in 1583 is widely considered his most important work. In it, Andrea Cesalpino presented his principles of botany. He published a total of 16 books of which the first consisted of 14 chapters. Cesalpino covered the nutrition of plants, structures of the flower, fruit, and seed. The botanist used his knowledge of Aristotle’s thoughts on biological classification and Theophrastus’s criteria for plant classification. The 15 following books describe around 1500 plants, arranged according to Cesalpino’s system. His herbarium which he gave to his patron Bishop Tornabuoni is believed to be one of the oldest herbarium in existence and arranged according to his principles. It is now in the the Museum of Natural History in Florence. [3] Unfortunately for Andrea Cesalpino, his major work did not receive the attention it deserved. It is said that even for contemporaries, the work was hard to read with its dense prose which relied heavily on Aristotelian principles relating to the soul of plants but left much only implied and not fully stated. Also, there were no illustrations or tables to explain Cesalpino’s system. [3] During his career, Andrea Cesalpino lectured in philosophy, medicine and botany. He became Director of the Pisa Botanic garden in 1554, succeeding Ghini who had set it up in 1547, one year after the first Botanic Garden in Padua. De Plantis Libris XVI was dedicated to the Grand Duke Francisco I de Medici, the fruit of nearly forty years of teaching and practical experience combining philosophy, medicine and botany. [3] At yovisto, you can learn more about botany in the video lecture on ‘Human Livelihoods Depend on Wild Flowers: Kew’s Millennium Seed Bank explained‘.'],\n",
       " [262,\n",
       "  'Nikolai Lobachevsky – The Copernicus of Geometry.  Nikolai Ivanovich Lobachevsky (1792-1856). On February 24, 1856, Russian mathematician and geometer Nikolai Ivanovich Lobachevsky passed away. He is known primarily for his work on hyperbolic geometry. Lobachevsky’s main achievement is the development (independently from János Bolyai) of a non-Euclidean geometry, also referred to as Lobachevskian geometry. Nikolai Lobachevsky was born as one of three children either in or near the city of Nizhny Novgorod in Russia in 1792 to parents of Polish origin. His father Ivan Maksimovich Lobachevsky, a clerk in a land surveying office, died when he was seven, and his mother moved to Kazan. Financed by government scholarships, Lobachevsky attended Kazan Gymnasium from 1802, graduating in 1807 and then received a scholarship to Kazan University, which was founded just three years earlier in 1804. His original intention was to study medicine but he changed to study a broad scientific course involving mathematics and physics.[1] At Kazan University, Lobachevsky was influenced by professor Johann Christian Martin Bartels, a former school teacher and friend of German mathematician Carl Friedrich Gauss. Bartels was noted for his encyclopedic knowledge of mathematics and soon interested Lobachevsky in mathematics. Lobachevsky received a Master’s degree in physics and mathematics in 1811. In 1814, he became a lecturer at Kazan University, in 1816 he was promoted to associate professor, and in 1822, at the age of 30, he became a full professor, teaching mathematics, physics, and astronomy, the same year in which he began an administrative career as a member of the committee formed to supervise the construction of new university buildings. He served in many administrative positions and became the rector of Kazan University in 1827, where he stayed until 1846, when he was dismissed due to his deteriorating health. The University of Kazan flourished while Lobachevsky was rector, and this was largely due to his influence. By the early 1850s, he was nearly blind and unable to walk. Nevertheless, Lobachevsky continued his mathematical activity until he died in poverty in 1856. “There is no branch of mathematics, however abstract, which may not some day be applied to phenomena of the real world.” (Nokolay Ivanovitch Lobachevsky, quoted in George Edward Martin, The Foundations of Geometry and the Non-Euclidean Plane, Springer (1998 [1975]), p. 225) Lobachevsky’s main achievement is the development (independently from János Bolyai) of a non-Euclidean geometry. Since Euclid’s axiomatic formulation of geometry mathematicians had been trying to prove his fifth postulate as a theorem deduced from the other four axioms. The fifth postulate states that given a line and a point not on the line, a unique line can be drawn through the point parallel to the given line. Lobachevsky did not try to prove this postulate as a theorem. Instead he studied geometry in which the fifth postulate does not necessarily hold. Lobachevsky categorized euclidean as a special case of this more general geometry. This idea was first reported in 1826 to the session of the department of physics and mathematics, and the first publication of this research appeared in 1829–1830 only in a small Kazan periodical as A concise outline of the foundations of geometry[2], which was rejected when it was submitted to the St. Petersburg Academy of Sciences for publication. Lobachevsky based his geometry on the following assumption: In the plane formed by a line and a point not on the line it is possible to draw infinitely many lines through the point that are parallel to the original line. It was later proved that his geometry was self-consistent and, as a result, that the parallel postulate is independent of Euclid’s other axioms—hence, not derivable as a theorem from them.[3] In the Poincaré disc model of the hyperbolic plane, lines are represented by circular arcs orthogonal to the boundary of the closure of the disc. The thin black lines meet at a common point and do not intersect the thick blue line, illustrating that in the hyperbolic plane there are infinitely many lines parallel to a given line passing through the same point. (wikipedia) Lobachevsky called his work “imaginary geometry,” but as a sympathizer with the empirical spirit of Francis Bacon, he attempted to determine the “true” geometry of space by analyzing astronomical data obtained in the measurement of the parallax of stars. A physical interpretation of Lobachevsky’s geometry on a surface of negative curvature was discovered by the Italian mathematician Eugenio Beltrami in 1868. In 1842 Lobachevsky’s work was noticed and highly praised by Gauss, at whose instigation Lobachevsky was elected that year as a corresponding member of the Royal Society of Göttingen. In addition to his geometry, Lobachevsky obtained interesting results in algebra and analysis, such as the Lobachevsky criterion for convergence of an infinite series (1834–36). His research interests also included the theory of probability, integral calculus, mechanics, astronomy, and meteorology. The real significance of Lobachevsky’s new geometry was not fully understood and appreciated until the work of Bernhard Riemann on the foundations of geometry (1868) and the proof of the consistency of non-Euclidean geometry by Felix Klein in 1871.[3] At yovisto, you can learn more about Non-Euclidian geometry in the History of Mathematics lecture of Professor N. J. Wildberger “MathHist12 – Non-Euclidian Geometry“.'],\n",
       " [263,\n",
       "  'Camille Flammarion and his Balancing Act between Popular Science and Science Fiction.  Nicolas Camille Flammarion (1842-1925). On February 26, 1848, French astronomer and author Nicolas Camille Flammarion was born. He maintained a private observatory, where he studied double and multiple stars, the moon and Mars. He is best known as a prolific author of more than fifty titles, including popular science works about astronomy, several notable early science fiction novels, and works on psychical research and related topics. Camille Flammarion was born in Montigny-le-Roi, Haute-Marne, France, of humble parents. He was a precocious boy mastering to read and to write already at the age of four. At the age ten, Flammarion was placed in a seminary, and continued his education under the care of the Jesuits. At the age 15, he was apprenticed to an engraver, and worked in his shop for some months. Whilst thus engaged, however, he managed to continue his studies, mastered English and the classics, and was able earn the degree of bachelor, as well as his matriculation to the Polytechnic School, and at the age of sixteen to enter the Paris observatory as pupil astronomer. As a young man, Flammarion was exposed to two significant social movements in the western world: the thoughts and ideas of Charles Darwin and Jean-Baptiste Lamarck, and the rising popularity of spiritism with spiritualist churches and organizations appearing all over Europe. He was influenced by Jean Reynaud and his Terre at ciel (1854), which described a religious system based on the transmigration of souls believed to be reconcilable with both Christianity and pluralism. He was convinced that souls after the physical death pass from planet to planet, progressively improving at each new incarnation. According to [1] Flammarion at that time was already the author of a work entitled The Cosmogony of the Universe greatly admired by famous astronomer Urbain Le Verrier, to whose influence he principally owed his admission to the observatory. There, Flammarion was attached to the Bureau des Calculs, and had the good fortune to be able to make certain observations of comets which have been described as the most interesting that have been made during this century. At the same time he found time to write his next work, The Plurality of Inhabited Worlds. (1862). In Real and Imaginary Worlds (1864) and Lumen (1887), he described a range of exotic species, including sentient plants which combine the processes of digestion and respiration. This belief in extraterrestrial life, Flammarion combined with a religious conviction derived from the writings of Jean Reynaud and their emphasis upon the transmigration of souls. Influenced by his fellow Frenchman Allan Kardec, Flammarion became interested in psychical studies, which also influenced some of his science fiction writings, where he would write about his beliefs in a cosmic version of metempsychosis. Among other things, Flammarion believed that all planets went through more or less the same stages of development, but at different rates depending on their sizes. Flammarion approached spiritism, psychical research and reincarnation from the viewpoint of the scientific method. He had studied mediumship and wrote “It is infinitely to be regretted that we cannot trust the loyalty of mediums. They almost always cheat“. However, Flammarion a believer in psychic phenomena attended séances and produced in his book alleged levitation photographs, which were considered only little convincing. His book The Unknown (1900) received a negative review due to a lack of critical judgment in the estimation of evidence. After two years investigation into automatic writing Flammarion wrote that the subconscious mind is the explanation and there is no evidence for the spirit hypothesis. Flammarion believed in the survival of the soul after death but wrote that mediumship had not been scientifically proven. He also believed that telepathy could explain some paranormal phenomena. The fusion of science, science fiction and the spiritual influenced other readers as well. With great commercial success he blended scientific speculation with science fiction to propagate modern myths such as the notion that “superior” extraterrestrial species reside on numerous planets, and that the human soul evolves through cosmic reincarnation. Authors such as Edgar Rice Burroughs, Olaf Stapledon are referring to him and Arthur Conan Doyle’s The Poison Belt (1913) has a lot in common with Flammarion’s worries that the tail of Halley’s Comet would be poisonous for earth life. In the 1920s Flammarion, a member of the Theosophical Society, changed some of his beliefs on apparitions and hauntings but still claimed there was no evidence for the spirit hypothesis of mediumship in Spiritism. In his 1924 book Haunted Houses he came to the conclusion that in some rare cases hauntings are caused by departed souls whilst others are caused by the “remote action of the psychic force of a living person. Famous engraving in Camille Flammarion’s 1888 book L’atmosphère: météorologie populaire OK, usually we are dealing with ‘serious’ scientists. Why do we mention Camille Flammarion, who besides being an author of popular books believed some esoteric parapsychological phenomena? Well, because of the so-called Flammarion Engraving, which is also the title picture of this article. The Flammarion engraving is a wood engraving by an unknown artist, so named because its first documented appearance is in Camille Flammarion’s 1888 book L’atmosphère: météorologie populaire The engraving has often, but erroneously, been referred to as a woodcut. It has been used to represent a supposedly medieval cosmology, including a flat earth bounded by a solid and opaque sky, or firmament, and also as a metaphorical illustration of either the scientific or the mystical quests for knowledge. In 1957, astronomer Ernst Zinner claimed that the image dated to the German Renaissance, but he was unable to find any version published earlier than 1906. Further investigation, however, revealed that the work was a composite of images characteristic of different historical periods, and that it had been made with a burin, a tool used for wood engraving only since the late 18th century. Nevertheless, I like the picture of the man looking beyond his earthly horizon and use this also as an illustration in my lectures. At yovisto, you may enjoy a short video lecture by Carl Sagan, a more or less contemporary but definitely more scientific version of Camille Flammarion, explaining the 4th Dimension.'],\n",
       " [264,\n",
       "  'Giovanni Battista Morgagni and the Science of Anatomy.  Giovanni Battista Morgagni (1682 – 1771).  On February 25, 1682, Italian anatomist Giovanni Battista Morgagni was born. His works helped to make anatomy an exact science. Thus, he often is celebrated as the father of modern anatomical pathology. Giovanni Battista Morgagni was born at Forli, in the Romagna and received a decent scientific education from early years. Already at the age of 14, Morgagni managed to read verses of his compositions and take part in debating philosophical questions at the local academy. He enrolled at the University of Bologna at the age of 16 and earned his Doctor’s degree in philosophy and medicine around 1701. Although Morgagni never confined his scientific interest to medicine, his first chosen field of work was anatomy. He made his first publishment in 1706, titled ‘Adversaria Anatomica Prima‘. It contained new discoveries in anatomy and corrections of many errors of previous writers. The scientist then spent some time to research at Padua and Venice before being appointed professor of Theoretical Medicine at Padua. He was appointed Chair of Anatomy three years later. To one of his major works belongs ‘De Sedibus et Causis Morborum per Anatomen Indagatis‘ (Of the seats and causes of diseases investigated through anatomy), published in Venice in 1761. The work was published in five books printed as two folio volumes, which was reprinted several times: in its original Latin, French, English, and German. In it, Morgagni layed the foundations for pathological anatomy. He described the changes from regular condition found in the body after death from diseases of various kinds and also traced the connection between the lesions and the symptoms observed during life. Next to his works on medical science, Morgagni als published papers in archaeology, history, geography, and philology. Throughout his life and beyond, Giovanni Battista Morgagni received numerous academic dignities across Europe. His native town even placed a marble bust of him in its Council Hall during his lifetime, with an inscription describing him as “primus in humani corporis historid”. At yovisto you may learn more about the future of the Science of Anatomy in a lecture by Jack Choi.'],\n",
       " [265,\n",
       "  'Samuel Pierpont Langley and his Aviation Work.  Attempt to fly the manned Langley Aerodrome October 7, 1903.  On February 27, 1906, American astronomer, physicist, inventor of the bolometer and pioneer of aviation Samuel Pierpont Langley passed away. Langley attempted to make a working piloted heavier-than-air aircraft. His models flew, but his two attempts at piloted flight were not successful. Samuel Pierpont Langley was born in 1834 in Roxbury. He started his education at the Boston Latin School and was interested in astronomy immediately. His brother helped him to build instruments and they experimented with refractor types together. The brothers managed to observe the phases of Venus, craters and “seas” on the moon, the Galilean moons of Jupiter, and the rings of Saturn. Langley became an assistant at the Harvard College Observatory and soon he started his career with the U.S. Naval Acadamy where he was appointed professor of mathematics. He then moved to Pennsylvania in order to work at the Allegheny Observatory. Langley always believed that science should be made available to the public. He published for instance his works on the Sun for the non-technical reader and gave numerous lectures. Langley’s research on the Sun also led to expeditions into high mountains to perform experiments. During his time in Pennsylvania, Langley also became quite enthusiastic about aviation. He read numerous papers on the topics and wondered, what he could do himself. Langley started experimenting with aerodynamics soon. He intended to construct a functioning heavier than air aircraft. Even though his models flew, his attempts at piloted flight were not too successful. He proceded to design flying models powered by miniature steam engines. Rudyard Kipling described Langley’s experiments later on: Through Roosevelt I met Professor Langley of the Smithsonian, an old man who had designed a model aeroplane driven—for petrol had not yet arrived—by a miniature flash-boiler engine, a marvel of delicate craftsmanship. It flew on trial over two hundred yards, and drowned itself in the waters of the Potomac, which was cause of great mirth and humour to the Press of his country. Langley took it coolly enough and said to me that, though he would never live till then, I should see the aeroplane established. In 1896, Samuel Pierpont Langley made his first successful attempt. He managed to fly approximately 3/4 of a mile after being launched from a boat on Potomac River. It is assumed that this distance was ten times longer than any previously attempted heavier than air aircraft. Langley managed to further increase the distance and acquired money from the Smithsonian to develop a piloted airplane. He called his construction the Aerodrome. It is believed that Samuel Pierpont Langley heard about the Wright brothers’ success with their glider in 1902 and it is further believed that he wanted to meet them, without success. Langley’s approach to design an aircraft was quite different to the approaches of the Wright brothers, who preferred a controllable airplane that could fly against a strong wind and land on solid ground. Langley’s model however, had no landing gears and was mostly tried out at calm weathers over Potomac River. He required a catapult for launch and the descent into the water resulted in the rebuilding of the plane. Due to safety reasons, the project was highly criticized by journalists and the government. However, the test pilot was always recovered from the river unharmed. The last attempt was made in December 1903. At yovisto you may learn more about the future of aviation and space flight in the presentation from Marc Millis on ‘Space Flight Predictions: After AI & Transhumanism‘'],\n",
       " [266,\n",
       "  'A life is like a garden – Leonard Nimoy.  Publicity photo of Leonard Nimoy and William Shatner as Mr. Spock and Captain Kirk from the television program Star Trek. (1968) This is not one of our usual daily history in science posts. Today, we want to pay tribute to an actor who played an extraordinary character that has become an icon: Leonard Nimoy and his alter ego Spock, the scientific officer aboard the starship USS Enterprise. I was shocked yesterday evening by the news of Leonard Nimoy’s passing. As Spock, he was one of my childhood’s heroes. And not only one of them, Spock was THE hero and role model, one of the main reasons why I have become a scientist. Probably this also holds for many others of my generation who later should become a scientist. When I grew up, one of the very first moments I remember having seen on TV was one of the Apollo moon missions. I was so sure that one day I should become an astronaut, although I only knew that astronauts are doing cool things in fancy suits somewhere in space and other planets. But, I don’t remember having seen anything personal of these astronauts. It was simply because they were riding in space ships doing incredible cool things. But then one day, I saw Star Trek, the original series, on TV. Suddenly, the astronauts have become “real life” persons. And wow, they were involved in some cool space adventures, too. I immediately became addicted to technology, fancying about the possibilities of space travel, warp drive, and teleportation. The main character of the TV series was Captain James T. Kirk, a classical heroic figure that is said to be heavily influenced by C.S. Forester’s Horatio Hornblower, but always with a twinkle in the eye. Nobody else but William Shatner was able to bring him to live and we all love him for that. But for a boy like me, of course the scientific officer Spock,the laconic and imperturbable extra-terrestrial from planet Vulcan, living on perfect logic unable to express emotions, was the much more ‘fascinating’ character. (Almost) nobody was able to raise any visible emotions or anger in him. Well, besides raising one of his eyebrows maybe. While Captain Kirk usually solved conflicts with his bare fists, Spock didn’t need to. He had his reasoning based on pure logic. Thus, Spock also became the centre of Star Trek’s optimistic vision of humanity’s future. Solving conflicts peacefully by the application of logic. That was also one of the goals that famous mathematician and philosopher Gottfried Wilhelm Leibniz (futilely in his times) aimed to achieve by applying his logical calculus to language. Today, understanding (natural) language as well as the content of images, audio files, and videos by application of machine learning, statistics, linguistics, and logics, has become one of my main research fields as a computer scientist. And as you might guess, there is still a long way to go… What later became much more interesting for me about Spock was the constant struggle with his both legacies, Human and Vulcan. He was “struggling to maintain a Vulcan attitude, a Vulcan philosophical posture and a Vulcan logic, opposing what was fighting him internally, which was human emotion.”[1] Thank you, Leonard Nimoy for sharing with us this optimistic and inspiring character! You taught us to ‘Live Long And Prosper.’ Read more: http://www.rollingstone.com/tv/news/leonard-nimoy-star-treks-spock-dead-at-83-20150227#ixzz3T3YNN3ZJ Follow us: @rollingstone on Twitter | RollingStone on Facebook References: [1] Dillard, J. M. (1994). Star Trek: “Where No Man Has Gone Before” – A History in Pictures.'],\n",
       " [267,\n",
       "  'Robert Cornelius shoots the very first Selfie.  Robert Cornelius (1809 – 1893).  On March 1, 1809, American photographic pioneer and business man Robert Cornelius was born. He is credited of making the very first selfie in th U.S. With his own knowledge of chemistry and metallurgy, Cornelius attempted to perfect the daguerreotype. As we all know, ‘selfies’ have become really popular in the past years. There is even this project called selfiecity, “investigating the style of selfies in five cities across the world” with some pretty detailed infos and statistics. The term ‘selfie‘ has probably been introduced in 2002, but the first ever self-portrait has been taken in 1838 or 1839 (the sources differ) by Robert Cornelius. Robert Cornelius was sent to a private school as a boy and it is believed that his interest in chemistry evolved in that period. He started working for his father in 1831, he was a manufacturer of lamps and chandeliers. Cornelius specialized in silver plating and metal polishing. He was approached by Joseph Saxton for the silver plate required for his daguerreotype. Robert Cornelius then also took his interest in the procedure. [1] First known EVA selfie taken by Buzz Aldrin in 1966 Today, taking selfies is easy, especially with the (in my mind) ridiculous ‘selfie sticks’ which now appear en masse in tourist areas across the world. Robert Cornelius however, had to stand still for about five minutes when he took his picture. He soon opened one of the first photographic studios ever, specializing in portraits. Unfortunately, only a few of his images survived, because Cornelius soon returned to his father’s successful business. [2] Also, Cornelius did not really make much of his achievements in the field of ‘photography‘. In 1893, shortly before his death, he told a friend of some portraits he took. Julius Sachse, back then a noted Philadelphia photographer himself, and future editor the American Journal of Photography, showed interest in Cornelius’ work. However, no evidence of these images had been found until 1975, when a librarian at the American Philosophical Society found a photograph taken by Cornelius. It is believed that some 30 daguerreotypes by Cornelius survived. Most of them picture Philadelphia notables, but there are also some of Robert Cornelius himself and Martin Hans Boye from 1843, showing them performing chemical experiments. [1] Several years later, in 1914, the first known selfie taken by a teenager appeared. It was probably sent to a friend by the Russian Grand Duchess Anastasia Nikolaevna  at the age of 13. Now, selfies are so popular, that the term was even announced as the “word of the year” by the Oxford English Dictionary in 2013.   At yovisto you can learn more about the history of photography in the presentation of Nancy Crandall about the origins and beginnings of photography.'],\n",
       " [268,\n",
       "  'Walter Bruch and the PAL Color Television System.  The „Olympia-Kanone“ (Olympic-Cannon) television camera at the 1936 Summer Olympics in Berlin, operated by German Television Walter Bruch On March 2, 1908, German electrical engineer and pioneer of German Television Walter Bruch was born. From the early 1930s Bruch was involved in the development of television technology. He is best known for the invention of the PAL color television system at Telefunken in the early 1960s. Walter Bruch was born in Neustadt an der Weinstraße, German Empire. At his father’s request he attended a business school, but then trained as a machinist apprenticeship in a shoe factory. From 1928 he attended the university of applied science Hochschule Mittweida in Saxony. Already in 1925 as a schoolboy, Walter Bruch was fascinated by theoretical publications on television. These publications motivated him to start his own experiments to receive mechanically-scanned television transmissions broadcast from Berlin-Witzleben in 1929. After that, he was a guest student at the Technical University of Berlin, where he met Manfred von Ardenne and the Hungarian inventor Dénes von Mihály. From the early 1930s, Bruch was involved in the development of television technology. In 1933 he presented a “people’s television receiver” with a self-built telecine. In 1935 he started work as a technician in the Television and Physics research Department of Telefunken headed by Fritz Schröter. It was also at Telefunken, where Emil Mechau developed a special television camera for the 1936 Summer Olympics, which should became a milestone for audiovisual technology. There, Bruch was able to participate in the field test the first Iconoscope camera. In 1937 Bruch received the commission to establish the first all-electronic TV studio in Germany[2] and at the Paris International Exposition, he introduced an iconoscope television unit that he had designed. During World War II he operated a closed-circuit television system installed at the secret military rocket test site Peenemünde used to control the A4 (V2) rocket launches from a safe distance from a bunker. He also worked on TV transmission systems for planes and radar technology using the glass delay line patented by Telefunken in 1940 and used in the “Rehbock” distance control unit.[1] In 1950 Telefunken commissioned him to develop the first post-war television receivers. Some time later, he returned to physics research and later color television. He studied and thoroughly tested the American NTSC system and what would later become the French SECAM system. His work led him and his co-workers to devise a new color television system that automatically corrected for the differential phase distortion that can occur along the transmission channel. Television encoding systems by nation; countries using the PAL system are shown in blue. On 3 January 1963 Bruch gave the first public presentation of the Phase Alternation Line System (PAL) to a group of experts from the European Broadcasting Union in Hannover. This is considered to be the date of birth of the PAL-Telefunken system, which was later adopted by more than 100 countries. The PAL system uses a 4:3 aspect ratio for the transmission of color pictures at 625 lines per frame. The picture is drawn in two passes, in the so-called half-frame process. The phase of the color carrier of a color difference signal is reversed by 180 degrees from line to line. In addition, the PAL system also allows the simultaneous transmission of audio channels, supporting stereo sound as well as a language choice. It automatically corrects color errors and maintains a very impressive degree of color fidelity.[2] In the Federal Republic of Germany PAL color television was officially introduced on 25 August 1967, when German Chancellor Willy Brandt pushed the button at the IFA in Berlin. Walter Bruch maintained a position as an honorary lecturer at Hannover Technical University and retired in 1974. At yovisto you can watch an RCA documentary on the history of television with the John Logie Baird giving the world`s first public demonstration of live, moving images in 1925.'],\n",
       " [269,\n",
       "  'Jeremias Richter and the Law of Definite Proportions.  Jeremias Benjamin Richter (1762-1807).  .  On March 10, 1762, German chemist Jeremias Benjamin Richter was born. He discovered the law of definite proportions and is best known for introducing the term stoichiometry, i.e. the calculation of relative quantities of reactants and products in chemical reactions. Jeremias Benjamin Richter was born at Hirschberg in Silesia, today’s Jelenia Góra in Western Poland. He graduated from the Hirschberg Gymnasium, and in 1778 joined the engineering corps of the Prussian army. Richter devoted his spare time to studying chemistry and, after seven years, left the army to enter the University of Königsberg, where he studied mathematics and philosophy and probably attended Immanuel Kant’s lectures. He was awarded the doctorate in 1789 with the dissertation De usu matheseos in chemia, in which he set out the determinations of the specific gravities of a number of substances, both compounds and solutions, and attempted to determine the weight of phlogiston. Richter went to Gross-Ober-Tschirnau, near Glogau, in Lower Silesia, where he established a laboratory and supported himself by chemical research and making aerometers. In 1795 he became secretary and assayer to the Oberbergamt at Breslau (now Wrocław), and in 1798 he became “second Areanist,” or chemist, at the Royal Porcelain Works at Berlin. Richter was a corresponding member of the Gross-britaunnische Societät of Göttingen and of the Munich and St. Petersburg academies. He never held an academic position, never married, and died of tuberculosis at the age of forty-five. As a chemist, Richter is responsible for some of the earliest determinations of the quantities by weight in which acids saturate bases and bases acids, and of arriving at the conception that those amounts of different bases which can saturate the same quantity of a particular acid are equivalent to each other. Driven by his achieved results, Richter was led to conclude that chemistry is a branch of applied mathematics. Actually, he wrote in the preface to the The Principles of Stoichiometry, or the Art of Measuring Chemical Elements (vols. 1–3, 1792–94): “All sciences concerned with magnitudes belong to mathematics. The reason that so little progress is made in this branch is that chemists only rarely occupy themselves with mathematics and mathematicians feel no call to make conquests for the art of measurement in the field of chemistry.“ Thus he was able to trace a law according to which the quantities of different bases required to saturate a given acid formed an arithmetical progression, and the quantities of acids saturating a given base a geometric progression. In 1792, Richter proposed the law of definite proportions, which gave evidence for the existence of atoms. Richter found that the ratio by weight of the compounds consumed in a chemical reaction was always the same. It took 615 parts by weight of magnesia (MgO), for example, to neutralize 1000 parts by weight of sulfuric acid. From his data, Ernst Gottfried Fischer calculated in 1802 the first table of chemical equivalents, taking sulphuric acid as the standard with the figure 1000. Richter defines his new science of Stoichiometry, as “the science of measuring the quantitative proportions or mass ratios in which chemical elements strand one to another.” The law of definite proportions and constant composition do not prove that atoms exist, but they are difficult to explain without assuming that chemical compounds are formed when atoms combine in constant proportions. Unfortunately Richter’s writing style has been described as obscure and clumsy. Despite his imaginative theorizing and skillful laboratory work, his chemical achievements passed almost unnoticed among his contemporaries until 1802, when it was summarized in Ernst Gottfried Fischer’s tables. Richter’s results had virtually no influence on the development of chemistry until after the acceptance of Dalton’s atomic theory.   At yovisto, you may be interested in a short documentary on one of the founders of modern chemistry:  Jöns Jacob Berzelius.'],\n",
       " [270,\n",
       "  'John Murray and the Oceanography.  John Murray (1841 – 1914).  On March 3, 1841, pioneering Scottish oceanographer, marine biologist and limnologist Sir John Murray was born. As one of its founders, coined the name oceanography. He studied ocean basins, deep-sea deposits, and coral-reef formation. As a marine scientist, he took part in the Challenger Expedition (1872-76), the first major oceanographic expedition of the world. John Murray was born in Coburg, Ontario as the son of a Scottish emigrant. He left Canada at the age of 17, and attended Edinburgh University after finishing High School. He intended to study medicine, but joined a whaler as a surgeon during a seven month journey to the Arctic. After his return, Murray began to study geology and zoology. He started working with Peter Guthrie Tait, Professor of Natural Philosophy, who then recommended the young scientist to Wyville Thomson, back then Professor of Natural History at the University of Edinburgh. [1] From 1872 to 1876, John Murray was part of the Challenger Expedition. The expedition was prompted by Charles Wyville Thomson and the  Royal Society of London. The crew sailed from Portsmouth, England and traveled about 70.000 nautical miles. As a result, the ‘Report Of The Scientific Results of the Exploring Voyage of H.M.S. Challenger during the years 1873-76′ was published. It catalouged more than 4.000 species that were previously unknown. John Murray supervised the publication and described it as ‘the greatest advance in the knowledge of our planet since the celebrated discoveries of the fifteenth and sixteenth centuries‘. [1,2] Fortunately, John Murray was, due to his participation in the Challenger Expedition, forwarded collections from expeditions sent out from Norway, Italy, France, Germany and the United States. In 1883, Murray set up the Edinburgh Marine Laboratory at Granton, which was the first of its kind in Britain. In 1894, the laboratory was moved to Millport and became the Scottish Marine Station for work in the Clyde Sea area. The laboratory is known as the forerunner of the Scottish Marine Biological Association (SMBA) and the Scottish Association for Marine Science (SAMS). [2] For coining the term ‘oceanography‘, his advances in the field, and the dominance, the University of Edinburgh had retained through Murray in the field, he has widely been credited as the founder of modern oceanography. To his contributions to oceanography belongs the study of ocean depths from the Challenger Expedition. He made important attempts to construct from temperature and salinity observations a qualitative theory of water movement in the world’s oceans and worked on the mapping of the marine deposits of the world’s oceans. Further, John Murray investigated and experimented on the dissolution of calcium carbonate. He was the first who identified the carbonate compensation depth in oceans. In 1905, he published in a series of volumes the definitive work on freshwater Scottish lochs, which involved their hydrography, bathymetry and sedimentology. [2] At yovisto, you may learn more about oceans in a video titled ‘Exploring the Ocean’s Hidden Secrets‘ by Robert Ballard.'],\n",
       " [271,\n",
       "  'George Gamow and his fundamental Views on the Foundations of Science.  Bragg Laboratory staff in 1931with George Gamow at the rightmost.  On March 4, 1904, theoretical physicist and cosmologist George Gamow was born. He was an early advocate and developer of George Lemaître’s Big Bang theory. Besides his contributions to physics, in his middle and late career, Gamow focused more on teaching, and became well known as an author of popular books on science, which are still in print more than 50 years after their publication. Gamow was born in Odessa, Russian Empire (now in Ukraine). His father was a high school teacher of Russian language and literature and his mother taught geography and history at a school for girls. Gamow was educated at the Novorossiya University in Odessa and at the University of Leningrad, where he studied under Alexander Friedmann. He aspired to do his doctoral thesis under Friedmann, but due to Friedmann’s early death in 1925 had to change his advisors. At the University, Gamow made friends with three fellow students of theoretical physics, Lev Landau, Dmitri Ivanenko, and Matvey Bronshtein, who formed a group known as the Three Musketeers. They met to discuss and analyze the ground-breaking papers on quantum mechanics. On graduation, Gamow worked on quantum theory in Göttingen, where his research into the atomic nucleus provided the basis for his doctorate. From 1928 to 1931, he worked at the Theoretical Physics Institute of the University of Copenhagen with a break to work with Ernest Rutherford at the Cavendish Laboratory, Cambridge. He continued to study the atomic nucleus, but also worked on stellar physics with Robert Atkinson and Fritz Houtermans. By 1928, Gamow had solved the theory of the alpha decay of a nucleus via tunnelling, with mathematical help from Nikolai Kochin. In 1931 Gamow was elected a corresponding member of the Academy of Sciences of the USSR already at age 28. Gamow worked in the Physical Department of the Radium Institute (Leningrad), where under the guidance and direct participation of Igor Kurchatov, Lev Mysovskii and George Gamow, Europe’s first cyclotron was designed in 1932. Upon approval by the institute the cyclotron was not completed until 1937. Gamow and his wife tried to leave the Soviet Union, with or without official permission. Niels Bohr and other friends invited Gamow to visit during this period, but Gamow could not get permission to leave. In 1933 Gamow was suddenly granted permission to attend the 7th Solvay Conference on physics, in Brussels. Gamow was accompanied by his wife and arranged to extend their stay, with the help of Marie Curie and other physicists. Over the next year, Gamow obtained temporary work at the Curie Institute, University of London, and University of Michigan. In 1934, Gamow and his wife moved to the United States, where he became a professor at George Washington University (GWU) and recruited physicist Edward Teller from London to join him. In 1936, Gamow and Teller published what became known as the “Gamow–Teller selection rule” for beta decay. By the late 1930s, Gamow’s interests had turned towards astrophysics and cosmology. During World War II, Gamow did not work directly on the Manhattan Project producing the atomic bomb, in spite of his knowledge of radioactivity and nuclear fusion. He continued to teach physics at GWU, and consulted for the US Navy. Gamow further used his knowledge of nuclear reactions to interpret stellar evolution, collaborating with Teller on a theory of the internal structures of red giant stars (1942). From his work on stellar evolution, Gamow postulated that the Sun’s energy results from thermonuclear processes.[2] In 1945, he co-authored a paper supporting work by German theoretical physicist Carl Friedrich von Weizsäcker on planetary formation in the early solar system. Gamow and Teller were both proponents of the expanding-universe theory that had been advanced by Alexander Friedmann, Edwin Hubble, and Georges LeMaître. Gamow, however, modified the theory, and together with Ralph Alpher and Hans Bethe published this theory in a paper called The Origin of Chemical Elements (1948). This paper, attempting to explain the distribution of chemical elements throughout the universe, posits a primeval thermonuclear explosion, the big bang that began the universe. According to the theory, after the big bang, atomic nuclei were built up by the successive capture of neutrons by the initially formed pairs and triplets.[2] Furthermore, they were postulating that before the big bang there existed a primordial state of matter, (ylem) consisting of neutrons and their decay products, protons and electrons, mixed together in a sea of high-energy radiation—the basic ingredients necessary for the formation of deuterons and heavier, and heavier nuclei as the universe subsequently expanded.[3] George Gamow: One, Two, Three, …Infinity (first published 1947) In 1954 Gamow’s scientific interests grew to encompass biochemistry. Shortly after J. D. Watson and Francis Crick discovered the double helical structure of DNA, Gamow recognized that the information contained in the four different kinds of nucleotides (adenine, thymine, guanine, cytosine) constituting the DNA chains could be translated into the sequence of twenty amino acids which form protein molecules by counting all possible triplets one can form from four different quantities.[3] Gamow’s contribution to solving the problem of genetic coding gave rise to important models of biological degeneracy. In 1956, Gamow moved to the University of Colorado Boulder, where he remained for the rest of his career. Gamow continued his teaching at the University of Colorado Boulder, and focused increasingly on writing textbooks and books on science for the general public. His popular writings were designed to introduce to the nonspecialist such difficult subjects as relativity and cosmology. His first such work, Mr. Tompkins in Wonderland (1936), gave rise to the multivolume Mr. Tompkins series (1939–67). Among his other writings are One, Two, Three . . . Infinity (1947), The Creation of the Universe (1952), A Planet Called Earth (1963), and A Star Called the Sun (1964). On August 19, 1968, Gamow died at age 64 in Boulder, Colorado. At yovisto, you can learn more about George Lemaître’s ideas about the origins of our universe in the talk of Prof. Stephen Hawking on ‘Asking Big Questions about our Universe‘.'],\n",
       " [272,\n",
       "  \"The Philosophical Transactions of the Royal Society.  Title page to volume 1 of Philosophical Transactions.  On March 6, 1665, the very first issue of the Philosophical Transactions of the Royal Society was published. The journal published by the Royal Society was the first journal in the world exclusively devoted to science. Moreover, it is also the world’s longest-running scientific journal. Already in 1660, at Gresham College, London, UK, 12 men, including Christopher Wren, Robert Boyle, John Wilkins, and Sir Robert Moray decide to found what is later known as the Royal Society of London for Improving Natural Knowledge, a learned society for science, and possibly the oldest such society still in existence, embodying the principles of Sir Francis Bacon. By 1662, the Royal Society was granted a charter to publish by King Charles II and on 6 March 1665, the first issue of Philosophical Transactions was published under the visionary editorship of Henry Oldenburg, who was also the first Secretary of the Society, four-and-a-half years after the Royal Society was founded. Its full title of the journal as given by Oldenburg, “Philosophical Transactions, Giving some Account of the present Undertakings, Studies, and Labours of the Ingenious in many considerable parts of the World“. The Society’s Council minutes dated 1 March 1664 (in the Julian calendar) ordered that “the Philosophical Transactions, to be composed by Mr Oldenburg, be printed the first Munday of every month, if he have sufficient matter for it, and that that tract be licensed by the Council of this Society, being first revised by some Members of the same“. Oldenburg published the journal at his own personal expense and seems to have entered into an agreement with the Society’s Council allowing him to keep any resulting profits. He was to be disappointed, however, since the journal performed poorly from a financial point of view during his lifetime, just about covering the rent on his house in Piccadilly. Oldenburg put out 136 issues of the Transactions before his death in 1677. The first volumes of what was the world’s first scientific journal were very different from today’s journal, but in essence it served the same function; namely to inform the Fellows of the Society and other interested readers of the latest scientific discoveries.[1] The familiar functions of the scientific journal, as e.g. Registration (date stamping and provenance), Certification (peer review), Dissemination and Archiving were introduced at inception by Philosophical Transactions. In November 1664 Oldenburg wrote to Robert Boyle: ‘We must be very careful as well of regist’ring the person and time of any new matter, as the matter itselfe, whereby the honor of the invention will be reliably preserved to all posterity‘ (registration and archiving)’ and subsequently ‘...all ingenious men will thereby be incouraged to impact their knowledge and discoverys‘ (dissemination). In 1665 provisions were made for the tract to be revised by members of the Council of the Royal Society, providing the framework for peer review to eventually develop, becoming fully systematic as a process by the 1830s. Issue 1 contained such articles as: an account of the improvement of optic glasses; the first report on the Great Red Spot of Jupiter; a prediction on the motion of a recent comet (probably an Oort cloud object); a review of Robert Boyle’s ‘Experimental History of Cold'; Robert Boyle’s own report of a deformed calf[4]; and more.[2] In its formative years Isaac Newton had seventeen papers published in the journal including his first paper – New Theory about Light and Colours – which effectively served to launch his scientific career in 1672. In the same year his new reflecting telescope was described and the original drawing was also published in the journal. Philosophical Transactions has also published the work of Charles Darwin, Michael Faraday, William Herschel and many more celebrated names in science. Today, you can access the online archive of the Philosophical Transactions of the Royal Society with more than 60.000 articles including also the very first issue from 1665. Due to copyright restrictions only paper being published more than 70 years ago are freely available.[3] In July 2011 programmer Greg Maxwell released through the The Pirate Bay, nearly 19 thousand articles that had been published before 1923, and were therefore in the public domain. They had been digitized for the Royal Society by Jstor, and public access to them originally was restricted through a paywall. However, in October of the same year, the Royal Society released for free all its articles prior to 1941, but denied that this decision had been influenced by Maxwell’s actions. At yovisto, you may enjoy a more detailed explanation on the founding of the Royal Society by Professor Michael Hunter at Gresham College.\"],\n",
       " [273,\n",
       "  'William Oughtred and the Slide Rule.  William Oughtred.  On March 5, 1574, English mathematician and Anglican minister William Oughtred was born. After John Napier invented logarithms, and Edmund Gunter created the logarithmic scales (lines, or rules) upon which slide rules are based, it was Oughtred who first used two such scales sliding by one another to perform direct multiplication and division; and he is credited as the inventor of the slide rule in 1622. William Oughtred attended the presticous Eton School and enrolled at King’s College Cambridge in 1592. He received his M.A. eight years later and was especially interested in mathematics, even though the field has not been taught extensively at Cambridge back then. Outhred became Episcopal minister in 1603 and became vicar of Shalford one year later. Oughtred was announced rector of Albury in 1610 and took mainly private pupils who received a mathematical education. In 1631, Oughtred published his most impirtant work, ‘Clavis Mathematicae’. In it, he described Hindu-Arabic notations and decimal fractions as well as algebra. Oughtred began to experiment with new mathematical symbols like x for multiplication and :: for proportions. He used π for the circumference and introduced ‘greater than and less than’ symbols, which were not accepted by the community due to being too hard to remember. The now very familiar < and > were introduced by Harriot. [1] William Oughtred became especailly famous for an early version of the slide rule. Already in 1620, the English clergyman, mathematician, geometer and astronomer Edmund Gunter managed to plot a logarithmic scale along a single straight two foot long ruler. He began to add and substract lengths by using a pair of dividers. The operations used were equivalent to multiplying and dividing. William Oughtred invented a circular slide rule about one decade later. In 1632, Oughtred published Circles of Proportion and the Horizontal Instrument describing slide rules and sundials. [2] It is believed that William Oughtred and Richard Delamain invented the circular slide rule independently from each other. Delamain published his Grammelogia, or the Mathematical ring already in 1630. Big discussions arose over the topic and throughout Oughtred’s later life. [1]   At yovisto you can learn more about “Why is ‘x’ the symbol for an unknown?” in a humorous talk by Terry Moore.'],\n",
       " [274,\n",
       "  'Henry Draper and his Passion for Astronomy.  Henry Draper.  On March 7, 1837, American doctor and amateur astronomer Henry Draper was born. He is best known today as a pioneer of astrophotography. After his death, the Henry Draper Catalog of stellar spectra as well the Henry Draper medal is named after him. Henry Draper was the son of John William Draper, a doctor, chemist, and professor at New York University. He was known for his interest in the chemical effects of light and he managed to take the first daguerreotype of the Moon around 1839. Henry Draper then assisted his father in photographing microscope slides for a textbook with similar techniques. The young Draper spent a year in Ireland where back then the world’s largest telescope was located. After his return home, Draper was determined to devote his career to photography for astronomical purposes. He built his own observatory and still had time to work as a physician at Bellevue Hospital and leter as professor of medicine at New York University. Henry Draper’s wife, Anna Mary Palmer became his laboratory assistant and they often invited celebrities and contemporary scientists to their home. Henry Draper is best best known for obtaining the first astronomical photograph of a nebula. The image of the Great Nebula of Orion was created in September 1880. Throughout the years, Draper kept improving his images and he is also credited for the first stellar spectrum photograph, which he took of Vega in August 1872, the first wide-angle photograph of a comet’s tail, and the first spectrum of a comet’s head, both of these with Tebbutt’s Comet in 1881. Further, the amateur astronomer obtained photographs of the Moon, a benchmark spectrum of the Sun in 1873, and spectra of the Orion Nebula. Draper managed to publish much of his work in the field of astronomy and he suggested to build observatories in the Andes in order to avoid atmospheric turbulences. Henry Draper was honored numerous times during his lifetime and beyond. He received honorary degrees from NYU and the University of Wisconsin. He was awarded a Congressial medal and was elected to the National Academy of Sciences and the Astronomische Gesellschaft. Draper was a member of the American Photographic Society, the American Philosophical Society, the American Academy of Arts and Sciences, and the American Association for the Advancement of Science. At yovisto, you may enjoy a video lecture by Mary Dussault and Joe DePasquale titled ‘Understanding Astrophotograpy: Where Science and Art meet‘.'],\n",
       " [275,\n",
       "  'John Fothergill – Physician and Gardener.  John Fothergill (1712-1780). On March 8, 1712, English physician, plant collector, philanthropist and Quaker John Fothergill was born. was first to describe coronary arteriosclerosis (hardening and thickening of the arterial wall, with a loss of elasticity and reduced blood flow) associated with angina pectoris. John Fothergill was born at Carr End, near Bainbridge in Yorkshire, the son of John Fothergill, a Quaker preacher and farmer. John went to school at Frodsham and in 1724 entered the grammar school at Sedbergh in the Yorkshire Dales. He studied Greek and Latin, becoming fluent in Latin. After studying at Sedbergh School, Fothergill was apprenticed to the Bradford apothecary, bookseller and Quaker minister Benjamin Bartlett, who encouraged his interest in natural history. In 1734 he enrolled at the University of Edinburgh as an apothecary, but was noticed by Alexander Monro who influenced him to change to medicine. He graduated doctor of medicine in 1736 with a thesis on the use of emetics, followed by further studies at St Thomas’ Hospital, London. After visiting continental Europe in 1740 visiting Holland, Germany, and France, he settled in London to practise as an unlicensed physician, where he gained an extensive practice. He was admitted a Licentiate of the College of Physicians 1st October, 1744, and is the first graduate in medicine of the university of Edinburgh who was admitted by the College.[4] During the severe scarlet fever epidemic in London 1746-1748, Fothergill won a great reputation, abolishing bloodletting, purgatives, and other common treatments to that day. Instead, he treated the disease with wine, attenuated mineral acids and emetics in moderate doses. This resulted in his important work An Account of the Sore Throat Attended with Ulcers (1748). It contains one of the first descriptions of streptococcal sore throat in English, and was translated into several languages. His rejection of ineffective traditional therapies for this disease saved many lives. Fothergill gave a graphic description of migraine, with the visual precursors and the localized headache that follows as: “a singular kind of glimmering in the sight, objects swiftly changing their apparent position, and surrounded with luminous angles, like those of a fortification.”[3] During the epidemics of influenza in 1775 and 1776 Fothergill is said to have had sixty patients daily. Fothergill also is credited with first identifying and naming trigeminal neuralgia in his work Of a painful affection of the face in 1765. He also supported the publication of Benjamin Franklin’s papers on electricity, and wrote a preface for them. Fothergill, now the most sought for physician in London, worked unusually long hours and gained one of the most lucrative practices in the city. In fact, he was one of the richest physicians in England.[2] In his leisure, John Fothergill made a study of conchology and botany. At Upton, near Stratford, London, he had an extensive botanical garden where he grew many rare plants obtained from various parts of the world. His garden enabled Fothergill to delineate the natural history of many drugs. To his honour Carl von Linné named a wild growing shrub from Carolina Fothergilla.[2] Fothergill was instrumental in the formation of a society of physicians modelled on the Edinburgh Medical Society. He is known as the first to record coronary arteriosclerosis – a hardening of the walls of the arteries supplying blood to the heart muscle – in association with a case of angina pectoris. Fothergill also popularized the use of coffee in England and promoted its cultivation in the West Indies. In 1773 Fothergill gave the first full description of trigeminal neuralgia, which was, for a time, referred to as “Fothergill’s disease”.[2] John Fothergill died in London aged 68 on 26 December 1780. At yovisto you may learn more about the future of the Science of Anatomy in a lecture by Jack Choi.'],\n",
       " [276,\n",
       "  'Howard H. Aiken and the Harvard Mark I.  Aiken’s Harvard Mark I computer – Left Segment.  On March 9, 1900, computer pioneer Howard Hathaway Aiken was born. He was the original conceptual designer behind IBM’s Harvard Mark I computer, forerunner of the modern electronic digital computer. Howard H. Aiken studied at the University of Wisconsin – Madison. He earned his PhD in physics at Harvard University in 1939. During his studies, Aiken is supposed to have encountered differential equations only to be solved numerically. It is assumed that he envisioned an electro-mechanical computing device that could help him with his work. Aiken was supported by Harvard University for his ideas. He also discussed his ideas with several manufacturers, eventually finding interest at IBM, a company that specialized in calculating machines and punch card systems. The Mark I  project was led by Aiken and built by IBM engineers in Endicott, N.Y. When Mark I was delivered to Harvard in 1944, it was operated by the U.S. Navy Bureau of Ships for military purposes, solving mathematical problems that until then required large teams of human “computers.” Also in 1944, Grace Hopper joined the team. Between 1944 and 1959, Mark I was in operation. The Automatic Sequence Controlled Calculator (ASCC) consisted of relays, rotating shafts, and clutches. Mark I weighed about 4.500kg and also included an electric motor to synchronize the basic calculating units. Mark I used 800km of wire with several million connections and was held by a steel frame of 16m length. For his achievements, Howard Aiken was elected a Fellow of the American Academy of Arts and Sciences in 1947. He received the University of Wisconsin–Madison College of Engineering Engineers Day Award in 1958, the Harry H. Goode Memorial Award in 1964, the John Price Wetherill Medal in 1964, and the IEEE Edison Medal in 1970. In 1947, Howard Aiken introduced a master’s program for computer science at Harvard. At yovisto you may be interested in a video lecture on ‘The Birth of the Computer‘ by George Dyson.'],\n",
       " [277,\n",
       "  'Richard E. Byrd, Jr. – Aviator and Polar Explorer.  Richard Evelyn Byrd in front of a Vought VE-7 Bluebird seaplane.  On March 11, 1957, US-American explorer and aviator Richard Evelyn Byrd Jr. passed away. He claimed to be the first man to fly over both of the Earth’s poles. Richard Evelyn Byrd was born in 1888 and entered the United States Navy Academy at the age of 20. It is assumed that his passion for aviation evolved during World War I when he learned how to fly. Soon, Byrd became a flight instructor for the US Navy. Due to Byrd’s expertise in aerial navigation, the aviator was appointed to plan the flight path for the U.S. Navy’s 1919 transatlantic crossing. He then commanded the aviation unit of the arctic expedition to North Greenland led by Donald B. MacMillan from June to October 1925. [1] In 1926, Richard Byrd and pilot Floyd Bennett attempted a flight over the North Pole in a Fokker F-VII Tri-motor monoplane called Josephine Ford. The crew took off at Spitsbergen and covered about 1.360 miles in less than 16 hours. The pilots claimed to have reached the North Pole and Byrd received the Medal of Honor for his achievement. Also, his claims enabled him to secure fundings for an attempt to fly over the South Pole. However, with the years, heated controversies evolved about whether the pilots were actually able to reach the North Pole. Most of the critics brought to attention that the Josephine Ford may not have had enugh speed and winds to accomplish a flight from Spitzbergen to the North Pole and back in less than 16 hours. Since then, many publications try to reveal the truth around Byrd’s flight, but there are still open questions. [2,3] Further explorers claiming to have made the first successful expedition to the North Pole were Robert E. Peary and Frederick Cook. One year after the controversal flight, Richard Byrd announced to have the financial backings to attempt to win the Orteig Prize for making the first nonstop flight between the United States and France. He announced Floyd Bennett again as his chief pilot. However, during a practice, the Fokker Trimotor airplane crashed, injuring Bennett and Byrd. While the plane was going through repairs, Charles Lindbergh won the prestigous prize on May 21, 1927. [4] In 1928, Richard Byrd set himself another goal. He wanted to reach the South Pole by flight. With the expedition that consisted of two ships and three planes he established base camp called “Little America” on Ross Ice Shelf, from which many foot, sled and airplane expeditions were launched. The famous South Polar flight took place on November 28, 1929. To avoid the same mistakes he did during previous expeditions, Byrd paid special attention to data collection. Despite several difficulties during the adventure, Richard Byrd’s expedition was probably the first to reach the South Pole by air. Due to his success, Byrd took part in four more Antarctic expeditions and he managed to survive 5 winters alone while operating a meteorological station. [4] At yovisto, you can watch a movie by Admiral Peary’s adversary Dr. Frederick Cook in 1912, produced to substantiate his claim as discoverer of the North Pole.'],\n",
       " [278,\n",
       "  'Vladimir Vernadsky and the Biosphere.  Vladimir Ivanovich Vernadsky.  On March 12 (February 28 according to the old calendar), 1863, Ukrainian and Soviet mineralogist and geochemist Vladimir Ivanovich Vernadsky was born. He is considered one of the founders of geochemistry, biogeochemistry, and of radiogeology. He is most noted for his 1926 book “The Biosphere” in which he popularized the hypothesis that life is the geological force that shapes the Earth. Vladimir Ivanovich Vernadsky was born on March 12, 1863 in Saint Petersburg, Russia. His father was a professor at the Moscow University and he taught economics. Also, his father was editor of the journal ‘Economic Index‘. It is believed that his interest in science, especially natural science, evolved during his time attending a grammar school in Saint Petersburg. Vernadsky earned his degree from Saint Petersburg University’s Department of Natural, Physical and Mathematical Faculty. Vernadsky then decided to specialize in mineralogy due to the great poteltial he saw in the field. He trained under the famous Russian geologist V.V. Dokuchaev, who is credited with laying the foundations of soil science. [1] While thinking of a topic for his doctorate studies, Vernadsky traveled to Naples and began to study with Arcangelo Scacchi, the Italian mineralogist and discoverer of Dimorphite. However, its is believed that Vernadsky did not have the feeling to learn enough from Scacchi so he continued his journey to Germany in order to study with Paul Groth. Groth developed a tool which helped him to analyze the thermal, optical, electrical and magnetic properties of crystals and Vernadsky is believed to have enjoyed learning using modern machinery. Vernadsky was also allowed to use Professor Zonke’s physics lab, who was another expert in the field of crystallization. [1] Vladimir Vernadsky presented a report on the ‘Paragenesis of Chemical Elements in the Earth’s Crust‘ at the Congress of Medics and Natural Scientists. In his study, Vernadsky is believed to have laid the foundation for what became later known an geochemistry. He suggested to use radioactive phenomenon in studying the history of chemical elements and in seeing the genetic relationships between these elements. Vernadsky managed to establish the Radium Commission in 1909 and he developed the theory that radioactive substances are are major sources of energy. The result would be the fact that these substances could also be used in creating new chemical elements. Vernadsky started by collecting rock samples and mapping where deposits of radioactive substances can be found in great detail. The first known geochemical laboratory was established in Saint Petersburg around 1910 and the mineralogist and geochemist managed to make the concept of the noosphere more familiar. Also, Vladimir Vernadsky was able to contribute to the idea of the biosphere and developed the meaning that has largely been recognized by today’s scientific community, even though the actual term ‘biosphere‘ was coined by the Austrian geologist Eduard Suess in 1911. [1,2] Vladimir Vernadsky developed the theory that the noosphere is the third stage in the earth’s development, after the geosphere and the biosphere, defined as biological life. In this theory, the principles of both, life and cognition, are essential features of the Earth’s evolution, and must have been implicit in the earth all along. This systemic and geological analysis of living systems complements Charles Darwin’s theory of natural selection. Vernadsky’s visionary pronouncements were not widely accepted in the West. However, he was one of the first scientists to recognize that the oxygen, nitrogen and carbon dioxide in the Earth’s atmosphere result from biological processes. During the 1920s he published works arguing that living organisms could reshape the planets as surely as any physical force. [1,2,3] At yovisto, you may learn more about ‘Darwin and the Economy of the Natural World‘ in a lecture by Professor Paradis.'],\n",
       " [279,\n",
       "  'Joseph Priestley – The Educator and Historian.  Chart of Biography 1765.  On March 13, 1733 (March 24 according to the new Gregorian calendar), English theologian, Dissenting clergyman, natural philosopher and chemist Joseph Priestley was born. He is usually credited with the discovery of oxygen, having isolated it in its gaseous state, although Carl Wilhelm Scheele and Antoine Lavoisier also have a claim to the discovery. A scholar and teacher throughout his life, Priestley also made significant contributions to pedagogy, including the publication of a seminal work on English grammar, books on history, and he prepared some of the most influential early timelines. Joseph Priestley began teaching in Nantwich, Cheshire and back then he enjoyed tutoring his pupils in a wide range of topics: Latin, Greek, geography, math as well as English grammar. It is assumed that he also taught natural philosophy. Having received a decent education at Daventry, a Dissenting academy, Priestley was convinced was education was a major key to shaping people as well as the society’s future. Priestley kept supporting Dissenting academies throughout his lifetime and he consulted the founders of New College at Hackney on its curriculum. After Priestley emigrated to America in 1794, he continued his ‘mission’ and began communicating with Thomas Jefferson regarding the proper organization of a university. When the University of Virginia was founded by Jefferson, Priestley was able to highly influence the university’s educational principles. One of Joseph Priestley’s principles was his way of teaching natural philosophy. He always encouraged his students to give public presentations of their experiments. He was convinced that it was not enough to simply teach children in the subjects of grammar and rhetoric, but also tutor them in science to support their understanding of the world and the human race. Back in Birmingham, where Priestley lived in 1780, his home became a place for scientific education for the local children. Joseph Priestley also dedicated an Essay on a Course of Liberal Education for Civil and Active Life in 1765 to the governing board of Warrington Academy. He explained that children’s education should anticipate their practical needs instead of classical education in order to acquire useful skills. He proposed that students should lean English and the modern languages instead of the classical languages, learn practical mathematics, read modern rather than ancient history, and study the constitution and laws of England. In 1766 Warrington Academy replaced its old classical curriculum with Priestley’s new liberal arts model. Priestley’s teaching philosophy included a great knowledge of history. He believed that understanding history was necessary not only to success but also to spiritual growth. At Warrington Academy, Priestley gave lactured on the government and history. In his lectures, Priestley did not limit himself to narrating history, he also presented a method for historical research and was one of the first to argue for the primacy of original documents in the study of history. Due to Priestley’s view that education was the key to shape a person’s character, the educator also promoted the education of women. Alluding to the language of Locke’s Essay Concerning Human Understanding, he wrote: “certainly, the minds of women are capable of the same improvement, and the same furniture, as those of men.” Further, he came to believe that if women were to care for children and be intellectually stimulating companions for their husbands, they had to be well-educated. Although Priestley advocated education for middle-class women, he did not extend this logic to the poor. In his work as a teacher, Joseph Priestley also became famous for his Chart of Biography, published in 1765 and the New Chart of History, published in 1769. These charts allowed students to “race out distinctly the dependence of events to distribute them into such periods and divisions as shall lay the whole claim of past transactions in a just and orderly manner” as he put it. The Chart of Biography included a timespan from 1200 BC to 1800 AD  and about 2000 names. He established six categories, Statesman and Warriors, Divines and Metaphysicians, Mathematicians and Physicians, Poets and Artists, Orators and Critics, and Historians and Antiquarians. He devided the world’s history in several categories: Scandinavia, Poland, Russia, Great Britain, Spain, France, Italy, Turkey in Europe, Turkey in Asia, Germany, Persia, India, China, Africa and America. The goal was to show the history of empires and the passing power. His charts were highly popular, and A New Chart of History went through fifteen editions by 1816. At yovisto, you may learn more about ‘The child-driven education‘ in a very interesting lecture by Sugata Mitra.'],\n",
       " [280,\n",
       "  'Frederick Reines and the Neutrino.  Frederick Reines.  On March 16, 1918, American physicist and Nobel Laureate Frederick Reines was born. He is best known for his co-detection of the neutrino with Clyde Cowan in the neutrino experiment. The neutrino is a subatomic particle, a tiny lepton with little or no mass and a neutral charge which had been postulated by Wolfgang Pauli in the early 1930s but had previously remained undiscovered. Reines shared the Nobel Prize with physicist Martin Lewis Perl, who discovered the tau lepton. Frederick Reines was born in Paterson, New Jersey in 1918 and he once described the day he became fascinated by science: “The first stirrings of interest in science that I remember occurred during a moment of boredom at religious school, when, looking out of the window at twilight through a hand curled to simulate a telescope, I noticed something peculiar about the light; it was the phenomenon of diffraction. That began for me a fascination with light.” [1] His early education was mostly shaped by his older siblings, who became doctors of medicine and lawyers. Also, Reines’ scientific career was shaped by his membership in the Boy Scouts where he began to build crystal radios. In High School, Reines was encouraged by a science teacher to use the school’s lab and in his year book he noted as his principal ambition “To be a physicist extraordinaire.” Even though initially intending to enroll at MIT, Reines decided to go with the Stevens Institute of Technology  to study engineering. Reines received his Master of Science in mathematical physics in 1941 and continued his career at New York University, where he worked in experimental experimental cosmic ray physics under the direction of S.A. Korff, and wrote a theoretical Ph.D thesis on “The Liquid Drop Model for Nuclear Fission”. He was recruited by as a staff member under Richard Feynman in the Theoretical Division at the Los Alamos Scientific Laboratory, to work on the Manhattan Project. He directed his efforts to the basic understanding of the effects of nuclear blasts and coauthored a study of the air blast wave with John von Neumann. In 1951, during a sabbatical-in-residence from his duties at Los Alamos, Frederick Reines decided to attempt the ovservation of the neutrino. He formed a colllaboration with Clyde Cowan and decided that the reactor at Hanford, Washington would suit best as source of neutrinos. In 1953, John Wheeler contacted them about the new Savannah River reactor facility being built in South Carolina. The men transferred their operations there and observed the electron antineutrino in 1956. Reines started the first series of experiments at the Savannah River site to study the properties of the neutrino after Cowan left Los Alamos. The neutrino was first postulated by Wolfgang Pauli in 1930 to explain how beta decay could possibly conserve energy, momentum, and angular momentum. He hypothesized that an undetected particle that he called a “neutron” and he considered that the new particle was emitted from the nucleus together with the electron or beta particle in the process of beta decay. Two years later, James Chadwick discovered a much more massive nuclear particle and also named it a neutron. Enrico Fermi, who developed the theory of beta decay, then coined the term neutrino to resolve the confusion. Fermi published a paper in 1934, unifying Pauli’s neutrino with Paul Dirac’s positron and Werner Heisenberg’s neutron – proton model and gave a solid theoretical basis for future experimental work. But when the journal Nature rejected his paper, it was published to an Italian journal and the general lack of interest in his theory back then probably caused Fermi to switch to experimental physics. In 1942, Wang Ganchang first proposed the use of beta capture to experimentally detect neutrinos. In the 20 July 1956 issue of Science, Clyde Cowan, Frederick Reines, F. B. Harrison, H. W. Kruse, and A. D. McGuire published confirmation that they indeed had detected the neutrino, a result that was rewarded almost forty years later with the 1995 Nobel Prize. In this experiment, now known as the Cowan – Reines neutrino experiment, antineutrinos created in a nuclear reactor by beta decay reacted with protons to produce neutrons and positrons. When Reines also left Los Alamos in 1959, he became Professor and Head of the Department of Physics of the Case Institute of Technology in Cleveland, Ohio. There his group worked in reactor neutrino physics, double beta decay, electron lifetime studies, searched for nucleon decay, and performed an experiment in a gold mine in South Africa that made the first observation of the neutrinos produced in the atmosphere by cosmic rays. Reines took his research group to the new University of California, Irvine campus in 1966, where he became the Dean of the School of Physical Sciences. Reines later was appointed Distinguished Professor of Physics at UCI in 1987 and became Professor Emeritus in 1988. The “Neutrino Group” at Irvine has been actively involved in a wide range of neutrino and elementary particle physics experiments, including its role in the Irvine-Michigan-Brookhaven proton decay experiment. This group has continued the program of reactor neutrino experiments, has been the first to observe double beta decay in the laboratory, and was awarded the 1989 Bruno Rossi prize in High Energy Astrophysics by the American Astronomical Society for its joint observation of neutrinos from supernova 1987A. The detection of the supernova neutrinos was a particularly gratifying outcome of the IMB experiment. At yovisto you may learn more about Understanding Neutrinos Using Deep Dark Science in a lecture by Arthur B. McDonald.'],\n",
       " [281,\n",
       "  'The Life and Work of Philippe de La Hire.  Andromeda and Cassiopeia – detail from Planisphere celeste, Philippe de La Hire, 1705.  On March 18, 1640, French mathematician, astronomer, and key figure in the Académie royale des sciences Philippe de La Hire was born. Philippe de La Hire was educated as an artist and became skilled in drawing and painting early. It is believed that de La Hire received no formal education in an official school even though his father was probably teaching him at home. At the age of 16, Philippe was fully committed to becoming a professional artist and made plans to visit Italy. One reason for the journey was his poor health, which he hoped to improve. The other reason was to improve his art because in his early years, his father Laurent de La Hire had given him a love of Italian art. Starting from 1660, the young artist spent about four years attempting to develop his artistic skills and learning geometry. Soon, de La Hire realized that he enjoyed mathematics even more than painting and he began to focus more and more on geometry. By then, La Hire befriended Abraham Bosse, with whom he could share both artistic and mathematical interests. Influenced by Bosse’s work, La Hire began working on conic sections, which he published in 1672. The publication was titled Observations sur les Points d’Attouchement de Trois Lignes Droites qui touchent la Section d’un Cone and it was followed by his famous treatise Nouvelle méthode en géometrie pour les sections des superficies coniques et cylindriques in 1673. According to Taton, the Nouvelle méthode is a comprehensive study of conic sections by means of the projective approach, based on a homology which permits the deduction of the conic sections under examination from a particular circle. In his method, according to Taton, La Hire “provided an exposition of the properties of conic sections. He began with their focal definitions and applied Cartesian analytic geometry the study of equations and the solution of indeterminate problems. He also displayed the Cartesian method for solving certain types of equations by intersections of curves. Although not a work of great originality, it summarises the progress achieved in analytical geometry during half a century and contained some interesting ideas, among them the possible extension of space to more than three dimensions.” In January 1678, La Hire was elected to the Académie des Sciences due to his publications in geometry. It was a great honor for the artist and scientist and he was assigned by Jean-Baptiste Colbert, the French Minister of Finance, to assist Jean Picard in the surveying work in order to create more accurate maps of France. Together, La Hire and Picard worked in Brittany in 1679 and in Guyenne in 1880. La Hire then went, without Jean Picard, to survey around Calais and Dunkirk in 1681 and the coast of Provence in 1682. By that time, La Hire’s work for the Academy was closely linked to the Paris Observatory which had been founded largely due to Colbert. Also in that period, La Hire was appointed to the chair of mathematics at the Collège Royale. He was known to be a great teacher, who put much work in his lectures. Also, La Hire lectured his son in the same way he was educated by his father. His son, eventually joined his father’s teaching activities, which included the fields of mathematics, astronomy, mechanics, hydrostatics, dioptrics, and navigation. Gabriel-Philippe La Hire became the youngest member of the Academy in the seventeenth century. During his career, Philippe de La Hire contributed to many fields of science, even though he always preferred geometry. He published a comprehensive work on conic sections which contained a description of Desargues’ projective geometry in 1685. He calculated the length of the cardioid and wrote about the cycloid, the epicycloid, the conchoid and quatratures. In astronomy he installed the first transit instrument in the Paris Observatory. He also produced tables giving the movements of the Sun, Moon and the planets which he published in 1687, publishing further such tables in 1702. At yovisto, you may learn more about ‘The beautiful math that links coral, crochet and hyperbolic geometry‘ in a video lecture by Margaret Wertheim.'],\n",
       " [282,\n",
       "  'Ulugh Beg – Astronomer.  Ulugh Beg Image: Obaidullah.abrar.  On March 22, 1394, Mongolian astronomer, mathematician and sultan Mīrzā Muhammad Tāraghay bin Shāhrukh, better known as Ulugh Beg was (probably) born. Although the only important Mongol scientist, he was the greatest astronomer of his time. Pursuing this interest he built an observatory at Samarkand. In his observations he discovered a number of errors in the computations of the 2nd-century Alexandrian astronomer Ptolemy, whose figures were still being used. Ulugh Beg was the grandson of the conqueror Timur. After Timur’s death, the empire was disputed among his sons including Skah Rukh, Ulugh Beg’s father. Starting from 1407, he controlled a great part of the empire including Iran and Turkistan regaining control of Samarkand. Two years later, Shah Rukh decided to make Herat in Khorasan his new capital and made it a center of trade and culture while Samarkand was given to Ulugh Beg, who was highly interested in making the city a cultural centre instead of dealing with politics and the military. [1,3] It is believed that already in his early years, Ulugh Beg was interested in science, especially astronomy. He visited the remains of Maragha Observatory in his younger years. [2] However, Ulugh Beg also never neglected the arts, writing poetry himself and studying history. He built a center for higher education, especially mathematics, which was completed in 1420. Ulugh Beg began to appoint the best scientists he could find to positions there as lecturers. [1,2] Al-Kashi became one of the leading figures of the scientific life of Samarkand and in his letters, he praised the mathematical achievements of Ulugh Beg, who led scientific meetings where problems in astronomy were freely discussed. [1] Soon, Ulugh Beg started to built an astronomy at Samarkand and the construnction works probably began in 1428. The observatory was over 35 meters high and 50 meters in diameter. [1,2] The scientists working at the observatory were able to find methods for giving accurate approximate solutions of cubic equations and work with the binomial theorem. Also, Ulugh Beg’s accurate tables of sines and tangents correct to eight decimal places were established and formulae of spherical trigonometry were found. Further, Ulugh Beg’s Catalogue of the stars, the first comprehensive stellar catalogue since that of Ptolemy counts to one of their greatest achievements. [1] The star catalogue, the Zij-i Sultani, was published in 1437 and gives the positions of almost 1000 stars. The catalogue was accomplished by Ulugh Beg himself, al-Kashi, and Qadi Zada. The work contained tables of observations made at the Observatory, calendar calculations and results in trigonometry. Further, several mistakes in the calculations of Ptolemy were found and with the help of the new findings, Ulugh Beg was able to calculate the length of the year as 365 days 5 hours 49 minutes 15 seconds. [1,2] Unfortunately, after the death of Ulugh Beg’s father in 1447, he could not retain power and was put to death. In 1941, his tomb was discovered in the mausoleum built by Timur in Samarkand. [1,3] At yovisto you can learn more about today’s telescope technologies in a lecture by Roy Gould.'],\n",
       " [283,\n",
       "  'Georg Friedrich Philipp von Hardenberg aka Novalis.  Georg Philipp Friedrich Freiherr von Hardenberg (1772-1801). On March 25, 1801, poet, author, and philosopher of early German Romanticism Georg Philipp Friedrich Freiherr von Hardenberg, better known under his pen name Novalis passed away. In spite of his early death at age 28, Novalis left behind a complex philosophical legacy that encompasses discussions of subjectivity and self-consciousness, issues in epistemology, moral theory, political philosophy, problems of interpretation, philosophy of history, philosophy of religion, the proto-existentialist experience of the finality of human life, as well as a significant contribution to aesthetics and philosophy of art. Georg Philipp Friedrich von Hardenberg was born in 1772 at Oberwiederstedt manor, now part of Arnstein, Saxony-Anhalt, in the Harz mountains, as second of eleven children to his strictly pietistic father Heinrich Ulrich Erasmus Freiherr von Hardenberg, descended from ancient, Low German nobility. He spent his childhood on the family estate and used it as the starting point for his travels into the Harz mountains. First taught by private tutors, he attended the Lutheran grammar school in Eisleben. From the age of twelve, he moved to the home of his uncle, Gottlob Friedrich Wilhelm von Hardenberg, who is said to have taken an interest in French enlightenment philosophy. From 1790 to 1794, he studied law at Jena, Leipzig and Wittenberg, where he passed his exams with distinction. In Jena, he attended the lectures of Friedrich Schiller on history and later befriended Schiller during his illness. During these years, he also met Johann Wolfgang Goethe, Johann Gottfried Herder as well as Jean Paul, and made close friends with Ludwig Tieck, the brothers Friedrich and August Wilhelm Schlegel and Friedrich Wilhelm Joseph Schelling. Von Hardenberg passed his final exams in 1794 and moved on to work in the Prussian civil service in Tennstedt, where he also met the young Sophie von Kühn, with whom he got secretly engaged in 1795. Two years later, Sophie tragically died at the age of fifteen, an event that would move a whole generation of poets and artists in Germany, including Goethe.[1] Following in his father, von Hardenberg commenced his studies of mining in Freiberg, Saxony, and eventually took up an administrative position at the salt mines in Weißenfels, where he advanced to director of the salt mines. Until 1796, von Hardenberg concerned himself with the scientific teachings of Johann Gottlieb Fichte, which greatly influenced his world view. He even extended Fichte’s philosophic concepts by transforming Fichte’s Nicht-Ich (German “not I”) to a Du (“you”), an equal subject to the Ich (“I”). This was the starting point for von Hardenberg’s Liebesreligion (“religion of love”). Von Hardenberg’s first fragments were published in 1798 in the Athenäum, a magazine edited by the brothers Schlegel, who were also part of the early German Romantic movement. His first publication was entitled Blüthenstaub (Pollen), a collection of 114 aesthetic-philosophical fragments and reflections, and saw the first appearance of his pen name “Novalis” – referring back to an old family name while, all the same, conveying the meaning of “the one who clears new ground”.[1] Still deeply affected by the death of his young fiancee Sophie von Kühn, Novalis began his Hymnen an die Nacht (Hymns to the Night), which were published in 1800. In these six prose poems interspersed with verse he recounted his experience of Sophie’s death. He celebrates night, or death, as an entry into a higher life in the presence of God and his conversion to a kind of Christian mysticism in which he longed for his own death in order to be reunited with his beloved. Novalis became engaged for the second time in December 1798 with Julie von Charpentier. Unfortunately, he lived long enough to see the publication only of his works. His unfinished novels Heinrich von Ofterdingen and The Novices at Sais, his political speech Christendom or Europa, and numerous other notes and fragments were published posthumously by his friends Ludwig Tieck and Friedrich Schlegel. “..to philosophize is to throw off apathy, to become revived.” (Novalis, Studies in the History of the Renaissance) On the December 6, 1800, the twenty-eight-year-old Novalis was appointed “Supernumerar-Amtshauptmann” for the district of Thuringia, a position comparable to that of a present-day magistrate. But from August onward, he suffered from tuberculosis, and on March 25, 1801, he died in Weißenfels. Novalis’s last years were incredibly creative, filled with encyclopaedic studies, the draft of a philosophical system based on idealism, and poetic work. His mythical romance Heinrich von Ofterdingen, set in an idealized vision of the European Middle Ages, describes the mystical and romantic searchings of a young poet. The central image of his visions, a blue flower, became a widely recognized symbol of Romantic longing among Novalis’s fellow Romantics. [3] The core of Novalis’ literary works is the quest for the connection of science and poetry, and the result was supposed to be a “progressive universal poesy”. He was convinced that philosophy and the higher-ranking poetry have to be continually related to each other. Novalis’ poetry and writings were also an influence on Hermann Hesse. Moreover, he also influenced indirectly C. S. Lewis, the Inklings, and the whole modern fantasy genre with his work. At yovisto you can learn more about a fellow author of early German Romanticism, Friedrich Hölderlin, in the presentation of Prof. Richard Capobianco on “Heidegger on Hölderlin’s ‘Nature Gleaming’“.'],\n",
       " [284,\n",
       "  'Aristarchus of Samos and the Heliocentric System.  Aristarchus’s 3rd-century BC calculations on the relative sizes of the Sun, Earth and Moon   About 310 BC, ancient Greek astronomer and mathematician Aristarchus of Samos was born. He presented the first known model that placed the Sun at the center of the known universe with the Earth revolving around it. As Anaxagoras before him, he also suspected that the stars were just other bodies like the sun. His astronomical ideas were often rejected in favor of the geocentric theories of Aristotle and Ptolemy. Apparently, Aristarchus of Samos was a student of, who was head of Aristotle’s Lyceum. It is not clear however, that Aristarchus studied with Strato in Athens but rather that he studied with him in Alexandria. Aristarchus is mostly mentioned by Vitruvius, who was famous as a Roman architect and engineer, and the author of the important treatise ‘De architectura’. In this work Vitruvius lists men who have been knowledgeable across all branches of science: Men of this type are rare, men such as were, in past times, Aristarchus of Samos, Philolaus and Archytas of Tarentum, Apollonius of Perga, Eratosthenes of Cyrene, Archimedes and Scopinas of Syracuse, who left to posterity many mechanical and gnomonic appliances which they invented and explained on mathematical principles. Vitruvius also explains that Aristarchus invented a “sundial in the shape of a hemispherical bowl with a pointer to cast shadows placed in the middle of the bowl”. However, there are no clear evidences concerning the origin of Aristarchus’s belief in a heliocentric system. The greeks had not accepted the hypothesis and therefore, it never gained enough popularity. Apparently, historians only found out about Aristarchus’s believes through Archimedes. As Archimedes reported Aristarchus’ views, he also criticized them with “mathematically meaningless proportions”.[1] During the 4th century BC, Plato and Aristotle defended the geocentric model but both philosophers did so using mostly mystical and mythical arguments. The stars and planets were carried around the Earth on spheres, arranged in a concentric fashion. Plato even described the “universe as the Spindle of Necessity, attended by the Sirens and turned by the three Fates”. Plato explained that natural laws could not account for all the changes in the universe. Plutarch also wrote about Aristarchus, saying that he probably followed Heraclides of Pontus’  believes that the daily rotation of the fixed stars was a result of the rotation of the Earth on its axis. [2] It is suggested that there is only one surviving work of Aristarchus: “On the Sizes and Distances of the Sun and Moon”. However, the publication is not based on the sun centred theory. Also, the work in which Aristarchus probably described his theory on a heliocentric system is lost. “On the Sizes and Distances of the Sun and Moon” states that Sun was about 20 times as distant from the Earth as the Moon, and 20 times the Moon’s size. These estaimates were too small, which was probably the result of inaccurate instruments. It is believed that his work was published before Aristarchus adapted the believe of a heliocentric system. [1,2,3] It is not clear if Aristarchus sticked with his believe of the heliocentric system after most astronomers had rejected the theory. Hipparchus of Nicea was one of the most respected Greek astronomers, who concluded that the geocentric model better explained the observations than did the model of Aristarchus. It was found that the only way that Aristarchus’ theory could stand mathematical analysis was by supposing an elliptical orbit of the Earth, an assumption that was not accepted in the community.[2] At yovisto you may learn more about ‘Voyages to the Outer Solar System‘ in a lecture by Ian Morrison.'],\n",
       " [285,\n",
       "  'Hippolyte Fizeau and the Speed of Light.  Hippolyte Fizeau (1819-1896). photo: Charles Reutlinger, Académie des Sciences, Smithsonian Institution Libraries On September 23, 1819, French physicist Armand Hippolyte Louis Fizeau was born. He is well known for his calculation of the speed of light and his suggestion to use length of a light wave be used as a length standard. Hippolyte Fizeau was born in Paris as the eldest son of Béatrice and Louis Fizeau, who was professor of Pathology at the Paris Medical School. He attended the prestigious Collège Stanislas in Paris where he became a friend with one of his fellow students, Léon Foucault. In September 1839. Famous Louis Daguerre put on a free course on his new photographic techniques in Paris and the two friends Fizeau and Foucault attended. They watched Daguerre expose a plate in a camera pointing out the window, then after talking about his process for about 30 minutes, he developed the plate using a variety of chemicals to reveal the picture. Although Fizeau and Foucault were impressed they also realised the limitations of the process – it would be wonderful to be able to take portraits, they thought, but the subject could not be expected to remain motionless for 30 minutes. After the course ended they began to experiment to try to speed up the process. [1] Fizeau entered the Paris Medical School in 1840, but he soon gave up on medicine because of severe migraines and spent some time travelling during which time he regained his health. His new focus of attention should be physics. He attended Arago‘s lectures at the Observatory, and enrolled in a course on optics at the Collège de France. Furthermore, he began to deeply study notebooks containing the lecture notes taken by his brother who attended courses at the École Polytechnique. It was Arago, who encouraged Fizeau and Foucault in 1845 and suggested that they might attempt to make photographs of an image of the sun produced by a telescope. Thus, Fizeau and Foucault produced what is considered the first astronomical photography. It was in the field of optics that Fizeau earned a lasting reputation. The original inspiration came from François Arago, who looked for a decisive test between the corpuscular and wave theories of light. If the wave theory was true, the velocity of light had to be greater in moving media, such as water flowing in a tube. The project implied the working out of a terrestrial method of measuring the speed of light, and Arago suggested that this could be done by using a rotating mirror.[2] In 1849, Fizeau calculated a value for the speed of light more precise than the previous value determined by Ole Rømer in 1676. He used a beam of light reflected from a mirror eight kilometers away. The beam passed through the gaps between teeth of a rapidly rotating wheel. The speed of the wheel was increased until the returning light passed through the next gap and could be seen. Fizeau calculated the speed of light to be 313,300 kilometres per second, which was within about five percent of the correct value (299,792.458 kilometers per second). Fizeau published the first results obtained by his method for determining the speed of light in 1849. In 1851 he carried out a series of experiments in an attempt to detect the luminiferous ether—a hypothetical material that was thought to occupy all of space and to be necessary for carrying the vibrations of light waves. The experimental results failed to demonstrate the existence of the ether, but his work helped lead to the discarding of the ether theory in the early years of the 20th century.[3] Fizeau was elected a member of the Academy of Sciences in 1860, an a member of the Bureau des Longitudes in 1878. He received the decoration of the Legion of Honour in 1849 and became officer in 1875. In 1866 the Royal Society of London awarded him the Rumford Medal. At yovisto you can learn more about the physics behind the speed of light in the NASA documentary ‘Einsteins Cosmic Speed Limit‘.'],\n",
       " [286,\n",
       "  'James Dewar and the Liquefaction of Gases.  Sir James Dewar (1842-1923). On September 1842, Scottish chemist and physicist Sir James Dewar was born. He is probably best-known today for his invention of the Dewar flask, which he used in conjunction with extensive research into the liquefaction of gases. James Dewar was born in Kincardine, Fife, Scotland, in 1842, the youngest of six boys. He lost his parents at the age of 15. He was educated at Dollar Academy and the University of Edinburgh, where he studied under Lord Playfair, a famous Scottish scientist and Liberal politician, whose assistant he later became. Dewar would also study under August Kekulé at Ghent. In 1875, Dewar was elected Jacksonian professor of natural experimental philosophy at the University of Cambridge and became a member of the Royal Institution. In 1877, he replaced Dr. John Hall Gladstone in the role of Fullerian Professor of Chemistry in 1877. Dewar was also the President of the Chemical Society in 1897 and the British Association for the Advancement of Science in 1902, as well as serving on the Royal Commission established to examine London‘s water supply from 1893 to 1894 and the Committee on Explosives. It was whilst he was serving on the Committee on Explosives that he and Frederick Augustus Abel developed cordite, a smokeless gunpowder alternative. Dewar‘s scientific work covers a wide field and his earlier papers cover a wide range of topics; organic chemistry, Hydrogen and its physical constants, high temperature research, the temperature of the sun and of the electric spark, electro-photometry and the chemistry of the electric arc. In 1867 he described several chemical formulas for benzene. Ironically, one of the formulae, which does not represent benzene correctly and was not advocated by Dewar, is sometimes still called Dewar benzene. Dewar investigated the physiological action of light, and examined the changes which take place in the electrical condition of the retina under its influence. In 1878 a long series of spectroscopic observations, the later of which were devoted to the spectroscopic examination of various gaseous elements separated from atmospheric air by the aid of low temperatures. Dewar is most widely known in connection with his work on the liquefaction of the so-called permanent gases and his researches at temperatures approaching absolute zero. In 1877, Louis Cailletet and Raoul Pictet independently were able to create small amounts of oxygen and nitrogen in liquid form at temperatures less than 80° above absolute zero, a feat even Michael Faraday, who had liquified most of the known gases by 1845, had been unable to carry out.[1] In 1878 he devoted a Friday evening lecture at the Royal Institution to the then recent work of Cailletet and Pictet, and exhibited for the first time in Great Britain the working of the Cailletet apparatus. Six years later, again at the Royal Institution, he described the researches of Zygmunt Florenty Wróblewski and Karol Olszewski, and illustrated for the first time in public the liquefaction of oxygen and air. Soon afterwards he built a machine from which the liquefied gas could be drawn off through a valve for use as a cooling agent, before using the liquid oxygen in research work related to meteorites; about the same time he also obtained oxygen in the solid state. The greatest stumbling block he encountered in his work with liquification was keeping the gases cold long enough to study them. Liquid oxygen kept in a flask absorbed heat from the surrounding air and returned to its gaseous phase. To eliminate the effect of the warm air, Dewar put the flask of liquid gas inside a larger flask and created a vacuum between them. A vacuum would prevent the transfer of energy that occurred through conduction or convection; heat would not penetrate and cold would not escape. To eliminate the transfer of radiant energy, Dewar silvered the walls of the flasks so they would reflect, rather than absorb, energy. He also invented a technique to create a more efficient vacuum.[1] Dewar found that charcoal eats gas at low temperatures. So he placed a bit of charcoal in the gap; then evacuated it as best he could. When cold liquid gas filled the tank, the charcoal removed the remaining air from the wall space, and made the insulation nearly perfect.[2] James Dewar died in London in 1923, still holding the office of Fullerian Professor of Chemistry at the Royal Institution, having refused to retire. At yovisto, you can earn a better understanding of temperature in the laws of physics and chemistry in the lecture of Prof. Gerbrand Ceder from Massachussetts Institute of Technology on Atomistic Computer Modeling of Materials.'],\n",
       " [287,\n",
       "  'How Ötzi became World Famous.  Stereolithografic Model of Ötzi Image: Flominator.  On September 19, 1991, two German tourist found a corpse on the east ridge of the Fineilspitze in the Ötztal Alps on the Austrian–Italian border. The corpse turned out to be a well-preserved natural mummy of a man who lived around 3,300 BCE, which has become famous under the name “Ötzi“. On 19 September 1991, Ötzi was found by two German tourists in the Ötztal Alps on the Austrian–Italian border, believing that the body was of a recently deceased mountaineer. When a mountain gendarme and the keeper of the nearby Similaunhütte first attempted to remove the body, it was frozen in ice below the torso. It took about three days to completely extract the body from the ice and transport it to he University of Innsbruck, where it was recognized to be primeval the same day of its arrival. The body and the items found with the body were then examined, measured, X-rayed, and dated. It was found that Ötzi was about 1.65m and weighed about 50kg. The body was only partially deteriorated and after the analysis of the tooth enamel, the scientists concluded that Ötzi spent his childhood near the present village of Feldthurns, north of Bolzano, but later went to live in valleys about 50 kilometres farther north. It was also assumed that Ötzi was involved in copper smelting during his lifetime and that he performed long walks over hilly terrain, which was not characteristic of other Copper Age Europeans. It was then assumed that Ötzi was rather a high-altitude shepherd. A facial reconstruction has been performed with the help of 3D technologies. They figured out that Ötzi was quite old looking for his 45 years and that he had deep-set brown eyes, a beard, a furrowed face, and sunken cheeks. He is also depicted looking tired and ungroomed. It is believed that Ötzi had an intestinal parasite and that he was sick sick three times in the six months before he died. DNA analysis in February 2012 revealed that Ötzi was lactose intolerant, supporting the theory that lactose intolerance was still common at that time, despite the increasing spread of agriculture and dairying. The items found with Ötzi were a copper axe with a yew handle, a flint-bladed knife with an ash handle and a quiver of 14 arrows with viburnum and dogwood shafts. Also, he had berries with him, two birch bark baskets, and two species of polypore mushrooms with leather strings through them. One of these, the birch fungus, is known to have antibacterial properties, and was probably used for medicinal purposes. The other was a type of tinder fungus, included with part of what appeared to be a complex firestarting kit. The kit featured pieces of over a dozen different plants, in addition to flint and pyrite for creating sparks. At yovisto, you may be interested in a video lecture on ‘Great Riddles in Archaeology Lecture Series: Ötzi the Iceman‘ by Dr. Thomas Tartaron at Penn Museum.'],\n",
       " [288,\n",
       "  'Legendre’s Elements of Geometry.  1820 watercolor portrait of French mathematicians Adrien-Marie Legendre and Joseph Fourier.  On September 18, 1752, French mathematician Adrien-Marie Legendre was born. He is best known for his contributions in number theory, celestial mechanics and elliptic functions. It was in a paper on celestial mechanics concerning the motion of planets (1784) that he first introduced the Legendre Polynomials. Moreover, he served as director of the of the Bureau des Longitudes, standardizing French weights and measures. Adrien-Marie Legendre was born in Paris to a pretty wealthy family. He was admitted to the Collège Mazarin in Paris, and defended his thesis in physics and mathematics in 1770. Afterwards, he continued his career as a teacher at various institutions. In 1782, the Berlin Academy awarded Legendre a prize for his treatise on projectiles in resistant media. He became a member of the Académie des Sciences in 1783 and an associé in 1785. In 1789 he was elected a Fellow of the Royal Society. From 1799 to 1815, Legendre served as mathematics examiner for graduating artillery students at the École Militaire and was made an officer of the Légion d’Honneur. Legendre developed the least squares method, which has broad application in linear regression, signal processing, statistics, and curve fitting. This word was published in 1806 as part of his book on the paths of comets. In 1830 he gave a proof of Fermat‘s last theorem for exponent n = 5, which was also proven by Lejeune Dirichlet two years earlier. Legendre conjectured the quadratic reciprocity law which was subsequently proved by Gauss and he pioneered with several works on the distribution of primes, and on the application of analysis to number theory. His 1798 conjecture of the Prime number theorem was rigorously proved by Hadamard and de la Vallée-Poussin in 1896. The scientist became known for the Legendre transformation, which is used to go from the Lagrangian to the Hamiltonian formulation of classical mechanics. In thermodynamics it is also used to obtain the enthalpy and the Helmholtz and Gibbs energies from the internal energy. His best known work remains Éléments de géométrie which was published in 1794 and was the leading elementary text on the topic for around 100 years. At yovisto, you may be interested in a video lecture on ‘From one to many geometries‘ by Professor Flood at Gresham College.'],\n",
       " [289,\n",
       "  'John Goodricke and the Variable Star of Beta Persei.  (1764 – 1786) Source: Sky and Telescope (November, 1978).  On September 17, 1764, English amateur astronomer John Goodricke was born. He is best known for his observations of the variable star Algol (Beta Persei) in 1782. He was also first to correctly propose that the distant sun is periodically occulted by a dark body. Not much is known about John Goodricke. Clear is only that the astronomer was deaf and passed away very early at the age of only 21. He was the son of a British diplomat and a dutch merchant daughter. At the age of 5, Goodricke lost his hearing abilities as a result of scarlet fever, but after a decent education he was able to read lips and to speak. In order to achieve this, Goodricke was sent to a special school in Edinburgh. When he was 13, the young Goodricke was able to attend a regular school near York and school reports describe Goodricke as “a very tolerable classic and an excellent mathematician“. Goodricke‘s notebooks from Warrington reveal that he was already observing the sky at the age of 15. [1,2] His motivation to start studying astronomy came from his tutor William Enfield. However, most of his observations were performed along with his cousin and mentor Edward Pigott. Together they discovered and measured the variation of light from stars that would years later, in the 20th Century, enable astronomers to determine distances to distant galaxies. According to Goodricke‘s observations, it is believed that he was the first to calculate the period of Algol to 68 hours and 50 minutes, where the star was changing its brightness by more than a magnitude as seen from Earth. [1] The astronomer reported his observations in 1783 at the British Royal Society, and he proposed two theories in order to explain his findings. The first was that the distant sun is periodically occulted by a dark body, or that the star itself has a darker region which is directing to Earth periodically because of the star rotation. For his part in this work, the Royal Society of London awarded Goodricke the Copley Medal, its highest honour, at the age of 19. He remains the youngest recipient of the award. [1,2] At yovisto, you may be interested in a video lecture on Exploding Stars by Prof. Dr. Alex Filippenko at the University of Berkeley.'],\n",
       " [290,\n",
       "  'Bernard Siegfried Albinus and his Anatomic Works.  Bernhard Siegfried Albinus: Tabulae sceleti et musculorum corporis humani. London 1749. On September 9, 1770, German anatomist Bernard Siegfried Albinus passed away. He was the first to show the connection of the vascular systems of the mother and the fetus. He is best known for the excellent drawings in his Tabulae sceleti et musculorum corporis humani (1747; “Tables of the Skeleton and Muscles of the Human Body”). Bernard Siegfried Weiss was born in Frankfurt (Oder), Germany. Already his father was professor for medical science at the local university and was offered a new position in Leiden. The young Bernard Siegfried Weiss, who later on called himself ‘Albinus‘, was very well educated in Leiden and excelled in his studies. He was allowed to enter the university at the age of 12. Albinus finished his education in Leiden around 1718 and moved to Paris in order to study anatomy and botany. However, Albinus was told to return to Leiden one year later in order to start his position as teacher of anatomy and surgery. Also, the scientist received his doctoral degree in the same year. After the death of his father, Albinus was appointed professor at Leiden and he became one of the best known and most appreciated teachers in the field of anatomy in Europe. During his time in Leiden, Albinus came in contact with Jan Wandelaar, an artist and engraver. It was this collaboration and the art of Jan Wandelaar which have made Albinus’ books and illustration famous. Even though Albinus was often criticized for the luscious, detailed, and sometimes strange backgrounds of his anatomical images, the scientist defended the extraordinary art work of Wandelaar. Both dedicated their professional career to the faithful reproduction of anatomy in their publications, developing a grid system to reduce errors in production and printing. To Albinus‘ most famous publications belong “Historia muscolorum hominis” from 1734,  “Icones ossium foetus humani” from 1737, and “Tabulae sceleti et musculorum corporis humani” from 1749. Albinus received numerous offers to start teaching and researching across Europe, but always stayed in Leiden. He was elected to join the Royal Society in 1764 and passed away six years later. At yovisto, you may be interested in the Anatomy lecture by Professor Meighan at Berkeley.'],\n",
       " [291,\n",
       "  'August Wilhelm Schlegel and his Shakespeare Translations.  August Wilhelm Schlegel (1767 – 1845).  On September 8, 1767, German poet, translator, and critic August Wilhelm Schlegel was born, who became a foremost leader of German Romanticism. He is best known for his translations of Shakespeare‘s works into German. August Wilhelm Schlegel attended the school in Hannover, followed by the University of Göttingen, where he enrolled in 1787. At first, he studied theology, changing to classical philology and aesthetics later on. After Schlegel had worked in Amsterdam for a while as a teacher, he moved to Jena in order to work as a literary critic and write for Friedrich Schiller’s short-lived periodical Die Horen. He married in 1896 and his wife, Caroline Michaelis, highly motivated him to start his projects translating Shakespeare‘s plays, in which she also participated. In 1798, August Wilhelm and his brother Friedrich Schlegel founded the famous Athenaeum, being tired of the publishing troubles back then. The brothers were both, editors and main writers of the journal and they managed to become one of the German Romantic Movement‘s principal voices. The Athenaeum was devoted mainly to literary criticism with a philological and historical perspective, and a large section of it featured the review of contemporary literature. It contained critical essays, fragments, letters, announcements and dialogues and appeared twice a year between 1798 and 1800 [1,3]. Also in 1798, Schlegel was appointed professor at the University of Jena and there, he had the chance to continue his translation of the works of Shakespeare. Schlegel managed to translated over 16 Shakespearean plays, five plays from the Spanish dramaturge Calderón de la Barca, and other selected pieces from Dante, Petrarch, Giovanni Boccaccio, Miguel de Cervantes, Torquato Tasso, and Luís de Camões which were published in 1804 as “Blumensträusse italiänischer, spanischer, und portugiesischer Poesie” (Bouquets of Italian, Spanish, and Portuguese Poetry) [2]. The poet, translator, and critic also became well known for his great teaching abilities. Schlegel moved to Berlin in the early 19th century and his lectures were highly didactic while at the same time interspersed with important philosophical insights. Some of his lectures were later on also published in literary journals. In 1818, Schlegel was appointed professor of literature and art history in Bonn, where he published the scholarly journal ‘Indische Bibliothek’ and set up a Sanskrit printing press with which he provided the first printed editions of the Bhagavadg?t? and R?m?yana in continental Europe [1]. The rediscovery of Shakespeare‘s greatness in the 19th century was due, not only to Schlegel‘s translations, but most importantly to his special approach to Shakespearean theatre. Schlegel claimed that it should be analyzed on the grounds of constituting a necessary historical difference. This difference between the ancients and the modern was the cornerstone of Schlegel‘s critique and set the basis for his theoretical use of the concept Romantic, which became the key-concept in his comprehension and reevaluation of modernity [1]. At yovisto, you may be interested in a short video documentation about William Shakespeare.'],\n",
       " [292,\n",
       "  'John Dalton and the Atomic Theory.  John Dalton (1766-1844). On September 6, 1766, English chemist, meteorologist and physicist John Dalton was born. He is best known for his pioneering work in the development of modern atomic theory, and his research into colour blindness. He also recognised that the aurora borealis was an electrical phenomenon. John Dalton was born into a Quaker family at Eaglesfield, near Cockermouth, Cumberland, England, as son of a handloom weaver. Both he and his brother were born color-blind. After attending a Quaker school in his village in Cumberland, when Dalton was just 12 years old he started teaching there. Around 1790 Dalton seems to have considered taking up law or medicine, but his projects were not met with encouragement from his relatives – Dissenters were barred from attending or teaching at English universities. In 1793, he moved to Manchester and Dalton was appointed teacher of mathematics and natural philosophy at the “New College” in Manchester, a dissenting academy. He remained in that position until 1800, when the college’s worsening financial situation led him to resign his post and begin a new career as a private tutor for mathematics and natural philosophy. For one of his first research projects, Dalton pursued his avid interest in meteorology. He started keeping daily logs of the weather, paying special attention to details such as wind velocity and barometric pressure—a habit Dalton would continue all of his life.[1] He upheld the view, against contemporary opinion, that the atmosphere was a physical mixture of approximately 80 percent nitrogen and 20 percent oxygen rather than being a specific compound of elements. He measured the capacity of the air to absorb water vapor and defined partial pressure in terms of a physical law whereby every constituent in a mixture of gases exerted the same pressure it would have if it had been the only gas present.[2] Soon after his arrival at Manchester, Dalton was elected a member of the Manchester Literary and Philosophical Society. His first contribution to this society was a description of the defect he had discovered in his own and his brother’s vision. This paper was the first publication on color blindness, which for some time thereafter was known as Daltonism.[2] In 1803, he calculated atomic weights of chemical elements and assembled them in a table which consisted of six elements namely hydrogen, oxygen, nitrogen, carbon, sulfur, and phosphorus. He calculated these weights from percentage compositions of compounds using an arbitrary system to determine the probable atomic structure of each compound.[3] John Dalton’s Atomic theory has three principles that remain relatively unchanged. First, Elements are made of the smallest indivisible particles called atoms. Second, all atoms for a particular element are identical. Third, atoms of different elements can be told apart by their atomic weight. Fourth, atoms of different elements can combine in a chemical reaction to form chemical compounds in fixed ratios. Finally, atoms can not be created, destroyed, or divided as they are the smallest particles of matter.[3] In 1810, Sir Humphry Davy asked Dalton to offer himself as a candidate for the fellowship of the Royal Society, but Dalton declined, possibly for financial reasons. However, in 1822 he was proposed without his knowledge, and on election paid the usual fee. Dalton suffered a minor stroke in 1837, and a second one in 1838 left him with a speech impediment, though he remained able to do experiments. In May 1844 he had yet another stroke; on 26 July he recorded with trembling hand his last meteorological observation. One day later, Dalton fell from his bed and was found lifeless by his attendant. At yovisto, you can learn more about Dalton’s model of the atom in the lecture of MIT Prof. Donald Sadoway on ‘Introduction into Solid State Chemistry‘.'],\n",
       " [293,\n",
       "  'The Works of Heinrich Mann.  Heinrich Mann (1871-1950). On March 27, 1871, German novelist Luiz (Ludwig) Heinrich Mann was born. Being the elder brother of Nobel laureate Thomas Mann, he wrote works with strong social themes. His numerous criticisms of the growth of fascism forced him to flee for his life after the Nazis came to power in 1933. His book “Professor Unrat” was freely adapted into the legendary movie “Der Blaue Engel” starring Marlene Dietrich in her first major role. Heinrich Mann was born in Lübeck, as the oldest child of Thomas Johann Heinrich Mann and Júlia da Silva Bruhns. His father came from a bourgeois family of grain merchants and was a Senator for economics and finance of the Hanseatic city of Lübeck. Already as a young man, Heinrich Mann suffered from a lung disease, hemoptysis, and spent time in sanatoria and at health resorts. [1] After graduating from the Gymnasium, Heinrich Mann began an apprenticeship as a bookseller in Dresden, and in 1891/1892 Mann did his voluntary service at the S. Fischer publishing house in Berlin. After the death of his father, the family moved to Munich in 1903, while Heinrich, now being financially independent, studied at the Friedrich Wilhelm University in Berlin and began his career as a freier Schriftsteller or free novelist. At first a disciple of the French realists, especially Émile Zola and Guy de Maupassant, he wrote impressions, sketches, novelettes, and some poetry. His first novel, In einer Familie (In a Family, 1894), was published at his mother’s expense. It was as a reviewer that he made a name for himself from 1891 to 1896. Heinrich Mann’s first creative phase, from 1900 to 1914, began with a realistic, even naturalistic novel entitled Im Schlaraffenland (In the Land of Cockaigne, 1900) portraying the decadence of high society. In 1903, his most productive year, two more novels folowed, Die Göttinnen (Diana, 1903), a glorification of estheticism, and Die Jagd nach Liebe (Pursuit of Love, 1903), another novel of decadence.[2] Film Poster, The Blue Angel (1930) Heinrich Mann’s merciless portrait of a tyrannical provincial schoolmaster, Professor Unrat (Small Town Tyrant, 1905), became widely known through its film version Der blaue Engel (The Blue Angel, 1928), directed by Josef von Sternberg and starring Emil Jannings, Marlene Dietrich and Kurt Gerron. Originally, Heinrich Mann wanted his girlfriend, the actress Trude Hesterberg, to play the lead, but instead Marlene Dietrich was given her first sound role as the “actress” Lola Lola, which was the beginning of her world career. The novel earned Heinrich Mann also much respect during the Weimar Republic, since it satirized German society and explained how its political system had led to the First World War. His Kaiserreich trilogy consisting of Die Armen (The Poor, 1917); Der Untertan (The Patrioteer, 1918); and Der Kopf (The Chief, 1925) carries even further his indictment of the social types produced by the authoritarian state.[3] Heinrich Mann was devastated in 1910 when his sister, Clara Mann, took her own life. Two years later, Mann married the actress Maria Kanová from Prague. When his brother Thomas Mann, in Gedanken im Kriege (1915, Thoughts in War), expressed support for the war, Heinrich Mann cut off all contact with him. It was in 1922, fostered by Thomas Mann’s wife Katja, that the two brothers reconciled. After 1918 Mann became a prominent spokesman for democracy. Together with Albert Einstein and other celebrities, Heinrich Mann was a signatory to an open letter in the New York Times condemning the murder of Croatian scholar Dr Milan Šufflay in 1931. In the same year, Heinrich Mann became the president of the poetry department of the Prussian Academy of the Art, which was closed two years later on account of Mann’s political activities, which included signing the appeal to the Communist Party of Germany and the Social Democratic Party of Germany against the National Socialists. Mann became persona non grata in Nazi Germany and left even before the Reichstag fire in 1933. He first went to France where he lived in Paris and Nice. During the German occupation he made his way through collaborationist Vichy France to Marseille where he succeeded to escape to Spain and further to Portugal and then to America. The Nazis burnt Heinrich Mann’s books as “contrary to the German spirit” during the infamous book burning of May 10, 1933, which was instigated by propaganda minister Joseph Goebbels. During the 1930s and later in American exile, Heinrich Mann’s literary popularity went downhill. Nevertheless, from 1935 to 1938 he wrote Die Jugend des Königs Henri Quatre (Young Henry of Navarre) and Die Vollendung des Königs Henri Quatre (Henri Quatre: King of Franc) as part of the Exilliteratur. The two novels sketched the life and importance of Henry IV of France and were acclaimed by his brother Thomas Mann. The plot, based on Europe’s early modern history from a French perspective, anticipated the end of French–German enmity. In 1939, Heinrich Mann married his second wife Nelly Kröger, who suffered from mental illness and committed suicide in 1944 while the Manns’ were living in California. During the emigration, became chairman of the Preparatory Commission of the German Popular Front and was named honorary president of the exiled Social Democratic Party of Germany. Heinrich Mann died in Santa Monica, California, lonely and without much money, just months before he was to move to East Berlin to become president of the German Academy of Arts. At yovisto you can learn more about Heinrich Mann’s famous brother Thomas Mann in a seminar by the Goethe Institute Boston on Thomas Mann and his Stories.'],\n",
       " [294,\n",
       "  'The Visions of Emanuel Swedenborg.  Emanuel Swedenborg (1688-1772). On March 29, 1772, Swedish scientist, philosopher, theologian, and mystic Emanuel Swedenborg passed away. He is best known for his book on the afterlife, Heaven and Hell (1758). From Swedenborg’s inventive and mechanical genius came his method of finding terrestrial longitude by the Moon, new methods of constructing docks and even tentative suggestions for the submarine and the airplane. Swedenborg had a prolific career as an inventor and scientist. In 1741, at age 53, he entered into a spiritual phase, in which for the remaining 28 years of his life, he wrote more or less theological works. Emanuel Swedenborg was born as Emanuel Swedberg was born on January 29, 1688, as third of nine children to his father Jesper Swedberg, who descended from a wealthy mining family, and Sarah Behm Swedberg. Jesper Swedberg took interest in the beliefs of the dissenting Lutheran Pietist movement, which emphasized the virtues of communion with God rather than relying on sheer faith. While controversial, the beliefs were to have a major impact on his son Emanuel’s spirituality. Jesper Swedberg would later become professor of theology at Uppsala University and Bishop of Skara. From 1703 to 1709 Swedenborg lived in the house of Erik Benzelius the younger, a prominent priest, theologian, librarian, and one of Sweden’s important Enlightenment figures. Swedenborg completed his university courses at Uppsala in 1709, where he studied mechanics, geography, astronomy, and mathematics. In 1710, he started his grand tour through the Netherlands, France, and Germany, before reaching London, where he would spend the next four years, studying physics, mechanics and philosophy and read and wrote poetry. In 1715 Swedenborg returned to Sweden, where he devoted himself to natural science and engineering projects for the next two decades. A first step was his meeting with King Charles XII of Sweden in Lund, in 1716. The Swedish inventor Christopher Polhem, who became a close friend of Swedenborg, was also present. Swedenborg’s purpose was to persuade the king to fund an observatory in northern Sweden. However, the king did not consider this project important enough, but did appoint Swedenborg assessor-extraordinary on the Swedish Board of Mines (Bergskollegium) in Stockholm. For the next 30 years, Swedenborg’s main work was concentrated in the Swedish metal-mining industry. His engineering skill earned him a wide reputation.[1] From 1716 to 1718, Swedenborg published a scientific periodical entitled Daedalus Hyperboreus (The Northern Daedalus), a record of mechanical and mathematical inventions and discoveries. One notable description was that of a flying machine, the same he had already been sketching a few years earlier. In 1718, he published an article that attempted to explain spiritual and mental events in terms of minute vibrations or “tremulations”. In 1719, the family name was changed to Swedenborg when the family was ennobled. The Flying Machine, sketched in Swedenborg’s notebook from 1714. In 1721, Swedenborg issued a voluminous work in which he attempted to demonstrate the geometrical character of physics and chemistry. He spent the next 13 years researching and writing a three-volume work on the nature of physics, Opera philosophica et mineralia, published at Leipzig in 1734, where he tries to conjoin philosophy and metallurgy. He conceived of the atom as a particle vortex, each particle being composed of its own inner motions. This theory approximated the electron-nucleus framework of the atom in modern physics.[2] In 1724, he was offered the chair of mathematics at Uppsala University, but he declined and said that he had mainly dealt with geometry, chemistry and metallurgy during his career. He also said that he did not have the gift of eloquent speech because of a stutter, which forced him to speak slowly and carefully. Moreover, there are no known occurrences of his speaking in public. During the 1730s, Swedenborg undertook many studies of anatomy and physiology. He had the first anticipation, as far as known, of the neuron concept. It was not until a century later that science recognized the full significance of the nerve cell. He also had prescient ideas about the cerebral cortex, the hierarchical organization of the nervous system, the localization of the cerebrospinal fluid, the functions of the pituitary gland, the perivascular spaces, and the association of frontal brain regions with the intellect. In some cases his conclusions have been experimentally verified in modern times. In the late 1730s Swedenborg became increasingly interested in spiritual matters and was determined to find a theory which would explain how matter relates to spirit. Swedenborg’s desire to understand the order and purpose of creation first led him to investigate the structure of matter and the process of creation itself. In the Principia (1734) he outlined his philosophical method, which incorporated experience, geometry (the means whereby the inner order of the world can be known), and the power of reason. In the same year he published de Infinito (On the Infinite), where he attempted to explain how the finite is related to the infinite, and how the soul is connected to the body. He was aware that it might clash with established theologies, since he presents the view that the soul is based on material substances. In 1743, at age 55, Swedenborg requested a leave of absence to go abroad. His purpose was to gather source material for Regnum animale (The Animal Kingdom, or Kingdom of Life), in which he aimed to explain the soul from an anatomical point of view. He had planned to produce a total of seventeen volumes. Beginning in 1743 and continuing throughout 1744, Swedenborg experienced intense dreams and visions at night, which he recorded in his personal diary. Many of them revolved around a sense of spiritual unworthiness, a feeling that he had to purify himself of sin.[3] Although not a theologian in the strict sense, he was an outstanding philosopher or theological speculator. Utilizing some basic Christian truths, Swedenborg elaborated, partly on a scientific basis, partly on a philosophical basi, a theory of God, of man, and of divine revelation and redemption. On the basis of these theorizings, the Church of the New Jerusalem was founded in 1784.[2] In 1747, he refused a promotion that had been offered to him, instead petitioning the king to be released from his service on the Board of Mines so he could devote himself full time to theological writing. He took up afresh his study of Hebrew and began to work on the spiritual interpretation of the Bible with the goal of interpreting the spiritual meaning of every verse. He devoted all his energy to  complete his opus magnum, Arcana Cœlestia (Secrets of Heaven) as the basis of his further theological works. The work was originally was published anonymously in eight volumes between 1749 and 1756, and Swedenborg was not identified as the author until the late 1750s. It attracted only little attention, as few people were able to understand its meaning. Although Swedenborg intended to go through every verse of the entire Bible, he never did so. Instead, he continued his publications with Heaven and Hell, a description of the afterlife and the lives of its inhabitants; Other Planets, which describes the beings that live on other planets; Last Judgment and New Jerusalem. There, he writes that the Last Judgment is not a future event that will mark the end of our world, but a spiritual event where evil spirits who had managed to infiltrate heaven were cast down to hell, allowing human beings on earth and in heaven to receive spiritual truths more clearly. Swedenborg passed away on March 29, 1772, in London, in the aftermath of a stroke from which he never fully recovered. His visions and religious ideas have been a source of inspiration for a number of prominent writers, including Honoré de Balzac, Charles Baudelaire, Ralph Waldo Emerson, William Butler Yeats, and August Strindberg.[4] At yovisto currently we don’t have a video related to Emanuel Swedenborg. But, you might be interested to listen to famous author Umberto Eco being interviewed by Paul Holdengräber, Director of LIVE from the New York Public Library, talking about Umberto Eco’s novels as well as about one of his favourite literate topics: conspiracies…'],\n",
       " [295,\n",
       "  'Jethro Tull and the Agricultural Revolution.  Jethro Tull.  On March 30, 1674, English agricultural pioneer Jethro Tull was baptized. He perfected a horse-drawn seed drill in 1701 that economically sowed the seeds in neat rows. He later developed a horse-drawn hoe. Tull’s methods were adopted by many great land owners and helped to provide the basis for modern agriculture. This revolutionized the future of agricultural success. Jethro Tull matriculated at St John’s College, Oxford at the age of 17 in order to study law but it is assumed that he did not earn a degree. He was called to the bar by the benchers of Gray’s Inn in December 1693. Unfortunately, he became sick very soon with a pulmonary disorder and travelled across Europe in search of a cure. It is believed that he spent quite some time in Italy and the south of France, especially Montpellier. There, Tull began to compare the agriculture with that of his own country. Tull noted the similarity of his own horse-hoe husbandry to the practice followed by the vine-dressers in the observed regions, constantly hoeing or otherwise stirring their ground. He developed the theory that manuring soil was not necessary and came back to England to practice his new findings on the farm called Prosperous in Berkshire. Around 1701, Tull made early advances in planting crops with his seed drill. The mechanical seeder sowed at the at the correct depth and spacing. The next version of the seed drill was much lighter and more efficient. Further, it is assumed that Jethro Tull was the first to promote the advantages of hoeing cultivated soils. He explained to the farmers that even in the driest weather good hoeing may help to procure moisture to the roots of plants. Jethro Tull died in 1741 at Prosperous Farm. Due to his work on agriculture, a new movement was initiated called horse-hoeing husbandry. At yovisto, you can learn more about ‘The Future of Irrigated Agriculture: Where is the Water?‘ in a lecture at the University of Berkeley.'],\n",
       " [296,\n",
       "  'The psychologist must study mankind from the historical or comparative standpoint – Moritz Lazarus.  Moritz Lazarus and Nahilda Lazarus-Remy ca.1895.  On September 15, 1824, German philosopher and psychologist Moritz Lazarus was born. He held that humanity must be studied from the historical, comparative viewpoint, analyzing the elements that constitute the fabric of society, with its customs, its conventions, and the main tendencies of its evolution. He was Jewish and a leading opponent of anti-Semitism in his time. Moritz Lazarus received a Jewish education, taking classes in Hebrew literature and history until moving to study at a national Prussian school when he was about 9 years old. Moritz‘ father was an expert in Prussian law and served as a rabbinic judge in the local Beth Din. He represented the citizens in their connections with the authorities. Also he educated his son Moritz in Prussian law, but later insisted that the young Lazarus specialized in merchandizing in the house of an acquaintance in the city of Posen. In Berlin, he continued with his philosophical studies and also learned more about the ritual of German language and cultures. It is assumed that Lazarus got really caught in the spirit of the revolution and wakened his patriotic feelings towards Prussia and the Prussian culture. Lazarus even published his work “The moral priority of Prussians in Germany” in 1850. [1,2] Along with his colleague Steinthal, Lazarus established the magazine “Zeitschrift für Völkerpsychologie und Sprachwissenschaft” and simultaneously he started to print his trilogy of research called “The life of the soul“. It deals with the principal problems of psychology from the standpoint of the philosophy of Herbart. Written in a popular and easy style, it soon found a large circle of readers. Two years later the second part was published and in this book, Lazarus discussed the relationship between thinking and speaking, as well as how languages were born and developed, and how they create the collective soul in the nations. In 1861, Lazarus moved another step further and strengthened his analogy between individual research and the collective soul: there is a so called ‘national soul‘ which is greater than the total number of individual souls. The language is the most significant representation of the national soul, and there exists a dual influence between the individual and the collective soul. He said, that it is possible to understand the rules of the human soul and from it the collective soul. The national soul always exists in the individual soul.[1] In 1860 Lazarus was asked to be an honorary professor without pay at the small university of Bern, Switzerland. Lazarus‘ chances of being able to get a university position at a German university were very low because he was Jewish. However, the scientist had no financial worries and he chose to accept the position. It is believed that Lazarus became the first professor of psychology in any university worldwide. He was quite successful in Bern, his lectures were always full and it is known that the audiences were the leaders of Swiss society and serving diplomats. During his time at the university, Lazarus also spread his belief that women needed to be better included in research and philosophy. Even though, Lazarus seemed to fit in very well in Bern, he had to return to Berlin in 1867, where he became more involved with the issues of the Jewish community in the city. In Berlin, he tried to promote a new, activist opinion claiming that Jews need to fight against anti-Semitism, for equality and emancipation actively. In his article Was heißt National?, Lazarus claimed that the strength of Germany was in her multi culturalness including her Jews. He spoke on behalf of German unification and nationalism and asked his Jewish brothers to remain faithful to these German values.[1,2] At yovisto, you may be interested in a video lecture titled “Thinking and Talking about the Self” by John Perry at Berkeley.'],\n",
       " [297,\n",
       "  'The Sydney Harbour Bridge.  Sydney Harbour shot taken from the air. Bridge with the Opera house to the side Image: Rodney Haywood.  On March 19, 1932, the Sydney Harbour Bridge was opened, which connects the Sydney central business district and the North Shore. It is the sixth longest spanning-arch bridge in the world, and it is the tallest steel arch bridge, measuring 134 m from top to water level. The first proposals to building a bridge from the northern to the southern shore of the harbour were made in 1815 by Francis Greenway. He wrote a letter to the then “The Australian” newspaper stating that such a bridge would “give an idea of strength and magnificence that would reflect credit and glory on the colony and the Mother Country” ten years later. However, nothing happened. Several years later, in 1840 naval architect Robert Brindley proposed that a floating bridge be built. Only in 1900 the government organised a worldwide competition for the design and construction of a harbour bridge and the first submissions arrived. Unfortunately, all submissions were considered unsuitable and so the momentum for the bridge crossing stopped. After World War I, the plans got more serious. The New South Wales Government then invited worldwide tenders for the construction of the Bridge in 1922 and the contract was given to the English firm Dorman Long and Co of Middlesbrough. The construction work began in 1924 and took 1.400 men eight years to build. On this day, the bridge carries eight traffic lanes and two rail lines. For the opening of the bridge on March 19, 1932, John ‘Jack’ T. Lang was chosen to cut the ribbon to signify the opening of the Harbour Bridge. Then, Captain Francis De Groot of the political group The New Guard slashed the ribbon with his sword. Captain De Goot believed that the only person to open the Bridge should be a member of the Royal Family. Captain De Goot was detained, the ribbon tied together, and the Premier then officially cut the ribbon. It has been reported that in the 1940s, many pilots flew under the bridge with their planes including the Flight Lieutenant Peter Isaacson during tour around Australia to raise funds for the war effort. The famous Bridge Climb started in 1998. It attracts tourists as well as locals as the view is supposed to be breathtaking. Several celebrities are reported to have climbed Sydney’s Harbour Bridge including Prince Frederik and Princess Mary of Denmark, Matt Damon, Hugo Weaving, Sarah Ferguson, Cathy Freeman, Kylie Minogue and Kostya Tszyu. At yovisto, you may learn more about Lessons in Bridge Engineering in a lecture by John Stanton. References and Futher Reading: Sydney Harbour Bridge Website Sydney Harbour Bridge at structurae'],\n",
       " [298,\n",
       "  'B.F. Skinner and Radical Behaviorism.  B.F. Skinner at the Harvard Psychology Department, c.\\u20091950.  On March 20, 1904, American psychologist, behaviorist, author, inventor, and social philosopher Burrhus Frederic (B. F.) Skinner was born. His pioneering work in experimental psychology promoted behaviorism, shaping behavior through positive and negative reinforcement and demonstrated operant conditioning. The “Skinner box” he used in experiments from 1930 remains famous. Burrhus Frederic Skinner was born March 20, 1904. Skinner grew up in a small town in Pennsylvania as the son of a lawyer. Skinner received his BA in English from Hamilton College in upstate New York. The young man wanted to become a writer badly. He authored several poems and short stories and built himself a study in his parents’ attic to concentrate, but it just wasn’t working out for him. After some time, Skinner decided to go back to school, studying psychology at Harvard University and receiving his doctorate in 1931. For five years, Skinner continued his research at Harvard. In the next ten years, Skinner taught and researched at several universities across the United States before returning to Harvard in 1948, where he remained for the rest of his life. During his research, Skinner noticed that classical conditioning did not account for the behavior most of us are interested in, such as riding a bike or writing a book. His observations led him to propose a theory about how these and similar behaviors, called operants, come about. In operant conditioning, an operant is actively emitted and produces changes in the world that alter the likelihood that the behavior will occur again. Operant conditioning has two basic purposes, increasing or decreasing the probability that a specific behavior will occur in the future. They are accomplished by adding or removing one of two basic types of stimuli, positive-pleasant or negative-aversive. That means, if the probability of a behavior is increased as a consequence of the presentation of a stimulus, that stimulus is a positive reinforcer and vise versa, if the probability of a behavior is increased as a consequence of the withdrawal of a stimulus, that stimulus is a negative reinforcer. The famous Skinner box has a bar or pedal on one wall that, when pressed (for example by rats), causes a little mechanism to release a food pellet into the cage. So when the rat is put in the cage and it (probably accidentally) presses the bar for the first time, a food pellet falls into the cage. The operant in this scenario is the behavior just prior to the reinforcer, which is the food pellet, of course. The rat is now furiously peddling away at the bar, hoarding his pile of pellets in the corner of the cage. A behavior followed by a reinforcing stimulus results in an increased probability of that behavior occurring in the future. If the rat is not given any more pellets when pressing the bar, it will stop doing so, which is called extinction of the operant behavior. Then however, if the pellet machine is turned back on, the rat will learn the behavior much more quickly than the first time. By controlling this reinforcement together with discriminative stimuli such as lights and tones, or punishments such as electric shocks, experimenters have used the operant box to study a wide variety of topics, including schedules of reinforcement, discriminative control, delayed response, punishment, and so on. At yovisto, you may be interested in the video lecture What positive psychology can help you become by Martin Seligman.'],\n",
       " [299,\n",
       "  'The watches of Daniel Quare.  Bracket Clock by Daniel Quare on display at the Walker Art Gallery, Liverpool Image: Wikimedia User Racklever On March 21, 1724, English clockmaker and instrument maker Daniel Quare passed away. He is best known for his invention of a repeating watch movement in 1680 and a portable barometer in 1695.   Daniel Quare was probably born in 1648, but the sources differ. He was admitted a brother of the Clockmakers’ Company in April 1671. When Quare started his career, the pendulum was a novelty just as much as the spiral spring and anchor escapement invented by Robert Hooke, and the fusee chain. Daniel Quare is believed to have invented the repeating watches and it is claimed that he adapted the concentric minute hand. However, if Daniel Quare was really the inventor of all these things, he must have come up with the ideas quite early in his career, as two concentric hands are shown in a diagram in Christopher Huyghens’s ‘Horologium Oscillatorium,’ Paris, 1673. The clocks and watches made by Quare with only one hand are extant, or with two circles and pointers, one for the hours and another for the minutes. When in 1687 Edward Booth, alias Barlow, applied for a patent for ‘pulling or repeating clocks and watches,’ the Clockmakers’ Company successfully opposed the application on the ground that the alleged invention was anticipated by a watch previously invented and made by Quare. The latter’s watch was superior to Barlow’s, because it repeated both the hour and the quarter with one pressure, while Barlow’s required two. It is believed that Quare also made watched for James II. and William III., but the sources are apparently not very reliable on these facts. However, he most certainly made a clock for the king which went for a year without rewinding. Being specially made for a bedroom, it did not strike. In 1695, a patent was granted to Quare for a portable barometer. The barometer, in the words of the patent, ‘may be removed and carried to any place, though turned upside down, without spilling one drop of the quicksilver or letting any air into the tube, and yet nevertheless the air shall have the same liberty to operate upon it as on those common ones now in use with respect to the weight of the atmosphere‘. However, none of these said barometers are known to exist.   At yovisto, you may be interested in a video illustrating watch making.'],\n",
       " [300,\n",
       "  'Erich Fromm and the Frankfurt School of Critical Theory.  Erich Fromm Image: Wikimedia User Arturo Espinosa.  On March 23, 1900, German-American psychologist Erich Seligmann Fromm was born. He was associated with what became known as the Frankfurt School of critical theory. Fromm’s writings were notable as much for their social and political commentary as for their philosophical and psychological underpinnings. Although influenced by Sigmund Freud’s theories, Fromm diverged in thinking that beyond the unconscious alone, conditions of the society and economy affect human behaviour. Erich Fromm was born in 1900 and received a rather traditional education. He started out with sociology, but later developed his true passion in psychology. In 1918, he enrolled at the University of Frankfurt am Main and switched to Heidelberg in 1919. In the field of sociology, Fromm studied under Alfred Weber, Karl Jaspers, and Heinrich Rickert. He received his PhD in sociology in 1922 and trained to become a psychoanalyst though Frieda Reichmann‘s psychoanalytic sanatorium in Heidelberg. Fromm started his clinical practice in 1927 and joined the Frankfurt Institute for Social Research three years later. As soon as the Nazi-Party took over Germany, Fromm left and moved forst to Geneva, but began working at Columbia University in New York in 1934. He belonged to the Neo-Freudian school of psychoanalytical thought along with Karen Horney and Harry Stack Sullivan. After leaving Columbia, Fromm helped form the New York branch of the Washington School of Psychiatry in 1943, and in 1946 co-founded the William Alanson White Institute of Psychiatry, Psychoanalysis, and Psychology. Erich Fromm was appointed professor at the National Autonomous University of Mexico in 1949, where he established a psychoanalytic section at the medical school. He also taught as a professor of psychology at Michigan State University from 1957 to 1961 and as an adjunct professor of psychology at the graduate division of Arts and Sciences at New York University after 1962. The famous term ‘Frankfurt School‘ stood for the thinkers who were affiliated with the Frankfurt Institute for Social Research. The Frankfurt School can be traced back to Felix Weil, who wrote about the problems of implementing socialism. A discussion group evolved surrounding Weil and together, they established the institute. In 1930, Max Horkheimer became the institute’s director and recruited Theodor W. Adorno, Erich Fromm, and Herbert Marcuse. Max Horkheimer outlined the objectives of critical theory in the 1930s with the goal to analyze the true significance of “the ruling understandings generated in bourgeois society, in order to show how they misrepresented actual human interaction in the real world, and in so doing functioned to justify or legitimize the domination of people by capitalism“. At yovisto you may learn more about the Frankfurt School of Critical Theory in a lecture by Paul Fry.'],\n",
       " [301,\n",
       "  'Vanguard 1 – the first Solar Powered Satellite.  Vanguard 1 satellite (NASA) Composite illustration assembled from static display of satellite, Earth from orbit and telescope photo of stars. On March 17, 1958, Vanguard 1, the fourth artificial Earth orbital satellite was launched, which was the first solar-powered satellite. Although communication with it was lost in 1964, it remains the oldest manmade satellite still in orbit. It was designed to test the launch capabilities of a three-stage launch vehicle as a part of Project Vanguard, and the effects of the environment on a satellite and its systems in Earth orbit. It also was used to obtain geodetic measurements through orbit analysis. Vanguard 1 was placed into orbit on March 17, 1958. Original estimates had the orbit lasting for 2,000 years. However, it was discovered that solar radiation pressure and atmospheric drag during high levels of solar activity produced significant perturbations in the perigee height of the satellite, which caused a significant decrease in its expected lifetime to only about 240 years. Vanguard 1 transmitted its signals for nearly 7 years as it orbited the Earth. As a result of the project, it was found that the shape of the Earth has a slight north-south asymmetry, occasionally described as pear-shaped with the stem at the North Pole. With the help of radio signals, the total electron content between the satellite and selected ground-receiving stations were determined. The last signals were received at Quito, Ecuador in May 1964 after which the spacecraft was optically tracked from Earth. Vanguard 1 was also used by the researchers for determining upper atmospheric densities as a function of altitude, latitude, season, and solar activity. Prior to launch, the Initial Naval Research Laboratory’s proposals included conical satellite bodies. This eliminated the need for a separate fairing and ejection mechanisms, and their associated weight and failure modes. Radio tracking would then gather data and establish a position. Early in the program, optical tracking was also added. A panel of scientists proposed changing the design to spheres, at least twenty inches in diameter . A sphere would have a constant optical reflection, and constant coefficient of drag, based on size alone, while a cone would have properties that varied with its orientation. Since three of the Vanguard satellites are still orbiting in the 2010s, with their drag properties essentially unchanged, they form a baseline data set on the atmosphere of Earth that is over 50 years old and continuing. On March 17, 2008, Vanguard 1 logged its 50th year in Earth orbit. It holds the record for being in space longer than any other man-made object.   At yovisto you may learn more about the First Space Satellite.'],\n",
       " [302,\n",
       "  'The Expeditions of John Wesley Powell.  John Powell with Tau-gu, a Paiute.  On March 24, 1834, American geologist and ethnologist John Wesley Powell was born. He published the first classification of American Indian languages and was the first director of the U.S. Bureau of Ethnology. He is famous for the 1869 Powell Geographic Expedition, a three-month river trip down the Green and Colorado rivers, including the first known passage through the Grand Canyon. John Powell was born in Mount Morris, New York, in 1834. His family had emigrated from England four years prior and later on moved to Illinois. The young man studied at Illinois College, Illinois Institute, and Oberlin College. He also started teacherin but didn’t earn a degree. He learned Latin and Ancient Greek, but his main interest was devoted to natural sciences which was against the wished of his father. In 1860, Powell went on a lecture tour and realized that the American Civil War was starting, he began to study military science and engineering to prepare himself for the conflict. [1] He explored Wisconsin, Illinois, Iowa, and the Iron Mountain regions of Missouri, collecting shells, minerals, and general natural history objects, which led to his election in 1859 to the secretaryship of the Illinois Natural History Society. It is said that, in 1856, the only 22 year old man descended the Mississippi by himself in a rowboat from the Falls of St. Anthony to its mouth, making collections on the way. 1857, he possibly rowed the whole length of the Ohio River from Pittsburg to its mouth, and in 1858 made a life trip down the Illinois River to its mouth and thence up the Des Moines . [2] During the Civil War, John Powell as enlisted in the 20th Illinois volunteers in the position of second lieutenant. He took part in the battle of Shiloh, losing his right arm at Pittsburg Landing. However, Powell returned to the war and fought in the battles of Champion Hill and Black River Bridge. After the Civil War, John Powell left his service as Major and accepted the position of Professor of Geology and Curator of the Museum of the Illinois Wesleyan University at Bloomington. He also became connected with the Illinois Normal University and was widely known throughout the state by his lectures and addresses on scientific subjects. [2] On May 24, 1869, John Powell and nine further men left for a 10 months journey into the Rocky Mountains and around the Green and Colorado rivers. With four boats, they set out from Green River, Wyoming, passing down the Green River to its confluence with the Colorado River near present-day Moab, Utah, and completed the journey on August 30, 1869. After only one month in the expedition, one man already quit and three further men left at Separation Canyon during the third month. Unfortunately, these three men disappeared, which remains a mystery up to this day. In 1871, John Powell retraced part of the 1869 route with another expedition traveling from Green River, Wyoming to Kanab Creek in the Grand Canyon. As a result of the expedition, photographs have been published along with maps and papers. However, it was noticed that these maps were not too precise. In preparation of the expedition, Jacob Hamblin, a Mormon missionary in southern Utah and northern Arizona was employed. He was known to have developed good relationships with Native Americans. He was asked by Powell to work as a negotiator in order to ensure their safety from local Native American groups. Powell mentioned that he believed the three missing men were killed by the Native Americans due to mistaken identities. John Powell’s subsequent geological descriptions of the explored region introduced an entire new branch of geology called geomorphology.[1,2] In his publications, Powell described his theories of the role of stream flows in wearing down mountains and creating river valleys, which established him as a nationally recognized geologist. Due to his recognition and his ability to talk with politicians, Powell was appointed the second director of the United States Geological Survey in 1881. However, it is believed that due to his insistence on putting truth before politics eventually earned him powerful enemies. Some of his enemies were very eager to exploit the natural resources of the West, objecting to Powell’s insistence on understanding the natural science of the region before developing it. John Powell was pushed out of his position in 1894 and continued his scientific work within the Bureau of American Ethnology. [1] At yovisto you can learn more about Native Americans in the 19th Century in a video discussion at Berkeley University.'],\n",
       " [303,\n",
       "  'Seymour R. Cray – the Father of Supercomputing.  CRAY 1 with exposed interiors.  On September 28, 1925, American electrical engineer and supercomputer architect Seymour Roger Cray was born. He designed a series of computers that were the fastest in the world for decades, and founded Cray Research which built many of these machines. Called “the father of supercomputing,” Cray has been credited with creating the supercomputer industry. Seymour Cray was born in 1925 in Chippewa Falls, Wisconsin, a small town situated in the heart of Wisconsin’s dairy farm country, to Seymour R. and Lillian Cray. His father was a civil engineer who fostered Cray’s interest in science and engineering. As early as the age of ten he was able to build a device out of Erector Set components that converted punched paper tape into Morse code signals. The basement of the family home was given over to the young Cray as a “laboratory”. Cray graduated from Chippewa Falls High School in 1943 before being drafted for World War II as a radio operator. He saw action in Europe, and then moved to the Pacific theatre where he worked on breaking Japanese naval codes. On his return to the U.S. he received a B.Sc. in Electrical Engineering at the University of Minnesota, graduating in 1949. He also was awarded a M.Sc. in applied mathematics in 1951. In 1950, Cray joined Engineering Research Associates (ERA) in Saint Paul, Minnesota. ERA had formed out of a former United States Navy lab that had built code breaking machines, a tradition ERA carried on when such work was available. ERA was introduced to computer technology during one such effort, but in other times had worked on a wide variety of basic engineering as well. There, Cray quickly came to be regarded as an expert on digital computer technology, especially following his design work on the ERA 1103, one of the first commercially successful scientific computer. He remained at ERA when it was bought by Remington Rand and then Sperry Corporation in the early 1950s. At the newly formed Sperry-Rand, ERA became the “scientific computing” arm of their UNIVAC division.[1] In 1957, a number of employees of the scientific computer division left to form Control Data Corporation (CDC). Cray joined the new company later and by 1960 he had completed the design of the CDC 1604, an improved low-cost ERA 1103 that had impressive performance for its price range. Cray did not enjoy working on traditional business computers constrained to design for low-cost construction, so CDC could sell lots of them. His desire was to produce the fastest computer in the world. Although in terms of hardware his design of the CDC 6600 was not on the leading edge, Cray invested considerable effort in an attempt to enable it to run as fast as possible. Unlike most high-end projects, Cray realized that there was considerably more to performance than simple processor speed, that I/O bandwidth had to be maximized as well in order to avoid “starving” the processor of data to crunch. As he later noted, Anyone can build a fast CPU. The trick is to build a fast system.[2] The CDC 6600 was the first commercial supercomputer, the first to employ freon to cool its 350,000 transistors, outperforming everything then available by a wide margin. While expensive, for those that needed the absolutely fastest computer available there was nothing else on the market that could compete. Cray continued to design further supercomputers for CDC, such as the CDC 7600 and CDC 8600, but the supercomputer projects had almost bankrupted the company while they were being designed and Cray decided to start his own company Cray Research in 1972. The first Cray-1 system was installed at Los Alamos National Laboratory in 1976 for $8.8 million. It boasted a world-record speed of 160 million floating-point operations per second (160 megaflops) and an 8 megabyte main memory. The Cray-1‘s architecture reflected its designer’s penchant for bridging technical hurdles with revolutionary ideas. In order to increase the speed of this system, the Cray-1 had a unique “C” shape which enabled integrated circuits to be closer together. No wire in the system was more than four feet long. To handle the intense heat generated by the computer, Cray developed an innovative refrigeration system using Freon [2]. In order to concentrate his efforts on design, Cray left the CEO position in 1980 and became an independent contractor. The Cray-2 system appeared in 1985, providing a tenfold increase in performance over the Cray-1. In 1988, Cray Research introduced the Cray Y-MP, the world’s first supercomputer to sustain over 1 gigaflop on many applications. Multiple 333 MFLOPS processors powered the system to a record sustained speed of 2.3 gigaflops. Always a visionary, Seymour Cray had been exploring the use of gallium arsenide in creating a semiconductor faster than silicon. However, the costs and complexities of this material made it difficult for the company to support both the Cray-3 and the Cray C90 development efforts. In 1989, Cray Research spun off the Cray-3 project into a separate company, Cray Computer Corporation, headed by Seymour Cray and based in Colorado Springs, Colorado. Tragically, Seymour Cray died of injuries suffered in an auto accident in September 1996 at the age of 71.[2] Cray had always resisted the massively parallel solution to high-speed computing, offering a variety of reasons that it would never work as well as one very fast processor. He famously quipped “If you were plowing a field, which would you rather use: Two strong oxen or 1024 chickens?” By the mid-1990s this argument was becoming increasingly difficult to justify, and modern compiler technology made developing programs on such machines not much more difficult than their simpler counterparts At yovisto, you can listen to a panel discussion about the 30th anniversary of the first CRAY supercomputer.'],\n",
       " [304,\n",
       "  'Joseph Proust and the Law of Constant Composition.  Joseph Proust (1754-1826). On September 26, 1754, French chemist Joseph Louis Proust was born. He was best known for his discovery of the law of constant composition in 1799, stating that in chemical reactions matter is neither created nor destroyed. Joseph L. Proust was born on September 26, 1754 in Angers, France as the second son of Joseph Proust, an apothecary, and Rosalie Sartre. Joseph studied chemistry in his father’s shop and later came to Paris, where he studied chemistry with Hilaire-Martin Rouelle. In 1776 Proust was appointed a pharmacist at the Salpêtrière Hospital in Paris. He published his first papers while at this hospital. However, his position was short-lived, for in 1778 Proust abandoned pharmacy to take a professorship of chemistry at the recently established Seminario Patriótico Vascongado in Vergara, Spain. This school was the creation of the Real Sociedad Económica Vascongada de Amigos del País, the first and most important of the “enlightened” provincial societies in Spain.[1] In 1780 Proust returned to Paris, where he taught chemistry at the Musée, a private teaching institution founded by scientific impresario and aeronaut Jean-François Pilâtre de Rozier. Part of this association involved Proust with aerostatic experiments, which culminated in a balloon ascent with Pilâtre on June 23, 1784, at Versailles, in the presence of the king and queen of France, the king of Sweden, and the French court. In 1786 Proust returned to Spain to teach chemistry, first at Madrid and then in 1788 at the Royal Artillery School in Segovia. Founded in 1764, this school was part of the program of the government of Charles III to bring Spain abreast of the northern European countries regarding military training. Because of Spain’s scientific backwardness, expert instructors had to be sought abroad and Proust had been recommended by no less than the great French chemist Antoine-Laurent de Lavoisier. But when Napoleon invaded Spain, they burned Proust’s laboratory and forced him back to France. Proust is best known for two major advances in analytical chemistry. First, he developed the use of hydrogen sulfide as a reagent (a substance used to detect the presence of other substances by the chemical reactions it causes). Hydrogen sulfide is a colorless, extremely poisonous gas with a sweetish taste and a strong odor of rotten eggs. Chemical compounds containing sulfur produce hydrogen sulfide when they react with certain other chemical compounds. This is why the odor of hydrogen sulfide can be detected around decaying organic matter. Hydrogen sulfide is flammable and burns with a pale blue flame. Chemists make hydrogen sulfide in the laboratory by combining such strong acids as hydrochloric acid with such metal sulfides as iron sulfide. They use the gas to analyze the composition of mixtures and to produce other compounds.[2] His second achievement derived from a controversy with C.L. Berthollet on the law of definite proportions, which is sometimes also known as Proust’s Law. Proust studied copper carbonate, the two tin oxides, and the two iron sulfides to prove this law. He did this by making artificial copper carbonate and comparing it to natural copper carbonate. With this he showed that each had the same proportion of weights between the three elements involved . Between the two types of the other compounds, Proust showed that no intermediate compounds exist between them. Proust published this paper in 1794, and his famous opponent Berthollet did not believe that substances always combine in constant and definite proportions. Moreover, Bethollet claimed that that the products of a reaction depend on the ratio of reactants. Proust’s law was not accepted until 1812, when the Swedish chemist Jöns Jacob Berzelius gave him credit for it. Although Proust was correct in his observations, the reason why reagents behave in the way he described did not become clear until English chemist John Dalton formulated his atomic theory in 1803. According to Dalton, a fixed number of atoms of one substance always combined with a fixed number of atoms of another substance in forming a compound. Dalton realized that substances must combine in the same proportions by weight as the weight proportions of their atoms. Other chemists had already observed that pure substances do combine in fixed proportions. They called that finding the law of definite (or constant) proportions. Dalton’s theory explained the law. Proust also performed a series of researches to characterize different types of sugars, present in vegetable products. After the death of his wife in 1817, Proust moved to Angers, where in 1820 he took over the pharmacy of his brother Joachim. In 1819 he became a chevalier of the Legion of Honor, and in 1820 he was granted a pension by Louis XVIII. [3] On July 5, 1826 he died in Angers, France. At yovisto, you can earn a better understanding basic chemistry in the organic chemistry lecture series of Yale Prof. J. Michael McBride on Rise of the Atomic Theory (1790-1850).'],\n",
       " [305,\n",
       "  'Abraham Werner and the School of Neptunism.  Abraham Gottlob Werner (1749-1817). On September 25, 1749, German geologist Abraham Gottlob Werner was born. He is best known for his early theory about the stratification of the Earth’s crust. Moreover, he propounded an earth history that others labeled Neptunism that states that holding that all rocks have aqueous origins. While most tenets of Neptunism were eventually set aside, science is indebted to Werner for clearly demonstrating the chronological succession of rocks, for the zeal which he infused into his pupils, and for the impulse which he thereby gave to the study of geology. Thus, he has been called the “father of German geology.” Abraham Gottlob Werner was born in Wehrau (now Osiecznica, Lower Silesian Voivodeship), a village in Prussian Silesia, as second child, and only son. His family had been involved in the mining industry for many years, where his father, Abraham David Werner, was an inspector at the Duke of Solm’s ironworks. Wernerwas educated at Freiberg and Leipzig, where he studied law and mining after working with his father for five years in the ironworks at Wehrau and Lorzendorf. While in Leipzig, Werner became interested in the systematic identification and classification of minerals. Within a year he published the first modern textbook on descriptive mineralogy, Von den äusserlichen Kennzeichen der Fossilien (On the External Characters of Fossils, or of Minerals; 1774). During his career, he discovered eight minerals and named 26. In 1775 he was then appointed as Inspector and Teacher of Mining and Mineralogy at the small, but influential, Freiberg Mining Academy. During his 40-year tenure, the school grew from a local academy into a world-renowned centre of scientific learning. Werner was a brilliant lecturer and a man of great charm, and his genius attracted students who, inspired by him, became the foremost geologists of Europe.[1] A distinguishing feature of Werner’s teaching was the care with which he taught the study of rocks and minerals and the orderly succession of geological formations, a subject that he called geognosy. Influenced by the works of Johann Gottlob Lehmann and Georg Christian Füchsel, Werner demonstrated that the rocks of the Earth are deposited in a definite order. Although he had never travelled, he assumed that the sequence of the rocks he observed in Saxony was the same for the rest of the world.[1] In the 18th century, rocks were explained in terms of the biblical flood, and were classified into three categories that most people associated with the biblical flood: “primary” for ancient rocks without fossils (believed to precede the flood), “secondary” for rocks containing fossils (often attributed to the flood itself) and “tertiary” for sediments believed to have been deposited after the flood. Werner didn’t overturn the commonly held belief in the biblical flood, but he did recognize a different group of rocks that didn’t fit this classification: rocks with a few fossils that were younger than primary rocks but older than secondary rocks. He called these “transition” rocks.[4] During his career, Werner published very little, but his fame as a teacher spread throughout Europe, attracting students, who became virtual disciples, and spread his interpretations throughout their homelands. Socratic in his lecturing style, Werner developed an appreciation for the broader implications and interrelations of geology within his students, who provided an enthusiastic and attentive audience. Werner theorized that at one time the Earth had been completely covered with oceans and that as sediments and chemicals in the water fell to the ocean floor, they formed layers of rock, which eventually became the land. Over time, water from the ocean evaporated, exposing the land and leaving pockets of water in low-lying areas. Werner’s ideas had many followers and they came to be known as Neptunists, after Neptune, the Roman god of the water. But Werner’s theory was not without opposition. Scottish geologist James Hutton had a much different theory. Hutton led a group known as the Plutonists, named for Pluto, the Roman god of the underworld. The Plutonists held that rock formed with the aid of heat instead of water. During the late 1700’s, there was a great deal of debate in the scientific community as to which group was correct. Although some of Hutton’s ideas were later modified, scientists in the early 1800’s were able to prove that his theory was more accurate, and Werner’s Neptunism was discredited.[2] One criticism of this hypothesis was that Werner hadn’t traveled enough to verify it. However, Neptunism certainly had its attractions, with Werner’s disciples distributed all over Europe. The advantages of the theory were that it was theologically acceptable, it was simple, and it showed how the Earth could be formed in the short time available.[3] Werner was also a mineralogist and he constructed a new classification of minerals. There was a major split among 18th-century mineralogists as to whether minerals should be classified according to their external form (the natural method) or by their chemical composition (the chemical method). Werner finally adopted, in 1817, a mixed set of criteria by which he divided minerals into four main classes – earthy, saline, combustible, and metallic.[3] He was elected a foreign member of the Royal Swedish Academy of Sciences in 1810. Werner was plagued by frail health his entire life, and passed a quiet existence in the immediate environs of Freiberg. He died at Dresden as a bachelor in 1817, from internal complications said to have been caused by his consternation over the misfortunes that had befallen Saxony during the Napoleonic Wars. At yovisto you can learn more about basic geology in the lecture of Aida Awan ‘Introduction to Geology 01‘.'],\n",
       " [306,\n",
       "  'Georg Simmel – First Generation Sociologist.  Georg Simmel (1858-1918). On March 1, 1858, German sociologist, philosopher and critic Georg Simmel was born. Along with Max Weber and Emile Durkheim, Simmel was one of the first generation sociologists, questioning the definition of society, nature, and culture.  Georg Simmel was born, grew up and spent most of his research time in Berlin. He earned his doctorate in philosophy and history in 1881 and afterwards became a private teacher at the University, lecturing philosophy, logic, ethics, art, and sociology. But even though Simmel’s lectures were highly popular in the University and beyond and his friend Max Weber supported him, he was not able to establish himself as an official lecturer at the university until 1901. Often the scientific community mocked Simmel for the reason that his articles were written for the general public instead of a scientific audience. On the other hand, this made Simmel so famous. Not only in Germany, but also across Europe and America his writings were highly appreciated and he became one of the most influential of his field of research.     Along with Max Weber and Ferdinand Tönnies, Georg Simmel founded the German Society for Sociology. The outbreak of World War I  caused nearly all German Universities to halt, since the lecture halls were transformed into shelter and hospital facilities, which basically meant to be the end of Simmel’s professional career. He did not survive the war and passed away in 1918 due to cancer.  To Simmel’s most important works belongs the essay ‘The Metropolis and Mental Life‘ from 1903, which originated in a lecture series on the city by Simmel. Even though this work counts as one of Simmel’s most significant, it was not very well received in his lifetime. When exhibited at the Dresden cities exhibition of 1903, the exhibitors mainly focused on Simmel’s negative comments on city life rather than pointing out his positive arguments. Still, the essay reached a great audience and critically influenced the ‘Chicago School‘ of sociology in the 1920s and ‘30s. In the middle of the 20th century, it was translated into English and published as part of the collection ‘The Sociology of Georg Simmel‘, still taught in most sociology classes in Europe.  ‘The Philosophy of Money‘ depicts Simmel’s major work, in which he defines money as an important part of human lives helping us to understand life’s totality. The work is also linked with his ideas on city life. According to Simmel, city life is responsible for the division of labor and the increase of financialization. In his means, it then becomes more important what a person can do rather than who the person really is as a consequence to these increasing financial transactions. His work caused very diverse reactions and often, Simmel has been misinterpreted during his lifetime.  Georg Simmel counts as one of the most important sociologists of all times and influenced not only colleagues of his time, like Max Weber, he also left much to discuss for later researchers on the field like Jürgen Habermas or Erving Goffman.  At yovisto, you may enjoy the video lecture ‘Weber on Protestantism and Capitalism‘ by Ivan Szelenyi of Yale University.'],\n",
       " [307,\n",
       "  'Carl Jacobi and the Elliptic Functions.  Jacobi elliptic function sn u Image by Wikimedia User Fibonacci” width=”402″ height=”401″ /> Complex graph of the Jacobi elliptic function sn u Image by Wikimedia User Fibonacci On December 10, 1804, German mathematician Carl Gustav Jacob Jacobi was born. He made fundamental contributions to elliptic functions, dynamics, differential equations, and number theory. Carl Gustav Jacob Jacobi (1804 – 1851)   Carl Jacobi was the son of a banker and grew up in a rather wealthy family. His brother, Moritz Jacobi became a famous physicist. Carl received his early education from his mother and entered the Gymnasium in Potsdam at about 12 years. However, his previous education was so good and he was so talented that the young Jacobi was put into the final class during his first year. This means that Carl Jacobi reached the necessary standard to enroll at a university when he was 12 years old. Unfortunately, the University of Berlin did not accept students below the age of 16 and Jacobi had to remain in the same class at the Gymnasium in Potsdam until the spring of 1821. [1] In the meantime, Carl Jacobi received awards in Latin, Greek, and history. Also, he studied advanced mathematics including Euler’s Introductio in analysin infinitorum and even began researching on his own in the field of mathematics, which was not always liked by his teachers. [2] However, by the time, Jacobi finally antered the university, he was still not aware, which field he wanted to focus on and attended seminars in philosophy as well as mathematics. When he decided so devote his life to mathematics, the student began reading the works of Lagrange. [1] Jacobi submitted his dissertation at the age of 19 and began teaching at a grammar school in Berlin next to working on his habilitation thesis. The rights of citizenship and freedom in Germany for jews from 1812 was revoked in 1822 and all jews were officially taken from the civil services. Jacobi converted to Christianity in 1825 and became privatdozent. Jacobi was quite influenced by Gauss’ research on quadratic and biquadratic residues and studied cubic residues and informed Gauss of his discoveries, who was quite impressed. [3] By that time, Jacobi already made several major discoveries in the field of number theory and was privatdozent at Königsberg. In this period, Jacobi also summarized his new ideas about elliptic functions and wrote a letter to Legendre, who was back then the leading expert on this topic. Legendre could have been mad or jealous that Jacobi (and also Abel) had made fundamental advances in his favorite topic, however, Legendre helped Jacobi to be promoted as associate professor in 1827. Legendre wrote a letter to Jacobi in this year: It gives me great satisfaction to see two young mathematicians such as you and [Abel] cultivate with such success a branch of analysis which for such a long time has been my favourite topic of study but which had not been received in my own country as well as it deserves. By your works you place yourselves in the ranks of the best analysts of our era. About two years later, Jacobi met Legendre as well as other mathematicians such as Fourier, Poisson, and Gauss, increasing his reputation in mathematics. The fundamental work on Jacobi’s theory of elliptic functions that impressed Legendre so much was based on four theta functions. Especially notable in this field is his paper Fundamenta nova theoria functionum ellipticarum, published in 1829. [1] At yovisto, you may enjoy the video lecture “History of Mathematics in 50 Minutes” by John Dersch.'],\n",
       " [308,\n",
       "  'Paul Ehrlich and the Chemotherapy.  Paul Ehrlich and Sahachiro Hata.  On March 14, 1854, German Jewish physician Paul Ehrlich was born. Ehrlich made significant contributions in the fields of hematology, immunology, and chemotherapy. He invented the precursor technique to Gram staining bacteria. The methods he developed for staining tissue made it possible to distinguish between different type of blood cells, which led to the capability to diagnose numerous blood diseases. Paul Ehrlich became fascinated by the process of staining microscopic tissue substances during his time at the secondary school in Breslau. He studied medicine at the universities of Breslau, Strasbourg, Freiburg im Breisgau and Leipzig, receiving his doctorate in 1882. Afterwards, he began working at Charité in Berlin as an assistant medical director under Theodor Frerichs, the founder of experimental clinical medicine, focusing on histology, hematology and color chemistry. Ehrlich traveled to Egypt in the mid 1880s in order to find a cure for tuberculosis. He established a private medical practice and a laboratory in Berlin-Steglitz. In 1891, Paul Ehrlich received was asked by Robert Koch to join the staff at his Berlin Institute of Infectious Diseases. In 1896 a new institute was established for Ehrlich’s specialization, the Institute for Serum Research and Testing, whose director he became. Later on, Paul Ehrlich became the director of the Georg Speyer House in Frankfurt, a private research foundation affiliated with his institute. As his habilitation thesis, Ehrlich submitted The Need of the Organism for Oxygen in 1885. In it, he introduced the new technology of in vivo staining. Through injecting the dyes alizarin blue and indophenol blue into laboratory animals, he found that after their death, various organs had been colored to different degrees. He then theorized that all life processes can be traced to processes of physical chemistry occurring in the cell. Further, Paul Ehrlich came to believe that methylene blue could be particularly suitable for staining bacteria. He believed that since the parasite family of Plasmodiidae can be stained with methylene blue, it could possibly be used in the treatment of malaria. After trating two patients in Berlin-Moabit successfully, Paul Ehrlich obtained methylene blue from the company Hoechst AG, which ended up in a long collaboration with this company. Paul Ehrlich continued his research on methylene blue and started looking for an agent which was as good as methylene blue but without its side effects. He thought there must be chemical pharmaceuticals which would have just as specific an effect on individual diseases and he wanted to find a “Therapia sterilisans magna”, a treatment that could kill all disease pathogens. The scientist systematically tested chemical compounds and he discovered that for instance Arsenophenylglycine had a large therapeutic effect. In 1909, he also discovered a compound that combatted the causes of syphilis and had only little side effects. It was marketed as Salvarsan starting from 1910 which was a great success. It turned out to be the most effective drug for treating syphilis until penicillin became available. At yovisto you may learn more about The wireless future of medicine in a lecture by Eric Topol. References and Futher Reading: Paul Ehrlich Biography at the Nobel Museum Paul Ehrlich at the New York Times Paul Ehrlich and Salvarsan'],\n",
       " [309,\n",
       "  'John Snow and His Work on Cholera.  John Snow (1813 – 1858).  On March 15, 1813, English physician and a leader in the adoption of anaesthesia and medical hygiene John Snow was born. He is considered one of the fathers of modern epidemiology, in part because of his work in tracing the source of a cholera outbreak in Soho, London, in 1854. John Snow studied in York until the age of 14, when he was apprenticed to William Hardcastle, a surgeon in Newcastle upon Tyne. In 1831, it is believed that he first encountered cholera. The disease entered Newcastle and devastated the town. Snow enrolled as the Hunterian school of medicine on Great Windmill Street, London in 1836. He began his career at the Westminster Hospital in 1837 and was admitted as a member of the Royal College of Surgeons of England one year later. Snow was also admitted to the Royal College of Physicians and became one of the founding members of the Epidemiological Society of London, formed in response to the cholera outbreak of 1849. During his work as a physician, John Snow was one of the first to study the dosages of ether and chloroform as surgical anaesthetics. He managed to design a device to administer ether to his patients and he designed masks to administer the chloroform. Snow is said to have personally administered chloroform to Queen Victoria when she gave birth to the last two of her nine children. Back then, the London sewer system had not reached the Soho district yet and as a result, Soho had to deal with serious health and hygiene problems. London’s government also decided to dump the city’s waste into the River Thames which caused a dramatic pollution of the water and eventually leading to the famous cholera outbreak of 1854. John Snow referred to the outbreak as “the most terrible outbreak of cholera which ever occurred in this kingdom“. Starting at the end of August, 1854, the outbreak caused presumably 500 deaths by September 10. John Snow began investigating the disease by talking to locals. He managed to identify the source of the outbreak as the public water pump on Broad Street, today Broadwick Street. He performed several chemical experiments and microscope examinations. Eventually, authorities agreed to disable the well pump, ending the outbreak. Snow later started to map how the cases of cholera were centered on the pump. With the help of statistics and what is today known as the Voronoi diagram, Snow illustrated the quality of the source of water and cholera cases. Snow noticed one significant anomaly, being that none of the monks in the adjacent monastery contracted cholera. It turned out that the monks drank only beer, which they brewed themselves. Due to the fermented water, residents in the brewery were not infected. Snow also found out that Southwark and Vauxhall Waterworks Company was taking water from sewage-polluted sections of the Thames and delivering the water to homes with an increased incidence of cholera. In the history of public health and health geography, Snow’s study was probably the founding events of the science of epidemiology. At yovisto, you may learn more about Cholera in the 19th century by Bohumil Drassar.'],\n",
       " [310,\n",
       "  'William Budd and the Infectious Diseases.  William Budd (1811 –  1880).  On September 14, 1811, English physician and epidemiologist William Budd was born. He is best known known for his discovery that infectious diseases were contagious. Budd was born in North Tawton, Devon. Already his father was a surgeon and also six of the ten children in the family became doctors. Three graduated in Edinburgh and three in Cambridge. William Budd attended the École de Médecine in Paris and finished in 1837 to attend Edinburgh University in order to complete his M.D. In the following year, Budd was appointed assistant physician at the Seaman‘s Hospital in Greenwich. Between 1839 and the early 1840s, Budd studied more than 80 cases of typhoid at North Tawton, coming to the conclusion that the “poisons” of the disease grew and multiplied in the intestines of the victim and were vanished in that person‘s excretions. Budd further concluded that these ‘poisons‘ were contaminating water supplies and infected individuals who drank that water. Against the general public opinion, Budd then implemented public health measures promoting the importance of disinfection and keeping water supplies clean and uncontaminated with sewage, because he also assumed that cholera was transmitted the same way. In this way, Budd managed to decrease the cases of cholera in 1866 in Bristol. The physician continued and applied his theory to more diseases, such as diphtheria, scarlet fever, tuberculosis, and sheep-pox. Also, he published all of his findings in 1873 but still, most of his contemporaries believed them to be incorrect. Unfortunately, Budd had to retire from Seaman‘s Hospital due to health issues. He founded the Bristol Microscopical and Pathological societies, and served 10 years as a councilor and ultimately became president of the Bath and Bristol Provincial Medical and Surgical Association. He gave important evidence before the Royal Sanitary Commission in 1869, and was elected a fellow of the Royal Society in 1871 because of his views on epidemics and the spread of infectious diseases. At yovisto, you may be interested in the lecture ‘Human Strategies for Targeting Viral Infections‘'],\n",
       " [311,\n",
       "  'El Escorial – The World’s largest Renaissance Building.  A distant view of the Royal Seat of San Lorenzo de El Escorial Image by Ecemaml.  On September 13, 1584, the Royal Site of San Lorenzo de El Escorial, about 45 kilometers northwest of the Spanish capital, Madrid, is finished. El Escorial is the world largest Renaissance building. Philip II of Spain appointed the Spanish architect, Juan Bautista de Toledo, to be his collaborator in the design of El Escorial. The architect had already worked on St. Peter‘s basilica in Rome and participated in several projects in Naples. He was announced architect-royal in 1559, and together they designed El Escorial as a monument to Spain‘s role as a center of the Christian world. The building’s cornerstone was laid on 23 April 1563. Unfortunately, Juan Bautista de Toledo did not live to see the completion of the project. After his death, his apprentice Juan de Herrera was appointed to finish the complex. It has since then been the burial site for most of the Spanish kings of the last five centuries. The basilica of San Lorenzo el Real was originally designed to take the form of a Latin cross. However, this plan was modified by Juan de Herrera to that of a Greek cross, a form with all four arms of equal length. Behind the altar is a three-tiered reredos, made of red granite and jasper, nearly twenty-eight metres tall and adorned with gilded bronze statuary by Leone Leoni, and three sets of religious paintings commissioned by Philip II. Next to the main altar of the Basilica, the residence of King Philip II is made up of a series of austerely decorated rooms with windows from which the king could observe mass from his bed. Another important part of the complex is the Pantheon of the Kings, which consists of twenty-six marble sepulchers containing the remains of the kings and queens regnant. The most recent monarch interred in the pantheon is King Alfonso XIII, removed there from the Church of Santa Maria in Monserrato, Rome in 1980. Another highly impressive part of the complex is the library. Philip II donated his personal collection of documents to the building, and also undertook the acquisition of the finest libraries and works of Spain and foreign countries. The library’s collection consists of more than 40,000 volumes, located in a great hall fifty-four meters in length, nine meters wide and ten meters tall with marble floors and beautifully carved wood shelves. Also numerous illuminated manuscripts, such as the Ottonian Golden Gospels of Henry III can be found there. he vault of the library’s ceiling is decorated with frescoes depicting the seven liberal arts: Rhetoric, Dialectic, Music, Grammar, Arithmetic, Geometry and Astronomy. Back in the day, the library was protected from inquisitional oversight, it preserved many prohibited books that were thought to be removed. The only known copy of the Kitab al-I’tibar, a 12th-century Syrian autobiography, was discovered there in the 19th century. In 1984, UNESCO declared The Royal Seat of San Lorenzo of El Escorial a World Heritage Site and more than 500000 tourists visit the complex every year At yovisto, you may be interested in a video lecture about the Renaissance in Northern Europe and Spain.'],\n",
       " [312,\n",
       "  'Harvey Fletcher – the Father of Stereophonic Sound.  Setup for the oil drop experiment. On September 11, 1884, US-american physicist Harvey Fletcher was born. Considered as the “father of stereophonic sound” he is credited with the invention of hearing aids and is well known for his contributions in acoustics, electrical engineering, speech, medicine, music, atomic physics, sound pictures, and education. Harvey Fletcher was raised in Utah in a religious community. He received his early education at he Brigham Young University where he graduated in 1907. The young engineer then moved to Chicago in order to continue his studies. There, he worked together with Rober A. Millikan measuring the charge of the electron. Their findings in this period highly contributed to the development of radio and television. After successfully performing the oil drop experiment along with Millikan, Fletcher graduated with the first summa cum laude Ph.D. ever awarded by the Physics Department at Chicago. [1,2] As promised by Fletcher, the scientist returned to Brigham as the chair of the university’s physics department. However, he accepted an offer made by the Western Electric Company, and moved to New York in 1916. The engineer had always shown interest in sound and was then responsible to study the fundamentals of human speech-produced sound. He managed to develop the 2-A Audiometer and continued broadly contributing to Bell’s work on sound technologies. It was Fletcher, who guided the development of the Western Electric Hearing Aid, the first device of this kind to use vacuum tubes. [2] In 1928, Fletcher was appointed director of the director of acoustical research at Bell Labs and was even promoted Director of all Physical Research about seven years later. His first demonstration of stereophonic transmission and stereophonic recording also took place in the 1930s. Reporting on the first presentation of “three dimensional” sound in 1934, the New York Times said that the audience was quite “mystified” and “terrified”. Also, it was stated that “Had it not been for the knowledge they were witnessing a practical scientific demonstration, the audience might have believed they were attending a spiritualist seance. Some women in the audience, admitting a feeling of ‘spookiness’ left the auditorium in fright“. Back then, his system used three separate sound channels, in contrast to the two used in modern stereo. [2,3] Fletcher left Bell Labs at the age of 65 in order to help Columbia University develop a department on acoustics. The engineer also helped found the American Acoustical Society and became its first president. He was elected an honorary member of this Society, an honor which is only shared by Thomas A. Edison. And by the way, Edison was also one of the first to be equipped with Fletcher‘s innovative hearing aids. However, his experience differed from most of Fletcher‘s patients. Edison states that “When I used to attend these dinners I sat in silence wondering what the after-dinner speaker was saying and wishing I could hear him, but I was content to turn my thoughts toward some of my inventions. But now with the hearing aid I can hear and understand the speaker but usually find it so dull I turn it off and turn my thought to my inventions.” [1] At yovisto, you may be interested in a short documentary on Harvey Fletcher at Brigham Young University'],\n",
       " [313,\n",
       "  'Jacques de Perthes and European Archaeology.  Jacques de Perthes (1788 – 1868).  On September 10, 1788, French archeologist Jacques Boucher de Crèvecœur de Perthes was born. He was the first to establish that Europe had been populated by early man. Further, his discovery of whole handaxes, tools and fragments embedded in and scattered about the fossilized bones of prehistoric mammals in the high banks of the Somme River showed that man existed at least as early as the ancient creature. Jacques de Perthes first joined the French government as a customs officer and remained a French public servant for the rest of his life. His duties kept him for six years in Italy, but when he returned in 1811, de Perthes was quickly promoted and finally appointed to succeed his father as director of the customs office at Abbeville. De Perthes mostly spent his leisure time studying what was afterwards called the Stone Age and antediluvian man, as he expressed it. The customs officer developed his archaeological skills at the gravel pits in the Somme Valley. It was in these pits that he discovered numerous archaeological tools and arrived at some remarkable conclusions. However, it took many years before de Perthes publicly announced his important discoveries. In 1847, he published the issue of his famous three volume work, Antiquités celtiques et antédiluviennes, a work in which he was the first to establish the existence of man in the Pleistocene or early Quaternary period. At first, his views met with little approval, partly because he had previously propounded theories regarding the antiquity of man without facts to support them, partly because the figures in his book were badly executed and they included drawings of flints which showed no clear sign of workmanship. However, de Perthes discovered complete hand axes, flint objects, and many fragments of items that he claimed were also tools shaped by human endeavour. These tools were said by the hobby archaeologist to be scattered among a collection of fossilised mammal bones from “very old” animals. De Perthes implied that the people who made the tools must have been alive concurrently with the ancient animals and thus proposed this as evidence of so-called primitive man. Charles Lyell visited de Perthes and the British Royal Society concurred with the findings of the customs officer, which engaged an increasing scientific interest to further study the theory. Some archaeologists had discovered animals, such as European reindeer, with whole axes embedded into their frames. All across Europe discoveries were being reported of caves with their internal walls covered in primitive drawings. The drawings exhibited extinct animals along with humans. Bones discovered in the caves appeared to be from many of the mammals in the drawings. In the late 1850s, de Perthes‘ findings were finally confirmed. Charles Lyell also indicated that the chalk plateau of Picardy, France had once been connected to the chalk lands of Kent, England and that the Strait of Dover or Pas de Calais was the recent result of very long term complex erosion forces. Although Jacques de Perthes was the first to establish that Europe had been populated by early man, he was not able to describe the period more precisely, because the scientific frame of reference did not exist yet. Today, the hand axes of the Somme River district are widely accepted to be at least 500,000 years old and therefore the product of Neanderthal populations, while some authorities think they may be as old as one million years and therefore associated with Homo erectus. At yovisto, you may enjoy a lecture by Walter Alvarez on ‘Earth History in the Broadest Possible Context‘ at Berkeley.'],\n",
       " [314,\n",
       "  'Pavlov and the Conditional Reflex.  Ivan Petrovich Pavlov (1849-1936). On September 27, 1849, Russian physiologist and Nobel Laureate Ivan Petrovich Pavlov was born. He is primarily known primarily for his work in classical conditioning. And what is the first thing you will think about when you hear Pavlov‘s name? Well, probably his experiments with dogs, where he conditioned dogs to salivate when hearing a bell ringing because they expected to get food. But, let’s take a closer look at Pavlov and his work. “Science demands from a man all his life. If you had two lives that would not be enough for you. Be passionate in your work and in your searching.” – Ivan Pavlov Ivan Pavlov, the eldest of eleven children, was born in Ryazan of the Russian Empire, to Peter Dmitrievich Pavlov, a village priest, and Varvara Ivanovna Uspenskaya, a devoted homemaker. Although able to read by the age of 7, Pavlov was seriously injured when he fell from a high wall onto stone pavement, and he did not undergo formal schooling until he was 11 years old as a result of his injuries. Pavlov attended and graduated from the Ryazan Church School before entering the local theological seminary. But, without graduating he went to attend the university at St. Petersburg where he enrolled in the physics and math department. In his fourth year, his first research project on the physiology of the nerves of the pancreas won him a prestigious university award. He proceeded to the Academy of Medical Surgery, where he obtained a position as a laboratory assistant to Professor Ustimovich at the physiological department of the Veterinary Institute. In 1879, Pavlov graduated from the Medical Military Academy with a gold medal award for his research work. In 1883, he presented his doctor‘s thesis on the subject of The centrifugal nerves of the heart and posited the idea of nervism and the basic principles on the trophic function of the nervous system. In 1890 Pavlov was invited to organize and direct the Department of Physiology at the Institute of Experimental Medicine. Under his direction, which continued over a period of 45 years to the end of his life, this Institute became one of the most important centers of physiological research. Also in 1890 Pavlov was appointed Professor of Pharmacology at the Military Medical Academy and five years later he was appointed to the then vacant Chair of Physiology, which he held till 1925. There, Pavlov developed the surgical method of the «chronic» experiment with extensive use of fistulas, which enabled the functions of various organs to be observed continuously under relatively normal conditions. This discovery opened a new era in the development of physiology, for until then the principal method used had been that of acute vivisection, and the function of an organism had only been arrived at by a process of analysis. With his method of research, Pavlov opened the way for new advances in theoretical and practical medicine.[1] Pavlov‘s observations led him to formulate his concept of the conditioned reflex. While researching the digestive function of dogs, he noted his subjects would salivate before the delivery of food. In his most famous experiment, he sounded a tone just before presenting dogs with food, conditioning them to begin salivating every time he sounded the tone. Pavlov published his results in 1903, and delivered a presentation on “The Experimental Psychology and Psychopathology of Animals” at the 14th International Medical Congress in Madrid, Spain, later that year.[2] Pavlov also discovered that these reflexes originate in the cerebral cortex of the brain.[3] Pavlov received considerable acclaim for his work, including a 1901 appointment to the Russian Academy of Sciences and the 1904 Nobel Prize in Physiology. The Soviet government also offered substantial support for Pavlov‘s work, and the Soviet Union soon became a well-known center of physiology research.[3] Conscious until his very last moment, Pavlov asked one of his students to sit beside his bed and to record the circumstances of his dying. He wanted to create unique evidence of subjective experiences of this terminal phase of life. Pavlov died of double pneumonia at the age of 86. At yovisto you can learn more about the human mind in the TED talk of MIT Prof. Marvin Minsky on Health, Society, and the human mind.'],\n",
       " [315,\n",
       "  'The First Spacecraft to Land on the Moon – Luna 2.  Luna 2.  On September 12, 1959, Soviet spaceprobe Luna 2 was launched. It was the first spacecraft to reach the surface of the Moon and was also the first man-made object to land on another celestial body. On September 14, 1959 it successfully impacted with the lunar surface east of Mare Imbrium near the craters Aristides, Archimedes, and Autolycus. Actually, already Lunar 1 was intended as an impactor and was launched as part of the Luna program in 1959. But, due to an incorrectly timed upper stage burn during its launch, it missed the Moon. However, while traveling through the outer Van Allen radiation belt, the spacecraft‘s scintillator made observations indicating that a small number of high energy particles exist in the outer belt. The measurements obtained during this mission provided new data on the Earth’s radiation belt and outer space. The Moon was found to have no detectable magnetic field. The first ever direct observations and measurements of the solar wind, a strong flow of ionized plasma emanating from the Sun and streaming through interplanetary space, were performed. The spacecraft also marked the first instance of radio communication at the half-million-kilometer distance. Luna 2, also known as Lunik 2, was similar in design to Luna 1, a spherical spacecraft with protruding antennas and instrument parts. The instrumentation was also similar, including scintillation counters, geiger counters, a magnetometer, Cherenkov detectors, and micrometeorite detectors. The spacecraft also carried Soviet pennants. Two of them, located in the spacecraft, were sphere-shaped, with the surface covered by identical pentagonal elements. In the center of this sphere was an explosive for the purpose of slowing the huge impact velocity. This was designed as a very simple way to provide the last necessary delta-v for those elements on the retro side of the sphere to not get vaporized. The spacecraft‘s launch was originally scheduled for September 9, but after the Blok I core stage failed to reach full thrust at ignition it was shut down. After all, the flight was delayed by three days because the booster had to be removed from the pad and replaced by a different vehicle. The spacecraft took a direct path to the Moon with a journey time of around 36 hours. Luna 2 hit the Moon about 800 kilometers from the centre of the visible disk 1959 September 13 at around 9pm. At yovisto, you may be interested in an American News Report on Luna 2.'],\n",
       " [316,\n",
       "  'The Passionate Life of Charlotte Brontë.  Charlotte Brontë (1816-1854). by George Richmond, 1850.  On April 21, 1816, English novelist and poet Charlotte Brontë, the eldest of the three Brontë sisters was born, whose novels are English literature standards. Most notably she wrote Jane Eyre under the pen name Currer Bell. Following the usual stereotype, computer scientists are nerds and the only literature they read – if they read any literature at all – are science fiction stories or fantasy novels. Of course I like science fiction stories – at least it was the kind of genre I’ve read first. It was also the kind of genre which started my love for literature at all. It took a while until I also read the classical and romantic English novelists, but it was worth while. I really love the novels of Jane Austen, who understood to sketch the very pinpoint characteristics of English society in the early 19th century – always with a twinkle in the eye. And there are also the Brontë sisters. While Emily Brontë wrote “Wuthering Heights” – for sure you will know the heartache epic of Heathcliff, Cathy, and the moors (that’s even too much for me … not to forget the famous Kate Bush song - Charlotte, her eldest sister, has left us ‘Jane Eyre‘, a gothic like novel containing elements of social criticism, with a strong sense of morality at its core, but nonetheless a novel many consider ahead of its time exploring also sexuality, religion, as well as feminism. Charlotte was born in Thornton, West Riding of Yorkshire in 1816, the third of six children, to Maria and Patrick Brontë, an Irish Anglican clergyman. In 1820 the family moved a few miles to the village of Haworth, when Charlotte’s mother died of cancer in 1821, leaving five daughters, Maria, Elizabeth, Charlotte, Emily, Anne and a son Branwell to be taken care of by her sister, Elizabeth Branwell. After the deaths of her older sisters Maria and Elizabeth of tuberculosis in 1825, Charlotte acted as “the motherly friend and guardian of her younger sisters”. She and her surviving siblings – Branwell, Emily, and Anne – created their own literary fictional worlds and began chronicling the lives and struggles of the inhabitants of their imaginary kingdoms. Between 1831 and 1832 Charlotte continued her education at Roe Head in Mirfield, where she met her lifelong friends and correspondents, Ellen Nussey and Mary Taylor. In 1833 she wrote a novella, The Green Dwarf, under the pen name Wellesley. She returned to Roe Head as a teacher from 1835 to 1838. In 1839 she took up the first of many positions as governess to families in Yorkshire, a career she pursued until 1841. In 1842 Charlotte and Emily travelled to Brussels to enroll at a boarding school. In return for board and tuition, Charlotte taught English and Emily taught music. After the death of her aunt Elizabeth Branwell, who had taken care of the children after their mother‘s death, Charlotte returned alone to Brussels in January 1843 to take up a teaching post at the school. But, her second stay was not happy and she returned already to Haworth in 1844. In May 1846 Charlotte, Emily and Anne self-financed the publication of a joint collection of poetry under their assumed names Currer, Ellis and Acton Bell. The pseudonyms veiled the sisters’ gender whilst preserving their initials, thus Charlotte was “Currer Bell“. Charlotte’s first manuscript, The Professor, did not secure a publisher, although she was heartened by an encouraging response. Thus, in September 1847, she published her best known novel Jane Eyre: An Autobiography. It tells the story of Jane, a plain governess who, after early life difficulties, falls in love with her Byronic employer, Edward Rochester, the lord of Thornfield Hall. (Please skip the rest of the paragraph, if you don’t want to spoil your reading experience…) They marry, but only after Rochester’s insane first wife of whom Jane initially had no knowledge dies in a dramatic fire. In Jane Eyre Charlotte transformed her very own experiences into a novel with universal appeal. Commercially it was an instant success, and initially received favourable reviews. The book’s style was innovative, combining naturalism with gothic melodrama, and broke new ground in being written from an intensely first-person female perspective. Speculation about the identity of Currer Bell and whether the author was male or female heightened with the publication of Emily‘s Wuthering Heights by “Ellis Bell” and Anne‘s Agnes Grey by “Acton Bell“. Following the success of Jane Eyre, in 1848 Charlotte began work on the manuscript of her second novel, Shirley, when the Brontë household suffered a tragic series of events. In September 1848 Branwell died, when Emily became seriously ill and died of pulmonary tuberculosis. One year later in 1849, Anne died of the same disease. Nevertheless, Charlotte resumed writing as a way of dealing with her grief and finished Shirley which deals with themes of industrial unrest and the role of women in society was published in October 1849. Before the publication of Charlotte’s third novel Villette, she received a marriage proposal from Arthur Bell Nicholls, her father‘s curate who had long been in love with her. After initially turning down this proposal, she accepted in 1854 and got married. Charlotte became pregnant soon after the marriage but her health declined rapidly. She died with her unborn child on 31 March 1855, aged 38. At yovisto you can learn more about Charlotte Brontë’s most famous novel ‘Jane Eyre’ in a lecture at DLD college, London.'],\n",
       " [317,\n",
       "  'Royal Botanist Charles Plumier.  Franipani (Plumeria) flowers in Perth, Western Australia Author: Renesis.  On April 20, 1646, French botanist Charles Plumier was born. He is considered one of the most important of the botanical explorers of his time. He made three botanizing expeditions to the West Indies, which resulted in a massive work Nova Plantarum Americanarum Genera (1703–04) and was appointed botanist to king Louis XIV of France. Charles Plumier (1646 – 1704) Charles Plumier was born in Marseille and entered the order of the Minims, when he was 16 years old. They were members of a Roman Catholic religious order of friars founded by Saint Francis of Paola in fifteenth-century Italy. The Order soon spread to France, Germany and Spain, and continues to exist today. However, Charles Plumier developed a great interest in mathematics and physics. He started building his own physical instruments and also devoted much of his time to paining and turning. Plumier was sent to the French monastery of Trinità dei Monti at Rome and there, he began his studies in botany. He was supported and taught by two members of the order. It is also assumed that he studied under the famous Italian botanist Paolo Boccone. Another important influence to Plumier was Joseph Pitton de Tournefort. The botanist became known for creating the first clear definition of the concept of genus for plants. Also Plumier was able to follow Tournefort on several voyages. Charles Plumier‘s first big journey started in 1689. By order of the government, Plumier accompanied the collector Joseph Donat Surian to the French Antilles, as Surian‘s illustrator and writer. The journey lasted for about one year and a half and resulted in Plumier‘s first masterpiece, the Description des Plantes d’Amérique, published in 1693. This work was very successful and Plumier was appointed royal botanist shortly after. The second voyage took off in 1693 by command of Louis XIV of France and another expedition followed two years later. In the West Indies, he was assisted by the Dominican botanist Jean-Baptiste Labat. The material they gathered during these trips formed an incredible foundation for Plumier‘s later works, Nova Plantarum Americanarum Genera, Plumier‘s Filicetum Americanum, and several shorter pieces for the Journal des Savants and the Memoires de Trévoux. Charles Plumier passed away on 20 November 1704. He left numerous manuscript volumes containing notes and descriptions, and about 6,000 drawings, 4,000 of which were of plants, while the remainder reproduced American animals of nearly all classes, especially birds and fishes. The Plumeria, a genus of flowering plants in the dogbane family, Apocynaceae, was named after Charles Plumier by Tournefort and Linnaeus. At yovisto, you may be interested in a video lecture on ‘Human Livelihoods Depend on Wild Flowers: Kew’s Millennium Seed Bank explained‘.'],\n",
       " [318,\n",
       "  'August Wilhelm Iffland and the Iffland Ring.  August Wilhelm Iffland (1759-1814). On April 19, 1759, German actor and dramatic author August Wilhelm Iffland was born. He was the most important actor of his age and is best remembered for playing the main part of Franz Moor in Friedrich Schiller‘s ‘The Robbers‘. And there is this ring, the Iffland-Ring, which bears Iffland‘s likeness, and is borne by the most important German-speaking actor, as decided by his predecessor. When I first heard the story of the Iffland-Ring, to me it sounded a little bit like a ‘Lord of the Ring‘ like story. There is a ring, passed over from generation to generation, and only its bearer decides who is worthy to bear it next… OK, so who was this August Wilhelm Iffland? Born in Hanover, capital of Lower Saxony, in northwestern Germany, his father originally intended him to be a clergyman, but Iffland preferred the stage, and in 1777, at age eighteen ran away to the city of Gotha in central Germany, in order to prepare himself for a theatrical career. When Iffland first started his career in theater, it was the German actor Konrad Ekhof who taught Iffland both the art and indeed business of acting. Iffland made fast progress. In 1779, Iffland joined the cast of the National Theatre of Mannheim at the request of Prince Charles Theodore of Bavaria, where Iffland made a name for himself by developing and performing acts that became famous for their psychological and realistic touch. In 1782, Iffland who performed on every single one of the main stages in Germany, triumphed in the role of Franz Moor in The Robbers, written by the German poet, philosopher and playwright Friedrich von Schiller. Schiller enjoyed Iffland’s acting so much that a fruitful collaboration developed between the two men. Iffland also gained an important reputation in the country by performing on every single one of the main stages of Germany. In April 1796, Iffland travelled to Weimar, responding to the invitation of the famous German poet, philosopher and playwright Johann Wolfgang von Goethe had extended to him. In the same year he settled in Berlin, where Iffland became director of the national theater of Prussia, and in 1811 he was made general director of all presentations before royalty. Iffland produced all the classical works of Goethe and Schiller with conscientious care, but he had little understanding for the drama of the romantic writers. As an actor, he was conspicuous for his comedy parts: fine gentlemen, polished men of the world, and distinguished princes. On the other hand, Iffland also had success as an author himself. His most famous plays are The Hunters (“Die Jäger”, 1785), Dienstpflicht (“Compulsory Service”), and Die Hagstolzen (“The Old Boys”). The form of play in which Iffland was most at home, both as an actor and playwright, was the domestic drama, the sentimental play of everyday life. His works show little imagination, but they display a thorough mastery of the technical necessities of the stage, and a remarkable power of devising effective situations. Moreover, he was also an important drama critic. In fact, German actors used to take with great importance the remarks that Iffland could make on their works in his Almanach für Theater und Theaterfreunde. What is today famous as the “Iffland-Ring”, which is engraved with the portrait of Iffland, is since Ludwig Devrient worn by a German actor chosen by his predecessor as one of the main representatives of the profession. Iffland was inspired by the Romanticism. Thus, he might be have been inspired to commission the ring the play Nathan the Wise by Gotthold Ephraim Lessing telling the famous “Ringparabel“. The circumstances of where and when Iffland passed on the ring to its first bearer Ludwig Devrient are uncertain. But there is the story that Iffland handed the ring to Devrient in 1814, after his last performance in Breslau. Shortly after, in September 1814, Iffland died in Berlin. The current holder of the Iffland-Ring is Swiss actor Bruno Ganz, who is well known for his performance as Adolf Hitler in “The Downfall“. At yovisto you can learn more about classical theatre in the lecture of Sam Walters, the Artistic Director of Orange Tree Theatre, at Gresham College on ‘Is Theatre History?‘'],\n",
       " [319,\n",
       "  'The Natural History Museum in London.  The Natural History Museum image: Wikimedia user Diliff.  On April 18, 1881, the Natural History Museum in London was opened for the public. It is one of the largest natural history museum‘s of the world. Sir Hans Sloane was an Irish physician, but also a collector who provided the foundation for the museum. He allowed his collections to be purchased by the British government below their actual value on the free market. The collections included dried plants, and animal and human skeletons, which were initially housed in Bloomsbury at Montagu House. Unfortunately, the majority of the collection had disappeared by the early decades of the nineteenth century. In 1833 the Annual Report stated that, of the 5,500 insects listed in the Sloane catalogue, none remained. It is assumed that in the first years, the staff of the natural history departments did not have much knowledge about conserving the specimens. Richard Owen was then appointed Superintendent of the natural history departments of the British Museum in 1856. He saw that the natural history departments needed more space, and that implied a separate building as the British Museum site was limited. More land was purchased, and in 1864 a competition was held to design the new museum. Francis Fowke won the design contest. He was a civil engineer Captain and passed away shortly after. The scheme was then taken over by Alfred Waterhouse who substantially revised the agreed plans, and designed the facades in his own idiosyncratic Romanesque style. The original plans included wings on either side of the main building, but these plans were soon abandoned for budgetary reasons. The space these would have occupied are now taken by the Earth Galleries and Darwin Centre. Construction work began in 1873 and was completed in 1880. The museum officially opened in 1881, but the move from the old museum was not completed until two years later. After the opening, the Natural History Museum remained a department of the British Museum. With the passing of the British Museum Act 1963, the British Museum became an independent museum with its own Board of Trustees, although the former name was retained. Only with the Museums and Galleries Act 1992 did the Museum’s formal title finally change to the Natural History Museum. In 1986, the museum absorbed the adjacent Geological Museum of the British Geological Survey. The Geological Museum became world famous for exhibitions including an active volcano model and an earthquake machine, and it housed the world’s first computer-enhanced exhibition. The newly developed Darwin Centre is designed as a new home for the museum’s collection of millions of preserved specimens, as well as new work spaces for the museum’s scientific staff, and new educational visitor experiences. Arguably the most famous creature in the centre is the 8.62-metre-long giant squid, affectionately named Archie. As part of the museum’s remit to communicate science education and conservation work, a new multimedia studio will form an important part of Darwin Centre. In collaboration with the BBC’s Natural History Unit, the Attenborough Studio provides a multimedia environment for educational events. The studio plans to continue the daily lectures and demonstrations. The museum runs a series of educational and public engagement programs, including a “How Science Works” hands on workshop for school students demonstrating the use of microfossils in geological research. The museum also played a major role in securing designation of the Jurassic Coast of Devon and Dorset as a UNESCO World Heritage site and has subsequently been a lead partner in the Lyme Regis Fossil Festivals. At yovisto, you may be interested in taking a virtual tour of the Natural History Museum in London.'],\n",
       " [320,\n",
       "  'William Wilson and the First German Railway.  William Wilson (1809-1862). On April 17, 1862, British mechanical engineer William Wilson passed away. He was the first engine driver of the locomotive Adler on the first German railway. There was a time, when every little boy wanted to become an engineer or engine driver. Master of the huge and powerful machine, driving the rails, faster and faster. But, this was already way before my time. I wanted to become an astronaut. What did I do instead? Now I am a scientist. Comes pretty close, well if you take out the space flight. But, let’s look at the life of the very first engine driver in Germany, who had become a role model for generations of litle boys after him. William Wilson was born on 18 May 1809 in Walbottle, England and, in 1829, engaged by railway pioneer George Stephenson as a mechanic. Stephenson should become the first who built a public inter-city railway line using steam locomotives, the Liverpool and Manchester Railway which opened in 1830. The development of public railways in Britain attracted interest from the rest of Europe. The first railway line in Germany was opened on 7 December 1835 between Nuremberg and Fürth. Its first steam locomotive was supplied by Stephenson, because at that time there were no suitable and affordable steam engines available in Germany. At the request of the Ludwig Railway Company (Ludwigs-Eisenbahn-Gesellschaft), Stephenson also provided Wilson to act as engine driver and engineer. He was to instruct the locomotive crew and train successors, for which he was given an eight-month contract. Stephenson stipulated a maximum working period of 12 hours per day and Wilson‘s travel costs were borne by the Ludwig Railway Company. In addition, he took on the fitting out, and later the direction, of a railway workshop. He was given a high salary commensurate with his qualification that exceeded the income of the general manager (Generaldirektor) of the railway company. On 7 December 1835 William Wilson finally drove the locomotive, Adler, as the engine driver, on the first German railway on the newly built 7.45 km line operated by the Ludwig Railway. The high cost of importing coal from Saxony meant that only two of the hourly passenger services were steam-hauled, with the remainder drawn by horses. After eight months he made no arrangements to leave. Both as a result of his safe performance during this journey as well as his excellent credentials, his contract was repeatedly extended. The passengers wanted to travel with no-one else but the “tall Englishman“. Whenever he was not driving the locomotive himself, income fell. Over time, the various lands in Germany started building their own railway systems, which began to connect the corners of Germany together. From 1842 he alternated as engine driver with his assistance, Bockmüller. His health was seriously damaged by his occupation, however, because he would stand on the driver’s platform in all weathers in a gentleman‘s overcoat and top hat, but without any protection from the elements. Not until the winter of 1845/46 were engine drivers given leather coats as protection agains the weather. Finally, eight years later, the engines were furnished with protective roofs over the driver’s stand. In spite of tempting offers by the Bavarian State Railway, Wilson remained with the Ludwig Railway. In 1859, he was unable to work regularly as a result of his worsening health. At the 25th anniversary celebrations of the Ludwig Railway he was greatly honored. He died on 17 April 1862 in Nuremberg as a result of his illness. At yovisto you can learn more about early steam locomotives in a video about the reenacted Rainhill Trials by the Manchester Museum of Science and Technology.'],\n",
       " [321,\n",
       "  'Aviation Pioneer Harriet Quimby.  Harriet Quimby (1875-1912). in the Moisant monoplane she learned to fly in Image: Library of Congress.  On April 16, 1912, Harriet Quimby became the first woman to fly across the English Channel. She was the the first woman to gain a pilot‘s license in the United States. Although Quimby lived only to the age of thirty-seven, she had a major influence upon the role of women in aviation. Harriet Quimby was born into a farmer‘s family in Michigan and moved to San Francisco in order to become an actress. However, Quimby later decided to become a journalist instead and continued her career in New York city. There, she wrote often for the Leslie‘s magazine. Quimby began to travel and earned herself a great reputation as a journey reporter and photographer traveleing across Cuba, Europe, Egypt, and Mexico. Around 1906, Harriet Quimby discovered her interest in fast vehicles during a work on the Vanderbilt racetrack. Soon, she bought her own car and became known as a very successful young woman, who traveled around the world and even managed to support her family financially. It is assumed that Quimby‘s interest in aviation was initiated in 1910 when she visited a flight contest at Belmont Park. The young woman got to know John Moisant, who was back then a very popular aviator and teacher and became known for his flight around the Statue of Liberty. As the brothers Wright did not take any female students at the time, Quimby was very pleased that Moisant agreed to teach her. Next to her increasing interest in flight, Harriet Quimby also began writing screenplays for silent movies and continued her journalism career. On 1 August, 1911, she received her pilot license as the first woman in the United States. In the Leslie‘s, she wrote about her adventures as the first woman flying over Mexico and as the first woman achieving a flight at night time. Also, she fantasized about the future of aviation and imagined big flight airlines that would carry thousands of passengers every day. Her next big goal was the crossing of the English Channel from Great Britain to France, but she kept this plan secret for a while. Only Louis Blériot, who crossed the channel in the other direction in 1909 knew about her plans and allowed Quimby to use his plane. The highly motivated Quimby faced bad luck on 2 April, 1912. Gustav Hamel took Eleanor Trehawke Davie with him while crossing the channel and Quimby could not be the first woman to achieve this. However, she continued her plans and became the first female pilot to make it across the channel. Even though many came to applaud the female pilot for her achievement, it played only a minor role in the media, since the sinking of the Titanic, which occurred only two days before filled all newspapers back then. After Quimby had returned to New York City, she planned to take part in further aviation competitions. On 1 July, 1912 she flew Bleriot‘s new machine but due to a until this day unknown error, the pilot lost control of the plane and all passengers died in the accident. At yovisto, you may be interested in a video documentation on aviation history and Bleriot’s flight across the English Channel.'],\n",
       " [322,\n",
       "  'Samuel Johnson and his Famous Dictionary.  Samuel Johnson reading the “Vicar of Wakefield“.  On April 15, 1755, after nine years of intensive labor, Samuel Johnson publishes his “Dictionary of the English Language”, sometimes published as Johnson‘s Dictionary. It is among the most influential dictionaries in the history of the English language. Samuel Johnson showed signs of great intelligence quite early and his parents decided to start his educational program, when he was only three years old. At the age of nine, he was already promoted to the upper school. The financial situation of the Johnson family decreased and next to his studies, the young Samuel began stitching books. He entered the entered Pembroke College at Oxford in 1728 and also began writing several poems. Due to financial issues, Johnson had to leave Pembroke early without a degree. Johnson spent a lot time looking for positions where a degree was not necessary and taught for a while under Wolstan Dixie, 4th Baronet. After an argument with his wife however, Johnson had to look for a different position. During this period, Johnson spent much time with his friend Edmund Hector, who was living in the home of the publisher Thomas Warren. Johnson was asked for help with his Birmingham Journal, which improved his connection to Warren. In 1735, Johnson had applied unsuccessfully for the position of headmaster at Solihull School and he made the conclusion that he would become a successful teacher only if he ran his own school. In the same year, Johnson opened Edial Hall School as a private academy with only 3 students at first. However, the school turned out to be unsuccessful. Many historians assume, that the Tourette syndrom he was suffering from was responsible for his failing as a schoolmaster. Johnson then began working on his first masterpiece, the historical tragedy ‘Irene‘. Johnson soon found employment as a writer for The Gentleman’s Magazine and moved to London. In 1746, a group of publishers approached Johnson with an idea about creating an authoritative dictionary of the English language. Johnson agreed and claimed to be finished in three years. He did finish the work ‘only’ after nine years, but in comparison, the Académie Française had forty scholars spending forty years to complete their dictionary. Even though, the dictionary was later also criticized, it was still referred to as “one of the greatest single achievements of scholarship, and probably the greatest ever performed by one individual who laboured under anything like the disadvantages in a comparable length of time“. Johnson‘s dictionary became the most commonly used and imitated for the 150 years between its first publication and the completion of the Oxford English Dictionary in 1928. It is said, that Johnson‘s Dictionary offered insights into the 18th century and “a faithful record of the language people used”. The Dictionary was finally published in April 1755, with the title page acknowledging that Oxford had awarded Johnson a Master of Arts degree in anticipation of the work. It contained 42,773 entries and an important innovation in English lexicography was to illustrate the meanings of his words by literary quotation, of which there were approximately 114,000. Next to writing his dictionary, Johnson also spent the nine years writing several essays and poems. He produced a series titled as “The Rambler” which were published every Tuesday and Saturday. The popularity of The Rambler took off once the issues were collected in a volume, they were reprinted nine times during Johnson‘s life. At yovisto, you may be interested in a Gresham College video lecture by Henry Hitchings on the history of the dictionary entitled ‘Dr Johnson, I presume?‘.'],\n",
       " [323,\n",
       "  'The Kinetoscope and Edison’s Wrong Way to Invent the Cinema.  The 1895 version of the Kinetoscope with earphones that lead to the cylinder phonograph within the cabinet On April 14, 1894, chief engineer William K. L. Dickson in the team of Thomas Alva Edison, presents the newly invented Kinetoscope, an early motion picture exhibition device designed for films to be viewed by one individual at a time through a peephole viewer window at the top of the device. Ok, according to Edison, the cinema would never have become the silver screen you know, but would have remained a cheap fairground attraction. The movies Edison produced and presented in his Kinetoscopes worked more or less like in a peep show. You stand in front of the apparatus, looking into it from the top, insert a nickle and follow the most times funny movies of only a few minutes length. That’s it. Can you imagine that a movie like Star Wars would have been produced if cinema would just have stayed like that? I doubt. But, let’s have a look at Edison‘s invention of the movie industry. The works and ideas of photographic pioneer Eadweard Muybridge appear to have spurred Thomas A. Edison to pursue the development of a motion picture system. On February 25, 1888, in Orange, New Jersey, Muybridge gave a lecture that may have included a demonstration of his zoopraxiscope, a device that projected sequential images drawn around the edge of a glass disc, producing the illusion of motion. Two days later, Muybridge and Edison met at Edison‘s laboratory in West Orange to talk about a collaboration to join Muybridge‘s device with the Edison phonograph — a combination system that would play sound and images concurrently. But, the collaboration never happened. Moreover, in October 1888, Edison filed a preliminary claim, known as a caveat, with the U.S. Patent Office announcing his plans to create a device that would do “for the Eye what the phonograph does for the Ear”. In March 1889, a second caveat followed, which gave a name to the proposed motion picture device, the Kinetoscope, derived from the Greek roots kineto- (“movement“) and scopos (“to view”). Edison assigned Dickson, one of his most talented employees, to the job of making the Kinetoscope a reality. Edison‘s original idea involved recording pinpoint photographs, 1/32 of an inch wide, directly on to a cylinder with a synchronized audio cylinder for sound recording. Although expanded in later testing, the coarseness of the silver bromide emulsion used on the cylinder became unacceptably apparent. Thus, they tried sensitized celluloid sheets wrapped around the cylinder, providing a far superior base for the recording of photographs. The first film made for the Kinetoscope, and apparently the first motion picture ever produced on photographic film in the U.S., may have been shot at this time, known as Monkeyshines, No. 1, it shows an employee of the lab in an apparently tongue-in-cheek display of physical dexterity. Attempts at synchronizing sound were soon left behind. A trip of Edison‘s to Europe and the Exposition Universelle in Paris in 1889 gave Edison new ideas for the realization of his Kinetoscope. There, he met scientist-photographer Étienne-Jules Marey, who had devised a “chronophotographic gun“, the first portable motion picture camera. He also came across early European film pioneers like French inventor Charles-Émile Reynaud, who used images painted on gelatine frames as well as German inventor Ottamar Anschütz. Their crucial innovation was to take advantage of the persistence of vision theory by using an intermittent light source to momentarily “freeze” the projection of each image; the goal was to facilitate the viewer‘s retention of many minutely different stages of a photographed activity, thus producing a highly effective illusion of constant motion. By early 1891, however, Edison‘s team had succeeded in devising a functional strip-based film viewing system. In the new design, whose mechanics were housed in a wooden cabinet, a loop of horizontally configured 19 mm (3/4 inch) film ran around a series of spindles. The film, with a single row of perforations engaged by an electrically powered sprocket wheel, was drawn continuously beneath a magnifying lens. The lab also developed a motor-powered camera, the Kinetograph, capable of shooting with the new sprocketed film. On May 20, 1891, the first public demonstration of a prototype Kinetoscope was given at the laboratory for approximately 150 members of the National Federation of Women‘s Clubs. The New York Sun described what the club women saw in the “small pine box” they encountered: In the top of the box was a hole perhaps an inch in diameter. As they looked through the hole they saw the picture of a man. It was a most marvelous picture. It bowed and smiled and waved its hands and took off its hat with the most perfect naturalness and grace. Every motion was perfect…On April 14, 1894, the first commercial exhibition of motion pictures in history was given in New York City, using ten Kinetoscopes. This can be considered the birth of American movie culture. At yovisto you can watch some of the early kinetoscope productions from Edison’s filmstudios from the years 1894-1896.'],\n",
       " [324,\n",
       "  'Catherine de Medici and St. Bartholomew’s Day.  Catherine and Henry‘s marriage.  On April 13, 1519, Italian noblewoman and Queen of France Catherine de’ Medici was born. Catherine played a key role in the reign of her sons, and is blamed for the excessive persecutions of the Hugenots in particular for the St. Bartholomew‘s Day massacre of 1572, in which thousands of Huguenots were killed in Paris and throughout France. Catherine de’ Medici was born into a very influential family. Her father was made Duke of Urbino by his uncle Pope Leo X and her mother was from one of the most prominent and ancient French noble families. Unfortunately, her parents passed away early, wherefore she grew up with further family members. However, the family’s power decreased in 1527 and Pope Clement had to crown Charles Holy Roman Emperor. Charles‘ troops laid siege to Florence and Catherine was supposed to be killed or exposed naked and chained to the city walls. The city surrendered in 1530 and Clement had Catherine move to Rome. When Francis I of France offered that his second son, Henry, Duke of Orléans, would marry Catherine and Clement highly supported the wedding. It took place in 1533, but the 14-year old’s saw only little of each other during their first year of marriage. Also it is assumed, that Prince Henry showed only little interest in his wife at all and for a quite long time they failed to produce any children. Unfortunately, Henry‘s mistress gave birth to a daughter, which proved that he was fertile. He openly acknowledged her and added much pressure on Catherine. After quite a while, divorce was even discussed and Catherine now tried anything to get pregnant and in 1544, she finally gave birth to a son. The couples marriage did not improve after having several children, but Catherine was still respected as Henry‘s consort. After the death of King Francis I, she became the queen consort of France and was crowned in the basilica of Saint-Denis. However, Catherine‘s political power was very limited and Henry gave the Château of Chenonceau, which Catherine had wanted for herself, to Diane de Poitiers, who took her place at the center of power, dispensing patronage and accepting favours. After a sport accident, King Henry first lost his sight and speech and passed away on 10 July, 1559. Francis II became king at the age of fifteen and Catherine was not strictly entitled to a role in Francis‘s government, because he was deemed old enough to rule for himself. Still, it is assumed that she played a major role in his decision making. When her son died in 1560, Catherine was appointed govenor of France and the nine year old Charles IX became King, who cried during his coronation. On 1 March 1562, in an incident known as the Massacre of Vassy, the Duke of Guise and his men attacked worshipping Huguenots in a barn at Vassy, killing 74 and wounding 104. Guise, who called the massacre “a regrettable accident“, was cheered as a hero in the streets of Paris while the Huguenots called for revenge. The massacre lit the fuse that sparked the French Wars of Religion. For the next thirty years, France found itself in a state of either civil war or armed truce. Louis de Bourbon, Prince of Condé raised a large army, formed an alliance with England and started seizing town after town in France. After further conflicts with her allies as well as her enemies, Catherine now rallied Hugenot and Catholic forces to retake Le Havre from England. When Charles IX was declared of age, he still showed only little interest in government and Catherine decided to enforce the Edict of Amboise and revive loyalty to the crown. Philip II sent the Duke of Alba to tell Catherine to scrap the Edict of Amboise and to find punitive solutions to the problem of heresy. In 1566, Charles IX of France and Catherine de Medicis unsuccessfully proposed to the Ottoman Court a plan to resettle French Huguenots and French and German Lutherans in Ottoman-controlled Moldavia. In 1570, Charles IX married the daughter of Maximilian II, Holy Roman Emperor. Catherine was also eager for a match between one of her two youngest sons and Elizabeth I of England. After Elisabeth died in childbirth in 1568, Catherine had touted her youngest daughter Margaret as a bride for Philip II of Spain. Now she sought a marriage between Margaret and Henry III of Navarre, with the aim of uniting Valois and Bourbon interests. Margaret, however, was secretly involved with Henry of Guise, the son of the late Duke of Guise and she faced great problems when Catherine found out about it. When Admiral Coligny was shot and wounded through his window, Catherine, who was said to have received the news without emotion, made a tearful visit to Coligny and promised to punish his attacker. Many historians have blamed Catherine for the attack. Two days later, the St. Bartholomew‘s Day massacre took place. It stained Catherine‘s reputation ever since, since there is no reason to believe she was not party to the decision when on 23 August Charles IX ordered, “Then kill them all! Kill them all!”. Catherine and her advisers expected a Huguenot uprising to avenge the attack on Coligny. They chose therefore to strike first and wipe out the Huguenot leaders while they were still in Paris after the wedding of Henry and Catherine‘s daughter Margaret. The massacre lasted for almost one week and spread across France where it persisted into the fall. At yovisto, you may be interested in a video lectureby Barbara Diefendorf on ‘The Saint Barthomomew’s Day Massacre‘ held at the University of Boston.'],\n",
       " [325,\n",
       "  'Robert Delaunay and Orphism.  Graphic Champs de Mars: La Tour Rouge. Robert Delaunay.  On April 12, 1885, French artist Robert Delaunay was born. Together with his wife Sonia Delaunay and others, he cofounded the Orphism art movement, noted for its use of strong colours and geometric shapes. Robert Delauney grew up with his aunt and uncle near Bourges and when he failed his final schooling exam, he declared that he wanted to become a painter. His uncle sent him to Ronsin‘s atelier for decorative arts in Paris. It is assumed that at the age of 19, Delauney decided to completely devote his life to painting. He already managed to contribute several early works to the Salon des Indépendants in 1904. In the following years, Delaunay started becoming friends with the artist Jean Metzinger, with whom he then shared an exhibition. Delauney and Metzinger painted portraits of each other in prominent rectangles of pigment, driven by the Neo-Impressionist movement. However, it is assumed that Metzinger‘s Neo-Impressionist period lasted a lot longer than Delauney’s. However, Robert Delaunay is most closely identified with Orphism. He started studying color and lighting intensively, influenced by many artists including Macdonald Wright, Morgan Russell, Patrick Bruce, The Blaue Reiter group, August Macke, Franz Marc, Paul Klee, and Lyonel Feininger. Delauney became known as an artist, who painted with brilliant colors that increased the dynamic in his pictures dramatically. Delauney also started publishing his theories on color, which were highly influenced by scientists on the one hand, but also turned out to be rather intuitive on the other. Often, statements based on the belief that color is a thing in itself with its own powers of expression and form could be read. In 1908, Delauney met Sonia Terk, his later wife. In the meantime, the artist began painting several works in the city of Paris, including the Eiffel Tower. Delauney’s influence in Switzerland, Russia, and Germany grew as well and he was invited to join the Munich based group ‘Der Blaue Reiter‘. The artist traveled to Berlin in 1913 for an exhibition of his work at Galerie Der Sturm. However, Delauney’s influence soon began to spread across Europe. When World War I started, the artist couple traveled to Spain and immediately decided not to return to France for a while. They moved to Portugal the year after, while Robert was declared a deserter. However, he was later declared unfit for military duty. Next bad news did not take long. Due to the Russian Revolution, Sonia was no longer financially supported by her family. When trying to engage a working relationship with Paul Poiret, it is said that he refused a cooperation in 1920 due to her marriage with a ‘deserter‘. The couple returned to France three years after the war and Robert continued painting in increasingly abstract styles. Robert and Sonia Delaunay are today known for “relaunching the use of color during the monochromatic phase of Cubism“. Together they became key figures in the movement, especially their early works ‘Finnish Girl’ (Sonia) and ‘Paysage au disque’ (Robert) played a major role. In Robert’s Eiffel Town Series, the subject is portrayed as if seen from several viewpoints at once, adapting the concept of mobile perspective by Metzinger. In 1913 the Delaunays showed their works in the Salon des Indépendants and the Herbst Salon, the latter being the first Orphist Salon, which also hosted works by Picabia, Metzinger, Gleizes, Léger, and Futurist painters. Unlike others associated with Orphism, the Delaunays would return to this style throughout their lives. At yovisto, you may be interested in an entertaining lecture by Dr. Sherry Buckberrough about ‘Sonia Delaunay and The New Woman‘.'],\n",
       " [326,\n",
       "  'Vom Science Slam zur Bestsellerliste.  Vor ein paar Jahren haben uns bei yovisto die Science Slam Videos begeistert. Insbesondere ist uns diese Medizinstudentin in Erinnerung geblieben, die mit Ihren kurios interessanten Ausführungen zum Darmrohr als Siegerin dieser Veranstaltung hervorging. Giulia Enders, 24 Jahre alt und Medizinstudentin hat es verstanden, mehr daraus zu machen und führt inzwischen mit ihrem Buch “Darm mit Charme: Alles über ein unterschätztes Organ” die deutsche Bestsellerliste Paperback-Sachbuch an. Im Mittelpunkt des daraus entstandenen Medieninteresses liest man jetzt allerortens Interviews mit der Studentin, in der sie Fragen über Fragen zum Thema “Pupsen” und “Kacken” Rede und Antwort stehen muss. Wir freuen uns mit ihr über diesen Erfolg und stellen Euch daher heute noch einmal ihr mittlerweile “berühmtes” Siegervideo “Das Darmrohr” vom Science Slam Berlin vor.'],\n",
       " [327,\n",
       "  'James Parkinson and Parkinson’s Disease.  Woodcut of a man suffering from Parkinson‘s disease published in 1886.  On April 11, 1755, English apothecary surgeon, geologist, paleontologist, and political activist James Parkinson was born. He is most famous for his 1817 work, An Essay on the Shaking Palsy, in which he was the first to describe “paralysis agitans“, a condition that would later be renamed Parkinson‘s disease. James Parkinson was born in London. His father was an apothecary and surgeon, practicing in the city and in 1784 Parkinson was approved as a surgeon as well. Next to his medical practice, Parkinson‘s interest in politics grew as well. He was known as an advocate for the under-privileged and proponent for the French Revolution. During his lifetime, Parkinson published several political writings, especially in the post-French Revolution period. However, between 1799 and 1807, Parkinson published several medical works including first papers on peritonitis. Next to his most important research topic, Parkinson‘s disease, the scientists also helped improving the general health of the population. Parkinson published doctrines, proposing methods for a better health and welfare as well as legal protection for the mentally ill. Before James Parkinson, the disease’s symptoms were indeed described. The oldest known records were found in Egyptian papyrus from the 12th century B.C. mentioning a king drooling with age and also the Bible contains several references to tremor. Also in the 17th century, the disease was observed and distinguished from other tremors. In 1817 however, it was James Parkinson, who published an essay describing six cases of paralysis agitans. Another essay described on the ‘Shaking Palsy‘ described the characteristic resting tremor, abnormal posture and gait, paralysis and diminished muscle strength. Also, an explanation on the diseases progress over time was given in the paper. Unfortunately, the now famous essay received only very little attention after being published, even though on this day, it is considered the seminal work on the disease. In the following years, several neurologists continued researching the ‘Shaky Palsy‘ and managed to make further additions to the knowledge on the disease. The French neurologist Jean-Martin Charcot is probably the most notable and best known scientist whose studies between 1868 and 1881 were a landmark in the understanding of the disease. Among other advances he made the distinction between rigidity, weakness and bradykinesia. He also championed the renaming of the disease in honor of James Parkinson. Next to observing and describing the Parkinson‘s disease, scientists also began finding possible treatments. Modern surgery for tremor, consisting of the lesioning of some of the basal ganglia structures was first tried in 1939 and was improved over the following 20 years. By the late 1980s deep brain stimulation emerged as a possible treatment and it was approved for clinical use in 1997. At yovisto, you may be interested in a video lecture by Dr Melita Petrossian, who explains Parkinson’s Disease.'],\n",
       " [328,\n",
       "  'Juan de la Cierva and the Autogiro.  Demonstration of Cierva C.6 autogiro at Farnborough, Oct. 1925.  On September 21, 1895, Spanish civil engineer and aviation pioneer Juan de la Cierva y Codorníu was born. His most famous accomplishment was the invention in 1920 of the Autogiro, a single-rotor type of aircraft, a predecessor of today‘s helicopter. Juan de la Cierva was born in Murcia, Spain to a wealthy family. Although trained as a civil engineer, Cierva became interested in aviation early in his youth. After several successful experiments with aviation as a boy, he eventually earned a civil engineering degree. For six years he attended the Escuela Especial de Ingenieros de Caminos, Canales y Puertos in Madrid, Spain, where he studied theoretical aerodynamics. Following this, he entered a competition to design military aircraft for the government and built a biplane bomber with an airfoil (the part of a plane that provides lift) that he designed mathematically. The plane was tested in May 1919, but it crashed when the pilot stalled it.[1] Cierva believed that fixed-wing aircraft were unsafe, so he experimented with a rotary-wing design. In 1919 he started to consider the use of a rotor to generate lift at low airspeed, and eliminate the risk of stall. In order to achieve this, he utilized the ability of a lifting rotor to autorotate, whereby at a suitable pitch setting, a rotor will continue to rotate without mechanical drive, sustained by the torque equilibrium of the lift and drag forces acting on the blades. This phenomenon was already known, and was available as a safety feature to allow controlled descent of a helicopter in the event of engine failure. With De la Cierva‘s autogiro, the rotor was drawn through the air by means of conventional propeller, with the result that the rotor generated sufficient lift to sustain level flight, climb and descent. Before this could be satisfactorily achieved, De la Cierva experienced several failures primarily associated with the unbalanced rolling movement generated when attempting take-off, due to dissymmetry of lift between the advancing and retreating blades. This major difficulty was resolved by the introduction of the flapping hinge. In 1923, De la Cierva‘s first successful Autogiro was flown in Spain. In a fixed-wing aircraft, lift is provided by the wing, thrust by the propeller. Cierva, though, believed that the autogiro controlled these forces better than fixed-wing aircraft, which had a tendency in those days to stall, or lose lift suddenly. He also wanted to develop an aircraft that needed only a short takeoff run and could slowly land in small areas. The autogiro was a major step toward those goals.[1] In 1925, he demonstrated his autogiro to the British Air Ministry at Farnborough, Hampshire, which was a great success, and resulted in an invitation to continue the work in the UK. The same year, de la Cierva moved to England where, with the support of Scottish industrialist James G. Weir, he established the Cierva Autogiro Company. On September 18, 1928, he flew one of his autogiros (C.8) across the English Channel, and in 1930, he flew one from England to Spain. As De la Cierva‘s autogiros achieved success and acceptance, others began to follow and with them came further innovation. Most important was the development of direct rotor control through cyclic pitch variation, achieved initially by tilting the rotor hub and subsequently by Raoul Hafner by the application of a spider mechanism that acted directly on each rotor blade. The introduction of jump take-off was another major improvement in capability. The rotor was accelerated in no-lift pitch until the rotor speed required for flight was achieved, and then declutched. At the outbreak of the Spanish Civil War in 1936, de la Cierva supported the forces of Francisco Franco, while his brother was executed by the Republican army in Paracuellos del Jarama. In a very ironic twist of fate the man who spent the better part of his life to develop a safe aircraft would loose his own life in an aircraft accident. On the morning of 9 December 1936, de la Cierva boarded a Dutch DC-2 of KLM at Croydon Airfield, bound for Amsterdam, which during take off should stall and crash on the roof of a building at the end of the runway.[2] Autogiros were used during the 1930s for military liaison, mail delivery, and agricultural purposes. De la Cierva’s work on rotor dynamics and control made possible the modern helicopter, whose development as a practical means of flight had been prevented by these problems. At yovisto you can learn more about the history of early helicopters in a short documentary produced for Encyclopedia Britannica, now part of the Prellinger archive on Helicopters from 1953.'],\n",
       " [329,\n",
       "  'Squire Whipple – The Father of the Iron Bridge.  Truss Bridge patented by Squire Whipple.  On September 16, 1804, US-American civil engineer Squire Whipple was born. He who provided the first scientifically based rules for bridge construction and has become known as the father of iron bridge building in America. The civil engineer was born in Hardwick, Massachusetts in 1804 the son of a farmer. He was exposed to construction sites and materials from early age, since his father designed, built and ran a cotton-spinning mill in nearby Greenwich, Massachusetts. After receiving the best common school education available he attended Hartwick Academy and Fairfield Academy located in central New York near his home. In 1830 Whipple graduated from Union College in Schenectady, New York after one year of study. He spent the decade of the 1830s serving his apprenticeship working on the Baltimore and Ohio Railroad, the Erie Canal Enlargement, the New York and Erie Railroad and several other railroads. When work was slow, he designed, built and sold mathematical instruments such as transits and engineer’s levels and drafting equipment. [1] In the early 1840s, Whipple designed and built a weigh lock scale with a capacity of 300 tons to weigh the canal boats on the enlarged Erie Canal in Utica. This was probably the largest weighing device in the country at the time. After a while, Whipple became interested in the design and construction of iron and wooden bridges. Having worked on the enlargement of the Erie Canal, he knew that wooden bridges that crossed the original canal had a short-life. He also knew that the new, wider canal would require longer span bridges and must be made of a modern material, iron.[1,3] His very first bowstring iron truss was patented in 1841. His patent showed an understanding of structural behavior of the diagonals and verticals and the need to size them to handle their loads as either tension or compression members. The engineer received his first chance to build a bridge across the canal at First Street in Utica fell. He tried to convince the Canal Commissioners that a bridge built of iron was a good long-term investment, but they were reluctant to trust a new material for their bridge. To illustrate the stability and strength of his bridge, Whipple had one built at his own expense on a vacant lot in Utica near the offices of the Canal commissioners. When the First Street Bridge fell, they approved the construction of his bridge.[1,2] At yovisto, you may be interested in a video of the Golden Gate Bridge Opening in 1937.'],\n",
       " [330,\n",
       "  'William Playfair and the Beginnings of Infographics.  Playfair’s trade-balance time-series chart, from The Commercial and Political Atlas and Statistical Breviary, 1786 On September 22, 1759, Scottish engineer and political economist William Playfair was born. He is generally considered the founder of graphical methods of statistics. William Playfair invented four types of diagrams: line graph, bar chart, pie chart, and circle graph. Playfair was born in 1759 in Scotland during the Enlightenment, a Golden Age in the arts, sciences, industry and commerce. He was the fourth son of the reverend James Playfair of the parish of Liff & Benvie near the city of Dundee in Scotland. His notable brothers were architect James Playfair and John Playfair, Professor of Mathematics and later Professor of Natural Philosophy at the University of Edinburgh. His father died in 1772 when William was 13, leaving the eldest brother John to care for the family and his education. His early taste for mechanics prompted his friends to place him as apprentice to a mill-wright Andrew Meikle, the inventor of the threshing machine. But, this is were William Playfair‘s multifaceted career should only start. He was in turn a millwright, engineer, draftsman, accountant, inventor, silversmith, merchant, investment broker, economist, statistician, pamphleteer, translator, publicist, land speculator, convict, banker, ardent royalist, editor, blackmailer and journalist. In 1780, he went to England, was engaged as draftsman and personal assistant of the inventor James Watt at the steam engine manufacturing works of Boulton & Watt in Birmingham in 1777, where he received a scientific and engineering training. Among the most useful of his mechanical efforts, was the unrequited discovery of the French telegraph, gathered from a few partial hints, and afterwards adapted by an alphabet of his own invention to British use. [1] On leaving Watt‘s company in 1782, he set up a silversmithing business and shop in London, which failed. In 1787 he moved to Paris, taking part in the storming of the Bastille two years later. He returned to London in 1793, where he opened a “security bank“, which also failed. From 1775 he worked as a writer and pamphleteer and did some engineering work. Playfair‘s main achievement lies primarily in his innovations in the presentation of quantitative information by means of graphs and charts. But, he was not the first to come up with the idea. Already in 1765, Joseph Priestley had created the innovation of the first timeline charts, in which individual bars were used to visualize the life span of a person to compare the life spans of multiple persons. These timelines directly inspired Wiliam Playfair‘s invention of the bar chart, which first appeared in his Commercial and Political Atlas, published in 1786. Actually, Playfair was driven to this invention by a lack of data. He had collected data about the import and export from different countries over the years, which he presented as line graphs. Because he lacked the necessary series data for Scotland, he graphed its trade data for a single year (1781) as a series of bars, one for each of Scotland‘s trading partners.[4] Playfair‘s Pie Charts from The Commercial and Political Atlas and Statistical Breviary, 1786 Playfair, who argued that charts communicated better than tables of data, has been credited with inventing the line, bar, and pie charts. His time-series plots are still presented as models of clarity. Playfair first published The Commercial and Political Atlas in London in 1786. It contained 43 time-series plots and one bar chart, a form apparently introduced in this work. It has been described as the first major work to contain statistical graphs. Playfair‘s Statistical Breviary, published in London in 1801, contains what is generally credited as the first pie chart. He was the first to use hachure, shading, and color, thus incorporating elements of classification into the quantitative depiction. The quality and detail of his work was such that in the two centuries since there has been no appreciable improvement of his basic designs. [5] After the Bourbon restoration in France, William Playfair returned to Paris, where he edited a journal called Galignani’s Messenger. He had to flee the country a second time when prosecuted for libel, and thereafter spent his time writing in London, where he died at the age of 64.[3] Playfair has invented a universal language useful to science and commerce alike and though his contemporaries failed to grasp the significance, he had no doubt that he had forever changed the way we would look at data. However, it took almost a century after his death before his invention was fully accepted. [5] At yovisto you can learn more about the visualization of statistical data in the famous TED-talk of Prof. Hans Rosling on ‘Let my dataset change your mindset‘.'],\n",
       " [331,\n",
       "  'Juan Bautista de Anza and the Route to San Francisco Bay.  Juan Bautista de Anza, from a portrait in oil by Fray Orsi in 1774.  On March 28, 1776, Basque New-Spanish explorer Juan Bautista de Anza was the first to reach the San Francisco Bay by land. De Anza was the first European to establish an overland route from Mexico, through the Sonoran Desert, to the Pacific coast of California. New World Spanish explorers had been seeking such a route through the desert southwest for more than two centuries. Juan Bautista de Anza was born in Sonora, New Spain in 1736. De Anza enlisted in the army at the Presidio of Fronteras in 1752 and became a captain in 1760. De Anza proposed an expedition to Alta California in the early 1770s. The region had been colonized in the late 1760s and the colonies had been established at San Diego and Monterey. Still, a direct land route was desired and De Anza’s mission was apporoved by the King of Spain and on January 8, 1774. The expedition including 20 soldiers, and 140 horses was guided by a Native American. Together they took a southern route along the Rio Altar, then paralleled the modern Mexico California border. The expedition crossed the Colorado River at its confluence with the Gila River. The expedition was observed by Viceroy and King and they decided that De Anza should lead a group of colonists to Alta California. The expedition arrived at Mission San Gabriel Arcángel in January, 1776 and continued to Monterey with the colonists. De Anza and 247 colonists arrived at the future site of San Francisco on this day in 1776. De Anza established a presidio, or military fort, on the tip of the San Francisco peninsula. Six months later, a Spanish Franciscan priest founded a mission near the presidio that he named in honor of St. Francis of Assisi – in Spanish, San Francisco de Asiacutes. However, San Francisco remained an isolated settlement for many years after Anza founded the first settlement. It is believed that in the 1830s, the potential of the area was eventually realized. Back then, San Francisco was only a rather small town of 900 people, but after gold had been discovered, more and more settlers came to the city and by the 1850s, it is believed that more than 36.000 people lived there. Juan Bautista de Anza himself was appointed governor of New Mexico in 1777. He negotiated a critical peace treaty with Commanche Indians, who agreed to join the Spanish in making war on the Apache. He retired in 1786 and passed away two years later. At yovisto you may learn more about Native Americans in a lecture at Berkeley University.']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import unicodedata\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# Ruta que se debe cambiar segun la ubicacion del archivo, al descomprimir el zip no deberia afectar\n",
    "#  '../data/docs-raw-texts/wes2015.d001.naf'\n",
    "\n",
    "documents_path = '../data/docs-raw-texts'\n",
    "\n",
    "def load_documents(documents_folder_path):\n",
    "    dataframe = []\n",
    "    doc_id = 1\n",
    "    for filename in os.listdir(documents_folder_path):\n",
    "        text = pd.read_xml(os.path.join(documents_folder_path, filename))['raw'].tolist()[1]\n",
    "        filtered_text = text.replace('\\n', ' ').replace('\\xa0', ' ')\n",
    "        row = [doc_id, filtered_text]\n",
    "        dataframe.append(row)\n",
    "        doc_id += 1\n",
    "        #NFKC\n",
    "    return dataframe\n",
    "\n",
    "data = load_documents(documents_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.stem.PorterStemmer  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
